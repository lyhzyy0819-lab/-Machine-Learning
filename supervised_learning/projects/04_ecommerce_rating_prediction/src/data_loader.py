"""
æ•°æ®åŠ è½½æ¨¡å—
è´Ÿè´£ä»CSVæ–‡ä»¶åŠ è½½Amazoné”€å”®æ•°æ®
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, Tuple
import logging

import sys
sys.path.append(str(Path(__file__).parent.parent))
import config
from src.utils import Timer, print_dataframe_info, reduce_mem_usage


def download_data_instructions() -> None:
    """
    æ‰“å°ä¸‹è½½æ•°æ®çš„è¯´æ˜

    TODO: æ‰“å°ä¸‹è½½æŒ‡å—
    æç¤ºç”¨æˆ·å¦‚ä½•ä»Kaggleä¸‹è½½æ•°æ®é›†
    æ•°æ®é›†: karkavelrajaj/amazon-sales-dataset
    ä¸‹è½½åæ”¾ç½®åœ¨: config.RAW_DATA_DIR / 'amazon.csv'
    """
    print("=" * 60)
    print("ğŸ“¥ æ•°æ®ä¸‹è½½è¯´æ˜")
    print("=" * 60)
    print(f"1. è®¿é—®Kaggleæ•°æ®é›†: {config.KAGGLE_DATASET}")
    print("2. ä¸‹è½½ 'amazon.csv' æ–‡ä»¶")
    print(f"3. å°†æ–‡ä»¶æ”¾ç½®åˆ°: {config.RAW_DATA_FILE}")
    print("=" * 60)


def load_data_from_csv(filepath: Path,
                       nrows: Optional[int] = None,
                       optimize_memory: bool = True) -> pd.DataFrame:
    """
    ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®

    Args:
        filepath: CSVæ–‡ä»¶è·¯å¾„
        nrows: è¯»å–çš„è¡Œæ•°ï¼ˆNoneè¡¨ç¤ºè¯»å–å…¨éƒ¨ï¼‰
        optimize_memory: æ˜¯å¦ä¼˜åŒ–å†…å­˜ä½¿ç”¨

    Returns:
        åŠ è½½çš„DataFrame

    TODO 1: æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    # logger = logging.getLogger("Ecommerce_Rating")
    # if not filepath.exists():
    #     logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    #     download_data_instructions()
    #     raise FileNotFoundError(f"è¯·å…ˆä¸‹è½½æ•°æ®æ–‡ä»¶åˆ°: {filepath}")

    TODO 2: ä½¿ç”¨Timerè®¡æ—¶ï¼Œè¯»å–CSVæ–‡ä»¶
    # with Timer(f"åŠ è½½æ•°æ®: {filepath.name}"):
    #     df = pd.read_csv(filepath, nrows=nrows)
    #     logger.info(f"æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—")

    TODO 3: å¦‚æœéœ€è¦ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨
    #     if optimize_memory:
    #         df = reduce_mem_usage(df, verbose=True)

    TODO 4: è¿”å›DataFrame
    # return df
    """
    # TODO: å®ç°CSVæ•°æ®åŠ è½½
    pass


def load_raw_data(use_sample: bool = False,
                  sample_size: int = 500) -> pd.DataFrame:
    """
    åŠ è½½åŸå§‹æ•°æ®

    Args:
        use_sample: æ˜¯å¦ä½¿ç”¨æ ·æœ¬æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
        sample_size: æ ·æœ¬å¤§å°

    Returns:
        åŸå§‹æ•°æ®DataFrame

    TODO 1: æ‰“å°åŠ è½½ä¿¡æ¯
    # logger = logging.getLogger("Ecommerce_Rating")
    # logger.info("=" * 60)
    # logger.info("åŠ è½½Amazoné”€å”®æ•°æ®")
    # logger.info("=" * 60)

    TODO 2: æ ¹æ®use_sampleå†³å®šè¯»å–è¡Œæ•°
    # nrows = sample_size if use_sample else None

    TODO 3: è°ƒç”¨load_data_from_csvåŠ è½½æ•°æ®
    # df = load_data_from_csv(
    #     config.RAW_DATA_FILE,
    #     nrows=nrows,
    #     optimize_memory=True
    # )

    TODO 4: æ‰“å°æ•°æ®ä¿¡æ¯å¹¶è¿”å›
    # print_dataframe_info(df, "åŸå§‹æ•°æ®")
    # return df
    """
    # TODO: å®ç°åŸå§‹æ•°æ®åŠ è½½
    pass


def validate_data(df: pd.DataFrame) -> Tuple[bool, list]:
    """
    éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œåˆç†æ€§

    Args:
        df: è¾“å…¥DataFrame

    Returns:
        (æ˜¯å¦é€šè¿‡éªŒè¯, é—®é¢˜åˆ—è¡¨)

    TODO 1: åˆå§‹åŒ–é—®é¢˜åˆ—è¡¨
    # logger = logging.getLogger("Ecommerce_Rating")
    # issues = []

    TODO 2: æ£€æŸ¥å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
    # required_columns = ['rating', 'discounted_price', 'category']
    # for col in required_columns:
    #     if col not in df.columns:
    #         issues.append(f"ç¼ºå°‘å¿…éœ€åˆ—: {col}")

    TODO 3: æ£€æŸ¥è¯„åˆ†èŒƒå›´ï¼ˆåº”è¯¥åœ¨1.0-5.0ä¹‹é—´ï¼‰
    # if 'rating' in df.columns:
    #     invalid_rating = ((df['rating'] < 1.0) | (df['rating'] > 5.0)).sum()
    #     if invalid_rating > 0:
    #         issues.append(f"{invalid_rating} ä¸ªè¯„åˆ†è¶…å‡ºèŒƒå›´ [1.0, 5.0]")

    TODO 4: æ£€æŸ¥ä»·æ ¼åˆ—ï¼ˆåº”è¯¥å¤§äº0ï¼‰
    # if 'discounted_price' in df.columns:
    #     invalid_price = (df['discounted_price'] <= 0).sum()
    #     if invalid_price > 0:
    #         issues.append(f"{invalid_price} ä¸ªä»·æ ¼å°äºç­‰äº0")

    TODO 5: æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹
    # missing = df.isnull().sum()
    # high_missing_cols = missing[missing / len(df) > 0.5]
    # if len(high_missing_cols) > 0:
    #     issues.append(f"ä»¥ä¸‹åˆ—ç¼ºå¤±å€¼è¶…è¿‡50%: {list(high_missing_cols.index)}")

    TODO 6: è¿”å›éªŒè¯ç»“æœ
    # is_valid = len(issues) == 0
    # if is_valid:
    #     logger.info("âœ“ æ•°æ®éªŒè¯é€šè¿‡")
    # else:
    #     logger.warning(f"âœ— å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
    #     for issue in issues:
    #         logger.warning(f"  - {issue}")
    # return is_valid, issues
    """
    # TODO: å®ç°æ•°æ®éªŒè¯
    pass


def get_data_summary(df: pd.DataFrame) -> dict:
    """
    è·å–æ•°æ®æ‘˜è¦ç»Ÿè®¡

    Args:
        df: è¾“å…¥DataFrame

    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸

    TODO 1: åˆ›å»ºåŸºç¡€æ‘˜è¦ä¿¡æ¯
    # summary = {
    #     'shape': df.shape,
    #     'columns': df.columns.tolist(),
    #     'dtypes': df.dtypes.astype(str).to_dict(),
    #     'missing_values': df.isnull().sum().to_dict(),
    #     'memory_usage_mb': df.memory_usage(deep=True).sum() / 1024**2,
    # }

    TODO 2: æ·»åŠ æ•°å€¼åˆ—ç»Ÿè®¡
    # numeric_cols = df.select_dtypes(include=[np.number]).columns
    # if len(numeric_cols) > 0:
    #     summary['numeric_stats'] = df[numeric_cols].describe().to_dict()

    TODO 3: æ·»åŠ åˆ†ç±»åˆ—ç»Ÿè®¡ï¼ˆæ¯ä¸ªåˆ†ç±»åˆ—çš„å”¯ä¸€å€¼æ•°é‡ï¼‰
    # categorical_cols = df.select_dtypes(include=['object']).columns
    # if len(categorical_cols) > 0:
    #     summary['categorical_stats'] = {
    #         col: {
    #             'unique_count': df[col].nunique(),
    #             'top_5_values': df[col].value_counts().head(5).to_dict()
    #         }
    #         for col in categorical_cols
    #     }

    TODO 4: è¿”å›æ‘˜è¦å­—å…¸
    # return summary
    """
    # TODO: å®ç°æ•°æ®æ‘˜è¦
    pass


def parse_price(price_str: str) -> float:
    """
    è§£æä»·æ ¼å­—ç¬¦ä¸²ï¼ˆå¯èƒ½åŒ…å«è´§å¸ç¬¦å·å’Œé€—å·ï¼‰

    Args:
        price_str: ä»·æ ¼å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼š"â‚¹1,299", "$99.99"ï¼‰

    Returns:
        æµ®ç‚¹æ•°ä»·æ ¼

    TODO 1: å¤„ç†ç©ºå€¼
    # if pd.isna(price_str) or price_str == '':
    #     return np.nan

    TODO 2: ç§»é™¤è´§å¸ç¬¦å·å’Œé€—å·ï¼Œè½¬æ¢ä¸ºæµ®ç‚¹æ•°
    # try:
    #     # ç§»é™¤è´§å¸ç¬¦å·ï¼ˆâ‚¹, $ç­‰ï¼‰å’Œé€—å·
    #     clean_str = ''.join(c for c in str(price_str) if c.isdigit() or c == '.')
    #     return float(clean_str) if clean_str else np.nan
    # except:
    #     return np.nan
    """
    # TODO: å®ç°ä»·æ ¼è§£æ
    pass


def preprocess_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    é¢„å¤„ç†åˆ—åå’Œæ•°æ®ç±»å‹

    Args:
        df: è¾“å…¥DataFrame

    Returns:
        é¢„å¤„ç†åçš„DataFrame

    TODO 1: å¤åˆ¶DataFrame
    # df_clean = df.copy()
    # logger = logging.getLogger("Ecommerce_Rating")
    # logger.info("é¢„å¤„ç†åˆ—åå’Œæ•°æ®ç±»å‹...")

    TODO 2: æ ‡å‡†åŒ–åˆ—åï¼ˆè½¬å°å†™ï¼Œæ›¿æ¢ç©ºæ ¼ä¸ºä¸‹åˆ’çº¿ï¼‰
    # df_clean.columns = df_clean.columns.str.lower().str.replace(' ', '_')
    # logger.info("  åˆ—åå·²æ ‡å‡†åŒ–")

    TODO 3: è§£æä»·æ ¼åˆ—ï¼ˆå¦‚æœå­˜åœ¨ç‰¹æ®Šæ ¼å¼ï¼‰
    # if 'discounted_price' in df_clean.columns:
    #     df_clean['discounted_price'] = df_clean['discounted_price'].apply(parse_price)
    # if 'actual_price' in df_clean.columns:
    #     df_clean['actual_price'] = df_clean['actual_price'].apply(parse_price)

    TODO 4: è½¬æ¢è¯„åˆ†ä¸ºæµ®ç‚¹æ•°
    # if 'rating' in df_clean.columns:
    #     df_clean['rating'] = pd.to_numeric(df_clean['rating'], errors='coerce')

    TODO 5: è½¬æ¢è¯„åˆ†æ•°é‡ä¸ºæ•´æ•°
    # if 'rating_count' in df_clean.columns:
    #     df_clean['rating_count'] = pd.to_numeric(df_clean['rating_count'], errors='coerce').astype('Int64')

    TODO 6: è¿”å›æ¸…æ´—åçš„DataFrame
    # logger.info("  æ•°æ®ç±»å‹è½¬æ¢å®Œæˆ")
    # return df_clean
    """
    # TODO: å®ç°åˆ—é¢„å¤„ç†
    pass


if __name__ == '__main__':
    # æµ‹è¯•æ•°æ®åŠ è½½
    from src.utils import setup_logger

    # TODO: è®¾ç½®æ—¥å¿—
    # logger = setup_logger("Ecommerce_Rating", config.LOG_DIR / "data_loader_test.log", "INFO")

    print("=" * 60)
    print("æ•°æ®åŠ è½½æ¨¡å—æµ‹è¯•")
    print("=" * 60)

    # TODO 1: å°è¯•åŠ è½½æ•°æ®ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ‰“å°ä¸‹è½½è¯´æ˜ï¼‰
    # try:
    #     df = load_raw_data(use_sample=True, sample_size=100)
    #     print(f"\nåŠ è½½æ•°æ®å½¢çŠ¶: {df.shape}")
    #     print(f"\nå‰5è¡Œæ•°æ®:\n{df.head()}")

    # TODO 2: éªŒè¯æ•°æ®
    #     is_valid, issues = validate_data(df)

    # TODO 3: è·å–æ•°æ®æ‘˜è¦
    #     summary = get_data_summary(df)
    #     print(f"\næ•°æ®ç»´åº¦: {summary['shape']}")
    #     print(f"å†…å­˜ä½¿ç”¨: {summary['memory_usage_mb']:.2f} MB")

    # except FileNotFoundError:
    #     print("\nè¯·å…ˆä¸‹è½½æ•°æ®æ–‡ä»¶ï¼")

    print("\næç¤ºï¼šå®ç°ä¸Šè¿°TODOåè¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæµ‹è¯•")
