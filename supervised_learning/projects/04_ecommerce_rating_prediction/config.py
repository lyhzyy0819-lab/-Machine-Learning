"""
ç”µå•†è¯„åˆ†é¢„æµ‹é¡¹ç›®é…ç½®æ–‡ä»¶
åŒ…å«æ‰€æœ‰è·¯å¾„ã€å‚æ•°å’Œæ¨¡å‹é…ç½®
"""

from pathlib import Path
from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.svm import SVC
try:
    from xgboost import XGBRegressor, XGBClassifier
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False
    print("âš ï¸  XGBoost not installed. Install with: pip install xgboost")


# ==================== è·¯å¾„é…ç½® ====================

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / 'data'
RAW_DATA_DIR = DATA_DIR / 'raw'
PROCESSED_DATA_DIR = DATA_DIR / 'processed'
MODEL_DIR = PROJECT_ROOT / 'models'
FIGURE_DIR = PROJECT_ROOT / 'figures'
LOG_DIR = PROJECT_ROOT / 'logs'

# æ•°æ®æ–‡ä»¶
RAW_DATA_FILE = RAW_DATA_DIR / 'amazon.csv'  # ä¸‹è½½åçš„æ•°æ®æ–‡ä»¶
PROCESSED_DATA_FILE = PROCESSED_DATA_DIR / 'processed_data.csv'

# æ¨¡å‹æ–‡ä»¶
REGRESSION_MODEL_FILE = MODEL_DIR / 'rating_regression_model.pkl'
CLASSIFICATION_MODEL_FILE = MODEL_DIR / 'rating_classification_model.pkl'
SCALER_FILE = MODEL_DIR / 'scaler.pkl'
TFIDF_FILE = MODEL_DIR / 'tfidf_vectorizer.pkl'
METADATA_FILE = MODEL_DIR / 'metadata.json'


# ==================== æ•°æ®é…ç½® ====================

# Kaggleæ•°æ®é›†ä¿¡æ¯
KAGGLE_DATASET = 'karkavelrajaj/amazon-sales-dataset'
EXPECTED_COLUMNS = [
    'product_id', 'product_name', 'category',
    'discounted_price', 'actual_price', 'discount_percentage',
    'rating', 'rating_count', 'about_product',
    'user_id', 'user_name', 'review_id',
    'review_title', 'review_content', 'img_link', 'product_link'
]

# ç›®æ ‡å˜é‡
TARGET_REGRESSION = 'rating'  # å›å½’ç›®æ ‡ï¼šé¢„æµ‹è¯„åˆ† (1.0-5.0)
TARGET_CLASSIFICATION = 'high_rating'  # åˆ†ç±»ç›®æ ‡ï¼šé¢„æµ‹é«˜/ä½è¯„åˆ† (>= 4.0)

# é«˜è¯„åˆ†é˜ˆå€¼
HIGH_RATING_THRESHOLD = 4.0


# ==================== ç‰¹å¾å·¥ç¨‹é…ç½® ====================

# æ–‡æœ¬ç‰¹å¾
TFIDF_MAX_FEATURES = 100  # TF-IDFæå–çš„æœ€å¤§ç‰¹å¾æ•°
TFIDF_MIN_DF = 2  # æœ€å°æ–‡æ¡£é¢‘ç‡
TFIDF_MAX_DF = 0.8  # æœ€å¤§æ–‡æ¡£é¢‘ç‡
TEXT_COLUMNS = ['review_content', 'review_title', 'about_product']

# ä»·æ ¼åˆ†æ¡¶
PRICE_BINS = [0, 500, 1000, 2000, 5000, 100000]
PRICE_LABELS = ['very_low', 'low', 'medium', 'high', 'very_high']

# æŠ˜æ‰£åŠ›åº¦åˆ†æ¡¶
DISCOUNT_BINS = [0, 20, 40, 60, 100]
DISCOUNT_LABELS = ['low', 'medium', 'high', 'very_high']

# ç±»åˆ«ç¼–ç 
CATEGORY_ENCODING = 'onehot'  # 'onehot' or 'label'


# ==================== æ¨¡å‹è®­ç»ƒé…ç½® ====================

# é€šç”¨å‚æ•°
RANDOM_STATE = 42
TEST_SIZE = 0.2
CV_FOLDS = 5

# å›å½’æ¨¡å‹é…ç½®
REGRESSION_MODELS = {
    'linear': {
        'model': LinearRegression(),
        'description': 'çº¿æ€§å›å½’ï¼ˆBaselineï¼‰'
    },
    'ridge': {
        'model': Ridge(alpha=1.0, random_state=RANDOM_STATE),
        'description': 'Ridgeå›å½’ï¼ˆL2æ­£åˆ™åŒ–ï¼‰',
        'param_grid': {
            'alpha': [0.1, 1.0, 10.0, 100.0]
        }
    },
    'lasso': {
        'model': Lasso(alpha=1.0, random_state=RANDOM_STATE, max_iter=10000),
        'description': 'Lassoå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰',
        'param_grid': {
            'alpha': [0.01, 0.1, 1.0, 10.0]
        }
    },
    'random_forest': {
        'model': RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),
        'description': 'éšæœºæ£®æ—å›å½’',
        'param_grid': {
            'n_estimators': [50, 100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5]
        }
    }
}

# å¦‚æœå®‰è£…äº†XGBoostï¼Œæ·»åŠ XGBoostæ¨¡å‹
if HAS_XGBOOST:
    REGRESSION_MODELS['xgboost'] = {
        'model': XGBRegressor(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),
        'description': 'XGBoostå›å½’',
        'param_grid': {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    }

# åˆ†ç±»æ¨¡å‹é…ç½®
CLASSIFICATION_MODELS = {
    'logistic': {
        'model': LogisticRegression(random_state=RANDOM_STATE, max_iter=1000),
        'description': 'é€»è¾‘å›å½’ï¼ˆBaselineï¼‰',
        'param_grid': {
            'C': [0.1, 1.0, 10.0],
            'penalty': ['l2']
        }
    },
    'svm': {
        'model': SVC(random_state=RANDOM_STATE, probability=True),
        'description': 'æ”¯æŒå‘é‡æœºï¼ˆSVMï¼‰',
        'param_grid': {
            'C': [0.1, 1.0, 10.0],
            'kernel': ['rbf', 'linear']
        }
    },
    'random_forest': {
        'model': RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1),
        'description': 'éšæœºæ£®æ—åˆ†ç±»',
        'param_grid': {
            'n_estimators': [50, 100, 200],
            'max_depth': [10, 20, None],
            'min_samples_split': [2, 5]
        }
    }
}

# å¦‚æœå®‰è£…äº†XGBoostï¼Œæ·»åŠ XGBooståˆ†ç±»æ¨¡å‹
if HAS_XGBOOST:
    CLASSIFICATION_MODELS['xgboost'] = {
        'model': XGBClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1, eval_metric='logloss'),
        'description': 'XGBooståˆ†ç±»',
        'param_grid': {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    }


# ==================== è¯„ä¼°æŒ‡æ ‡é…ç½® ====================

# å›å½’è¯„ä¼°æŒ‡æ ‡
REGRESSION_METRICS = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']

# åˆ†ç±»è¯„ä¼°æŒ‡æ ‡
CLASSIFICATION_METRICS = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']


# ==================== å¯è§†åŒ–é…ç½® ====================

# å›¾è¡¨æ ·å¼
FIGURE_SIZE = (10, 6)
FIGURE_DPI = 100
PLOT_STYLE = 'seaborn-v0_8-darkgrid'

# é¢œè‰²é…ç½®
COLOR_PALETTE = 'Set2'
PRIMARY_COLOR = '#1f77b4'
SECONDARY_COLOR = '#ff7f0e'


# ==================== æ—¥å¿—é…ç½® ====================

# æ—¥å¿—çº§åˆ«
LOG_LEVEL = 'INFO'  # 'DEBUG', 'INFO', 'WARNING', 'ERROR'

# æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'


# ==================== è¿è¡Œæ¨¡å¼é…ç½® ====================

# æ˜¯å¦ä½¿ç”¨æ ·æœ¬æ•°æ®ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
USE_SAMPLE = False
SAMPLE_SIZE = 500

# æ˜¯å¦è·³è¿‡è€—æ—¶çš„æ¨¡å‹ï¼ˆå¦‚XGBoostï¼‰
QUICK_MODE = False

# æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
GENERATE_PLOTS = True

# æ˜¯å¦è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜
TUNE_HYPERPARAMETERS = False


# ==================== è¾…åŠ©å‡½æ•° ====================

def create_directories():
    """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•"""
    for directory in [RAW_DATA_DIR, PROCESSED_DATA_DIR, MODEL_DIR, FIGURE_DIR, LOG_DIR]:
        directory.mkdir(parents=True, exist_ok=True)


def get_model_config(task='regression'):
    """
    è·å–æ¨¡å‹é…ç½®

    Args:
        task: 'regression' or 'classification'

    Returns:
        æ¨¡å‹é…ç½®å­—å…¸
    """
    if task == 'regression':
        return REGRESSION_MODELS
    elif task == 'classification':
        return CLASSIFICATION_MODELS
    else:
        raise ValueError(f"Unknown task: {task}. Must be 'regression' or 'classification'")


if __name__ == '__main__':
    # åˆ›å»ºç›®å½•
    create_directories()
    print("âœ… é…ç½®åŠ è½½æˆåŠŸ!")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {RAW_DATA_FILE}")
    print(f"ğŸ¤– æ¨¡å‹ä¿å­˜ç›®å½•: {MODEL_DIR}")
    print(f"ğŸ“ˆ å¯ç”¨å›å½’æ¨¡å‹: {list(REGRESSION_MODELS.keys())}")
    print(f"ğŸ¯ å¯ç”¨åˆ†ç±»æ¨¡å‹: {list(CLASSIFICATION_MODELS.keys())}")
