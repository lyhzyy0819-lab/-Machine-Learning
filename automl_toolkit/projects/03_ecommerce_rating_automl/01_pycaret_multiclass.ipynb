{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç”µå•†è¯„åˆ†é¢„æµ‹ - PyCaretå¤šåˆ†ç±»å®ç°\n",
    "\n",
    "> ğŸ¯ å°†è¯„åˆ†1-5è§†ä¸º5ä¸ªç±»åˆ«ï¼Œä½¿ç”¨åˆ†ç±»æ–¹æ³•é¢„æµ‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¯å¢ƒå‡†å¤‡\n",
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨åŸé¡¹ç›®æ•°æ®ï¼‰\n",
    "data_path = \"../../../supervised_learning/projects/04_ecommerce_rating_prediction/data/Womens_Clothing_E-Commerce_Reviews.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é¢„å¤„ç†\n",
    "# 1. åˆ é™¤æ— ç”¨åˆ—\n",
    "data = data.drop(['Unnamed: 0', 'Title', 'Review Text', 'Positive Feedback Count'], axis=1, errors='ignore')\n",
    "\n",
    "# 2. å¤„ç†ç¼ºå¤±å€¼\n",
    "data = data.dropna(subset=['Rating'])\n",
    "\n",
    "# 3. å°†Ratingè½¬ä¸ºå­—ç¬¦ä¸²ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰\n",
    "data['Rating'] = data['Rating'].astype(int).astype(str)\n",
    "\n",
    "# 4. æŸ¥çœ‹è¯„åˆ†åˆ†å¸ƒ\n",
    "print(\"\\nè¯„åˆ†åˆ†å¸ƒ:\")\n",
    "print(data['Rating'].value_counts().sort_index())\n",
    "\n",
    "print(f\"\\næ¸…æ´—åæ•°æ®å½¢çŠ¶: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaretåˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–å¤šåˆ†ç±»ç¯å¢ƒ\n",
    "clf = setup(\n",
    "    data=data,\n",
    "    target='Rating',\n",
    "    session_id=42,\n",
    "    \n",
    "    # æ•°æ®é¢„å¤„ç†\n",
    "    normalize=True,\n",
    "    fix_imbalance=True,          # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆé‡è¦ï¼ï¼‰\n",
    "    \n",
    "    # ç‰¹å¾å·¥ç¨‹\n",
    "    feature_selection=True,\n",
    "    \n",
    "    # è¯„ä¼°è®¾ç½®\n",
    "    fold=5,                      # 5æŠ˜äº¤å‰éªŒè¯\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”æ¨¡å‹ï¼ˆå¤šåˆ†ç±»ï¼‰\n",
    "best_model = compare_models(\n",
    "    sort='Accuracy',\n",
    "    n_select=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è°ƒä¼˜\n",
    "tuned_model = tune_model(\n",
    "    best_model,\n",
    "    optimize='Accuracy',\n",
    "    n_iter=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ··æ·†çŸ©é˜µ\n",
    "plot_model(tuned_model, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç±»åˆ«æŠ¥å‘Š\n",
    "plot_model(tuned_model, plot='class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‰¹å¾é‡è¦æ€§\n",
    "plot_model(tuned_model, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•é›†é¢„æµ‹\n",
    "predictions = predict_model(tuned_model)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
    "\n",
    "y_test = predictions['Rating'].astype(int)\n",
    "y_pred = predictions['prediction_label'].astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "### å¤šåˆ†ç±»æ–¹æ³•ç‰¹ç‚¹\n",
    "\n",
    "**ä¼˜åŠ¿**:\n",
    "- âœ… ç›´æ¥é¢„æµ‹è¯„åˆ†ç±»åˆ«\n",
    "- âœ… å¯ä»¥ä½¿ç”¨åˆ†ç±»è¯„ä¼°æŒ‡æ ‡\n",
    "- âœ… AutoMLè‡ªåŠ¨å¤„ç†ç±»åˆ«ä¸å¹³è¡¡\n",
    "\n",
    "**åŠ£åŠ¿**:\n",
    "- âŒ å¿½ç•¥è¯„åˆ†é¡ºåºï¼ˆ3æ˜Ÿ>1æ˜Ÿï¼‰\n",
    "- âŒ é¢„æµ‹é”™è¯¯ä»£ä»·ä¸ä¸€è‡´\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**: æŸ¥çœ‹ `02_pycaret_regression.ipynb` å¯¹æ¯”å›å½’æ–¹æ³•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
