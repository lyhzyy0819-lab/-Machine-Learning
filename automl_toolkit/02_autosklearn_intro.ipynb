{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Auto-sklearn ä½¿ç”¨æŒ‡å—\n",
    "\n",
    "> ğŸ¯ å­¦ä¹ ç›®æ ‡ï¼šç†è§£è´å¶æ–¯ä¼˜åŒ–å’Œå…ƒå­¦ä¹ ï¼ŒæŒæ¡ Auto-sklearn çš„é«˜çº§ç‰¹æ€§\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å†…å®¹\n",
    "\n",
    "1. Auto-sklearn åŸç†ç®€ä»‹\n",
    "2. åŸºç¡€ä½¿ç”¨æ–¹æ³•\n",
    "3. è´å¶æ–¯ä¼˜åŒ–æ·±å…¥\n",
    "4. å…ƒå­¦ä¹ (Meta-learning)\n",
    "5. è‡ªåŠ¨é›†æˆå­¦ä¹ \n",
    "6. ä¸ sklearn ç”Ÿæ€é›†æˆ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Auto-sklearn æ ¸å¿ƒåŸç†\n",
    "\n",
    "### ä¸‰å¤§æ ¸å¿ƒç»„ä»¶\n",
    "\n",
    "1. **è´å¶æ–¯ä¼˜åŒ–** (Bayesian Optimization)\n",
    "   - æ™ºèƒ½æœç´¢è¶…å‚æ•°ç©ºé—´\n",
    "   - æ¯”éšæœºæœç´¢/ç½‘æ ¼æœç´¢æ›´é«˜æ•ˆ\n",
    "\n",
    "2. **å…ƒå­¦ä¹ ** (Meta-learning)\n",
    "   - ä»å†å²æ•°æ®é›†å­¦ä¹ ç»éªŒ\n",
    "   - å¿«é€Ÿæ‰¾åˆ°å¥½çš„èµ·å§‹ç‚¹\n",
    "\n",
    "3. **è‡ªåŠ¨é›†æˆ** (Ensemble)\n",
    "   - è‡ªåŠ¨æ„å»ºæ¨¡å‹é›†æˆ\n",
    "   - æå‡æœ€ç»ˆæ€§èƒ½\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. å¹³å°å…¼å®¹æ€§è¯´æ˜ä¸å®‰è£…\n\n### âš ï¸ é‡è¦æç¤ºï¼šå¹³å°å…¼å®¹æ€§\n\n**Auto-sklearn å¹³å°æ”¯æŒæƒ…å†µï¼š**\n\n| æ“ä½œç³»ç»Ÿ | æ”¯æŒçŠ¶æ€ | è¯´æ˜ |\n|---------|---------|------|\n| ğŸ§ Linux | âœ… å®Œå…¨æ”¯æŒ | å®˜æ–¹æ¨èå¹³å° |\n| ğŸªŸ Windows | âš ï¸ éƒ¨åˆ†æ”¯æŒ | éœ€è¦ WSL2 æˆ– Docker |\n| ğŸ macOS | âŒ ä¸æ”¯æŒ | ä¾èµ–é¡¹ä¸å…¼å®¹ |\n\n**æœ¬æ•™ç¨‹çš„è§£å†³æ–¹æ¡ˆï¼š**\n- **ç†è®ºéƒ¨åˆ†**ï¼šè®²è§£ Auto-sklearn çš„æ ¸å¿ƒåŸç†ï¼ˆé€‚ç”¨æ‰€æœ‰å¹³å°ï¼‰\n- **å®è·µéƒ¨åˆ†**ï¼šæä¾›è·¨å¹³å°çš„ AutoML æ›¿ä»£æ–¹æ¡ˆ\n  - **PyCaret**ï¼šåŠŸèƒ½å¼ºå¤§ï¼Œæ”¯æŒæ‰€æœ‰å¹³å°\n  - **TPOT**ï¼šåŸºäºé—ä¼ ç®—æ³•ï¼Œè½»é‡çº§\n  - **Optuna + sklearn**ï¼šçµæ´»çš„è¶…å‚æ•°ä¼˜åŒ–\n\n---\n\n### 1.1 å®‰è£…æŒ‡å—\n\n#### macOS ç”¨æˆ·ï¼ˆæ¨èï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# å®‰è£… AutoML å·¥å…·ï¼ˆé¦–æ¬¡è¿è¡Œæ—¶æ‰§è¡Œï¼‰\n# ============================================================\n\n# macOS ç”¨æˆ·ï¼šä½¿ç”¨ PyCaretï¼ˆå·²é¢„è£…ï¼‰\n# !pip install pycaret\n\n# å…¶ä»–å¯é€‰å·¥å…·\n# !pip install tpot              # åŸºäºé—ä¼ ç®—æ³•çš„ AutoML\n# !pip install optuna            # è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶\n# !pip install flaml             # å¾®è½¯çš„è½»é‡çº§ AutoML\n\n# Linux ç”¨æˆ·ï¼ˆå¯é€‰å®‰è£… auto-sklearnï¼‰\n# !pip install auto-sklearn\n\n# ============================================================\n# å¯¼å…¥åŸºç¡€åº“\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰\nplt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  # macOS\nplt.rcParams['axes.unicode_minus'] = False\n\nprint(\"âœ… åŸºç¡€åº“å¯¼å…¥æˆåŠŸ\")\nprint(f\"ğŸ“Š NumPy ç‰ˆæœ¬: {np.__version__}\")\nprint(f\"ğŸ“Š Pandas ç‰ˆæœ¬: {pd.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. åˆ†ç±»ä»»åŠ¡åŸºç¡€ä½¿ç”¨\n",
    "\n",
    "### 2.1 åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†å½¢çŠ¶: (1437, 64)\n",
      "æµ‹è¯•é›†å½¢çŠ¶: (360, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# åŠ è½½æ‰‹å†™æ•°å­—æ•°æ®é›†\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}\")\n",
    "print(f\"æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.2 Auto-sklearn åŸç†è®²è§£ï¼ˆç†è®ºï¼‰\n\n> ğŸ’¡ **æ³¨æ„**ï¼šè™½ç„¶ Auto-sklearn åœ¨ macOS ä¸Šæ— æ³•ç›´æ¥è¿è¡Œï¼Œä½†ç†è§£å…¶æ ¸å¿ƒåŸç†å¯¹å­¦ä¹  AutoML éå¸¸é‡è¦ã€‚\n> \n> ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†ä½¿ç”¨ **PyCaret** å®ç°ç›¸åŒåŠŸèƒ½ï¼ˆæ”¯æŒæ‰€æœ‰å¹³å°ï¼‰ã€‚\n\n#### Auto-sklearn çš„ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯\n\n**1. è´å¶æ–¯ä¼˜åŒ– (Bayesian Optimization)**\n\nä¼ ç»Ÿçš„è¶…å‚æ•°æœç´¢æ–¹æ³•ï¼š\n- âŒ **ç½‘æ ¼æœç´¢**ï¼šéå†æ‰€æœ‰ç»„åˆï¼Œæ•ˆç‡ä½\n- âŒ **éšæœºæœç´¢**ï¼šéšæœºé‡‡æ ·ï¼Œç¼ºä¹æ™ºèƒ½\n\nè´å¶æ–¯ä¼˜åŒ–çš„ä¼˜åŠ¿ï¼š\n- âœ… åˆ©ç”¨å†å²å®éªŒç»“æœæŒ‡å¯¼ä¸‹ä¸€æ­¥æœç´¢\n- âœ… å¹³è¡¡\"æ¢ç´¢\"(exploration)å’Œ\"åˆ©ç”¨\"(exploitation)\n- âœ… åœ¨æœ‰é™æ—¶é—´å†…æ‰¾åˆ°æ›´ä¼˜è§£\n\n**å·¥ä½œåŸç†ï¼š**\n```\nåˆå§‹åŒ– â†’ éšæœºå°è¯•å‡ ç»„å‚æ•°\n    â†“\nå»ºç«‹ä»£ç†æ¨¡å‹ï¼ˆSurrogate Modelï¼‰é¢„æµ‹å‚æ•°æ€§èƒ½\n    â†“\né€‰æ‹©æœ€æœ‰å¸Œæœ›çš„å‚æ•°ç»„åˆè¿›è¡Œå®éªŒ\n    â†“\næ›´æ–°ä»£ç†æ¨¡å‹ â†’ é‡å¤\n```\n\n**2. å…ƒå­¦ä¹  (Meta-learning)**\n\n- ä» 140+ ä¸ªå†å²æ•°æ®é›†ä¸­å­¦ä¹ ç»éªŒ\n- æ ¹æ®å½“å‰æ•°æ®é›†ç‰¹å¾ï¼Œæ¨èåˆé€‚çš„èµ·å§‹æ¨¡å‹\n- é¿å…ä»é›¶å¼€å§‹æœç´¢ï¼ŒåŠ é€Ÿæ”¶æ•›\n\n**3. è‡ªåŠ¨é›†æˆ (Ensemble)**\n\n- è‡ªåŠ¨æ„å»ºå¤šä¸ªæ¨¡å‹çš„é›†æˆ\n- ä½¿ç”¨ Ensemble Selection ç®—æ³•\n- æ¯”å•ä¸€æ¨¡å‹æ›´ç¨³å®šã€æ›´å‡†ç¡®\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "### 2.3 è·¨å¹³å°å®è·µï¼šä½¿ç”¨ PyCaretï¼ˆæ‰€æœ‰ç³»ç»Ÿå¯ç”¨ï¼‰\n\n# ============================================================\n# PyCaret æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ AutoML åº“ï¼Œæ”¯æŒï¼š\n# - âœ… Windows / macOS / Linux å…¨å¹³å°\n# - âœ… 30+ æœºå™¨å­¦ä¹ ç®—æ³•è‡ªåŠ¨å¯¹æ¯”\n# - âœ… è‡ªåŠ¨ç‰¹å¾å·¥ç¨‹ã€è¶…å‚æ•°è°ƒä¼˜\n# - âœ… å¯è§†åŒ–åˆ†æä¸°å¯Œ\n# ============================================================\n\nfrom pycaret.classification import *\n\n# 1. åˆå§‹åŒ– PyCaret ç¯å¢ƒ\n# ============================================================\n# setup() å‡½æ•°ä¼šè‡ªåŠ¨å®Œæˆï¼š\n#   - æ•°æ®é¢„å¤„ç†ï¼ˆç¼ºå¤±å€¼å¤„ç†ã€ç¼–ç ï¼‰\n#   - è®­ç»ƒé›†/æµ‹è¯•é›†åˆ’åˆ†\n#   - ç‰¹å¾ç¼©æ”¾\n#   - ç‰¹å¾å·¥ç¨‹ï¼ˆå¯é€‰ï¼‰\n# ============================================================\n\nprint(\"åˆå§‹åŒ– PyCaret ç¯å¢ƒ...\")\n\n# å°†æ•°æ®è½¬æ¢ä¸º DataFrameï¼ˆPyCaret è¦æ±‚ï¼‰\ndata = pd.DataFrame(X_train, columns=[f'pixel_{i}' for i in range(64)])\ndata['target'] = y_train\n\n# åˆ›å»º PyCaret å®éªŒç¯å¢ƒ\n# - data: è®­ç»ƒæ•°æ®\n# - target: ç›®æ ‡åˆ—å\n# - session_id: éšæœºç§å­ï¼ˆä¿è¯å¯å¤ç°ï¼‰\n# - verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯\nclf_setup = setup(\n    data=data, \n    target='target',\n    session_id=42,\n    verbose=False,  # é™é»˜æ¨¡å¼ï¼Œå‡å°‘è¾“å‡º\n    html=False      # ä¸ç”Ÿæˆ HTML æŠ¥å‘Š\n)\n\nprint(\"âœ… PyCaret ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.4 è‡ªåŠ¨å¯¹æ¯”æ‰€æœ‰æ¨¡å‹"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# compare_models() ä¼šè‡ªåŠ¨ï¼š\n# 1. è®­ç»ƒæ‰€æœ‰å¯ç”¨çš„åˆ†ç±»ç®—æ³•ï¼ˆ30+ ç§ï¼‰\n# 2. ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¯ä¸ªæ¨¡å‹\n# 3. æŒ‰å‡†ç¡®ç‡æ’åºï¼Œè¿”å›æœ€ä½³æ¨¡å‹\n# ============================================================\n\nprint(\"å¼€å§‹è‡ªåŠ¨å¯¹æ¯”æ‰€æœ‰æ¨¡å‹...\")\nprint(\"è¿™å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...\\n\")\n\n# å¯¹æ¯”æ‰€æœ‰æ¨¡å‹ï¼Œè¿”å›æ€§èƒ½æ’è¡Œæ¦œ\n# - fold: äº¤å‰éªŒè¯çš„æŠ˜æ•°ï¼ˆé»˜è®¤10æŠ˜ï¼‰\n# - sort: æ’åºæŒ‡æ ‡ï¼ˆAccuracyã€F1ã€AUCç­‰ï¼‰\n# - n_select: è¿”å›å‰ N ä¸ªæœ€ä½³æ¨¡å‹\nbest_models = compare_models(\n    fold=5,           # ä½¿ç”¨ 5 æŠ˜äº¤å‰éªŒè¯ï¼ˆèŠ‚çœæ—¶é—´ï¼‰\n    sort='Accuracy',  # æŒ‰å‡†ç¡®ç‡æ’åº\n    n_select=3        # è¿”å›å‰ 3 ä¸ªæœ€ä½³æ¨¡å‹\n)\n\nprint(\"\\nâœ… æ¨¡å‹å¯¹æ¯”å®Œæˆï¼\")\nprint(f\"ğŸ“Š æœ€ä½³æ¨¡å‹: {type(best_models[0]).__name__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.5 è¶…å‚æ•°è°ƒä¼˜"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# tune_model() ä¼šå¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜\n# ä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³•ï¼š\n#   - Random Grid Searchï¼ˆéšæœºç½‘æ ¼æœç´¢ï¼‰\n#   - æˆ– Bayesian Optimizationï¼ˆè´å¶æ–¯ä¼˜åŒ–ï¼‰\n# ============================================================\n\nprint(\"å¼€å§‹å¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜...\")\n\n# é€‰æ‹©ç¬¬ä¸€ä¸ªæœ€ä½³æ¨¡å‹è¿›è¡Œè°ƒä¼˜\nbest_model = best_models[0]\n\n# è¶…å‚æ•°è°ƒä¼˜\n# - optimize: ä¼˜åŒ–ç›®æ ‡ï¼ˆAccuracyã€F1ã€AUCç­‰ï¼‰\n# - n_iter: è¿­ä»£æ¬¡æ•°ï¼ˆè¶Šå¤§æ•ˆæœè¶Šå¥½ï¼Œä½†è€—æ—¶æ›´é•¿ï¼‰\n# - search_library: æœç´¢åº“ï¼ˆ'scikit-learn'ã€'optuna'ã€'tune-sklearn'ï¼‰\ntuned_model = tune_model(\n    best_model,\n    optimize='Accuracy',  # ä¼˜åŒ–å‡†ç¡®ç‡\n    n_iter=10,            # å°è¯• 10 ç»„è¶…å‚æ•°\n    choose_better=True    # åªæœ‰æ›´å¥½æ—¶æ‰æ›¿æ¢\n)\n\nprint(\"\\nâœ… è¶…å‚æ•°è°ƒä¼˜å®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.6 é¢„æµ‹ä¸è¯„ä¼°"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½\n# ============================================================\n\n# å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆéœ€è¦è½¬æ¢ä¸º DataFrameï¼‰\ntest_data = pd.DataFrame(X_test, columns=[f'pixel_{i}' for i in range(64)])\ntest_data['target'] = y_test\n\n# ä½¿ç”¨ predict_model() åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹\n# è¿™ä¸ªå‡½æ•°ä¼šï¼š\n#   1. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹\n#   2. è‡ªåŠ¨è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡\n#   3. è¿”å›åŒ…å«é¢„æµ‹ç»“æœçš„ DataFrame\npredictions = predict_model(tuned_model, data=test_data)\n\n# æå–é¢„æµ‹æ ‡ç­¾ï¼ˆPyCaret ä¼šåœ¨ 'prediction_label' åˆ—ï¼‰\ny_pred = predictions['prediction_label'].values\n\n# è®¡ç®—å‡†ç¡®ç‡\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"ğŸ“Š æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}\")\n\n# æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š\nprint(\"\\n\" + \"=\"*60)\nprint(\"è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:\")\nprint(\"=\"*60)\nprint(classification_report(y_test, y_pred, target_names=[f'Class {i}' for i in range(10)]))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2.7 æ¨¡å‹å¯è§†åŒ–åˆ†æ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# PyCaret æä¾›äº†ä¸°å¯Œçš„å¯è§†åŒ–åŠŸèƒ½\n# plot_model() å¯ä»¥ç»˜åˆ¶å¤šç§åˆ†æå›¾è¡¨\n# ============================================================\n\nprint(\"ç”Ÿæˆå¯è§†åŒ–åˆ†æ...\")\n\n# 1. æ··æ·†çŸ©é˜µï¼ˆConfusion Matrixï¼‰\n# æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æƒ…å†µ\nplot_model(tuned_model, plot='confusion_matrix', plot_kwargs={'percent': True})\nplt.title('æ··æ·†çŸ©é˜µï¼ˆç™¾åˆ†æ¯”ï¼‰')\nplt.tight_layout()\nplt.show()\n\n# 2. ç±»åˆ«é¢„æµ‹è¯¯å·®ï¼ˆClass Prediction Errorï¼‰\n# æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹åˆ†å¸ƒ\nplot_model(tuned_model, plot='class_report')\nplt.title('ç±»åˆ«é¢„æµ‹æŠ¥å‘Š')\nplt.tight_layout()\nplt.show()\n\n# 3. ROC æ›²çº¿ï¼ˆå¤šåˆ†ç±»ï¼‰\n# æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„ ROC æ›²çº¿\nplot_model(tuned_model, plot='auc')\nplt.title('ROC æ›²çº¿ï¼ˆå¤šåˆ†ç±»ï¼‰')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nâœ… å¯è§†åŒ–åˆ†æå®Œæˆï¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. å›å½’ä»»åŠ¡ç¤ºä¾‹\n\n### 3.1 åŠ è½½å›å½’æ•°æ®"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# å›å½’ä»»åŠ¡ï¼šé¢„æµ‹ç³–å°¿ç—…ç—…æƒ…è¿›å±•\n# ============================================================\n\nfrom sklearn.datasets import load_diabetes\n\n# åŠ è½½ç³–å°¿ç—…æ•°æ®é›†\n# - ç‰¹å¾ï¼šå¹´é¾„ã€æ€§åˆ«ã€BMIã€è¡€å‹ã€è¡€æ¸…æŒ‡æ ‡ç­‰\n# - ç›®æ ‡ï¼šä¸€å¹´åçš„ç–¾ç—…è¿›å±•æŒ‡æ ‡\nX_reg, y_reg = load_diabetes(return_X_y=True)\n\n# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\nX_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n    X_reg, y_reg, test_size=0.2, random_state=42\n)\n\nprint(f\"ğŸ“Š è®­ç»ƒé›†å½¢çŠ¶: {X_train_reg.shape}\")\nprint(f\"ğŸ“Š æµ‹è¯•é›†å½¢çŠ¶: {X_test_reg.shape}\")\nprint(f\"\\nç›®æ ‡å˜é‡ç»Ÿè®¡:\")\nprint(f\"  å‡å€¼: {y_train_reg.mean():.2f}\")\nprint(f\"  æ ‡å‡†å·®: {y_train_reg.std():.2f}\")\nprint(f\"  èŒƒå›´: [{y_train_reg.min():.2f}, {y_train_reg.max():.2f}]\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3.2 ä½¿ç”¨ PyCaret è¿›è¡Œå›å½’ä»»åŠ¡"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# PyCaret å›å½’ä»»åŠ¡å·¥ä½œæµ\n# ============================================================\n\nfrom pycaret.regression import *\n\n# 1. å‡†å¤‡æ•°æ®\ndata_reg = pd.DataFrame(X_train_reg, columns=[f'feature_{i}' for i in range(10)])\ndata_reg['target'] = y_train_reg\n\n# 2. åˆå§‹åŒ–å›å½’ç¯å¢ƒ\nprint(\"åˆå§‹åŒ– PyCaret å›å½’ç¯å¢ƒ...\")\nreg_setup = setup(\n    data=data_reg,\n    target='target',\n    session_id=42,\n    verbose=False,\n    html=False\n)\n\n# 3. å¯¹æ¯”æ‰€æœ‰å›å½’æ¨¡å‹\nprint(\"\\nå¯¹æ¯”æ‰€æœ‰å›å½’æ¨¡å‹...\")\nbest_reg_models = compare_models(\n    fold=5,\n    sort='R2',      # æŒ‰ RÂ² æ’åº\n    n_select=3\n)\n\n# 4. è°ƒä¼˜æœ€ä½³æ¨¡å‹\nprint(\"\\nè¶…å‚æ•°è°ƒä¼˜...\")\ntuned_reg_model = tune_model(\n    best_reg_models[0],\n    optimize='R2',\n    n_iter=10\n)\n\n# 5. è¯„ä¼°\ntest_data_reg = pd.DataFrame(X_test_reg, columns=[f'feature_{i}' for i in range(10)])\ntest_data_reg['target'] = y_test_reg\n\npredictions_reg = predict_model(tuned_reg_model, data=test_data_reg)\ny_pred_reg = predictions_reg['prediction_label'].values\n\n# è®¡ç®—æŒ‡æ ‡\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\nr2 = r2_score(y_test_reg, y_pred_reg)\nrmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\nmae = mean_absolute_error(y_test_reg, y_pred_reg)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ:\")\nprint(\"=\"*60)\nprint(f\"ğŸ“Š RÂ² Score: {r2:.4f}  (è¶Šæ¥è¿‘1è¶Šå¥½)\")\nprint(f\"ğŸ“Š RMSE: {rmse:.2f}     (è¶Šå°è¶Šå¥½)\")\nprint(f\"ğŸ“Š MAE: {mae:.2f}      (è¶Šå°è¶Šå¥½)\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. é«˜çº§ç‰¹æ€§ï¼šAutoML æ·±åº¦å¯¹æ¯”\n\n### 4.1 è´å¶æ–¯ä¼˜åŒ– vs éšæœºæœç´¢ï¼ˆç†è®ºå¯¹æ¯”ï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# å¯¹æ¯”ä¸‰ç§è¶…å‚æ•°æœç´¢ç­–ç•¥ï¼š\n# 1. ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰- éå†æ‰€æœ‰ç»„åˆ\n# 2. éšæœºæœç´¢ï¼ˆRandom Searchï¼‰- éšæœºé‡‡æ ·\n# 3. è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰- æ™ºèƒ½æœç´¢\n# ============================================================\n\nimport time\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# é‡æ–°åŠ è½½åˆ†ç±»æ•°æ®\nX_cmp, y_cmp = load_digits(return_X_y=True)\nX_train_cmp, X_test_cmp, y_train_cmp, y_test_cmp = train_test_split(\n    X_cmp, y_cmp, test_size=0.2, random_state=42\n)\n\n# å®šä¹‰è¶…å‚æ•°ç©ºé—´\nparam_grid = {\n    'n_estimators': [50, 100, 150, 200],\n    'max_depth': [5, 10, 15, 20, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\nresults = {}\n\n# ========== 1. ç½‘æ ¼æœç´¢ ==========\nprint(\"ğŸ” æ–¹æ³•1: ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰\")\nprint(\"   ç‰¹ç‚¹ï¼šéå†æ‰€æœ‰å‚æ•°ç»„åˆï¼Œæ•ˆç‡ä½ä½†ç»“æœç¡®å®š\")\nstart = time.time()\ngrid_search = GridSearchCV(\n    RandomForestClassifier(random_state=42),\n    param_grid,\n    cv=3,\n    n_jobs=-1,\n    verbose=0\n)\ngrid_search.fit(X_train_cmp, y_train_cmp)\ngrid_time = time.time() - start\ngrid_score = accuracy_score(y_test_cmp, grid_search.predict(X_test_cmp))\nresults['Grid Search'] = {'time': grid_time, 'accuracy': grid_score}\nprint(f\"   â±ï¸  è€—æ—¶: {grid_time:.2f}ç§’\")\nprint(f\"   ğŸ¯ å‡†ç¡®ç‡: {grid_score:.4f}\\n\")\n\n# ========== 2. éšæœºæœç´¢ ==========\nprint(\"ğŸ² æ–¹æ³•2: éšæœºæœç´¢ï¼ˆRandom Searchï¼‰\")\nprint(\"   ç‰¹ç‚¹ï¼šéšæœºé‡‡æ ·å‚æ•°ç»„åˆï¼Œæ•ˆç‡é«˜ä½†ç¼ºä¹æ™ºèƒ½\")\nstart = time.time()\nrandom_search = RandomizedSearchCV(\n    RandomForestClassifier(random_state=42),\n    param_grid,\n    n_iter=20,  # åªå°è¯•20ç»„å‚æ•°\n    cv=3,\n    random_state=42,\n    n_jobs=-1,\n    verbose=0\n)\nrandom_search.fit(X_train_cmp, y_train_cmp)\nrandom_time = time.time() - start\nrandom_score = accuracy_score(y_test_cmp, random_search.predict(X_test_cmp))\nresults['Random Search'] = {'time': random_time, 'accuracy': random_score}\nprint(f\"   â±ï¸  è€—æ—¶: {random_time:.2f}ç§’\")\nprint(f\"   ğŸ¯ å‡†ç¡®ç‡: {random_score:.4f}\\n\")\n\n# ========== 3. PyCaret (ä½¿ç”¨è´å¶æ–¯ä¼˜åŒ–) ==========\nprint(\"ğŸ§  æ–¹æ³•3: PyCaretï¼ˆå†…ç½®æ™ºèƒ½ä¼˜åŒ–ï¼‰\")\nprint(\"   ç‰¹ç‚¹ï¼šæ™ºèƒ½æœç´¢ï¼Œå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨\")\n# (å·²åœ¨å‰é¢è®­ç»ƒè¿‡ï¼Œè¿™é‡Œä½¿ç”¨ä¹‹å‰çš„ç»“æœ)\nprint(f\"   â±ï¸  è€—æ—¶: ~60-120ç§’ï¼ˆåŒ…å«æ¨¡å‹å¯¹æ¯”ï¼‰\")\nprint(f\"   ğŸ¯ å‡†ç¡®ç‡: {accuracy:.4f}\\n\")\n\n# å¯è§†åŒ–å¯¹æ¯”\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# è€—æ—¶å¯¹æ¯”\nmethods = list(results.keys())\ntimes = [results[m]['time'] for m in methods]\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n\nax1.barh(methods, times, color=colors)\nax1.set_xlabel('è€—æ—¶ï¼ˆç§’ï¼‰', fontsize=12)\nax1.set_title('è¶…å‚æ•°æœç´¢è€—æ—¶å¯¹æ¯”', fontsize=14, fontweight='bold')\nax1.grid(axis='x', alpha=0.3)\n\n# å‡†ç¡®ç‡å¯¹æ¯”\naccuracies = [results[m]['accuracy'] for m in methods]\nax2.barh(methods, accuracies, color=colors)\nax2.set_xlabel('å‡†ç¡®ç‡', fontsize=12)\nax2.set_xlim(0.9, 1.0)\nax2.set_title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')\nax2.grid(axis='x', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ’¡ æ€»ç»“:\")\nprint(\"   âœ… ç½‘æ ¼æœç´¢: ç»“æœæœ€ä¼˜ä½†è€—æ—¶é•¿\")\nprint(\"   âš¡ éšæœºæœç´¢: æ•ˆç‡é«˜ä½†æ€§èƒ½ä¸ç¨³å®š\")\nprint(\"   ğŸ¯ è´å¶æ–¯ä¼˜åŒ–: æ™ºèƒ½æœç´¢ï¼Œæ€§èƒ½ä¸æ•ˆç‡å¹³è¡¡æœ€ä½³\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.2 æ¨¡å‹é›†æˆï¼ˆEnsembleï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# æ¨¡å‹é›†æˆï¼šç»„åˆå¤šä¸ªæ¨¡å‹æå‡æ€§èƒ½\n# \n# PyCaret æä¾›ä¸‰ç§é›†æˆæ–¹æ³•ï¼š\n# 1. Bagging - å‡å°‘æ–¹å·®ï¼Œæé«˜ç¨³å®šæ€§\n# 2. Boosting - å‡å°‘åå·®ï¼Œæé«˜å‡†ç¡®æ€§\n# 3. Blending/Stacking - ç»„åˆå¤šä¸ªä¸åŒæ¨¡å‹\n# ============================================================\n\n# æ–¹æ³•1: Baggingï¼ˆè£…è¢‹æ³•ï¼‰\n# ä½¿ç”¨ Bootstrap é‡‡æ ·è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼Œç„¶åæŠ•ç¥¨\nprint(\"ğŸ’ æ–¹æ³•1: Baggingï¼ˆè£…è¢‹æ³•ï¼‰\")\nprint(\"   åŸç†ï¼šè®­ç»ƒå¤šä¸ªç›¸åŒæ¨¡å‹ï¼Œé™ä½æ–¹å·®\")\n\nbagged_model = ensemble_model(\n    tuned_model,\n    method='Bagging',\n    n_estimators=10  # é›†æˆ10ä¸ªæ¨¡å‹\n)\n\n# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°\nbagged_pred = predict_model(bagged_model, data=test_data)\nbagged_accuracy = accuracy_score(y_test, bagged_pred['prediction_label'])\nprint(f\"   ğŸ¯ Bagging å‡†ç¡®ç‡: {bagged_accuracy:.4f}\\n\")\n\n# æ–¹æ³•2: Boostingï¼ˆæå‡æ³•ï¼‰\n# é€æ­¥è®­ç»ƒæ¨¡å‹ï¼Œåç»­æ¨¡å‹å…³æ³¨å‰é¢æ¨¡å‹çš„é”™è¯¯\nprint(\"ğŸš€ æ–¹æ³•2: Boostingï¼ˆæå‡æ³•ï¼‰\")\nprint(\"   åŸç†ï¼šé€æ­¥è®­ç»ƒï¼Œæ¯ä¸ªæ¨¡å‹ä¿®æ­£å‰ä¸€ä¸ªçš„é”™è¯¯\")\n\nboosted_model = ensemble_model(\n    tuned_model,\n    method='Boosting',\n    n_estimators=10\n)\n\nboosted_pred = predict_model(boosted_model, data=test_data)\nboosted_accuracy = accuracy_score(y_test, boosted_pred['prediction_label'])\nprint(f\"   ğŸ¯ Boosting å‡†ç¡®ç‡: {boosted_accuracy:.4f}\\n\")\n\n# æ–¹æ³•3: Blendingï¼ˆæ··åˆæ³•ï¼‰\n# ç»„åˆå‰3ä¸ªæœ€ä½³æ¨¡å‹\nprint(\"ğŸ¨ æ–¹æ³•3: Blendingï¼ˆæ··åˆå¤šä¸ªä¸åŒæ¨¡å‹ï¼‰\")\nprint(\"   åŸç†ï¼šç»„åˆä¸åŒç®—æ³•çš„ä¼˜åŠ¿\")\n\nblended_model = blend_models(\n    estimator_list=best_models,  # ä½¿ç”¨å‰3ä¸ªæœ€ä½³æ¨¡å‹\n    method='soft'  # ä½¿ç”¨æ¦‚ç‡æŠ•ç¥¨\n)\n\nblended_pred = predict_model(blended_model, data=test_data)\nblended_accuracy = accuracy_score(y_test, blended_pred['prediction_label'])\nprint(f\"   ğŸ¯ Blending å‡†ç¡®ç‡: {blended_accuracy:.4f}\\n\")\n\n# å¯è§†åŒ–å¯¹æ¯”\nensemble_results = {\n    'å•ä¸€æ¨¡å‹': accuracy,\n    'Bagging': bagged_accuracy,\n    'Boosting': boosted_accuracy,\n    'Blending': blended_accuracy\n}\n\nplt.figure(figsize=(10, 6))\nmethods = list(ensemble_results.keys())\naccuracies = list(ensemble_results.values())\ncolors = ['#95E1D3', '#F38181', '#AA96DA', '#FCBAD3']\n\nbars = plt.barh(methods, accuracies, color=colors)\nplt.xlabel('å‡†ç¡®ç‡', fontsize=12)\nplt.xlim(0.95, 1.0)\nplt.title('é›†æˆæ–¹æ³•æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')\nplt.grid(axis='x', alpha=0.3)\n\n# æ·»åŠ æ•°å€¼æ ‡ç­¾\nfor i, (bar, acc) in enumerate(zip(bars, accuracies)):\n    plt.text(acc + 0.001, i, f'{acc:.4f}', va='center', fontsize=10)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ’¡ é›†æˆå­¦ä¹ æ€»ç»“:\")\nprint(\"   âœ… Bagging: é€‚åˆé™ä½æ¨¡å‹æ–¹å·®ï¼ˆå¦‚éšæœºæ£®æ—ï¼‰\")\nprint(\"   âš¡ Boosting: é€‚åˆæå‡å¼±æ¨¡å‹æ€§èƒ½ï¼ˆå¦‚ XGBoostï¼‰\")\nprint(\"   ğŸ¯ Blending: é€‚åˆç»„åˆä¸åŒç±»å‹çš„æ¨¡å‹\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 æ¨¡å‹æŒä¹…åŒ–ä¸éƒ¨ç½²"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# æ¨¡å‹ä¿å­˜ä¸åŠ è½½\n# PyCaret æä¾›äº†ä¾¿æ·çš„æ¨¡å‹ä¿å­˜åŠŸèƒ½\n# ============================================================\n\n# 1. ä¿å­˜æ¨¡å‹ï¼ˆPyCaret æ–¹å¼ï¼‰\nprint(\"ğŸ’¾ ä¿å­˜æ¨¡å‹...\")\nsave_model(tuned_model, 'pycaret_best_model')\nprint(\"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: pycaret_best_model.pkl\\n\")\n\n# 2. åŠ è½½æ¨¡å‹\nprint(\"ğŸ“‚ åŠ è½½æ¨¡å‹...\")\nloaded_model = load_model('pycaret_best_model')\nprint(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\\n\")\n\n# 3. ä½¿ç”¨åŠ è½½çš„æ¨¡å‹é¢„æµ‹\nprint(\"ğŸ”® ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹...\")\nnew_predictions = predict_model(loaded_model, data=test_data)\nloaded_accuracy = accuracy_score(y_test, new_predictions['prediction_label'])\nprint(f\"ğŸ“Š åŠ è½½æ¨¡å‹çš„å‡†ç¡®ç‡: {loaded_accuracy:.4f}\")\nprint(f\"âœ… ä¸åŸæ¨¡å‹ä¸€è‡´: {loaded_accuracy == accuracy}\\n\")\n\n# 4. å¯¼å‡ºä¸º Pickleï¼ˆæ ‡å‡† Python æ–¹å¼ï¼‰\nimport pickle\n\nwith open('standard_model.pkl', 'wb') as f:\n    pickle.dump(tuned_model, f)\nprint(\"âœ… ä¹Ÿå¯ä½¿ç”¨æ ‡å‡† pickle ä¿å­˜\")\n\nprint(\"\\nğŸ’¡ æ¨¡å‹éƒ¨ç½²å»ºè®®:\")\nprint(\"   1ï¸âƒ£  æœ¬åœ°éƒ¨ç½²ï¼šç›´æ¥ä½¿ç”¨ .pkl æ–‡ä»¶\")\nprint(\"   2ï¸âƒ£  WebæœåŠ¡ï¼šä½¿ç”¨ Flask/FastAPI å°è£… API\")\nprint(\"   3ï¸âƒ£  äº‘éƒ¨ç½²ï¼šä½¿ç”¨ AWS SageMakerã€Azure MLç­‰\")\nprint(\"   4ï¸âƒ£  è¾¹ç¼˜éƒ¨ç½²ï¼šè½¬æ¢ä¸º ONNXã€TensorFlow Liteç­‰æ ¼å¼\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. å…¶ä»– AutoML å·¥å…·ä»‹ç»\n\n### 5.1 TPOTï¼ˆåŸºäºé—ä¼ ç®—æ³•ï¼‰"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# TPOT (Tree-based Pipeline Optimization Tool)\n# \n# ç‰¹ç‚¹ï¼š\n# - ä½¿ç”¨é—ä¼ ç®—æ³•ï¼ˆGenetic Programmingï¼‰ä¼˜åŒ–æ•´ä¸ªMLæµç¨‹\n# - ä¸ä»…ä¼˜åŒ–è¶…å‚æ•°ï¼Œè¿˜ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹é€‰æ‹©\n# - è½»é‡çº§ï¼Œæ˜“äºå®‰è£…\n# - å¯å¯¼å‡ºä¸º sklearn Pipeline ä»£ç \n# ============================================================\n\n# å®‰è£…: pip install tpot\n\n# ç¤ºä¾‹ä»£ç ï¼ˆå¦‚æœå·²å®‰è£…TPOTï¼Œå¯å–æ¶ˆæ³¨é‡Šè¿è¡Œï¼‰\n\"\"\"\nfrom tpot import TPOTClassifier\n\n# åˆ›å»º TPOT åˆ†ç±»å™¨\n# generations: é—ä¼ ç®—æ³•çš„ä»£æ•°\n# population_size: æ¯ä»£çš„ç§ç¾¤å¤§å°\n# cv: äº¤å‰éªŒè¯æŠ˜æ•°\ntpot = TPOTClassifier(\n    generations=5,       # è¿›åŒ–5ä»£\n    population_size=20,  # æ¯ä»£20ä¸ªä¸ªä½“\n    cv=5,\n    random_state=42,\n    verbosity=2\n)\n\n# è®­ç»ƒï¼ˆä¼šè‡ªåŠ¨æœç´¢æœ€ä½³pipelineï¼‰\ntpot.fit(X_train, y_train)\n\n# è¯„ä¼°\nprint(f'TPOT å‡†ç¡®ç‡: {tpot.score(X_test, y_test):.4f}')\n\n# å¯¼å‡ºæœ€ä½³ pipeline ä¸º Python ä»£ç \ntpot.export('tpot_best_pipeline.py')\n\"\"\"\n\nprint(\"ğŸ“š TPOT æ ¸å¿ƒæ¦‚å¿µ:\")\nprint(\"\\n1ï¸âƒ£  é—ä¼ ç®—æ³•ï¼ˆGenetic Algorithmï¼‰:\")\nprint(\"   - åˆå§‹åŒ–ï¼šéšæœºç”Ÿæˆä¸€æ‰¹ ML pipelines\")\nprint(\"   - é€‰æ‹©ï¼šè¯„ä¼°æ¯ä¸ª pipeline çš„æ€§èƒ½\")\nprint(\"   - äº¤å‰ï¼šç»„åˆä¸¤ä¸ªä¼˜ç§€ pipeline çš„ç‰¹å¾\")\nprint(\"   - å˜å¼‚ï¼šéšæœºä¿®æ”¹ pipeline çš„æŸäº›éƒ¨åˆ†\")\nprint(\"   - è¿­ä»£ï¼šé‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œé€æ­¥è¿›åŒ–\")\nprint(\"\\n2ï¸âƒ£  ä¼˜åŠ¿:\")\nprint(\"   âœ… è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹\")\nprint(\"   âœ… æœç´¢ç©ºé—´å¹¿ï¼ˆåŒ…å«æ•´ä¸ª sklearn ç”Ÿæ€ï¼‰\")\nprint(\"   âœ… å¯å¯¼å‡ºä»£ç ï¼Œä¾¿äºç†è§£å’Œå®šåˆ¶\")\nprint(\"\\n3ï¸âƒ£  é€‚ç”¨åœºæ™¯:\")\nprint(\"   - æ•°æ®é›†è¾ƒå°ï¼ˆ< 100k æ ·æœ¬ï¼‰\")\nprint(\"   - éœ€è¦æ¢ç´¢å¤šç§ç‰¹å¾å·¥ç¨‹æ–¹æ³•\")\nprint(\"   - æƒ³è¦ç†è§£ AutoML çš„å†…éƒ¨é€»è¾‘\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.2 AutoML å·¥å…·å¯¹æ¯”æ€»ç»“"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# ä¸»æµ AutoML å·¥å…·å¯¹æ¯”\n# ============================================================\n\ncomparison_data = {\n    'å·¥å…·': ['Auto-sklearn', 'PyCaret', 'TPOT', 'H2O AutoML', 'FLAML'],\n    'ä¼˜åŒ–ç®—æ³•': ['è´å¶æ–¯ä¼˜åŒ–', 'ç½‘æ ¼/è´å¶æ–¯', 'é—ä¼ ç®—æ³•', 'éšæœºæœç´¢', 'CFOç®—æ³•'],\n    'macOSæ”¯æŒ': ['âŒ', 'âœ…', 'âœ…', 'âœ…', 'âœ…'],\n    'æ˜“ç”¨æ€§': ['â­â­â­', 'â­â­â­â­â­', 'â­â­â­â­', 'â­â­â­â­', 'â­â­â­'],\n    'åŠŸèƒ½ä¸°å¯Œåº¦': ['â­â­â­â­', 'â­â­â­â­â­', 'â­â­â­', 'â­â­â­â­â­', 'â­â­â­â­'],\n    'æ€§èƒ½': ['â­â­â­â­â­', 'â­â­â­â­', 'â­â­â­', 'â­â­â­â­', 'â­â­â­â­â­'],\n    'æ¨èåœºæ™¯': [\n        'Linuxç ”ç©¶/ç«èµ›',\n        'å¿«é€ŸåŸå‹å¼€å‘',\n        'å­¦ä¹ AutoMLåŸç†',\n        'å¤§è§„æ¨¡æ•°æ®',\n        'é«˜æ•ˆä¼˜åŒ–'\n    ]\n}\n\ndf_comparison = pd.DataFrame(comparison_data)\n\nprint(\"=\"*80)\nprint(\"AutoML å·¥å…·å¯¹æ¯”è¡¨\")\nprint(\"=\"*80)\nprint(df_comparison.to_string(index=False))\nprint(\"=\"*80)\n\nprint(\"\\nğŸ’¡ é€‰æ‹©å»ºè®®:\")\nprint(\"\\nğŸ¯ åˆå­¦è€…/å¿«é€Ÿå¼€å‘ â†’ PyCaret\")\nprint(\"   - æœ€æ˜“ä¸Šæ‰‹ï¼Œæ–‡æ¡£ä¸°å¯Œ\")\nprint(\"   - å¯è§†åŒ–åŠŸèƒ½å¼ºå¤§\")\nprint(\"   - æ”¯æŒæ‰€æœ‰å¹³å°\")\n\nprint(\"\\nğŸ§ª å­¦ä¹ AutoMLåŸç† â†’ TPOT\")\nprint(\"   - å¯å¯¼å‡ºä»£ç ï¼Œä¾¿äºç†è§£\")\nprint(\"   - é—ä¼ ç®—æ³•ç›´è§‚\")\nprint(\"   - è½»é‡çº§ï¼Œæ˜“è°ƒè¯•\")\n\nprint(\"\\nğŸ† è¿½æ±‚æè‡´æ€§èƒ½ â†’ Auto-sklearn (Linux) / FLAML (è·¨å¹³å°)\")\nprint(\"   - Auto-sklearn: è´å¶æ–¯ä¼˜åŒ– + å…ƒå­¦ä¹ \")\nprint(\"   - FLAML: å¾®è½¯å¼€å‘ï¼Œé«˜æ•ˆæœç´¢\")\n\nprint(\"\\nğŸ¢ ç”Ÿäº§ç¯å¢ƒ/å¤§æ•°æ® â†’ H2O AutoML\")\nprint(\"   - æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ\")\nprint(\"   - ä¼ä¸šçº§åŠŸèƒ½\")\nprint(\"   - Java/Python åŒæ¥å£\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. æ€»ç»“ä¸æœ€ä½³å®è·µ\n\n### ğŸ“š æœ¬èŠ‚æ ¸å¿ƒçŸ¥è¯†ç‚¹\n\n#### 1. AutoML çš„ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯\n\n**è´å¶æ–¯ä¼˜åŒ–ï¼ˆBayesian Optimizationï¼‰**\n```\nå·¥ä½œåŸç†ï¼š\n1. å»ºç«‹ä»£ç†æ¨¡å‹ï¼ˆSurrogate Modelï¼‰é¢„æµ‹å‚æ•°æ€§èƒ½\n2. ä½¿ç”¨é‡‡é›†å‡½æ•°ï¼ˆAcquisition Functionï¼‰å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨\n3. é€‰æ‹©ä¸‹ä¸€ç»„æœ€æœ‰å¸Œæœ›çš„å‚æ•°è¿›è¡Œå®éªŒ\n4. æ›´æ–°ä»£ç†æ¨¡å‹ï¼Œé‡å¤è¿­ä»£\n\nä¼˜åŠ¿ï¼šæ¯”éšæœºæœç´¢å’Œç½‘æ ¼æœç´¢æ›´é«˜æ•ˆ\né€‚ç”¨ï¼šè¿ç»­å‚æ•°ç©ºé—´ï¼Œæ˜‚è´µçš„è¯„ä¼°å‡½æ•°\n```\n\n**å…ƒå­¦ä¹ ï¼ˆMeta-learningï¼‰**\n```\næ ¸å¿ƒæ€æƒ³ï¼šä»å†å²æ•°æ®é›†ä¸­å­¦ä¹ ç»éªŒ\n\nå·¥ä½œæµç¨‹ï¼š\n1. åˆ†ææ–°æ•°æ®é›†çš„ç‰¹å¾ï¼ˆæ ·æœ¬æ•°ã€ç‰¹å¾æ•°ã€åˆ†å¸ƒç­‰ï¼‰\n2. åœ¨å…ƒçŸ¥è¯†åº“ä¸­æŸ¥æ‰¾ç›¸ä¼¼æ•°æ®é›†\n3. æ¨èåœ¨ç›¸ä¼¼æ•°æ®é›†ä¸Šè¡¨ç°å¥½çš„æ¨¡å‹\n4. ä»æ¨èçš„èµ·ç‚¹å¼€å§‹ä¼˜åŒ–ï¼ˆè€Œééšæœºåˆå§‹åŒ–ï¼‰\n\nä¼˜åŠ¿ï¼šå¿«é€Ÿæ‰¾åˆ°å¥½çš„èµ·ç‚¹ï¼ŒåŠ é€Ÿæ”¶æ•›\n```\n\n**è‡ªåŠ¨é›†æˆï¼ˆEnsembleï¼‰**\n```\né›†æˆç­–ç•¥ï¼š\n- Bagging: é™ä½æ–¹å·®ï¼ˆå¦‚éšæœºæ£®æ—ï¼‰\n- Boosting: é™ä½åå·®ï¼ˆå¦‚XGBoostã€AdaBoostï¼‰\n- Stacking/Blending: ç»„åˆä¸åŒç®—æ³•\n\nä¼˜åŠ¿ï¼šæ¯”å•ä¸€æ¨¡å‹æ›´ç¨³å®šã€æ›´å‡†ç¡®\n```\n\n---\n\n### ğŸ¯ AutoML ä½¿ç”¨æœ€ä½³å®è·µ\n\n#### æ—¶é—´é¢„ç®—è®¾ç½®\n\n```python\n# å¿«é€ŸéªŒè¯ï¼ˆ1-3åˆ†é’Ÿï¼‰- é€‚åˆæ¢ç´¢é˜¶æ®µ\nsetup(..., session_id=42)\nbest = compare_models(fold=3)  # å‡å°‘äº¤å‰éªŒè¯æŠ˜æ•°\n\n# æ ‡å‡†è®­ç»ƒï¼ˆ10-30åˆ†é’Ÿï¼‰- é€‚åˆä¸€èˆ¬é¡¹ç›®\nbest = compare_models(fold=5)\ntuned = tune_model(best, n_iter=10)\n\n# æ·±åº¦æœç´¢ï¼ˆ1-2å°æ—¶ï¼‰- é€‚åˆç«èµ›/é‡è¦é¡¹ç›®\nbest = compare_models(fold=10)\ntuned = tune_model(best, n_iter=50)\nensemble = blend_models([...])\n```\n\n#### æ•°æ®é¢„å¤„ç†å»ºè®®\n\n```python\n# PyCaret ä¼šè‡ªåŠ¨å¤„ç†å¾ˆå¤šé¢„å¤„ç†æ­¥éª¤ï¼Œä½†ä»éœ€æ³¨æ„ï¼š\n\n# 1. æ£€æŸ¥æ•°æ®è´¨é‡\n# - ç¼ºå¤±å€¼æ¯”ä¾‹\n# - ç±»åˆ«ä¸å¹³è¡¡\n# - å¼‚å¸¸å€¼\n\n# 2. ç‰¹å¾å·¥ç¨‹ï¼ˆå¯é€‰ï¼‰\n# PyCaret å¯ä»¥è‡ªåŠ¨å®Œæˆï¼Œä½†æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹å¾€å¾€æ›´å¥½\nsetup(\n    data=data,\n    target='target',\n    normalize=True,              # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾\n    normalize_method='zscore',   # ä½¿ç”¨ Z-score\n    feature_selection=True,      # ç‰¹å¾é€‰æ‹©\n    remove_multicollinearity=True,  # å»é™¤å¤šé‡å…±çº¿æ€§\n    multicollinearity_threshold=0.9\n)\n```\n\n#### æ¨¡å‹è¯„ä¼°æŒ‡æ ‡é€‰æ‹©\n\n```python\n# åˆ†ç±»ä»»åŠ¡\n- å¹³è¡¡æ•°æ®é›† â†’ Accuracy\n- ä¸å¹³è¡¡æ•°æ®é›† â†’ F1-scoreã€AUC\n- å…³æ³¨å‡é˜³æ€§ â†’ Precision\n- å…³æ³¨å‡é˜´æ€§ â†’ Recall\n\n# å›å½’ä»»åŠ¡\n- ä¸€èˆ¬æƒ…å†µ â†’ RÂ²ã€RMSE\n- å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ â†’ MAE\n- ç™¾åˆ†æ¯”è¯¯å·® â†’ MAPE\n```\n\n---\n\n### âš ï¸ å¸¸è§é™·é˜±ä¸æ³¨æ„äº‹é¡¹\n\n#### 1ï¸âƒ£ æ•°æ®æ³„éœ²ï¼ˆData Leakageï¼‰\n\n```python\n# âŒ é”™è¯¯åšæ³•ï¼šåœ¨åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ä¹‹å‰è¿›è¡Œç‰¹å¾å·¥ç¨‹\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)  # åœ¨å…¨éƒ¨æ•°æ®ä¸Šfit\nX_train, X_test = train_test_split(X_scaled, ...)\n\n# âœ… æ­£ç¡®åšæ³•ï¼šè®© AutoML å·¥å…·è‡ªåŠ¨å¤„ç†\n# PyCaret ä¼šåœ¨ setup() æ—¶æ­£ç¡®å¤„ç†é¢„å¤„ç†æµç¨‹\n```\n\n#### 2ï¸âƒ£ è¿‡æ‹Ÿåˆé£é™©\n\n```python\n# AutoML å¯èƒ½åœ¨å°æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆ\n\n# é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•ï¼š\n1. ä½¿ç”¨æ›´å¤šçš„äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆfold=10ï¼‰\n2. åœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸ŠéªŒè¯\n3. ä½¿ç”¨æ­£åˆ™åŒ–æ¨¡å‹\n4. é™åˆ¶æ¨¡å‹å¤æ‚åº¦\n```\n\n#### 3ï¸âƒ£ æ—¶é—´é¢„ç®—é™·é˜±\n\n```python\n# âŒ æ—¶é—´è®¾ç½®è¿‡çŸ­ â†’ æœç´¢ä¸å……åˆ†\ncompare_models(fold=2)  # å¤ªå°‘ï¼Œç»“æœä¸ç¨³å®š\n\n# âŒ æ—¶é—´è®¾ç½®è¿‡é•¿ â†’ å›æŠ¥é€’å‡\ntune_model(best, n_iter=1000)  # åæœŸæå‡å¾®å°\n\n# âœ… å¹³è¡¡æ•ˆç‡ä¸æ€§èƒ½\ncompare_models(fold=5)\ntune_model(best, n_iter=10-20)\n```\n\n#### 4ï¸âƒ£ ç›²ç›®ä¿¡ä»» AutoML\n\n```python\n# AutoML ä¸æ˜¯ä¸‡èƒ½çš„ï¼\n\nä»éœ€è¦ï¼š\nâœ… ç†è§£æ•°æ®çš„ä¸šåŠ¡å«ä¹‰\nâœ… æ‰‹åŠ¨è¿›è¡Œé¢†åŸŸç›¸å…³çš„ç‰¹å¾å·¥ç¨‹\nâœ… æ£€æŸ¥æ¨¡å‹çš„å¯è§£é‡Šæ€§\nâœ… åœ¨çœŸå®åœºæ™¯ä¸­éªŒè¯\nâœ… ç›‘æ§æ¨¡å‹åœ¨ç”Ÿäº§ç¯å¢ƒçš„è¡¨ç°\n```\n\n---\n\n### ğŸ“Š AutoML å·¥ä½œæµç¨‹æ€»ç»“\n\n```\n1ï¸âƒ£ æ•°æ®å‡†å¤‡\n   â”œâ”€ æ¢ç´¢æ€§æ•°æ®åˆ†æï¼ˆEDAï¼‰\n   â”œâ”€ æ•°æ®æ¸…æ´—\n   â””â”€ åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†\n\n2ï¸âƒ£ AutoML åˆå§‹åŒ–\n   â”œâ”€ setup() é…ç½®ç¯å¢ƒ\n   â””â”€ è®¾ç½®é¢„å¤„ç†é€‰é¡¹\n\n3ï¸âƒ£ æ¨¡å‹æœç´¢\n   â”œâ”€ compare_models() å¯¹æ¯”æ‰€æœ‰ç®—æ³•\n   â””â”€ é€‰æ‹©æœ€ä½³æ¨¡å‹\n\n4ï¸âƒ£ è¶…å‚æ•°è°ƒä¼˜\n   â””â”€ tune_model() ä¼˜åŒ–æ€§èƒ½\n\n5ï¸âƒ£ æ¨¡å‹é›†æˆï¼ˆå¯é€‰ï¼‰\n   â”œâ”€ ensemble_model() å•æ¨¡å‹é›†æˆ\n   â””â”€ blend_models() å¤šæ¨¡å‹èåˆ\n\n6ï¸âƒ£ è¯„ä¼°ä¸éƒ¨ç½²\n   â”œâ”€ predict_model() æµ‹è¯•é›†è¯„ä¼°\n   â”œâ”€ plot_model() å¯è§†åŒ–åˆ†æ\n   â””â”€ save_model() ä¿å­˜æ¨¡å‹\n```\n\n---\n\n### ğŸ¯ å­¦ä¹ å»ºè®®\n\n1. **ç†è®ºå…ˆè¡Œ**ï¼šç†è§£è´å¶æ–¯ä¼˜åŒ–ã€å…ƒå­¦ä¹ ã€é›†æˆå­¦ä¹ çš„åŸç†\n2. **å·¥å…·å¯¹æ¯”**ï¼šå°è¯•ä¸åŒ AutoML å·¥å…·ï¼Œäº†è§£å„è‡ªä¼˜åŠ¿\n3. **æ‰‹åŠ¨å¯¹ç…§**ï¼šå°† AutoML ç»“æœä¸æ‰‹åŠ¨è°ƒå‚å¯¹æ¯”\n4. **æºç é˜…è¯»**ï¼šæŸ¥çœ‹ AutoML å¯¼å‡ºçš„ä»£ç ï¼Œå­¦ä¹ æœ€ä½³å®è·µ\n5. **å®æˆ˜åº”ç”¨**ï¼šåœ¨çœŸå®é¡¹ç›®ä¸­åº”ç”¨ï¼Œç§¯ç´¯ç»éªŒ\n\n---\n\n## ğŸ¯ ç»ƒä¹ ä»»åŠ¡\n\n### ä»»åŠ¡ 1ï¼šåŸºç¡€åº”ç”¨\nä½¿ç”¨ PyCaret åœ¨ sklearn çš„ Iris æ•°æ®é›†ä¸Šå®Œæˆå®Œæ•´çš„ AutoML æµç¨‹ã€‚\n\n### ä»»åŠ¡ 2ï¼šå¯¹æ¯”å®éªŒ\nåœ¨åŒä¸€æ•°æ®é›†ä¸Šå¯¹æ¯”ä»¥ä¸‹ä¸‰ç§æ–¹æ³•çš„æ•ˆæœï¼š\n- æ‰‹åŠ¨è°ƒå‚çš„å•ä¸€æ¨¡å‹\n- PyCaret çš„è‡ªåŠ¨è°ƒä¼˜\n- PyCaret çš„æ¨¡å‹é›†æˆ\n\n### ä»»åŠ¡ 3ï¼šç†è§£åŸç†\né˜…è¯» PyCaret æˆ– TPOT å¯¼å‡ºçš„ä»£ç ï¼Œåˆ†æï¼š\n- é€‰æ‹©äº†å“ªäº›ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Ÿ\n- æœ€ä½³æ¨¡å‹çš„è¶…å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿ\n- ä¸ºä»€ä¹ˆè¿™äº›å‚æ•°æ˜¯æœ€ä¼˜çš„ï¼Ÿ\n\n### ä»»åŠ¡ 4ï¼šè‡ªå®šä¹‰æ•°æ®é›†\nåœ¨ä½ è‡ªå·±çš„æ•°æ®é›†ä¸Šä½¿ç”¨ AutoMLï¼š\n- è®°å½•ä¸åŒæ—¶é—´é¢„ç®—ä¸‹çš„æ€§èƒ½\n- å°è¯•æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹èƒ½å¦è¶…è¶Š AutoML\n- åˆ†æ AutoML çš„ä¼˜åŠ¿å’Œå±€é™\n\n---\n\n## ğŸ“š å‚è€ƒèµ„æº\n\n### å®˜æ–¹æ–‡æ¡£\n- [PyCaret æ–‡æ¡£](https://pycaret.org/)\n- [Auto-sklearn æ–‡æ¡£](https://automl.github.io/auto-sklearn/)\n- [TPOT æ–‡æ¡£](http://epistasislab.github.io/tpot/)\n\n### å­¦æœ¯è®ºæ–‡\n- [Auto-sklearn è®ºæ–‡](https://papers.nips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html)\n- [è´å¶æ–¯ä¼˜åŒ–ç»¼è¿°](https://arxiv.org/abs/1807.02811)\n- [å…ƒå­¦ä¹ ç»¼è¿°](https://arxiv.org/abs/1810.03548)\n\n### è§†é¢‘æ•™ç¨‹\n- PyCaret YouTube é¢‘é“\n- Kaggle AutoML æ•™ç¨‹\n\n---\n\n**ä¸‹ä¸€èŠ‚é¢„å‘Š**: `03_advanced_automl.ipynb` - é«˜çº§ AutoML æŠ€å·§ä¸ä¼˜åŒ–ç­–ç•¥\n\n**å»ºè®®å­¦ä¹ æ—¶é—´**: 2-3å°æ—¶ï¼ˆç†è®º + å®è·µï¼‰"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}