# 📋 待完成的Notebooks

## 已完成 ✅

1. **`01_linear_algebra.ipynb`** - 线性代数基础
   - 向量和矩阵
   - 点积、矩阵乘法
   - 特征值和特征向量
   - ML应用：余弦相似度、PCA

2. **`02_calculus.ipynb`** - 微积分基础
   - 导数和梯度
   - 链式法则
   - 梯度下降
   - ML应用：反向传播、参数优化

---

## 即将添加 🔄

### 3. 概率统计基础 (`03_probability_statistics.ipynb`)

**核心内容：**
- 概率基础（条件概率、贝叶斯定理）
- 常见分布（正态分布、伯努利分布、泊松分布）
- 期望、方差、协方差
- 中心极限定理
- **ML应用**：
  - 逻辑回归（概率输出）
  - 朴素贝叶斯分类器
  - 高斯分布与正则化
  - 数据分析和EDA

### 4. 优化基础 (`04_optimization.ipynb`)

**核心内容：**
- 损失函数设计
- 梯度下降变体：
  - Batch GD
  - SGD（随机梯度下降）
  - Mini-batch GD
  - Momentum
  - RMSprop
  - Adam
- 学习率调度
- 凸优化 vs 非凸优化
- **ML应用**：
  - 选择合适的优化器
  - 超参数调优
  - 训练技巧

---

## 🎯 当前学习建议

### 已有的两个notebook已经足够开始学习监督学习！

#### 现在你可以：

1. **先完成线性代数和微积分**
   ```
   Day 1-2: 线性代数
   Day 3-4: 微积分
   ```

2. **然后回到监督学习**
   ```
   Day 5+: 开始学习线性回归
   ```

   有了数学基础后，你会发现：
   - ✅ 理解矩阵运算在做什么
   - ✅ 理解梯度下降如何工作
   - ✅ 能看懂公式推导
   - ✅ 调试训练问题更容易

3. **需要时再回来学概率统计**
   - 学习逻辑回归时
   - 学习朴素贝叶斯时
   - 做数据分析时

---

## 💡 学习路径建议

### 方案A：快速开始（推荐）
```
1. 线性代数（2-3天）✅
2. 微积分（2-3天）✅
3. 开始监督学习 → 线性回归
4. 需要时回来学概率统计
```

### 方案B：完整数学基础
```
1. 线性代数（2-3天）✅
2. 微积分（2-3天）✅
3. 等待概率统计notebook
4. 等待优化notebook
5. 再开始监督学习
```

**我推荐方案A**，因为：
- 边学边用，理解更深
- 不会因为等待而失去动力
- 需要时再补充数学知识

---

## 📚 概率统计暂时可以这样学

虽然notebook还没创建，但你可以：

### 基本概念
- **概率**：事件发生的可能性（0到1之间）
- **期望**：平均值 $E[X] = \sum x_i p_i$
- **方差**：离散程度 $Var(X) = E[(X-\mu)^2]$

### 重要分布
1. **正态分布**（高斯分布）
   - 钟形曲线
   - 参数：均值$\mu$，方差$\sigma^2$
   - 很多数据符合正态分布

2. **伯努利分布**
   - 0/1分布（成功/失败）
   - 逻辑回归用到

### NumPy快速上手
```python
import numpy as np

# 生成正态分布数据
data = np.random.normal(loc=0, scale=1, size=1000)

# 计算统计量
mean = np.mean(data)
variance = np.var(data)
std = np.std(data)
```

---

## 🚀 现在就开始

### 建议的学习顺序：

```
今天-明天:
  → 完成 01_linear_algebra.ipynb
  → 理解向量、矩阵、点积

后天-大后天:
  → 完成 02_calculus.ipynb
  → 理解导数、梯度、梯度下降

第5天开始:
  → 回到 supervised_learning/
  → 开始 01_linear_regression.ipynb
  → 有数学基础后会更容易理解！
```

---

## ✅ 完成标志

### 线性代数
- [ ] 理解向量和矩阵的几何意义
- [ ] 会用NumPy进行矩阵运算
- [ ] 理解点积 = 相似度
- [ ] 知道PCA用特征向量

### 微积分
- [ ] 理解导数 = 斜率
- [ ] 理解梯度 = 最快上升方向
- [ ] 能手动实现简单的梯度下降
- [ ] 理解链式法则（反向传播基础）

### 准备好开始ML
- [ ] 完成上述两个notebook
- [ ] 理解"训练"的数学本质
- [ ] 知道为什么用矩阵乘法

---

## 有问题吗？

如果你想：
1. **快速了解概率统计**：可以先看YouTube上的StatQuest系列
2. **了解优化算法**：可以先看cs231n课程的优化部分
3. **直接开始ML**：完成线性代数和微积分后就可以！

---

**不要等待完美，开始行动！** 🚀

两个已完成的notebook已经足够你开始学习机器学习了！