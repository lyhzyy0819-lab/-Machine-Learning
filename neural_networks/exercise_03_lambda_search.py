"""
============================================================================
ç»ƒä¹ 3ï¼šæœ€ä½³Î»æœç´¢ - ä½¿ç”¨éªŒè¯é›†é€‰æ‹©æœ€ä¼˜æ­£åˆ™åŒ–å¼ºåº¦
============================================================================

ğŸ“š é—®é¢˜èƒŒæ™¯ï¼š
    L2æ­£åˆ™åŒ–çš„å¼ºåº¦å‚æ•°Î»æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œéœ€è¦é€šè¿‡å®éªŒæ¥ç¡®å®šæœ€ä½³å€¼ã€‚
    Î»è¿‡å°ï¼šæ­£åˆ™åŒ–æ•ˆæœå¼±ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ
    Î»è¿‡å¤§ï¼šæ­£åˆ™åŒ–æ•ˆæœè¿‡å¼ºï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ

ğŸ¯ å­¦ä¹ ç›®æ ‡ï¼š
    1. ç†è§£è¶…å‚æ•°è°ƒä¼˜çš„é‡è¦æ€§
    2. æŒæ¡ä½¿ç”¨éªŒè¯é›†é€‰æ‹©è¶…å‚æ•°çš„æ–¹æ³•
    3. ç»˜åˆ¶éªŒè¯æ€§èƒ½ vs Î»çš„æ›²çº¿
    4. æ‰¾åˆ°æœ€ä½³çš„Î»å€¼
    5. ç†è§£åå·®-æ–¹å·®æƒè¡¡

============================================================================
"""

# ============================================================================
# ç¬¬1éƒ¨åˆ†ï¼šå¯¼å…¥åº“å’Œç¯å¢ƒé…ç½®
# ============================================================================

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'STHeiti']
plt.rcParams['axes.unicode_minus'] = False

print("=" * 70)
print("ç»ƒä¹ 3ï¼šæœ€ä½³Î»æœç´¢ - L2æ­£åˆ™åŒ–è¶…å‚æ•°è°ƒä¼˜")
print("=" * 70)


# ============================================================================
# ç¬¬2éƒ¨åˆ†ï¼šè¶…å‚æ•°è°ƒä¼˜åŸç†
# ============================================================================
"""
ğŸ“– ä¸ºä»€ä¹ˆéœ€è¦éªŒè¯é›†ï¼Ÿ

    æ•°æ®åˆ’åˆ†ï¼š
        åŸå§‹æ•°æ® â†’ è®­ç»ƒé›† + éªŒè¯é›† + æµ‹è¯•é›†

    å„é›†åˆçš„ä½œç”¨ï¼š
        è®­ç»ƒé›†ï¼šç”¨äºè®­ç»ƒæ¨¡å‹ï¼ˆæ›´æ–°å‚æ•°ï¼‰
        éªŒè¯é›†ï¼šç”¨äºé€‰æ‹©è¶…å‚æ•°ï¼ˆå¦‚Î»ï¼‰
        æµ‹è¯•é›†ï¼šæœ€ç»ˆè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆåªç”¨ä¸€æ¬¡ï¼ï¼‰

    âš ï¸ é‡è¦åŸåˆ™ï¼š
        ç»å¯¹ä¸èƒ½ç”¨æµ‹è¯•é›†æ¥é€‰æ‹©è¶…å‚æ•°ï¼
        å¦åˆ™æµ‹è¯•é›†çš„ä¿¡æ¯ä¼š"æ³„éœ²"åˆ°æ¨¡å‹ä¸­ï¼Œå¯¼è‡´è¿‡äºä¹è§‚çš„æ€§èƒ½ä¼°è®¡ã€‚

ğŸ“ Î»æœç´¢çš„æ•°å­¦ç†è§£ï¼š

    L2æ­£åˆ™åŒ–æŸå¤±ï¼š
        L(Î¸) = L_CE(Î¸) + Î»/2 * ||Î¸||Â²

    Î»çš„å½±å“ï¼š
        Î» â†’ 0: æ— æ­£åˆ™åŒ–ï¼Œæ¨¡å‹å¤æ‚åº¦é«˜ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ
        Î» â†’ âˆ: å¼ºæ­£åˆ™åŒ–ï¼ŒÎ¸ â†’ 0ï¼Œæ¨¡å‹è¿‡äºç®€å•ï¼Œæ¬ æ‹Ÿåˆ

    æœ€ä½³Î»ï¼šåœ¨åå·®å’Œæ–¹å·®ä¹‹é—´å–å¾—å¹³è¡¡

ğŸ’¡ æœç´¢ç­–ç•¥ï¼š

    1. ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰ï¼šåœ¨é¢„å®šä¹‰çš„å€™é€‰å€¼ä¸­æœç´¢
       å¸¸ç”¨å€™é€‰å€¼ï¼š[0.0001, 0.001, 0.01, 0.1, 1.0]

    2. å¯¹æ•°å°ºåº¦æœç´¢ï¼šå› ä¸ºÎ»çš„æœ€ä½³å€¼é€šå¸¸åœ¨å¤šä¸ªæ•°é‡çº§ä¸­å˜åŒ–
       ä½¿ç”¨ 10^(-4), 10^(-3), 10^(-2), 10^(-1), 10^0

    3. éšæœºæœç´¢ï¼šåœ¨æŸä¸ªèŒƒå›´å†…éšæœºé‡‡æ ·
"""


# ============================================================================
# ç¬¬3éƒ¨åˆ†ï¼šæ¿€æ´»å‡½æ•°å’Œç½‘ç»œç»„ä»¶
# ============================================================================

def relu(z):
    """ReLUæ¿€æ´»å‡½æ•°: max(0, z)"""
    return np.maximum(0, z)


def relu_derivative(z):
    """ReLUå¯¼æ•°: 1 if z > 0 else 0"""
    return (z > 0).astype(float)


def sigmoid(z):
    """Sigmoidæ¿€æ´»å‡½æ•°: 1 / (1 + e^(-z))"""
    return 1 / (1 + np.exp(-np.clip(z, -500, 500)))


# ============================================================================
# ç¬¬4éƒ¨åˆ†ï¼šç¥ç»ç½‘ç»œå®ç°
# ============================================================================

class L2RegularizedNetwork:
    """
    å¸¦L2æ­£åˆ™åŒ–çš„ç¥ç»ç½‘ç»œ

    ç”¨äºÎ»æœç´¢å®éªŒçš„ç½‘ç»œå®ç°

    ç½‘ç»œç»“æ„ï¼š2 â†’ 32 â†’ 16 â†’ 1
    ï¼ˆæ¯”ä¹‹å‰ç¨å°ï¼Œé€‚åˆå°æ•°æ®é›†ï¼‰
    """

    def __init__(self, lambda_reg=0.01):
        """
        åˆå§‹åŒ–ç½‘ç»œ

        å‚æ•°:
            lambda_reg: L2æ­£åˆ™åŒ–å¼ºåº¦Î»
        """
        self.lambda_reg = lambda_reg

        # Xavieråˆå§‹åŒ–
        np.random.seed(42)  # ä¿è¯æ¯æ¬¡åˆå§‹åŒ–ç›¸åŒï¼Œä¾¿äºå¯¹æ¯”

        self.W1 = np.random.randn(32, 2) * np.sqrt(1.0 / 2)
        self.b1 = np.zeros(32)

        self.W2 = np.random.randn(16, 32) * np.sqrt(1.0 / 32)
        self.b2 = np.zeros(16)

        self.W3 = np.random.randn(1, 16) * np.sqrt(1.0 / 16)
        self.b3 = np.zeros(1)

    def forward(self, X):
        """å‰å‘ä¼ æ’­"""
        self.z1 = X @ self.W1.T + self.b1
        self.a1 = relu(self.z1)

        self.z2 = self.a1 @ self.W2.T + self.b2
        self.a2 = relu(self.z2)

        self.z3 = self.a2 @ self.W3.T + self.b3
        self.a3 = sigmoid(self.z3)

        return self.a3

    def backward(self, X, y_true):
        """åå‘ä¼ æ’­ï¼ˆå¸¦L2æ­£åˆ™åŒ–ï¼‰"""
        m = X.shape[0]

        # è¾“å‡ºå±‚
        delta3 = (self.a3 - y_true.reshape(-1, 1)) / m
        grad_W3 = delta3.T @ self.a2 + self.lambda_reg * self.W3
        grad_b3 = np.sum(delta3, axis=0)

        # ç¬¬2å±‚
        delta2 = (delta3 @ self.W3) * relu_derivative(self.z2)
        grad_W2 = delta2.T @ self.a1 + self.lambda_reg * self.W2
        grad_b2 = np.sum(delta2, axis=0)

        # ç¬¬1å±‚
        delta1 = (delta2 @ self.W2) * relu_derivative(self.z1)
        grad_W1 = delta1.T @ X + self.lambda_reg * self.W1
        grad_b1 = np.sum(delta1, axis=0)

        return [grad_W1, grad_b1, grad_W2, grad_b2, grad_W3, grad_b3]

    def get_params(self):
        return [self.W1, self.b1, self.W2, self.b2, self.W3, self.b3]

    def set_params(self, params):
        self.W1, self.b1, self.W2, self.b2, self.W3, self.b3 = params

    def compute_loss(self, X, y_true):
        """è®¡ç®—æ€»æŸå¤±ï¼ˆåŒ…å«L2æ­£åˆ™åŒ–é¡¹ï¼‰"""
        y_pred = self.forward(X)
        epsilon = 1e-15
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)

        # äº¤å‰ç†µæŸå¤±
        ce_loss = -np.mean(
            y_true * np.log(y_pred.flatten()) +
            (1 - y_true) * np.log(1 - y_pred.flatten())
        )

        # L2æ­£åˆ™åŒ–é¡¹
        l2_penalty = self.lambda_reg / 2 * (
            np.sum(self.W1 ** 2) +
            np.sum(self.W2 ** 2) +
            np.sum(self.W3 ** 2)
        )

        return ce_loss + l2_penalty

    def compute_accuracy(self, X, y_true):
        """è®¡ç®—å‡†ç¡®ç‡"""
        y_pred = self.forward(X)
        predictions = (y_pred >= 0.5).astype(int).flatten()
        return np.mean(predictions == y_true)

    def get_weight_norm(self):
        """è®¡ç®—æƒé‡çš„L2èŒƒæ•°ï¼ˆç”¨äºåˆ†æï¼‰"""
        return np.sqrt(
            np.sum(self.W1 ** 2) +
            np.sum(self.W2 ** 2) +
            np.sum(self.W3 ** 2)
        )


# ============================================================================
# ç¬¬5éƒ¨åˆ†ï¼šè®­ç»ƒå’Œè¯„ä¼°å‡½æ•°
# ============================================================================

def train_and_evaluate(X_train, y_train, X_val, y_val, lambda_reg,
                       n_epochs=300, learning_rate=0.05, verbose=False):
    """
    è®­ç»ƒæ¨¡å‹å¹¶è¿”å›éªŒè¯æ€§èƒ½

    å‚æ•°:
        X_train, y_train: è®­ç»ƒæ•°æ®
        X_val, y_val: éªŒè¯æ•°æ®
        lambda_reg: L2æ­£åˆ™åŒ–å¼ºåº¦
        n_epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    è¿”å›:
        final_train_acc: æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡
        final_val_acc: æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡
        final_weight_norm: æœ€ç»ˆæƒé‡èŒƒæ•°
        history: è®­ç»ƒå†å²
    """
    model = L2RegularizedNetwork(lambda_reg=lambda_reg)

    history = {
        'train_acc': [],
        'val_acc': [],
        'train_loss': [],
        'val_loss': []
    }

    for epoch in range(n_epochs):
        # å‰å‘ä¼ æ’­
        model.forward(X_train)

        # åå‘ä¼ æ’­
        grads = model.backward(X_train, y_train)

        # å‚æ•°æ›´æ–°
        params = model.get_params()
        updated_params = [p - learning_rate * g for p, g in zip(params, grads)]
        model.set_params(updated_params)

        # è®°å½•æŒ‡æ ‡
        if epoch % 10 == 0:
            train_acc = model.compute_accuracy(X_train, y_train)
            val_acc = model.compute_accuracy(X_val, y_val)
            train_loss = model.compute_loss(X_train, y_train)
            val_loss = model.compute_loss(X_val, y_val)

            history['train_acc'].append(train_acc)
            history['val_acc'].append(val_acc)
            history['train_loss'].append(train_loss)
            history['val_loss'].append(val_loss)

            if verbose and epoch % 100 == 0:
                print(f"  Epoch {epoch}: Train={train_acc:.4f}, Val={val_acc:.4f}")

    final_train_acc = model.compute_accuracy(X_train, y_train)
    final_val_acc = model.compute_accuracy(X_val, y_val)
    final_weight_norm = model.get_weight_norm()

    return final_train_acc, final_val_acc, final_weight_norm, history, model


# ============================================================================
# ç¬¬6éƒ¨åˆ†ï¼šÎ»æœç´¢å®éªŒ
# ============================================================================

if __name__ == "__main__":

    # =====================================
    # 1. å‡†å¤‡æ•°æ®
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬1æ­¥ï¼šå‡†å¤‡æ•°æ®")
    print("=" * 70)

    # ç”Ÿæˆæœˆç‰™å½¢æ•°æ®
    X, y = make_moons(n_samples=300, noise=0.25, random_state=42)

    # åˆ’åˆ†ï¼šè®­ç»ƒé›† 60%ï¼ŒéªŒè¯é›† 20%ï¼Œæµ‹è¯•é›† 20%
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2
    )

    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_val = scaler.transform(X_val)
    X_test = scaler.transform(X_test)

    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")
    print(f"éªŒè¯é›†å¤§å°: {X_val.shape[0]}")
    print(f"æµ‹è¯•é›†å¤§å°: {X_test.shape[0]}")

    # =====================================
    # 2. å®šä¹‰å€™é€‰Î»å€¼
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬2æ­¥ï¼šå®šä¹‰å€™é€‰Î»å€¼")
    print("=" * 70)

    # ä½¿ç”¨å¯¹æ•°å°ºåº¦çš„å€™é€‰å€¼
    # ä»10^-4åˆ°10^1ï¼Œå…±6ä¸ªæ•°é‡çº§
    lambda_candidates = [0.0001, 0.001, 0.01, 0.1, 1.0]

    print("å€™é€‰Î»å€¼:")
    for lam in lambda_candidates:
        print(f"  Î» = {lam}")

    # =====================================
    # 3. ç½‘æ ¼æœç´¢
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬3æ­¥ï¼šç½‘æ ¼æœç´¢æœ€ä½³Î»")
    print("=" * 70)

    results = {}

    for lam in lambda_candidates:
        print(f"\n{'â”€' * 50}")
        print(f"æµ‹è¯• Î» = {lam}")
        print(f"{'â”€' * 50}")

        train_acc, val_acc, weight_norm, history, model = train_and_evaluate(
            X_train, y_train, X_val, y_val,
            lambda_reg=lam,
            n_epochs=300,
            learning_rate=0.05,
            verbose=True
        )

        results[lam] = {
            'train_acc': train_acc,
            'val_acc': val_acc,
            'weight_norm': weight_norm,
            'history': history,
            'model': model
        }

        print(f"æœ€ç»ˆç»“æœ: Train={train_acc:.4f}, Val={val_acc:.4f}, ||W||={weight_norm:.4f}")

    # =====================================
    # 4. æ‰¾å‡ºæœ€ä½³Î»
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬4æ­¥ï¼šç¡®å®šæœ€ä½³Î»")
    print("=" * 70)

    best_lambda = max(results, key=lambda x: results[x]['val_acc'])
    best_val_acc = results[best_lambda]['val_acc']

    print(f"\nğŸ† æœ€ä½³Î»å€¼: {best_lambda}")
    print(f"   éªŒè¯é›†å‡†ç¡®ç‡: {best_val_acc:.4f}")

    # =====================================
    # 5. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æœ€ä½³æ¨¡å‹
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬5æ­¥ï¼šåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°")
    print("=" * 70)

    best_model = results[best_lambda]['model']
    test_acc = best_model.compute_accuracy(X_test, y_test)

    print(f"\nä½¿ç”¨æœ€ä½³Î» = {best_lambda}:")
    print(f"  è®­ç»ƒå‡†ç¡®ç‡: {results[best_lambda]['train_acc']:.4f}")
    print(f"  éªŒè¯å‡†ç¡®ç‡: {results[best_lambda]['val_acc']:.4f}")
    print(f"  æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}")

    # =====================================
    # 6. å¯è§†åŒ–ç»“æœ
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬6æ­¥ï¼šå¯è§†åŒ–ç»“æœ")
    print("=" * 70)

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # ----- å›¾1ï¼šéªŒè¯å‡†ç¡®ç‡ vs Î» -----
    ax1 = axes[0, 0]
    train_accs = [results[lam]['train_acc'] for lam in lambda_candidates]
    val_accs = [results[lam]['val_acc'] for lam in lambda_candidates]

    ax1.semilogx(lambda_candidates, train_accs, 'o-', linewidth=2, markersize=8,
                 label='è®­ç»ƒå‡†ç¡®ç‡', color='#3498db')
    ax1.semilogx(lambda_candidates, val_accs, 's-', linewidth=2, markersize=8,
                 label='éªŒè¯å‡†ç¡®ç‡', color='#e74c3c')
    ax1.axvline(x=best_lambda, color='green', linestyle='--', linewidth=2,
                label=f'æœ€ä½³Î»={best_lambda}')

    ax1.set_xlabel('Î» (å¯¹æ•°å°ºåº¦)', fontsize=11)
    ax1.set_ylabel('Accuracy', fontsize=11)
    ax1.set_title('å‡†ç¡®ç‡ vs æ­£åˆ™åŒ–å¼ºåº¦Î»', fontsize=12, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # ----- å›¾2ï¼šæƒé‡èŒƒæ•° vs Î» -----
    ax2 = axes[0, 1]
    weight_norms = [results[lam]['weight_norm'] for lam in lambda_candidates]

    ax2.semilogx(lambda_candidates, weight_norms, 'D-', linewidth=2, markersize=8,
                 color='#9b59b6')
    ax2.axvline(x=best_lambda, color='green', linestyle='--', linewidth=2)

    ax2.set_xlabel('Î» (å¯¹æ•°å°ºåº¦)', fontsize=11)
    ax2.set_ylabel('||W|| (æƒé‡L2èŒƒæ•°)', fontsize=11)
    ax2.set_title('æƒé‡èŒƒæ•° vs æ­£åˆ™åŒ–å¼ºåº¦Î»', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)

    # æ·»åŠ æ³¨é‡Š
    ax2.annotate('Î»å¢å¤§\næƒé‡ç¼©å°',
                 xy=(0.5, weight_norms[3]),
                 xytext=(0.2, weight_norms[3] + 1),
                 fontsize=10,
                 arrowprops=dict(arrowstyle='->', color='gray'))

    # ----- å›¾3ï¼šä¸åŒÎ»çš„å­¦ä¹ æ›²çº¿ -----
    ax3 = axes[1, 0]
    colors = plt.cm.viridis(np.linspace(0, 1, len(lambda_candidates)))

    for i, lam in enumerate(lambda_candidates):
        epochs = np.arange(len(results[lam]['history']['val_acc'])) * 10
        ax3.plot(epochs, results[lam]['history']['val_acc'],
                 linewidth=2, color=colors[i], label=f'Î»={lam}')

    ax3.set_xlabel('Epoch', fontsize=11)
    ax3.set_ylabel('éªŒè¯å‡†ç¡®ç‡', fontsize=11)
    ax3.set_title('ä¸åŒÎ»çš„éªŒè¯å‡†ç¡®ç‡æ›²çº¿', fontsize=12, fontweight='bold')
    ax3.legend()
    ax3.grid(True, alpha=0.3)

    # ----- å›¾4ï¼šç»“æœæ±‡æ€»è¡¨ -----
    ax4 = axes[1, 1]

    summary_text = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Î»æœç´¢å®éªŒç»“æœæ±‡æ€»                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  ğŸ“Š æœç´¢ç»“æœ:                                                    â•‘
â•‘                                                                  â•‘
â•‘  {'Î»å€¼':<12} {'è®­ç»ƒå‡†ç¡®ç‡':<12} {'éªŒè¯å‡†ç¡®ç‡':<12} {'æƒé‡èŒƒæ•°':<12}          â•‘
â•‘  {'â”€'*52}   â•‘
"""
    for lam in lambda_candidates:
        star = ' â­' if lam == best_lambda else ''
        summary_text += f"""â•‘  {lam:<12} {results[lam]['train_acc']:<12.4f} {results[lam]['val_acc']:<12.4f} {results[lam]['weight_norm']:<12.4f}{star}â•‘
"""

    summary_text += f"""â•‘                                                                  â•‘
â•‘  ğŸ† æœ€ä½³Î»å€¼: {best_lambda}                                                â•‘
â•‘                                                                  â•‘
â•‘  ğŸ“ˆ æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f}                                      â•‘
â•‘                                                                  â•‘
â•‘  ğŸ’¡ è§‚å¯Ÿç»“è®º:                                                    â•‘
â•‘    â€¢ Î»è¿‡å°: è¿‡æ‹Ÿåˆ (è®­ç»ƒé«˜ï¼ŒéªŒè¯ä½)                               â•‘
â•‘    â€¢ Î»è¿‡å¤§: æ¬ æ‹Ÿåˆ (è®­ç»ƒå’ŒéªŒè¯éƒ½ä½)                               â•‘
â•‘    â€¢ æœ€ä½³Î»: åå·®-æ–¹å·®å¹³è¡¡ç‚¹                                      â•‘
â•‘                                                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

    ax4.text(0.02, 0.5, summary_text, fontsize=8.5, verticalalignment='center',
             bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.3))
    ax4.set_xlim(0, 1)
    ax4.set_ylim(0, 1)
    ax4.axis('off')

    plt.tight_layout()
    plt.savefig('/Users/lyh/Desktop/ Machine Learning/neural_networks/lambda_search_results.png',
                dpi=150, bbox_inches='tight')
    plt.show()

    # =====================================
    # 7. åå·®-æ–¹å·®åˆ†æå›¾
    # =====================================
    print("\n" + "=" * 70)
    print("ç¬¬7æ­¥ï¼šåå·®-æ–¹å·®æƒè¡¡åˆ†æ")
    print("=" * 70)

    fig, ax = plt.subplots(figsize=(10, 6))

    # è®¡ç®—åå·®å’Œæ–¹å·®çš„è¿‘ä¼¼æŒ‡æ ‡
    # åå·® â‰ˆ 1 - è®­ç»ƒå‡†ç¡®ç‡ï¼ˆè®­ç»ƒè¯¯å·®ï¼‰
    # æ–¹å·® â‰ˆ è®­ç»ƒå‡†ç¡®ç‡ - éªŒè¯å‡†ç¡®ç‡ï¼ˆæ³›åŒ–å·®è·ï¼‰
    biases = [1 - results[lam]['train_acc'] for lam in lambda_candidates]
    variances = [results[lam]['train_acc'] - results[lam]['val_acc']
                 for lam in lambda_candidates]
    total_errors = [1 - results[lam]['val_acc'] for lam in lambda_candidates]

    ax.semilogx(lambda_candidates, biases, 'o-', linewidth=2, markersize=8,
                label='åå·® (è®­ç»ƒè¯¯å·®)', color='#3498db')
    ax.semilogx(lambda_candidates, variances, 's-', linewidth=2, markersize=8,
                label='æ–¹å·® (æ³›åŒ–å·®è·)', color='#e74c3c')
    ax.semilogx(lambda_candidates, total_errors, '^-', linewidth=2, markersize=8,
                label='æ€»è¯¯å·® (éªŒè¯è¯¯å·®)', color='#2ecc71')
    ax.axvline(x=best_lambda, color='purple', linestyle='--', linewidth=2,
               label=f'æœ€ä½³Î»={best_lambda}')

    ax.set_xlabel('Î» (æ­£åˆ™åŒ–å¼ºåº¦)', fontsize=12)
    ax.set_ylabel('è¯¯å·®', fontsize=12)
    ax.set_title('åå·®-æ–¹å·®æƒè¡¡ (Bias-Variance Tradeoff)', fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)

    # æ·»åŠ åŒºåŸŸæ ‡æ³¨
    ax.annotate('æ¬ æ‹ŸåˆåŒºåŸŸ\n(é«˜åå·®)',
                xy=(lambda_candidates[-1], biases[-1]),
                xytext=(lambda_candidates[-1] * 2, biases[-1] + 0.05),
                fontsize=10,
                arrowprops=dict(arrowstyle='->', color='gray'))

    ax.annotate('è¿‡æ‹ŸåˆåŒºåŸŸ\n(é«˜æ–¹å·®)',
                xy=(lambda_candidates[0], variances[0]),
                xytext=(lambda_candidates[0] * 0.1, variances[0] + 0.02),
                fontsize=10,
                arrowprops=dict(arrowstyle='->', color='gray'))

    plt.tight_layout()
    plt.savefig('/Users/lyh/Desktop/ Machine Learning/neural_networks/bias_variance_tradeoff.png',
                dpi=150, bbox_inches='tight')
    plt.show()

    # =====================================
    # 8. æ‰“å°æœ€ç»ˆæ€»ç»“
    # =====================================
    print("\n" + "=" * 70)
    print("å®éªŒå®Œæˆï¼æœ€ç»ˆæ€»ç»“")
    print("=" * 70)

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                        Î»æœç´¢å®éªŒå®Œæˆï¼                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                       â•‘
â•‘  ğŸ“‹ å®éªŒè®¾ç½®:                                                         â•‘
â•‘    â€¢ æ•°æ®é›†: make_moons (300æ ·æœ¬, noise=0.25)                         â•‘
â•‘    â€¢ åˆ’åˆ†: è®­ç»ƒ60%, éªŒè¯20%, æµ‹è¯•20%                                  â•‘
â•‘    â€¢ å€™é€‰Î»: [0.0001, 0.001, 0.01, 0.1, 1.0]                          â•‘
â•‘                                                                       â•‘
â•‘  ğŸ† æœ€ä½³ç»“æœ:                                                         â•‘
â•‘    â€¢ æœ€ä½³Î»: {best_lambda}                                                    â•‘
â•‘    â€¢ éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}                                           â•‘
â•‘    â€¢ æµ‹è¯•å‡†ç¡®ç‡: {test_acc:.4f}                                           â•‘
â•‘                                                                       â•‘
â•‘  ğŸ“š å­¦ä¹ è¦ç‚¹:                                                         â•‘
â•‘                                                                       â•‘
â•‘    1. éªŒè¯é›†é€‰æ‹©è¶…å‚æ•°                                                â•‘
â•‘       â€¢ è®­ç»ƒé›†: è®­ç»ƒæ¨¡å‹                                              â•‘
â•‘       â€¢ éªŒè¯é›†: é€‰æ‹©è¶…å‚æ•°                                            â•‘
â•‘       â€¢ æµ‹è¯•é›†: æœ€ç»ˆè¯„ä¼°ï¼ˆåªç”¨ä¸€æ¬¡ï¼ï¼‰                                â•‘
â•‘                                                                       â•‘
â•‘    2. å¯¹æ•°å°ºåº¦æœç´¢                                                    â•‘
â•‘       â€¢ Î»çš„æœ€ä½³å€¼å¯èƒ½è·¨è¶Šå¤šä¸ªæ•°é‡çº§                                   â•‘
â•‘       â€¢ ä½¿ç”¨ 10^(-4), 10^(-3), ... æ›´é«˜æ•ˆ                            â•‘
â•‘                                                                       â•‘
â•‘    3. åå·®-æ–¹å·®æƒè¡¡                                                   â•‘
â•‘       â€¢ Î»å°: ä½åå·®ï¼Œé«˜æ–¹å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰                                 â•‘
â•‘       â€¢ Î»å¤§: é«˜åå·®ï¼Œä½æ–¹å·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰                                 â•‘
â•‘       â€¢ æœ€ä½³Î»: åœ¨ä¸¤è€…ä¹‹é—´å–å¾—å¹³è¡¡                                     â•‘
â•‘                                                                       â•‘
â•‘    4. æƒé‡èŒƒæ•°éšÎ»å˜åŒ–                                                 â•‘
â•‘       â€¢ Î»å¢å¤§ â†’ æƒé‡èŒƒæ•°å‡å°                                         â•‘
â•‘       â€¢ è¿™å°±æ˜¯"æƒé‡è¡°å‡"åç§°çš„ç”±æ¥                                    â•‘
â•‘                                                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    print("âœ… ç»ƒä¹ 3å®Œæˆï¼")
