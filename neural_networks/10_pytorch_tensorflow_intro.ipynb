{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬10ç« ï¼šPyTorchä¸TensorFlowå…¥é—¨\n",
    "\n",
    "> **å­¦ä¹ ç›®æ ‡**\n",
    "> - ç†è§£ä¸ºä»€ä¹ˆéœ€è¦æ·±åº¦å­¦ä¹ æ¡†æ¶\n",
    "> - æŒæ¡PyTorchçš„æ ¸å¿ƒæ¦‚å¿µï¼ˆå¼ é‡ã€è‡ªåŠ¨æ±‚å¯¼ã€æ¨¡å‹å®šä¹‰ï¼‰\n",
    "> - æŒæ¡TensorFlow/Kerasçš„æ ¸å¿ƒæ¦‚å¿µ\n",
    "> - ç”¨ä¸¤ä¸ªæ¡†æ¶å®ç°å®Œæ•´çš„ç¥ç»ç½‘ç»œè®­ç»ƒ\n",
    "> - äº†è§£ä¸¤ä¸ªæ¡†æ¶çš„å¯¹æ¯”å’Œé€‰æ‹©ç­–ç•¥\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Ÿ\n",
    "\n",
    "### ä»é›¶å®ç° vs ä½¿ç”¨æ¡†æ¶\n",
    "\n",
    "**å‰9ç« æˆ‘ä»¬åšäº†ä»€ä¹ˆï¼Ÿ**\n",
    "- ä»é›¶å®ç°ï¼šæ„ŸçŸ¥æœºã€MLPã€åå‘ä¼ æ’­ã€ä¼˜åŒ–å™¨ã€æ­£åˆ™åŒ–...\n",
    "- ç›®çš„ï¼š**æ·±å…¥ç†è§£åº•å±‚åŸç†**\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¦å­¦æ¡†æ¶ï¼Ÿ**\n",
    "- âœ… **è‡ªåŠ¨æ±‚å¯¼**ï¼šä¸ç”¨æ‰‹å†™åå‘ä¼ æ’­å…¬å¼\n",
    "- âœ… **GPUåŠ é€Ÿ**ï¼šè‡ªåŠ¨åˆ©ç”¨GPUå¹¶è¡Œè®¡ç®—\n",
    "- âœ… **æ¨¡å‹åº“**ï¼šé¢„è®­ç»ƒæ¨¡å‹ã€æ ‡å‡†å±‚\n",
    "- âœ… **è°ƒè¯•å·¥å…·**ï¼šå¯è§†åŒ–ã€ç›‘æ§\n",
    "- âœ… **ç”Ÿäº§éƒ¨ç½²**ï¼šæ¨¡å‹ä¿å­˜ã€æ¨ç†ä¼˜åŒ–\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¥ ä¸¤å¤§ä¸»æµæ¡†æ¶\n",
    "\n",
    "| ç‰¹æ€§ | PyTorch | TensorFlow/Keras |\n",
    "|------|---------|------------------|\n",
    "| **å¼€å‘è€…** | Meta (Facebook) | Google |\n",
    "| **å‘å¸ƒæ—¶é—´** | 2016 | 2015 (TF) / 2015 (Keras) |\n",
    "| **ç¼–ç¨‹é£æ ¼** | åŠ¨æ€å›¾ï¼ˆçµæ´»ï¼‰ | é™æ€å›¾ï¼ˆTF 1.xï¼‰+ åŠ¨æ€å›¾ï¼ˆTF 2.xï¼‰ |\n",
    "| **å­¦ä¹ æ›²çº¿** | é€‚ä¸­ï¼Œæ›´Pythonic | Kerasæ˜“å­¦ï¼ŒTFåº•å±‚å¤æ‚ |\n",
    "| **ç ”ç©¶ç¤¾åŒº** | â­â­â­â­â­ å­¦æœ¯ç•Œä¸»æµ | â­â­â­â­ å·¥ä¸šç•Œå¹¿æ³› |\n",
    "| **ç”Ÿäº§éƒ¨ç½²** | TorchScriptã€ONNX | TensorFlow Servingã€TFLite |\n",
    "| **è°ƒè¯•** | æ˜“äºè°ƒè¯•ï¼ˆPython debuggerï¼‰ | TF 2.xæ”¹è¿›æ˜æ˜¾ |\n",
    "\n",
    "**æœ¬ç« ç­–ç•¥ï¼š**\n",
    "- é‡ç‚¹å­¦ä¹  **PyTorch**ï¼ˆç ”ç©¶å’Œæ•™å­¦çš„é¦–é€‰ï¼‰\n",
    "- ç®€è¦ä»‹ç» **TensorFlow/Keras**ï¼ˆäº†è§£å·¥ä¸šç•Œå·¥å…·ï¼‰\n",
    "- åŒä¸€ä»»åŠ¡ç”¨ä¸¤ä¸ªæ¡†æ¶å®ç°ï¼Œä¾¿äºå¯¹æ¯”\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥æ˜¯å¦å®‰è£…äº†PyTorchå’ŒTensorFlow\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "    print(f\"   CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorchæœªå®‰è£…\")\n",
    "    print(\"   å®‰è£…å‘½ä»¤: pip install torch torchvision\")\n",
    "\n",
    "print()\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"âœ… TensorFlowç‰ˆæœ¬: {tf.__version__}\")\n",
    "    print(f\"   GPUå¯ç”¨: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"   GPUè®¾å¤‡: {gpus[0].name}\")\n",
    "except ImportError:\n",
    "    print(\"âŒ TensorFlowæœªå®‰è£…\")\n",
    "    print(\"   å®‰è£…å‘½ä»¤: pip install tensorflow\")\n",
    "\n",
    "# é€šç”¨åº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾æ ·å¼\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"\\nâœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ PyTorchåŸºç¡€\n",
    "\n",
    "### ğŸ“¦ æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "PyTorchçš„æ ¸å¿ƒæ˜¯ **Tensorï¼ˆå¼ é‡ï¼‰** å’Œ **Autogradï¼ˆè‡ªåŠ¨æ±‚å¯¼ï¼‰**\n",
    "\n",
    "#### ä»€ä¹ˆæ˜¯Tensorï¼Ÿ\n",
    "- Tensor = å¤šç»´æ•°ç»„ï¼ˆç±»ä¼¼NumPyçš„ndarrayï¼‰\n",
    "- ä½†å¯ä»¥åœ¨GPUä¸Šè¿è¡Œï¼Œå¹¶æ”¯æŒè‡ªåŠ¨æ±‚å¯¼\n",
    "\n",
    "**ç»´åº¦å¯¹åº”ï¼š**\n",
    "- 0ç»´ï¼šæ ‡é‡ï¼ˆscalarï¼‰\n",
    "- 1ç»´ï¼šå‘é‡ï¼ˆvectorï¼‰\n",
    "- 2ç»´ï¼šçŸ©é˜µï¼ˆmatrixï¼‰\n",
    "- 3ç»´+ï¼šå¼ é‡ï¼ˆtensorï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’» å¼ é‡åŸºç¡€æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  PyTorchå¼ é‡åŸºç¡€\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== 1. åˆ›å»ºå¼ é‡ =====\n",
    "print(\"\\n1ï¸âƒ£ åˆ›å»ºå¼ é‡çš„å¤šç§æ–¹å¼:\")\n",
    "\n",
    "# ä»Pythonåˆ—è¡¨åˆ›å»º\n",
    "x1 = torch.tensor([1, 2, 3, 4])\n",
    "print(f\"\\nä»åˆ—è¡¨åˆ›å»º: {x1}\")\n",
    "print(f\"  å½¢çŠ¶: {x1.shape}, æ•°æ®ç±»å‹: {x1.dtype}\")\n",
    "\n",
    "# åˆ›å»ºå…¨é›¶å¼ é‡\n",
    "x2 = torch.zeros(2, 3)  # 2x3çŸ©é˜µ\n",
    "print(f\"\\nå…¨é›¶å¼ é‡:\\n{x2}\")\n",
    "\n",
    "# åˆ›å»ºå…¨ä¸€å¼ é‡\n",
    "x3 = torch.ones(3, 4)\n",
    "print(f\"\\nå…¨ä¸€å¼ é‡:\\n{x3}\")\n",
    "\n",
    "# åˆ›å»ºéšæœºå¼ é‡ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰\n",
    "x4 = torch.randn(2, 3)  # æ ‡å‡†æ­£æ€åˆ†å¸ƒ\n",
    "print(f\"\\néšæœºå¼ é‡ï¼ˆN(0,1)ï¼‰:\\n{x4}\")\n",
    "\n",
    "# ä»NumPyæ•°ç»„åˆ›å»º\n",
    "np_array = np.array([[1, 2], [3, 4]])\n",
    "x5 = torch.from_numpy(np_array)\n",
    "print(f\"\\nä»NumPyåˆ›å»º:\\n{x5}\")\n",
    "\n",
    "# ===== 2. å¼ é‡è¿ç®— =====\n",
    "print(\"\\n\\n2ï¸âƒ£ å¼ é‡è¿ç®—:\")\n",
    "\n",
    "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = torch.tensor([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "# åŠ æ³•\n",
    "print(f\"\\na + b =\\n{a + b}\")\n",
    "\n",
    "# é€å…ƒç´ ä¹˜æ³•\n",
    "print(f\"\\na * b (é€å…ƒç´ ) =\\n{a * b}\")\n",
    "\n",
    "# çŸ©é˜µä¹˜æ³•\n",
    "print(f\"\\na @ b (çŸ©é˜µä¹˜æ³•) =\\n{a @ b}\")\n",
    "# æˆ–è€…ä½¿ç”¨ torch.matmul(a, b)\n",
    "\n",
    "# ===== 3. å½¢çŠ¶æ“ä½œ =====\n",
    "print(\"\\n\\n3ï¸âƒ£ å½¢çŠ¶æ“ä½œ:\")\n",
    "\n",
    "x = torch.randn(2, 3, 4)  # 3ç»´å¼ é‡\n",
    "print(f\"\\nåŸå§‹å½¢çŠ¶: {x.shape}\")\n",
    "\n",
    "# reshapeï¼ˆæ”¹å˜å½¢çŠ¶ï¼‰\n",
    "x_reshaped = x.reshape(2, 12)  # å˜æˆ 2x12\n",
    "print(f\"reshapeå: {x_reshaped.shape}\")\n",
    "\n",
    "# viewï¼ˆç±»ä¼¼reshapeï¼Œä½†è¦æ±‚å†…å­˜è¿ç»­ï¼‰\n",
    "x_viewed = x.view(6, 4)\n",
    "print(f\"viewå: {x_viewed.shape}\")\n",
    "\n",
    "# transposeï¼ˆè½¬ç½®ï¼‰\n",
    "x_t = x_viewed.T  # æˆ– x_viewed.transpose(0, 1)\n",
    "print(f\"è½¬ç½®å: {x_t.shape}\")\n",
    "\n",
    "# ===== 4. ç´¢å¼•å’Œåˆ‡ç‰‡ =====\n",
    "print(\"\\n\\n4ï¸âƒ£ ç´¢å¼•å’Œåˆ‡ç‰‡:\")\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], \n",
    "                  [4, 5, 6], \n",
    "                  [7, 8, 9]])\n",
    "print(f\"\\nåŸå§‹å¼ é‡:\\n{x}\")\n",
    "print(f\"ç¬¬1è¡Œ: {x[0, :]}\")\n",
    "print(f\"ç¬¬2åˆ—: {x[:, 1]}\")\n",
    "print(f\"å³ä¸‹è§’2x2:\\n{x[1:, 1:]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“ è‡ªåŠ¨æ±‚å¯¼ï¼ˆAutogradï¼‰\n",
    "\n",
    "**è¿™æ˜¯PyTorchçš„æ ¸å¿ƒé­”æ³•ï¼**\n",
    "\n",
    "#### åŸç†\n",
    "- æ¯ä¸ªå¼ é‡éƒ½æœ‰ä¸€ä¸ª `requires_grad` å±æ€§\n",
    "- è®¾ç½®ä¸º `True` åï¼ŒPyTorchä¼šè®°å½•æ‰€æœ‰æ“ä½œï¼ˆæ„å»ºè®¡ç®—å›¾ï¼‰\n",
    "- è°ƒç”¨ `.backward()` æ—¶ï¼Œè‡ªåŠ¨è®¡ç®—æ¢¯åº¦\n",
    "\n",
    "#### ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ\n",
    "- ä¸ç”¨æ‰‹å†™åå‘ä¼ æ’­ï¼\n",
    "- æ— è®ºç½‘ç»œå¤šå¤æ‚ï¼Œè‡ªåŠ¨è®¡ç®—æ‰€æœ‰æ¢¯åº¦\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"  PyTorchè‡ªåŠ¨æ±‚å¯¼ç¤ºä¾‹\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== ç¤ºä¾‹1ï¼šç®€å•å‡½æ•°çš„æ¢¯åº¦ =====\n",
    "print(\"\\nç¤ºä¾‹1: è®¡ç®— f(x) = x^2 åœ¨ x=3 å¤„çš„æ¢¯åº¦\")\n",
    "print(\"      ç†è®ºå€¼: df/dx = 2x = 2*3 = 6\")\n",
    "\n",
    "# åˆ›å»ºéœ€è¦æ¢¯åº¦çš„å¼ é‡\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "print(f\"\\nx = {x}, requires_grad = {x.requires_grad}\")\n",
    "\n",
    "# å‰å‘è®¡ç®—\n",
    "y = x ** 2\n",
    "print(f\"y = x^2 = {y}\")\n",
    "\n",
    "# åå‘ä¼ æ’­ï¼ˆè®¡ç®—æ¢¯åº¦ï¼‰\n",
    "y.backward()  # è‡ªåŠ¨è®¡ç®— dy/dx\n",
    "\n",
    "# æŸ¥çœ‹æ¢¯åº¦\n",
    "print(f\"dy/dx = {x.grad}\")\n",
    "print(f\"âœ… æ¢¯åº¦è®¡ç®—æ­£ç¡®ï¼\")\n",
    "\n",
    "# ===== ç¤ºä¾‹2ï¼šå¤šå˜é‡å‡½æ•° =====\n",
    "print(\"\\n\\nç¤ºä¾‹2: è®¡ç®— f(x, y) = x^2 + 2xy + y^2 çš„æ¢¯åº¦\")\n",
    "print(\"      ç†è®ºå€¼: âˆ‚f/âˆ‚x = 2x + 2y, âˆ‚f/âˆ‚y = 2x + 2y\")\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# å‰å‘è®¡ç®—\n",
    "f = x**2 + 2*x*y + y**2\n",
    "print(f\"\\nf(2, 3) = {f}\")\n",
    "\n",
    "# åå‘ä¼ æ’­\n",
    "f.backward()\n",
    "\n",
    "print(f\"âˆ‚f/âˆ‚x = {x.grad} (ç†è®ºå€¼: 2*2 + 2*3 = 10)\")\n",
    "print(f\"âˆ‚f/âˆ‚y = {y.grad} (ç†è®ºå€¼: 2*2 + 2*3 = 10)\")\n",
    "\n",
    "# ===== ç¤ºä¾‹3ï¼šæ¨¡æ‹Ÿç¥ç»ç½‘ç»œçš„å‰å‘å’Œåå‘ä¼ æ’­ =====\n",
    "print(\"\\n\\nç¤ºä¾‹3: æ¨¡æ‹Ÿç¥ç»ç½‘ç»œ y = W @ x + b\")\n",
    "\n",
    "# è¾“å…¥\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# å‚æ•°ï¼ˆéœ€è¦æ¢¯åº¦ï¼‰\n",
    "W = torch.randn(2, 3, requires_grad=True)  # æƒé‡çŸ©é˜µ\n",
    "b = torch.randn(2, requires_grad=True)      # åç½®å‘é‡\n",
    "\n",
    "# å‰å‘ä¼ æ’­\n",
    "y = W @ x + b\n",
    "loss = y.sum()  # ç®€å•çš„æŸå¤±å‡½æ•°\n",
    "\n",
    "print(f\"è¾“å‡º y = {y}\")\n",
    "print(f\"æŸå¤± loss = {loss}\")\n",
    "\n",
    "# åå‘ä¼ æ’­\n",
    "loss.backward()\n",
    "\n",
    "print(f\"\\næ¢¯åº¦å·²è®¡ç®—:\")\n",
    "print(f\"  dL/dW çš„å½¢çŠ¶: {W.grad.shape}\")\n",
    "print(f\"  dL/db çš„å½¢çŠ¶: {b.grad.shape}\")\n",
    "print(f\"\\nâœ… PyTorchè‡ªåŠ¨è®¡ç®—äº†æ‰€æœ‰æ¢¯åº¦ï¼\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ PyTorch vs TensorFlow/Kerasï¼šè¯¦ç»†å¯¹æ¯”\n",
    "\n",
    "### ğŸ“Š ä»£ç é£æ ¼å¯¹æ¯”\n",
    "\n",
    "| ä»»åŠ¡ | PyTorch | TensorFlow/Keras |\n",
    "|------|---------|------------------|\n",
    "| **æ¨¡å‹å®šä¹‰** | `class MyModel(nn.Module)` | `keras.Sequential([...])` |\n",
    "| **å‰å‘ä¼ æ’­** | æ˜¾å¼å®šä¹‰ `forward()` | è‡ªåŠ¨å¤„ç† |\n",
    "| **æŸå¤±è®¡ç®—** | æ‰‹åŠ¨è®¡ç®— | `model.compile(loss=...)` |\n",
    "| **è®­ç»ƒå¾ªç¯** | æ‰‹åŠ¨ç¼–å†™ï¼ˆçµæ´»ï¼‰| `model.fit()` ä¸€è¡Œæå®š |\n",
    "| **æ¢¯åº¦æ›´æ–°** | æ‰‹åŠ¨è°ƒç”¨ `.backward()` | è‡ªåŠ¨å¤„ç† |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ å¦‚ä½•é€‰æ‹©æ¡†æ¶ï¼Ÿ\n",
    "\n",
    "#### é€‰æ‹©PyTorchçš„åœºæ™¯ï¼š\n",
    "\n",
    "1. **å­¦æœ¯ç ”ç©¶** â­â­â­â­â­\n",
    "   - éœ€è¦è‡ªå®šä¹‰æŸå¤±å‡½æ•°ã€ç½‘ç»œå±‚\n",
    "   - å®éªŒæ–°ç®—æ³•\n",
    "   - å¤§å¤šæ•°é¡¶ä¼šè®ºæ–‡ä½¿ç”¨PyTorch\n",
    "\n",
    "2. **éœ€è¦çµæ´»æ€§**\n",
    "   - åŠ¨æ€è®¡ç®—å›¾\n",
    "   - å¤æ‚çš„æ§åˆ¶æµï¼ˆif/else/forï¼‰\n",
    "   - æ˜“äºè°ƒè¯•\n",
    "\n",
    "3. **å­¦ä¹ æ·±åº¦å­¦ä¹ åŸç†**\n",
    "   - ä»£ç æ›´æ¥è¿‘æ•°å­¦å…¬å¼\n",
    "   - æ‰‹åŠ¨æ§åˆ¶è®­ç»ƒæµç¨‹\n",
    "\n",
    "#### é€‰æ‹©TensorFlow/Kerasçš„åœºæ™¯ï¼š\n",
    "\n",
    "1. **ç”Ÿäº§éƒ¨ç½²** â­â­â­â­â­\n",
    "   - TensorFlow Servingï¼ˆäº‘ç«¯ï¼‰\n",
    "   - TensorFlow Liteï¼ˆç§»åŠ¨ç«¯ï¼‰\n",
    "   - TensorFlow.jsï¼ˆæµè§ˆå™¨ï¼‰\n",
    "\n",
    "2. **å¿«é€ŸåŸå‹**\n",
    "   - Keras APIæç®€\n",
    "   - é€‚åˆå·¥ç¨‹å¸ˆå¿«é€Ÿå®ç°\n",
    "\n",
    "3. **ä¼ä¸šçº§åº”ç”¨**\n",
    "   - Googleç”Ÿæ€ç³»ç»Ÿ\n",
    "   - å®Œå–„çš„éƒ¨ç½²å·¥å…·é“¾\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ æœ€ä½³å®è·µå»ºè®®\n",
    "\n",
    "#### ğŸ“ å¯¹äºå­¦ä¹ è€…\n",
    "\n",
    "**æ¨èè·¯å¾„ï¼š**\n",
    "1. **æ·±å…¥å­¦PyTorch**\n",
    "   - ç†è§£æ¯ä¸ªæ­¥éª¤ï¼ˆå‰å‘ã€åå‘ã€ä¼˜åŒ–ï¼‰\n",
    "   - å®¹æ˜“ç†è§£åº•å±‚åŸç†\n",
    "   \n",
    "2. **å¿«é€Ÿä¸Šæ‰‹Keras**\n",
    "   - äº†è§£é«˜å±‚APIçš„ä¾¿åˆ©\n",
    "   - å¯¹æ¯”ç†è§£ä¸¤ç§é£æ ¼\n",
    "\n",
    "#### ğŸ¢ å¯¹äºå·¥ç¨‹å¸ˆ\n",
    "\n",
    "- **ç ”ç©¶/å®éªŒé˜¶æ®µ**ï¼šPyTorchï¼ˆçµæ´»ï¼‰\n",
    "- **ç”Ÿäº§éƒ¨ç½²é˜¶æ®µ**ï¼šTensorFlowï¼ˆæˆç†Ÿå·¥å…·ï¼‰\n",
    "- **æˆ–è€…**ï¼šPyTorchè®­ç»ƒ + ONNXè½¬æ¢ + TensorFlowéƒ¨ç½²\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ ç»¼åˆæ€»ç»“\n",
    "\n",
    "### ğŸ¯ æ ¸å¿ƒæ¦‚å¿µå›é¡¾\n",
    "\n",
    "| æ¦‚å¿µ | PyTorch | TensorFlow/Keras |\n",
    "|------|---------|------------------|\n",
    "| **å¼ é‡æ“ä½œ** | `torch.Tensor` | `tf.Tensor` |\n",
    "| **è‡ªåŠ¨æ±‚å¯¼** | `requires_grad=True` + `.backward()` | `tf.GradientTape()` |\n",
    "| **æ¨¡å‹å®šä¹‰** | ç»§æ‰¿ `nn.Module` | `keras.Sequential` æˆ– Functional API |\n",
    "| **å±‚å®šä¹‰** | `nn.Linear`, `nn.Conv2d` | `layers.Dense`, `layers.Conv2D` |\n",
    "| **æ¿€æ´»å‡½æ•°** | `F.relu`, `F.softmax` | `activation='relu'` |\n",
    "| **æŸå¤±å‡½æ•°** | `nn.CrossEntropyLoss()` | `loss='categorical_crossentropy'` |\n",
    "| **ä¼˜åŒ–å™¨** | `optim.Adam()` | `optimizer='adam'` |\n",
    "| **è®­ç»ƒå¾ªç¯** | æ‰‹åŠ¨ç¼–å†™ | `model.fit()` |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ ä»é›¶å®ç° vs æ¡†æ¶å®ç°å¯¹æ¯”\n",
    "\n",
    "**å‰9ç« æˆ‘ä»¬åšçš„äº‹ï¼ˆä»é›¶å®ç°ï¼‰ï¼š**\n",
    "\n",
    "```python\n",
    "# æ‰‹å†™å‰å‘ä¼ æ’­\n",
    "z1 = X @ W1 + b1\n",
    "a1 = relu(z1)\n",
    "z2 = a1 @ W2 + b2\n",
    "y_pred = softmax(z2)\n",
    "\n",
    "# æ‰‹å†™åå‘ä¼ æ’­\n",
    "dW2 = a1.T @ (y_pred - y_true)\n",
    "db2 = np.sum(y_pred - y_true, axis=0)\n",
    "da1 = (y_pred - y_true) @ W2.T\n",
    "dz1 = da1 * relu_derivative(z1)\n",
    "dW1 = X.T @ dz1\n",
    "db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "# æ‰‹å†™å‚æ•°æ›´æ–°\n",
    "W1 -= learning_rate * dW1\n",
    "W2 -= learning_rate * dW2\n",
    "```\n",
    "\n",
    "**æ¡†æ¶å®ç°ï¼ˆPyTorchï¼‰ï¼š**\n",
    "\n",
    "```python\n",
    "# å‰å‘ä¼ æ’­\n",
    "output = model(X)\n",
    "loss = criterion(output, y_true)\n",
    "\n",
    "# åå‘ä¼ æ’­+å‚æ•°æ›´æ–°ï¼ˆè‡ªåŠ¨ï¼ï¼‰\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "\n",
    "**æ”¶è·ï¼š**\n",
    "- âœ… ç†è§£åº•å±‚åŸç†ï¼ˆæ‰‹å†™å®ç°ï¼‰\n",
    "- âœ… æé«˜å¼€å‘æ•ˆç‡ï¼ˆä½¿ç”¨æ¡†æ¶ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ å»ºè®®\n",
    "\n",
    "#### 1ï¸âƒ£ æ·±å…¥PyTorch\n",
    "\n",
    "- **å®˜æ–¹æ•™ç¨‹**: [pytorch.org/tutorials](https://pytorch.org/tutorials)\n",
    "- **è¿›é˜¶è¯é¢˜**:\n",
    "  - è‡ªå®šä¹‰å±‚å’ŒæŸå¤±å‡½æ•°\n",
    "  - æ•°æ®åŠ è½½å’Œå¢å¼ºï¼ˆ`torch.utils.data`ï¼‰\n",
    "  - å¤šGPUè®­ç»ƒï¼ˆ`DataParallel`ï¼‰\n",
    "  - æ¨¡å‹ä¿å­˜å’ŒåŠ è½½\n",
    "\n",
    "#### 2ï¸âƒ£ å®æˆ˜é¡¹ç›®\n",
    "\n",
    "- **è®¡ç®—æœºè§†è§‰**: å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹\n",
    "- **è‡ªç„¶è¯­è¨€å¤„ç†**: æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æ\n",
    "- **æ—¶é—´åºåˆ—**: è‚¡ç¥¨é¢„æµ‹ã€å¤©æ°”é¢„æŠ¥\n",
    "\n",
    "#### 3ï¸âƒ£ éƒ¨ç½²æŠ€èƒ½\n",
    "\n",
    "- **æ¨¡å‹å‹ç¼©**: å‰ªæã€é‡åŒ–\n",
    "- **æ¨ç†ä¼˜åŒ–**: ONNXã€TorchScript\n",
    "- **äº‘ç«¯éƒ¨ç½²**: AWSã€GCPã€Azure\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‹ï¸ ç»ƒä¹ é¢˜\n",
    "\n",
    "### â­â­ ç»ƒä¹ 1ï¼šå®ç°è‡ªå®šä¹‰æ¿€æ´»å‡½æ•°\n",
    "\n",
    "**ä»»åŠ¡ï¼š** åœ¨PyTorchä¸­å®ç°Swishæ¿€æ´»å‡½æ•°ï¼š$f(x) = x \\cdot \\sigma(x)$\n",
    "\n",
    "**è¦æ±‚ï¼š**\n",
    "- ç»§æ‰¿ `nn.Module`\n",
    "- å®ç° `forward()` æ–¹æ³•\n",
    "- åœ¨æ¨¡å‹ä¸­ä½¿ç”¨\n",
    "\n",
    "**æç¤ºï¼š**\n",
    "```python\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        # å®ç° x * sigmoid(x)\n",
    "        pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### â­â­â­ ç»ƒä¹ 2ï¼šæ·»åŠ Dropoutå’ŒBatch Normalization\n",
    "\n",
    "**ä»»åŠ¡ï¼š** ä¿®æ”¹SimpleNNæ¨¡å‹ï¼Œæ·»åŠ ï¼š\n",
    "1. Dropoutå±‚ï¼ˆp=0.5ï¼‰\n",
    "2. Batch Normalizationå±‚\n",
    "\n",
    "**è¦æ±‚ï¼š**\n",
    "- åœ¨ä¸¤å±‚ä¹‹é—´æ·»åŠ \n",
    "- å¯¹æ¯”æœ‰æ— è¿™äº›å±‚çš„æ•ˆæœ\n",
    "\n",
    "---\n",
    "\n",
    "### â­â­â­â­ ç»ƒä¹ 3ï¼šå®ç°å­¦ä¹ ç‡è°ƒåº¦\n",
    "\n",
    "**ä»»åŠ¡ï¼š** ä½¿ç”¨ç¬¬9ç« å­¦åˆ°çš„å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ã€‚\n",
    "\n",
    "**è¦æ±‚ï¼š**\n",
    "1. ä½¿ç”¨ `torch.optim.lr_scheduler.CosineAnnealingLR`\n",
    "2. å¯è§†åŒ–å­¦ä¹ ç‡å˜åŒ–\n",
    "3. å¯¹æ¯”å›ºå®šå­¦ä¹ ç‡å’Œè°ƒåº¦å­¦ä¹ ç‡çš„æ•ˆæœ\n",
    "\n",
    "**å‚è€ƒï¼š**\n",
    "```python\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "for epoch in range(num_epochs):\n",
    "    train(...)\n",
    "    scheduler.step()  # æ›´æ–°å­¦ä¹ ç‡\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### â­â­â­â­â­ ç»ƒä¹ 4ï¼šå®ç°å®Œæ•´çš„MNISTè®­ç»ƒï¼ˆçœŸå®æ•°æ®ï¼‰\n",
    "\n",
    "**ä»»åŠ¡ï¼š** ä½¿ç”¨çœŸæ­£çš„MNISTæ•°æ®é›†ï¼ˆ28x28å›¾åƒï¼‰ã€‚\n",
    "\n",
    "**è¦æ±‚ï¼š**\n",
    "1. ä½¿ç”¨ `torchvision.datasets.MNIST` åŠ è½½æ•°æ®\n",
    "2. å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ç»“æ„\n",
    "3. è®­ç»ƒå¹¶è¾¾åˆ° >98% å‡†ç¡®ç‡\n",
    "4. å¯è§†åŒ–é”™è¯¯é¢„æµ‹çš„æ ·æœ¬\n",
    "\n",
    "**æç¤ºï¼š**\n",
    "```python\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ å­¦ä¹ æ£€æŸ¥ç‚¹\n",
    "\n",
    "å®Œæˆæœ¬ç« åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š\n",
    "\n",
    "- [ ] **ç†è§£ä¸ºä»€ä¹ˆéœ€è¦æ·±åº¦å­¦ä¹ æ¡†æ¶** è€Œä¸æ˜¯ä¸€ç›´ä»é›¶å®ç°\n",
    "- [ ] **æŒæ¡PyTorchæ ¸å¿ƒæ¦‚å¿µ** å¼ é‡ã€è‡ªåŠ¨æ±‚å¯¼ã€æ¨¡å‹å®šä¹‰\n",
    "- [ ] **ç¼–å†™å®Œæ•´çš„PyTorchè®­ç»ƒå¾ªç¯** å‰å‘â†’æŸå¤±â†’åå‘â†’ä¼˜åŒ–\n",
    "- [ ] **äº†è§£TensorFlow/Kerasçš„ä½¿ç”¨** Sequential APIå’Œmodel.fit()\n",
    "- [ ] **å¯¹æ¯”ä¸¤ä¸ªæ¡†æ¶çš„ä¼˜åŠ£** å¹¶æ ¹æ®åœºæ™¯é€‰æ‹©\n",
    "- [ ] **å°†å‰9ç« çŸ¥è¯†åº”ç”¨åˆ°æ¡†æ¶ä¸­** ç†è§£æ¡†æ¶èƒŒåçš„åŸç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ æ­å–œï¼ç¥ç»ç½‘ç»œæ¨¡å—å®Œæˆï¼\n",
    "\n",
    "**ä½ å·²ç»å®Œæˆäº†ä»é›¶åˆ°ä¸€çš„å®Œæ•´æ—…ç¨‹ï¼š**\n",
    "\n",
    "1. âœ… **ç†è®ºåŸºç¡€**ï¼ˆç¬¬1-2ç« ï¼‰ï¼šæ„ŸçŸ¥æœºã€å•å±‚ç½‘ç»œ\n",
    "2. âœ… **æ ¸å¿ƒç®—æ³•**ï¼ˆç¬¬3-4ç« ï¼‰ï¼šMLPã€åå‘ä¼ æ’­\n",
    "3. âœ… **ä¼˜åŒ–æŠ€æœ¯**ï¼ˆç¬¬5-7ç« ï¼‰ï¼šæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨ã€æ­£åˆ™åŒ–\n",
    "4. âœ… **é«˜çº§æŠ€å·§**ï¼ˆç¬¬8-9ç« ï¼‰ï¼šæƒé‡åˆå§‹åŒ–ã€è®­ç»ƒè¯Šæ–­\n",
    "5. âœ… **å·¥ä¸šå·¥å…·**ï¼ˆç¬¬10ç« ï¼‰ï¼šPyTorch/TensorFlow\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥ï¼šåº”ç”¨ä¸æ·±å…¥\n",
    "\n",
    "#### ç»§ç»­æœ¬æ•™ç¨‹ï¼š\n",
    "\n",
    "1. **è®¡ç®—æœºè§†è§‰**ï¼ˆCNNï¼‰\n",
    "   - å·ç§¯å±‚ã€æ± åŒ–å±‚\n",
    "   - ç»å…¸æ¶æ„ï¼ˆLeNetã€VGGã€ResNetï¼‰\n",
    "\n",
    "2. **åºåˆ—æ¨¡å‹**ï¼ˆRNN/Transformerï¼‰\n",
    "   - å¾ªç¯ç¥ç»ç½‘ç»œ\n",
    "   - æ³¨æ„åŠ›æœºåˆ¶\n",
    "\n",
    "3. **ç”Ÿæˆæ¨¡å‹**\n",
    "   - å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰\n",
    "   - ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰\n",
    "\n",
    "#### ç‹¬ç«‹é¡¹ç›®ï¼š\n",
    "\n",
    "- å‚åŠ Kaggleç«èµ›\n",
    "- å¤ç°ç»å…¸è®ºæ–‡\n",
    "- æ„å»ºè‡ªå·±çš„æ·±åº¦å­¦ä¹ åº”ç”¨\n",
    "\n",
    "---\n",
    "\n",
    "**è®°ä½ï¼š**\n",
    "> **æ·±åº¦å­¦ä¹  = ç†è®º + å®è·µ + è°ƒå‚ç»éªŒ**\n",
    ">\n",
    "> å‰9ç« ç»™äº†ä½ **ç†è®ºå’Œå®ç°èƒ½åŠ›**\n",
    ">\n",
    "> ç¬¬10ç« ç»™äº†ä½ **å·¥ç¨‹å·¥å…·**\n",
    ">\n",
    "> ç°åœ¨éœ€è¦çš„æ˜¯**å¤§é‡å®è·µ**ï¼\n",
    "\n",
    "**Happy Deep Learning! ğŸ¯**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"  TensorFlow/Keraså®Œæ•´è®­ç»ƒç¤ºä¾‹\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # ä½¿ç”¨ç›¸åŒçš„æ•°æ®\n",
    "    print(\"\\n1ï¸âƒ£ ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒæ•°æ®...\")\n",
    "    print(f\"è®­ç»ƒé›†å¤§å°: {len(X_train)}\")\n",
    "    print(f\"æµ‹è¯•é›†å¤§å°: {len(X_test)}\")\n",
    "\n",
    "    # ===== æ–¹å¼1ï¼šSequential API =====\n",
    "    print(\"\\n2ï¸âƒ£ å®šä¹‰æ¨¡å‹ï¼ˆSequential APIï¼‰...\")\n",
    "    \n",
    "    model_keras = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(64,)),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    print(model_keras.summary())\n",
    "    \n",
    "    # ===== 3. ç¼–è¯‘æ¨¡å‹ =====\n",
    "    print(\"\\n3ï¸âƒ£ ç¼–è¯‘æ¨¡å‹...\")\n",
    "    \n",
    "    model_keras.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"ä¼˜åŒ–å™¨: Adam\")\n",
    "    print(\"æŸå¤±å‡½æ•°: SparseCategoricalCrossentropy\")\n",
    "    \n",
    "    # ===== 4. è®­ç»ƒæ¨¡å‹ =====\n",
    "    print(\"\\n4ï¸âƒ£ å¼€å§‹è®­ç»ƒ...\")\n",
    "    \n",
    "    history = model_keras.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=0  # ä¸æ‰“å°æ¯ä¸ªepoch\n",
    "    )\n",
    "    \n",
    "    # æ¯5ä¸ªepochæ‰“å°ä¸€æ¬¡\n",
    "    for epoch in range(0, 20, 5):\n",
    "        train_loss = history.history['loss'][epoch]\n",
    "        val_acc = history.history['val_accuracy'][epoch]\n",
    "        print(f\\\"Epoch [{epoch+1}/20] Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}\\\")\n",
    "    \n",
    "    print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "    final_acc = history.history['val_accuracy'][-1]\n",
    "    print(f\\\"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_acc:.4f}\\\")\n",
    "    \n",
    "    # ===== 5. å¯è§†åŒ–å¯¹æ¯” =====\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # è®­ç»ƒæŸå¤±\n",
    "    axes[0].plot(history.history['loss'], linewidth=2, color='steelblue', label='TensorFlow')\n",
    "    axes[0].plot(train_losses, linewidth=2, color='coral', label='PyTorch', linestyle='--')\n",
    "    axes[0].set_title('è®­ç»ƒæŸå¤±å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # æµ‹è¯•å‡†ç¡®ç‡\n",
    "    axes[1].plot(history.history['val_accuracy'], linewidth=2, color='forestgreen', label='TensorFlow')\n",
    "    axes[1].plot(test_accuracies, linewidth=2, color='orange', label='PyTorch', linestyle='--')\n",
    "    axes[1].set_title('æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('framework_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"âŒ TensorFlowæœªå®‰è£…ï¼Œè·³è¿‡Kerasç¤ºä¾‹\")\n",
    "    print(\"   å®‰è£…å‘½ä»¤: pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ TensorFlow/KerasåŸºç¡€\n",
    "\n",
    "### ğŸ“¦ Kerasï¼šé«˜å±‚API\n",
    "\n",
    "**TensorFlow 2.x çš„æ ¸å¿ƒï¼š** å°†Kerasä½œä¸ºå®˜æ–¹é«˜å±‚API\n",
    "\n",
    "**ä¼˜åŠ¿ï¼š**\n",
    "- âœ… æç®€çš„APIè®¾è®¡\n",
    "- âœ… å¿«é€ŸåŸå‹å¼€å‘\n",
    "- âœ… ç”Ÿäº§éƒ¨ç½²æˆç†Ÿ\n",
    "\n",
    "**æ ¸å¿ƒæ¦‚å¿µï¼š**\n",
    "- **Sequential API**ï¼šé€‚åˆç®€å•çš„é¡ºåºæ¨¡å‹\n",
    "- **Functional API**ï¼šé€‚åˆå¤æ‚æ¨¡å‹ï¼ˆå¤šè¾“å…¥/è¾“å‡ºã€åˆ†æ”¯ç»“æ„ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’» Kerasæ¨¡å‹å®šä¹‰å’Œè®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"  PyTorchå®Œæ•´è®­ç»ƒç¤ºä¾‹ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== 1. å‡†å¤‡æ•°æ® =====\n",
    "print(\"\\n1ï¸âƒ£ å‡†å¤‡æ•°æ®...\")\n",
    "\n",
    "# ä½¿ç”¨sklearnçš„æ‰‹å†™æ•°å­—æ•°æ®é›†ï¼ˆ8x8å›¾åƒï¼Œç±»ä¼¼MNISTä½†æ›´å°ï¼‰\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# è½¬æ¢ä¸ºPyTorchå¼ é‡\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†å¤§å°: {len(X_train)}\")\n",
    "print(f\"æµ‹è¯•é›†å¤§å°: {len(X_test)}\")\n",
    "print(f\"ç‰¹å¾ç»´åº¦: {X_train.shape[1]}\")\n",
    "print(f\"ç±»åˆ«æ•°: {len(np.unique(y))}\")\n",
    "\n",
    "# ===== 2. å®šä¹‰æ¨¡å‹ =====\n",
    "print(\"\\n2ï¸âƒ£ å®šä¹‰æ¨¡å‹...\")\n",
    "\n",
    "model = SimpleNN(input_size=64, hidden_size=128, num_classes=10)\n",
    "print(f\"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ===== 3. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ =====\n",
    "print(\"\\n3ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨...\")\n",
    "\n",
    "# äº¤å‰ç†µæŸå¤±ï¼ˆè‡ªåŠ¨åŒ…å«softmaxï¼‰\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adamä¼˜åŒ–å™¨\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"æŸå¤±å‡½æ•°: CrossEntropyLoss\")\n",
    "print(\"ä¼˜åŒ–å™¨: Adam (lr=0.001)\")\n",
    "\n",
    "# ===== 4. è®­ç»ƒå¾ªç¯ =====\n",
    "print(\"\\n4ï¸âƒ£ å¼€å§‹è®­ç»ƒ...\")\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ===== è®­ç»ƒæ¨¡å¼ =====\n",
    "    model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # åå‘ä¼ æ’­å’Œä¼˜åŒ–\n",
    "        optimizer.zero_grad()  # æ¸…é›¶æ¢¯åº¦\n",
    "        loss.backward()        # è®¡ç®—æ¢¯åº¦\n",
    "        optimizer.step()       # æ›´æ–°å‚æ•°\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # ===== éªŒè¯æ¨¡å¼ =====\n",
    "    model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        accuracy = (predicted == y_test_tensor).float().mean().item()\n",
    "        test_accuracies.append(accuracy)\n",
    "    \n",
    "    # æ‰“å°è¿›åº¦\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\\\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}, Test Acc: {accuracy:.4f}\\\")\n",
    "\n",
    "print(\\\"\\\\nâœ… è®­ç»ƒå®Œæˆï¼\\\")\n",
    "print(f\\\"æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {test_accuracies[-1]:.4f}\\\")\n",
    "\n",
    "# ===== 5. å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ =====\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# è®­ç»ƒæŸå¤±\n",
    "axes[0].plot(train_losses, linewidth=2, color='steelblue')\n",
    "axes[0].set_title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# æµ‹è¯•å‡†ç¡®ç‡\n",
    "axes[1].plot(test_accuracies, linewidth=2, color='forestgreen')\n",
    "axes[1].set_title('æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pytorch_training.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\\\"\\\\n\\\" + \\\"=\\\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸš€ å®Œæ•´çš„PyTorchè®­ç»ƒå¾ªç¯\n",
    "\n",
    "**æ ‡å‡†è®­ç»ƒæµç¨‹ï¼š**\n",
    "1. å®šä¹‰æ¨¡å‹\n",
    "2. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "3. åŠ è½½æ•°æ®\n",
    "4. è®­ç»ƒå¾ªç¯ï¼ˆå‰å‘ä¼ æ’­ â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ â†’ æ›´æ–°å‚æ•°ï¼‰\n",
    "5. éªŒè¯/æµ‹è¯•\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===== æ–¹å¼1ï¼šç»§æ‰¿nn.Module =====\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"\n",
    "    ç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰\n",
    "    \n",
    "    ç»“æ„: è¾“å…¥å±‚(784) -> éšè—å±‚(128) -> è¾“å‡ºå±‚(10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_size=128, num_classes=10):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–ç½‘ç»œå±‚\n",
    "        \n",
    "        å‚æ•°:\n",
    "            input_size: è¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆå¦‚MNISTçš„28*28=784ï¼‰\n",
    "            hidden_size: éšè—å±‚ç¥ç»å…ƒæ•°\n",
    "            num_classes: è¾“å‡ºç±»åˆ«æ•°\n",
    "        \"\"\"\n",
    "        super(SimpleNN, self).__init__()  # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–\n",
    "        \n",
    "        # å®šä¹‰ç½‘ç»œå±‚\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # å…¨è¿æ¥å±‚1\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # å…¨è¿æ¥å±‚2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: è¾“å…¥å¼ é‡, shape (batch_size, input_size)\n",
    "        \n",
    "        è¿”å›:\n",
    "            è¾“å‡ºå¼ é‡, shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # ç¬¬ä¸€å±‚ + ReLUæ¿€æ´»\n",
    "        x = self.fc1(x)      # (batch_size, hidden_size)\n",
    "        x = F.relu(x)        # ReLUæ¿€æ´»å‡½æ•°\n",
    "        \n",
    "        # ç¬¬äºŒå±‚ï¼ˆä¸åŠ æ¿€æ´»ï¼Œåé¢ä¼šç”¨softmaxï¼‰\n",
    "        x = self.fc2(x)      # (batch_size, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# ===== æ–¹å¼2ï¼šä½¿ç”¨Sequentialï¼ˆé€‚åˆç®€å•æ¨¡å‹ï¼‰=====\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "\n",
    "# ===== åˆ›å»ºå¹¶æŸ¥çœ‹æ¨¡å‹ =====\n",
    "print(\"=\"*60)\n",
    "print(\"  PyTorchæ¨¡å‹å®šä¹‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# å®ä¾‹åŒ–æ¨¡å‹\n",
    "model = SimpleNN(input_size=784, hidden_size=128, num_classes=10)\n",
    "\n",
    "print(\"\\næ¨¡å‹ç»“æ„:\")\n",
    "print(model)\n",
    "\n",
    "print(\"\\n\\næ¨¡å‹å‚æ•°:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {param.shape}\")\n",
    "\n",
    "# è®¡ç®—æ€»å‚æ•°æ•°é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\næ€»å‚æ•°æ•°é‡: {total_params:,}\")\n",
    "\n",
    "# ===== æµ‹è¯•å‰å‘ä¼ æ’­ =====\n",
    "print(\"\\n\\næµ‹è¯•å‰å‘ä¼ æ’­:\")\n",
    "# åˆ›å»ºä¸€ä¸ªbatchçš„å‡æ•°æ®\n",
    "batch_size = 16\n",
    "fake_input = torch.randn(batch_size, 784)\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {fake_input.shape}\")\n",
    "\n",
    "# å‰å‘ä¼ æ’­\n",
    "output = model(fake_input)\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "print(f\"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ PyTorchæ¨¡å‹å®šä¹‰\n",
    "\n",
    "åœ¨PyTorchä¸­ï¼Œå®šä¹‰æ¨¡å‹æœ‰ä¸¤ç§ä¸»è¦æ–¹å¼ï¼š\n",
    "\n",
    "#### æ–¹å¼1ï¼šç»§æ‰¿ `nn.Module`ï¼ˆæ¨èï¼‰\n",
    "\n",
    "è¿™æ˜¯æœ€æ ‡å‡†ã€æœ€çµæ´»çš„æ–¹å¼ã€‚\n",
    "\n",
    "**æ ¸å¿ƒæ­¥éª¤ï¼š**\n",
    "1. ç»§æ‰¿ `torch.nn.Module`\n",
    "2. åœ¨ `__init__` ä¸­å®šä¹‰å±‚\n",
    "3. åœ¨ `forward` ä¸­å®šä¹‰å‰å‘ä¼ æ’­é€»è¾‘\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
