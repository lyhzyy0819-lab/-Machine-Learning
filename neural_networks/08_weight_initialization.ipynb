{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬8ç« ï¼šæƒé‡åˆå§‹åŒ–ç­–ç•¥ (Weight Initialization)\n",
    "\n",
    "> **å­¦ä¹ ç›®æ ‡**ï¼šç†è§£ä¸ºä»€ä¹ˆåˆå§‹åŒ–å¦‚æ­¤é‡è¦ï¼ŒæŒæ¡Xavierå’ŒHeåˆå§‹åŒ–çš„æ•°å­¦åŸç†ï¼Œèƒ½ä»é›¶å®ç°å¹¶å¯¹æ¯”ä¸åŒåˆå§‹åŒ–æ–¹æ³•\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬ç« å†…å®¹\n",
    "\n",
    "1. **ä¸ºä»€ä¹ˆåˆå§‹åŒ–å¾ˆé‡è¦ï¼Ÿ**\n",
    "   - åˆå§‹åŒ–ä¸å½“å¯¼è‡´çš„é—®é¢˜\n",
    "   - å¯¹ç§°æ€§ç ´ç¼º\n",
    "   - æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸çš„æ ¹æº\n",
    "\n",
    "2. **ç»å…¸åˆå§‹åŒ–æ–¹æ³•æ¨å¯¼**\n",
    "   - Xavier/Glorot åˆå§‹åŒ–ï¼ˆé€‚ç”¨äº Tanh/Sigmoidï¼‰\n",
    "   - He åˆå§‹åŒ–ï¼ˆé€‚ç”¨äº ReLUï¼‰\n",
    "   - æ•°å­¦åŸç†è¯¦è§£\n",
    "\n",
    "3. **ä»é›¶å®ç°åˆå§‹åŒ–å·¥å…·ç±»**\n",
    "   - ç»Ÿä¸€çš„åˆå§‹åŒ–æ¥å£\n",
    "   - å¤šç§åˆå§‹åŒ–æ–¹æ³•\n",
    "\n",
    "4. **å¯è§†åŒ–å®éªŒ**\n",
    "   - æ¿€æ´»å€¼åˆ†å¸ƒå¯¹æ¯”\n",
    "   - æ¢¯åº¦æµåˆ†æ\n",
    "   - è®­ç»ƒæ›²çº¿å¯¹æ¯”\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸ºä»€ä¹ˆè¿™ä¸€ç« å¦‚æ­¤é‡è¦ï¼Ÿ\n",
    "\n",
    "**åˆå§‹åŒ–æ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒæˆåŠŸçš„å…³é”®ä¹‹ä¸€ï¼**\n",
    "\n",
    "| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |\n",
    "|------|------|----------|\n",
    "| è®­ç»ƒä¸æ”¶æ•› | åˆå§‹åŒ–è¿‡å°ï¼Œæ¢¯åº¦æ¶ˆå¤± | ä½¿ç”¨Xavier/Heåˆå§‹åŒ– |\n",
    "| æŸå¤±å˜ä¸ºNaN | åˆå§‹åŒ–è¿‡å¤§ï¼Œæ¢¯åº¦çˆ†ç‚¸ | å‡å°åˆå§‹åŒ–å°ºåº¦ |\n",
    "| æ‰€æœ‰ç¥ç»å…ƒè¾“å‡ºç›¸åŒ | å…¨é›¶åˆå§‹åŒ–ï¼Œæ— æ³•æ‰“ç ´å¯¹ç§°æ€§ | éšæœºåˆå§‹åŒ– |\n",
    "| æ·±å±‚ç½‘ç»œè®­ç»ƒå›°éš¾ | æ¿€æ´»å€¼é€å±‚è¡°å‡æˆ–çˆ†ç‚¸ | å±‚çº§è‡ªé€‚åº”åˆå§‹åŒ– |\n",
    "\n",
    "**ç±»æ¯”**ï¼š\n",
    "- åˆå§‹åŒ–å°±åƒç»™ç™»å±±é˜Ÿé€‰æ‹©èµ·ç‚¹\n",
    "- èµ·ç‚¹å¤ªä½ï¼ˆè¿‡å°åˆå§‹åŒ–ï¼‰â†’ çˆ¬ä¸åŠ¨ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰\n",
    "- èµ·ç‚¹å¤ªé«˜ï¼ˆè¿‡å¤§åˆå§‹åŒ–ï¼‰â†’ æ‘”ä¸‹æ¥ï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰\n",
    "- å¥½çš„èµ·ç‚¹ â†’ é¡ºåˆ©ç™»é¡¶ï¼ˆè®­ç»ƒæ”¶æ•›ï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ï¼ˆç¡®ä¿ç»“æœå¯å¤ç°ï¼‰\n",
    "np.random.seed(42)\n",
    "\n",
    "# è®¾ç½®matplotlibä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®ç»˜å›¾é£æ ¼\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒé…ç½®å®Œæˆï¼\")\n",
    "print(f\"NumPyç‰ˆæœ¬: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ ä¸ºä»€ä¹ˆåˆå§‹åŒ–å¾ˆé‡è¦ï¼Ÿ\n",
    "\n",
    "### 1.1 å…¨é›¶åˆå§‹åŒ–çš„é—®é¢˜ï¼šå¯¹ç§°æ€§ç ´ç¼º\n",
    "\n",
    "**é—®é¢˜**ï¼šå¦‚æœæ‰€æœ‰æƒé‡éƒ½åˆå§‹åŒ–ä¸º0ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ç­”æ¡ˆ**ï¼šæ‰€æœ‰ç¥ç»å…ƒçš„è¡Œä¸ºå®Œå…¨ç›¸åŒï¼Œæ— æ³•å­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾ï¼\n",
    "\n",
    "#### æ•°å­¦åˆ†æ\n",
    "\n",
    "å‡è®¾ä¸€ä¸ªç®€å•çš„ä¸¤å±‚ç½‘ç»œï¼š\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{z}^{(1)} &= W^{(1)} \\mathbf{x} + \\mathbf{b}^{(1)} \\\\\n",
    "\\mathbf{a}^{(1)} &= \\text{ReLU}(\\mathbf{z}^{(1)}) \\\\\n",
    "\\mathbf{z}^{(2)} &= W^{(2)} \\mathbf{a}^{(1)} + \\mathbf{b}^{(2)} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**å¦‚æœ $W^{(1)} = 0, \\mathbf{b}^{(1)} = 0$ï¼š**\n",
    "\n",
    "1. å‰å‘ä¼ æ’­ï¼š$\\mathbf{z}^{(1)} = 0 \\Rightarrow \\mathbf{a}^{(1)} = 0 \\Rightarrow \\mathbf{z}^{(2)} = 0$\n",
    "2. åå‘ä¼ æ’­ï¼š\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W^{(1)}_{ij}} = \\frac{\\partial L}{\\partial z^{(1)}_i} \\cdot x_j\n",
    "   $$\n",
    "   \n",
    "   å¯¹äºåŒä¸€å±‚çš„æ‰€æœ‰ç¥ç»å…ƒ $i$ï¼Œæ¢¯åº¦ $\\frac{\\partial L}{\\partial z^{(1)}_i}$ ç›¸åŒï¼Œå› æ­¤ï¼š\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W^{(1)}_{1j}} = \\frac{\\partial L}{\\partial W^{(1)}_{2j}} = \\cdots\n",
    "   $$\n",
    "   \n",
    "   æ‰€æœ‰ç¥ç»å…ƒçš„æƒé‡æ›´æ–°å®Œå…¨ç›¸åŒ â†’ **å¯¹ç§°æ€§æ— æ³•æ‰“ç ´** â†’ æ— æ³•å­¦ä¹ åˆ°ä¸åŒç‰¹å¾\n",
    "\n",
    "**ç»“è®º**ï¼šå¿…é¡»ä½¿ç”¨éšæœºåˆå§‹åŒ–æ‰“ç ´å¯¹ç§°æ€§ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºï¼šå…¨é›¶åˆå§‹åŒ–å¯¼è‡´çš„å¯¹ç§°æ€§é—®é¢˜\n",
    "\n",
    "def demonstrate_zero_init_problem():\n",
    "    \"\"\"\n",
    "    æ¼”ç¤ºå…¨é›¶åˆå§‹åŒ–å¯¼è‡´çš„å¯¹ç§°æ€§é—®é¢˜\n",
    "    \n",
    "    å®éªŒè®¾ç½®ï¼š\n",
    "    - 3ä¸ªéšè—ç¥ç»å…ƒ\n",
    "    - å…¨é›¶åˆå§‹åŒ–\n",
    "    - è§‚å¯Ÿå‰å‘ä¼ æ’­å’Œæ¢¯åº¦\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"å®éªŒï¼šå…¨é›¶åˆå§‹åŒ–å¯¼è‡´çš„å¯¹ç§°æ€§é—®é¢˜\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # è¾“å…¥æ•°æ®ï¼ˆ1ä¸ªæ ·æœ¬ï¼Œ2ä¸ªç‰¹å¾ï¼‰\n",
    "    X = np.array([[1.0, 2.0]])  # shape: (1, 2)\n",
    "    \n",
    "    # å…¨é›¶åˆå§‹åŒ–æƒé‡ï¼ˆ2ä¸ªè¾“å…¥ï¼Œ3ä¸ªéšè—ç¥ç»å…ƒï¼‰\n",
    "    W1 = np.zeros((2, 3))  # shape: (2, 3)\n",
    "    b1 = np.zeros((1, 3))  # shape: (1, 3)\n",
    "    \n",
    "    print(f\"\\nè¾“å…¥ X:\\n{X}\")\n",
    "    print(f\"\\næƒé‡ W1 (å…¨é›¶):\\n{W1}\")\n",
    "    print(f\"\\nåç½® b1 (å…¨é›¶):\\n{b1}\")\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    z1 = X @ W1 + b1  # shape: (1, 3)\n",
    "    a1 = np.maximum(0, z1)  # ReLUæ¿€æ´»\n",
    "    \n",
    "    print(f\"\\néšè—å±‚è¾“å‡º z1:\\n{z1}\")\n",
    "    print(f\"\\næ¿€æ´»å a1:\\n{a1}\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ¢¯åº¦ï¼ˆå‡è®¾æŸå¤±å‡½æ•°å¯¹a1çš„æ¢¯åº¦ï¼‰\n",
    "    dL_da1 = np.array([[0.5, 0.5, 0.5]])  # ä¸‰ä¸ªç¥ç»å…ƒçš„æ¢¯åº¦\n",
    "    \n",
    "    # åå‘ä¼ æ’­è®¡ç®—æƒé‡æ¢¯åº¦\n",
    "    # âˆ‚L/âˆ‚W1 = X^T @ (âˆ‚L/âˆ‚a1 âŠ™ âˆ‚a1/âˆ‚z1)\n",
    "    # ç”±äº z1 = 0, ReLUçš„å¯¼æ•°åœ¨0å¤„é€šå¸¸å–0æˆ–1ï¼ˆè¿™é‡Œå‡è®¾å–1ï¼‰\n",
    "    dL_dz1 = dL_da1 * 1  # ReLUå¯¼æ•°\n",
    "    dL_dW1 = X.T @ dL_dz1  # shape: (2, 3)\n",
    "    \n",
    "    print(f\"\\næƒé‡æ¢¯åº¦ âˆ‚L/âˆ‚W1:\\n{dL_dW1}\")\n",
    "    print(\"\\nâš ï¸  è§‚å¯Ÿï¼š\")\n",
    "    print(\"   1. æ‰€æœ‰éšè—ç¥ç»å…ƒçš„è¾“å‡ºéƒ½æ˜¯0\")\n",
    "    print(\"   2. æ¯ä¸€åˆ—ï¼ˆæ¯ä¸ªç¥ç»å…ƒï¼‰çš„æ¢¯åº¦å®Œå…¨ç›¸åŒ\")\n",
    "    print(\"   3. æƒé‡æ›´æ–°åï¼Œä¸‰ä¸ªç¥ç»å…ƒä»ç„¶ä¿æŒå¯¹ç§°\")\n",
    "    print(\"   4. æ— æ³•å­¦ä¹ åˆ°ä¸åŒçš„ç‰¹å¾ï¼\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿä¸€æ¬¡æƒé‡æ›´æ–°\n",
    "    learning_rate = 0.1\n",
    "    W1_updated = W1 - learning_rate * dL_dW1\n",
    "    \n",
    "    print(f\"\\næ›´æ–°åçš„æƒé‡ W1:\\n{W1_updated}\")\n",
    "    print(\"\\nâš ï¸  æ¯ä¸€åˆ—ï¼ˆæ¯ä¸ªç¥ç»å…ƒï¼‰çš„æƒé‡ä»ç„¶ç›¸åŒï¼\")\n",
    "    print(\"\\nâœ… ç»“è®ºï¼šå¿…é¡»ä½¿ç”¨éšæœºåˆå§‹åŒ–æ‰“ç ´å¯¹ç§°æ€§ï¼\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demonstrate_zero_init_problem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 éšæœºåˆå§‹åŒ–çš„é—®é¢˜ï¼šæ–¹å·®æ§åˆ¶\n",
    "\n",
    "è™½ç„¶éšæœºåˆå§‹åŒ–å¯ä»¥æ‰“ç ´å¯¹ç§°æ€§ï¼Œä½†å¦‚æœä¸æ§åˆ¶æ–¹å·®ï¼Œä¼šå¯¼è‡´ï¼š\n",
    "\n",
    "#### é—®é¢˜1ï¼šåˆå§‹åŒ–è¿‡å° â†’ æ¢¯åº¦æ¶ˆå¤±\n",
    "\n",
    "å‡è®¾æƒé‡ $W \\sim \\mathcal{N}(0, 0.01^2)$ï¼ˆæ–¹å·®å¾ˆå°ï¼‰\n",
    "\n",
    "**å‰å‘ä¼ æ’­**ï¼š\n",
    "$$\n",
    "\\mathbf{z}^{(l)} = W^{(l)} \\mathbf{a}^{(l-1)}\n",
    "$$\n",
    "\n",
    "å¦‚æœ $W$ å¾ˆå°ï¼Œ$\\mathbf{z}^{(l)}$ ä¼šè¶Šæ¥è¶Šå°ï¼Œæœ€ç»ˆè¶‹å‘äº0\n",
    "\n",
    "**åå‘ä¼ æ’­**ï¼š\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{a}^{(l-1)}} = (W^{(l)})^T \\frac{\\partial L}{\\partial \\mathbf{z}^{(l)}}\n",
    "$$\n",
    "\n",
    "å¦‚æœ $W$ å¾ˆå°ï¼Œæ¢¯åº¦ä¼šé€å±‚è¡°å‡ï¼Œæœ€ç»ˆè¶‹å‘äº0 â†’ **æ¢¯åº¦æ¶ˆå¤±**\n",
    "\n",
    "#### é—®é¢˜2ï¼šåˆå§‹åŒ–è¿‡å¤§ â†’ æ¢¯åº¦çˆ†ç‚¸\n",
    "\n",
    "å‡è®¾æƒé‡ $W \\sim \\mathcal{N}(0, 1^2)$ï¼ˆæ–¹å·®è¾ƒå¤§ï¼‰\n",
    "\n",
    "- å‰å‘ä¼ æ’­ï¼š$\\mathbf{z}^{(l)}$ ä¼šè¶Šæ¥è¶Šå¤§\n",
    "- åå‘ä¼ æ’­ï¼šæ¢¯åº¦ä¼šé€å±‚æ”¾å¤§ â†’ **æ¢¯åº¦çˆ†ç‚¸** â†’ æŸå¤±å˜ä¸ºNaN\n",
    "\n",
    "**å…³é”®é—®é¢˜**ï¼šå¦‚ä½•é€‰æ‹©åˆé€‚çš„åˆå§‹åŒ–æ–¹å·®ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¼”ç¤ºï¼šä¸åŒåˆå§‹åŒ–å°ºåº¦çš„å½±å“\n",
    "\n",
    "def demonstrate_initialization_scale(n_layers=10, n_neurons=100):\n",
    "    \"\"\"\n",
    "    æ¼”ç¤ºä¸åŒåˆå§‹åŒ–å°ºåº¦å¯¹æ¿€æ´»å€¼ä¼ æ’­çš„å½±å“\n",
    "    \n",
    "    å‚æ•°:\n",
    "    -----\n",
    "    n_layers : int\n",
    "        ç½‘ç»œæ·±åº¦ï¼ˆå±‚æ•°ï¼‰\n",
    "    n_neurons : int\n",
    "        æ¯å±‚ç¥ç»å…ƒæ•°é‡\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"å®éªŒï¼šä¸åŒåˆå§‹åŒ–å°ºåº¦çš„å½±å“ï¼ˆ{n_layers}å±‚ç½‘ç»œï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # è¾“å…¥æ•°æ®ï¼ˆæ ‡å‡†åŒ–ï¼Œå‡å€¼0æ–¹å·®1ï¼‰\n",
    "    X = np.random.randn(1000, n_neurons)\n",
    "    \n",
    "    # æµ‹è¯•ä¸åŒçš„åˆå§‹åŒ–å°ºåº¦\n",
    "    init_scales = {\n",
    "        'è¿‡å° (std=0.01)': 0.01,\n",
    "        'åå° (std=0.1)': 0.1,\n",
    "        'é€‚ä¸­ (std=0.5)': 0.5,\n",
    "        'åå¤§ (std=1.0)': 1.0,\n",
    "        'è¿‡å¤§ (std=2.0)': 2.0\n",
    "    }\n",
    "    \n",
    "    # å­˜å‚¨æ¯å±‚çš„æ¿€æ´»å€¼ç»Ÿè®¡\n",
    "    results = {}\n",
    "    \n",
    "    for name, scale in init_scales.items():\n",
    "        activations = X.copy()\n",
    "        layer_means = []\n",
    "        layer_stds = []\n",
    "        \n",
    "        # é€å±‚å‰å‘ä¼ æ’­\n",
    "        for layer in range(n_layers):\n",
    "            # åˆå§‹åŒ–æƒé‡\n",
    "            W = np.random.randn(n_neurons, n_neurons) * scale\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­ï¼ˆä¸ä½¿ç”¨åç½®ï¼Œç®€åŒ–åˆ†æï¼‰\n",
    "            z = activations @ W\n",
    "            activations = np.maximum(0, z)  # ReLUæ¿€æ´»\n",
    "            \n",
    "            # è®°å½•ç»Ÿè®¡ä¿¡æ¯\n",
    "            layer_means.append(np.mean(activations))\n",
    "            layer_stds.append(np.std(activations))\n",
    "        \n",
    "        results[name] = {\n",
    "            'means': layer_means,\n",
    "            'stds': layer_stds\n",
    "        }\n",
    "    \n",
    "    # å¯è§†åŒ–ç»“æœ\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # å­å›¾1ï¼šæ¯å±‚æ¿€æ´»å€¼çš„å‡å€¼\n",
    "    for name, data in results.items():\n",
    "        axes[0].plot(range(1, n_layers + 1), data['means'], \n",
    "                    marker='o', label=name, linewidth=2)\n",
    "    axes[0].set_xlabel('å±‚æ•°', fontsize=12)\n",
    "    axes[0].set_ylabel('æ¿€æ´»å€¼å‡å€¼', fontsize=12)\n",
    "    axes[0].set_title('ä¸åŒåˆå§‹åŒ–å°ºåº¦ä¸‹çš„æ¿€æ´»å€¼å‡å€¼ä¼ æ’­', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡æ›´æ¸…æ¥š\n",
    "    \n",
    "    # å­å›¾2ï¼šæ¯å±‚æ¿€æ´»å€¼çš„æ ‡å‡†å·®\n",
    "    for name, data in results.items():\n",
    "        axes[1].plot(range(1, n_layers + 1), data['stds'], \n",
    "                    marker='o', label=name, linewidth=2)\n",
    "    axes[1].set_xlabel('å±‚æ•°', fontsize=12)\n",
    "    axes[1].set_ylabel('æ¿€æ´»å€¼æ ‡å‡†å·®', fontsize=12)\n",
    "    axes[1].set_title('ä¸åŒåˆå§‹åŒ–å°ºåº¦ä¸‹çš„æ¿€æ´»å€¼æ ‡å‡†å·®ä¼ æ’­', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ‰“å°æœ€åä¸€å±‚çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\næœ€åä¸€å±‚ï¼ˆç¬¬{}å±‚ï¼‰çš„æ¿€æ´»å€¼ç»Ÿè®¡ï¼š\".format(n_layers))\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'åˆå§‹åŒ–æ–¹å¼':<20} {'å‡å€¼':<15} {'æ ‡å‡†å·®':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    for name, data in results.items():\n",
    "        mean_last = data['means'][-1]\n",
    "        std_last = data['stds'][-1]\n",
    "        print(f\"{name:<20} {mean_last:<15.6f} {std_last:<15.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\n",
    "    print(\"   1. è¿‡å°åˆå§‹åŒ–ï¼šæ¿€æ´»å€¼å¿«é€Ÿè¡°å‡åˆ°0ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰\")\n",
    "    print(\"   2. è¿‡å¤§åˆå§‹åŒ–ï¼šæ¿€æ´»å€¼å¯èƒ½çˆ†ç‚¸ï¼ˆæ¢¯åº¦çˆ†ç‚¸é£é™©ï¼‰\")\n",
    "    print(\"   3. é€‚ä¸­åˆå§‹åŒ–ï¼šæ¿€æ´»å€¼ä¿æŒç¨³å®š\")\n",
    "    print(\"\\nâœ… ç»“è®ºï¼šéœ€è¦ç²¾å¿ƒè®¾è®¡åˆå§‹åŒ–æ–¹å·®ï¼\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demonstrate_initialization_scale(n_layers=10, n_neurons=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Xavier/Glorot åˆå§‹åŒ–\n",
    "\n",
    "### 2.1 æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "**ç›®æ ‡**ï¼šä¿æŒå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶ï¼Œä¿¡å·çš„æ–¹å·®ä¸€è‡´\n",
    "\n",
    "- å‰å‘ä¼ æ’­ï¼šæ¯å±‚è¾“å‡ºçš„æ–¹å·®ä¸è¾“å…¥ç›¸åŒ\n",
    "- åå‘ä¼ æ’­ï¼šæ¯å±‚æ¢¯åº¦çš„æ–¹å·®ä¸ä¸Šä¸€å±‚ç›¸åŒ\n",
    "\n",
    "**å‡è®¾**ï¼š\n",
    "1. æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„æˆ–è¿‘ä¼¼çº¿æ€§ï¼ˆå¦‚Tanhåœ¨0é™„è¿‘ï¼‰\n",
    "2. è¾“å…¥æ•°æ®å·²æ ‡å‡†åŒ–ï¼ˆå‡å€¼0ï¼Œæ–¹å·®1ï¼‰\n",
    "3. æƒé‡å’Œè¾“å…¥ç‹¬ç«‹\n",
    "\n",
    "### 2.2 æ•°å­¦æ¨å¯¼\n",
    "\n",
    "#### å‰å‘ä¼ æ’­æ–¹å·®åˆ†æ\n",
    "\n",
    "è€ƒè™‘ä¸€ä¸ªçº¿æ€§å±‚ï¼š\n",
    "$$\n",
    "z_i = \\sum_{j=1}^{n_{\\text{in}}} w_{ij} a_j\n",
    "$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $z_i$ï¼šç¬¬ $i$ ä¸ªç¥ç»å…ƒçš„è¾“å‡º\n",
    "- $w_{ij}$ï¼šæƒé‡ï¼Œå‡è®¾ $w_{ij} \\sim \\mathcal{N}(0, \\sigma_w^2)$\n",
    "- $a_j$ï¼šè¾“å…¥ï¼Œå‡è®¾ $\\text{Var}(a_j) = \\sigma_a^2$\n",
    "- $n_{\\text{in}}$ï¼šè¾“å…¥ç¥ç»å…ƒæ•°é‡\n",
    "\n",
    "**è®¡ç®— $z_i$ çš„æ–¹å·®**ï¼š\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(z_i) &= \\text{Var}\\left(\\sum_{j=1}^{n_{\\text{in}}} w_{ij} a_j\\right) \\\\\n",
    "&= \\sum_{j=1}^{n_{\\text{in}}} \\text{Var}(w_{ij} a_j) \\quad \\text{ï¼ˆå‡è®¾ç‹¬ç«‹ï¼‰} \\\\\n",
    "&= \\sum_{j=1}^{n_{\\text{in}}} \\text{E}[w_{ij}]^2 \\text{Var}(a_j) + \\text{E}[a_j]^2 \\text{Var}(w_{ij}) + \\text{Var}(w_{ij})\\text{Var}(a_j) \\\\\n",
    "&= \\sum_{j=1}^{n_{\\text{in}}} (0 + 0 + \\sigma_w^2 \\sigma_a^2) \\quad \\text{ï¼ˆå‡å€¼ä¸º0ï¼‰} \\\\\n",
    "&= n_{\\text{in}} \\cdot \\sigma_w^2 \\cdot \\sigma_a^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**è¦ä½¿è¾“å‡ºæ–¹å·®ç­‰äºè¾“å…¥æ–¹å·®**ï¼š\n",
    "$$\n",
    "\\text{Var}(z_i) = \\sigma_a^2\n",
    "$$\n",
    "\n",
    "å› æ­¤ï¼š\n",
    "$$\n",
    "n_{\\text{in}} \\cdot \\sigma_w^2 \\cdot \\sigma_a^2 = \\sigma_a^2\n",
    "$$\n",
    "\n",
    "è§£å¾—ï¼š\n",
    "$$\n",
    "\\boxed{\\sigma_w^2 = \\frac{1}{n_{\\text{in}}}}\n",
    "$$\n",
    "\n",
    "#### åå‘ä¼ æ’­æ–¹å·®åˆ†æ\n",
    "\n",
    "åå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦ä¼ æ’­å…¬å¼ï¼š\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial a_j} = \\sum_{i=1}^{n_{\\text{out}}} w_{ij} \\frac{\\partial L}{\\partial z_i}\n",
    "$$\n",
    "\n",
    "ç±»ä¼¼æ¨å¯¼ï¼Œè¦ä½¿æ¢¯åº¦æ–¹å·®ä¿æŒä¸å˜ï¼š\n",
    "$$\n",
    "\\boxed{\\sigma_w^2 = \\frac{1}{n_{\\text{out}}}}\n",
    "$$\n",
    "\n",
    "#### XavieræŠ˜ä¸­æ–¹æ¡ˆ\n",
    "\n",
    "å‰å‘ä¼ æ’­è¦æ±‚ï¼š$\\sigma_w^2 = 1/n_{\\text{in}}$  \n",
    "åå‘ä¼ æ’­è¦æ±‚ï¼š$\\sigma_w^2 = 1/n_{\\text{out}}$\n",
    "\n",
    "**æŠ˜ä¸­**ï¼š\n",
    "$$\n",
    "\\boxed{\\sigma_w^2 = \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}}\n",
    "$$\n",
    "\n",
    "### 2.3 Xavieråˆå§‹åŒ–çš„ä¸¤ç§å½¢å¼\n",
    "\n",
    "#### å½¢å¼1ï¼šæ­£æ€åˆ†å¸ƒ\n",
    "$$\n",
    "W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\\right)\n",
    "$$\n",
    "\n",
    "#### å½¢å¼2ï¼šå‡åŒ€åˆ†å¸ƒ\n",
    "$$\n",
    "W \\sim \\mathcal{U}\\left[-\\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}, \\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}\\right]\n",
    "$$\n",
    "\n",
    "**ä¸ºä»€ä¹ˆæ˜¯ $\\sqrt{6/(n_{\\text{in}} + n_{\\text{out}})}$ï¼Ÿ**\n",
    "\n",
    "å‡åŒ€åˆ†å¸ƒ $\\mathcal{U}[-a, a]$ çš„æ–¹å·®ï¼š\n",
    "$$\n",
    "\\text{Var}(W) = \\frac{(2a)^2}{12} = \\frac{a^2}{3}\n",
    "$$\n",
    "\n",
    "è¦ä½¿æ–¹å·®ç­‰äº $\\frac{2}{n_{\\text{in}} + n_{\\text{out}}}$ï¼š\n",
    "$$\n",
    "\\frac{a^2}{3} = \\frac{2}{n_{\\text{in}} + n_{\\text{out}}} \\Rightarrow a = \\sqrt{\\frac{6}{n_{\\text{in}} + n_{\\text{out}}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ç° Xavier åˆå§‹åŒ–\n",
    "\n",
    "def xavier_uniform(n_in: int, n_out: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Xavierå‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–\n",
    "    \n",
    "    é€‚ç”¨äºï¼šTanhã€Sigmoidç­‰è¿‘ä¼¼çº¿æ€§çš„æ¿€æ´»å‡½æ•°\n",
    "    \n",
    "    å…¬å¼:\n",
    "    -----\n",
    "    W ~ U[-âˆš(6/(n_in + n_out)), âˆš(6/(n_in + n_out))]\n",
    "    \n",
    "    å‚æ•°:\n",
    "    -----\n",
    "    n_in : int\n",
    "        è¾“å…¥ç¥ç»å…ƒæ•°é‡ï¼ˆå‰ä¸€å±‚å¤§å°ï¼‰\n",
    "    n_out : int\n",
    "        è¾“å‡ºç¥ç»å…ƒæ•°é‡ï¼ˆå½“å‰å±‚å¤§å°ï¼‰\n",
    "    \n",
    "    è¿”å›:\n",
    "    -----\n",
    "    W : ndarray, shape (n_in, n_out)\n",
    "        åˆå§‹åŒ–åçš„æƒé‡çŸ©é˜µ\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å‡åŒ€åˆ†å¸ƒçš„è¾¹ç•Œ\n",
    "    limit = np.sqrt(6 / (n_in + n_out))\n",
    "    \n",
    "    # ä»å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·\n",
    "    W = np.random.uniform(-limit, limit, size=(n_in, n_out))\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "def xavier_normal(n_in: int, n_out: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Xavieræ­£æ€åˆ†å¸ƒåˆå§‹åŒ–\n",
    "    \n",
    "    é€‚ç”¨äºï¼šTanhã€Sigmoidç­‰è¿‘ä¼¼çº¿æ€§çš„æ¿€æ´»å‡½æ•°\n",
    "    \n",
    "    å…¬å¼:\n",
    "    -----\n",
    "    W ~ N(0, 2/(n_in + n_out))\n",
    "    \n",
    "    å‚æ•°:\n",
    "    -----\n",
    "    n_in : int\n",
    "        è¾“å…¥ç¥ç»å…ƒæ•°é‡\n",
    "    n_out : int\n",
    "        è¾“å‡ºç¥ç»å…ƒæ•°é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    -----\n",
    "    W : ndarray, shape (n_in, n_out)\n",
    "        åˆå§‹åŒ–åçš„æƒé‡çŸ©é˜µ\n",
    "    \"\"\"\n",
    "    # è®¡ç®—æ ‡å‡†å·®\n",
    "    std = np.sqrt(2 / (n_in + n_out))\n",
    "    \n",
    "    # ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·\n",
    "    W = np.random.normal(0, std, size=(n_in, n_out))\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "# æµ‹è¯•Xavieråˆå§‹åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"Xavieråˆå§‹åŒ–æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_in, n_out = 100, 50\n",
    "\n",
    "# Xavierå‡åŒ€åˆå§‹åŒ–\n",
    "W_xavier_uniform = xavier_uniform(n_in, n_out)\n",
    "print(f\"\\nXavierå‡åŒ€åˆå§‹åŒ– (n_in={n_in}, n_out={n_out}):\")\n",
    "print(f\"  å½¢çŠ¶: {W_xavier_uniform.shape}\")\n",
    "print(f\"  å‡å€¼: {np.mean(W_xavier_uniform):.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {np.std(W_xavier_uniform):.6f}\")\n",
    "print(f\"  ç†è®ºæ ‡å‡†å·®: {np.sqrt(2 / (n_in + n_out)):.6f}\")\n",
    "print(f\"  æœ€å°å€¼: {np.min(W_xavier_uniform):.6f}\")\n",
    "print(f\"  æœ€å¤§å€¼: {np.max(W_xavier_uniform):.6f}\")\n",
    "print(f\"  ç†è®ºè¾¹ç•Œ: Â±{np.sqrt(6 / (n_in + n_out)):.6f}\")\n",
    "\n",
    "# Xavieræ­£æ€åˆå§‹åŒ–\n",
    "W_xavier_normal = xavier_normal(n_in, n_out)\n",
    "print(f\"\\nXavieræ­£æ€åˆå§‹åŒ– (n_in={n_in}, n_out={n_out}):\")\n",
    "print(f\"  å½¢çŠ¶: {W_xavier_normal.shape}\")\n",
    "print(f\"  å‡å€¼: {np.mean(W_xavier_normal):.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {np.std(W_xavier_normal):.6f}\")\n",
    "print(f\"  ç†è®ºæ ‡å‡†å·®: {np.sqrt(2 / (n_in + n_out)):.6f}\")\n",
    "\n",
    "# å¯è§†åŒ–æƒé‡åˆ†å¸ƒ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Xavierå‡åŒ€åˆ†å¸ƒ\n",
    "axes[0].hist(W_xavier_uniform.flatten(), bins=50, density=True, \n",
    "            alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0].axvline(np.mean(W_xavier_uniform), color='red', \n",
    "               linestyle='--', linewidth=2, label=f'å‡å€¼={np.mean(W_xavier_uniform):.4f}')\n",
    "axes[0].set_xlabel('æƒé‡å€¼', fontsize=12)\n",
    "axes[0].set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12)\n",
    "axes[0].set_title('Xavierå‡åŒ€åˆå§‹åŒ– - æƒé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Xavieræ­£æ€åˆ†å¸ƒ\n",
    "axes[1].hist(W_xavier_normal.flatten(), bins=50, density=True, \n",
    "            alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1].axvline(np.mean(W_xavier_normal), color='red', \n",
    "               linestyle='--', linewidth=2, label=f'å‡å€¼={np.mean(W_xavier_normal):.4f}')\n",
    "\n",
    "# å åŠ ç†è®ºæ­£æ€åˆ†å¸ƒæ›²çº¿\n",
    "x = np.linspace(-0.3, 0.3, 1000)\n",
    "std_theory = np.sqrt(2 / (n_in + n_out))\n",
    "y = (1 / (std_theory * np.sqrt(2 * np.pi))) * np.exp(-0.5 * (x / std_theory)**2)\n",
    "axes[1].plot(x, y, 'r-', linewidth=2, label='ç†è®ºåˆ†å¸ƒ')\n",
    "\n",
    "axes[1].set_xlabel('æƒé‡å€¼', fontsize=12)\n",
    "axes[1].set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12)\n",
    "axes[1].set_title('Xavieræ­£æ€åˆå§‹åŒ– - æƒé‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Xavieråˆå§‹åŒ–æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ He åˆå§‹åŒ–\n",
    "\n",
    "### 3.1 ä¸ºä»€ä¹ˆéœ€è¦ He åˆå§‹åŒ–ï¼Ÿ\n",
    "\n",
    "**é—®é¢˜**ï¼šXavieråˆå§‹åŒ–å‡è®¾æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„ï¼Œä½† **ReLUä¸æ˜¯çº¿æ€§çš„**ï¼\n",
    "\n",
    "ReLUæ¿€æ´»å‡½æ•°ï¼š\n",
    "$$\n",
    "\\text{ReLU}(z) = \\max(0, z) = \\begin{cases}\n",
    "z, & \\text{if } z > 0 \\\\\n",
    "0, & \\text{if } z \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**å…³é”®è§‚å¯Ÿ**ï¼šReLUä¼šå°†çº¦ä¸€åŠçš„ç¥ç»å…ƒè¾“å‡ºç½®é›¶ï¼ˆè´Ÿå€¼éƒ¨åˆ†ï¼‰\n",
    "\n",
    "### 3.2 æ•°å­¦æ¨å¯¼\n",
    "\n",
    "å‡è®¾è¾“å…¥ $z \\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "\n",
    "**ReLUåçš„æ–¹å·®**ï¼š\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(\\text{ReLU}(z)) &= \\mathbb{E}[\\text{ReLU}(z)^2] - \\mathbb{E}[\\text{ReLU}(z)]^2 \\\\\n",
    "&\\approx \\frac{1}{2} \\cdot \\sigma^2 \\quad \\text{ï¼ˆReLUæ€æ­»ä¸€åŠç¥ç»å…ƒï¼‰}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**è¯¦ç»†æ¨å¯¼**ï¼š\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\text{ReLU}(z)^2] = \\int_{-\\infty}^{\\infty} \\max(0, z)^2 \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-z^2/(2\\sigma^2)} dz\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\int_{0}^{\\infty} z^2 \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-z^2/(2\\sigma^2)} dz = \\frac{\\sigma^2}{2}\n",
    "$$\n",
    "\n",
    "å› æ­¤ï¼Œå¦‚æœä½¿ç”¨Xavieråˆå§‹åŒ–ï¼Œç»è¿‡ReLUåï¼š\n",
    "$$\n",
    "\\text{Var}(\\text{output}) = \\frac{1}{2} \\cdot \\text{Var}(\\text{input})\n",
    "$$\n",
    "\n",
    "æ–¹å·®å‡åŠï¼ç»è¿‡å¤šå±‚åä¼šå¿«é€Ÿè¡°å‡ã€‚\n",
    "\n",
    "### 3.3 He åˆå§‹åŒ–è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "**æ€è·¯**ï¼šå°†Xavieråˆå§‹åŒ–çš„æ–¹å·®ä¹˜ä»¥2æ¥è¡¥å¿ReLUçš„æ–¹å·®å‡åŠæ•ˆåº”\n",
    "\n",
    "#### å‰å‘ä¼ æ’­åˆ†æï¼š\n",
    "\n",
    "$$\n",
    "z_i = \\sum_{j=1}^{n_{\\text{in}}} w_{ij} a_j, \\quad a = \\text{ReLU}(z)\n",
    "$$\n",
    "\n",
    "è¦ä½¿ $\\text{Var}(a_i) = \\text{Var}(a_{i-1})$ï¼š\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Var}(z_i) &= n_{\\text{in}} \\cdot \\sigma_w^2 \\cdot \\text{Var}(a_{i-1}) \\\\\n",
    "\\text{Var}(a_i) &= \\frac{1}{2} \\text{Var}(z_i) \\quad \\text{ï¼ˆReLUæ•ˆåº”ï¼‰} \\\\\n",
    "&= \\frac{1}{2} \\cdot n_{\\text{in}} \\cdot \\sigma_w^2 \\cdot \\text{Var}(a_{i-1})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "è¦ä½¿ $\\text{Var}(a_i) = \\text{Var}(a_{i-1})$ï¼š\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\cdot n_{\\text{in}} \\cdot \\sigma_w^2 = 1\n",
    "$$\n",
    "\n",
    "è§£å¾—ï¼š\n",
    "$$\n",
    "\\boxed{\\sigma_w^2 = \\frac{2}{n_{\\text{in}}}}\n",
    "$$\n",
    "\n",
    "### 3.4 Heåˆå§‹åŒ–çš„ä¸¤ç§å½¢å¼\n",
    "\n",
    "#### å½¢å¼1ï¼šæ­£æ€åˆ†å¸ƒï¼ˆæ¨èï¼‰\n",
    "$$\n",
    "W \\sim \\mathcal{N}\\left(0, \\frac{2}{n_{\\text{in}}}\\right)\n",
    "$$\n",
    "\n",
    "#### å½¢å¼2ï¼šå‡åŒ€åˆ†å¸ƒ\n",
    "$$\n",
    "W \\sim \\mathcal{U}\\left[-\\sqrt{\\frac{6}{n_{\\text{in}}}}, \\sqrt{\\frac{6}{n_{\\text{in}}}}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "source": "# å‡ ä½•ç›´è§‰ï¼šå¯è§†åŒ–ReLUå¯¹åˆ†å¸ƒçš„å½±å“\n\nprint(\"=\" * 70)\nprint(\"ğŸ¨ å‡ ä½•ç›´è§‰ï¼šReLUçš„'åŠç©ºé—´è¿‡æ»¤'æ•ˆåº”\")\nprint(\"=\" * 70)\n\n# ç”Ÿæˆæ•°æ®\nsigma = 1.0\nx = np.linspace(-4, 4, 1000)\nz_samples = np.random.normal(0, sigma, size=10000)\na_samples = np.maximum(0, z_samples)\n\n# ç†è®ºåˆ†å¸ƒ\npdf_z = (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * (x / sigma)**2)\n\n# åˆ›å»ºå›¾å½¢\nfig = plt.figure(figsize=(16, 10))\ngs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n\n# === ç¬¬1è¡Œï¼šåˆ†æ­¥æ¼”ç¤ºReLUçš„ä½œç”¨ ===\nax1 = fig.add_subplot(gs[0, :])\nax1.fill_between(x, 0, pdf_z, where=(x < 0), alpha=0.3, color='red', label='è´ŸåŠéƒ¨åˆ†ï¼ˆè¢«ç æ‰ï¼‰')\nax1.fill_between(x, 0, pdf_z, where=(x >= 0), alpha=0.7, color='green', label='æ­£åŠéƒ¨åˆ†ï¼ˆä¿ç•™ï¼‰')\nax1.plot(x, pdf_z, 'b-', linewidth=2, label='åŸå§‹æ­£æ€åˆ†å¸ƒ N(0,1)')\nax1.axvline(0, color='black', linestyle='--', linewidth=2, label='ReLUåˆ†ç•Œçº¿ (x=0)')\nax1.set_xlabel('z', fontsize=12)\nax1.set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12)\nax1.set_title('æ­¥éª¤1ï¼šReLUå°†è´ŸåŠéƒ¨åˆ†ç½®é›¶ï¼ˆç æ‰çº¢è‰²åŒºåŸŸï¼‰', fontsize=14, fontweight='bold')\nax1.legend(fontsize=11, loc='upper left')\nax1.grid(True, alpha=0.3)\n\n# æ·»åŠ æ–‡å­—æ ‡æ³¨\nax1.text(-2, 0.25, 'âŒ ç æ‰\\n(â†’ 0)', fontsize=14, ha='center',\n         bbox=dict(boxstyle='round', facecolor='red', alpha=0.6))\nax1.text(2, 0.25, 'âœ… ä¿ç•™\\n(ä¸å˜)', fontsize=14, ha='center',\n         bbox=dict(boxstyle='round', facecolor='green', alpha=0.6))\n\n# === ç¬¬2è¡Œå·¦ï¼šè¾“å…¥åˆ†å¸ƒ ===\nax2 = fig.add_subplot(gs[1, 0])\nax2.hist(z_samples, bins=60, density=True, alpha=0.7, color='blue', edgecolor='black')\nax2.axvline(0, color='red', linestyle='--', linewidth=3, label='ReLUé˜ˆå€¼')\nax2.set_xlabel('z', fontsize=11)\nax2.set_ylabel('å¯†åº¦', fontsize=11)\nax2.set_title('è¾“å…¥åˆ†å¸ƒ z ~ N(0, 1)', fontsize=13, fontweight='bold')\nax2.legend(fontsize=10)\nax2.grid(True, alpha=0.3)\n\n# ç»Ÿè®¡ä¿¡æ¯\nz_mean = np.mean(z_samples)\nz_var = np.var(z_samples)\nax2.text(0.05, 0.95, f'å‡å€¼: {z_mean:.3f}\\næ–¹å·®: {z_var:.3f}',\n         transform=ax2.transAxes, fontsize=10,\n         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8),\n         verticalalignment='top')\n\n# === ç¬¬2è¡Œå³ï¼šReLUè¾“å‡ºåˆ†å¸ƒ ===\nax3 = fig.add_subplot(gs[1, 1])\nax3.hist(a_samples, bins=60, density=True, alpha=0.7, color='green', edgecolor='black')\nax3.axvline(0, color='red', linestyle='--', linewidth=3)\nax3.set_xlabel('a', fontsize=11)\nax3.set_ylabel('å¯†åº¦', fontsize=11)\nax3.set_title('ReLUè¾“å‡ºåˆ†å¸ƒ a = max(0, z)', fontsize=13, fontweight='bold')\nax3.grid(True, alpha=0.3)\n\n# ç»Ÿè®¡ä¿¡æ¯\na_mean = np.mean(a_samples)\na_var = np.var(a_samples)\nax3.text(0.05, 0.95, f'å‡å€¼: {a_mean:.3f}\\næ–¹å·®: {a_var:.3f}',\n         transform=ax3.transAxes, fontsize=10,\n         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8),\n         verticalalignment='top')\n\n# æ·»åŠ å°–å³°æ ‡æ³¨ï¼ˆå¾ˆå¤šæ ·æœ¬åœ¨0å¤„ï¼‰\nax3.text(0.5, 0.5, f'â† çº¦50%çš„æ ·æœ¬\\n   è¢«ç½®é›¶ï¼ˆå †ç§¯åœ¨0å¤„ï¼‰',\n         fontsize=11, color='red', fontweight='bold',\n         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\n# === ç¬¬3è¡Œï¼šæ–¹å·®å¯¹æ¯” ===\nax4 = fig.add_subplot(gs[2, :])\n\ncategories = ['è¾“å…¥æ–¹å·®\\nVar(z)', 'ReLUåæ–¹å·®\\nVar(a)', 'ç†è®ºé¢„æµ‹\\n(Var(z)/2)']\nvalues = [z_var, a_var, z_var / 2]\ncolors = ['blue', 'green', 'orange']\n\nbars = ax4.bar(categories, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2, width=0.6)\nax4.set_ylabel('æ–¹å·®', fontsize=12)\nax4.set_title('æ–¹å·®å¯¹æ¯”ï¼šéªŒè¯\"æ–¹å·®å‡åŠ\"', fontsize=14, fontweight='bold')\nax4.grid(True, alpha=0.3, axis='y')\n\n# æ·»åŠ æ•°å€¼æ ‡ç­¾\nfor bar, val in zip(bars, values):\n    height = bar.get_height()\n    ax4.text(bar.get_x() + bar.get_width()/2., height,\n            f'{val:.4f}',\n            ha='center', va='bottom', fontsize=12, fontweight='bold')\n\n# æ·»åŠ ç®­å¤´å’Œæ ‡æ³¨\nax4.annotate('', xy=(1, a_var), xytext=(0, z_var),\n            arrowprops=dict(arrowstyle='->',lw=3, color='red'))\nax4.text(0.5, (z_var + a_var) / 2, f'å‡å°‘çº¦ {(1 - a_var/z_var)*100:.1f}%\\nâ‰ˆ 50%',\n        fontsize=12, ha='center', fontweight='bold',\n        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ¯ å‡ ä½•ç›´è§‰æ€»ç»“ï¼š\")\nprint(\"=\"*70)\nprint(\"1ï¸âƒ£  è¾“å…¥ï¼šå¯¹ç§°çš„é’Ÿå½¢æ›²çº¿ï¼ˆæ­£æ€åˆ†å¸ƒï¼‰\")\nprint(\"2ï¸âƒ£  ReLUä½œç”¨ï¼šç æ‰è´ŸåŠè¾¹ï¼Œä¿ç•™æ­£åŠè¾¹\")\nprint(\"3ï¸âƒ£  ç»“æœï¼š\")\nprint(\"    âœ“ çº¦50%çš„ç¥ç»å…ƒè¢«'æ€æ­»'ï¼ˆè¾“å‡ºä¸º0ï¼‰\")\nprint(\"    âœ“ æ•°æ®é›†ä¸­åœ¨æ­£åŠè½´\")\nprint(\"    âœ“ æ–¹å·®å‡åŠï¼ˆå› ä¸ºè´ŸåŠéƒ¨åˆ†æ–¹å·®'æ¶ˆå¤±'äº†ï¼‰\")\nprint(\"4ï¸âƒ£  æ¨è®ºï¼šéœ€è¦æ›´å¤§çš„åˆå§‹æƒé‡æ–¹å·®æ¥è¡¥å¿\")\nprint(\"    â†’ Xavier: ÏƒÂ² = 1/n_in\")\nprint(\"    â†’ He:     ÏƒÂ² = 2/n_in (ä¹˜ä»¥2è¡¥å¿)\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### æ–¹æ³•3ï¸âƒ£ï¼šå‡ ä½•ç›´è§‰ï¼ˆå¯è§†åŒ–ç†è§£ï¼‰\n\n**å…³é”®æ´å¯Ÿ**ï¼šReLUå°±åƒä¸€ä¸ª\"åŠç©ºé—´è¿‡æ»¤å™¨\"\n\n- **æ­£æ€åˆ†å¸ƒ**æ˜¯å…³äº0å¯¹ç§°çš„é’Ÿå½¢æ›²çº¿\n- **ReLU**å°†è´ŸåŠéƒ¨åˆ†\"ç æ‰\"ï¼ˆç½®é›¶ï¼‰\n- åªä¿ç•™æ­£åŠéƒ¨åˆ† â†’ æ•°æ®é‡å‡åŠ â†’ æ–¹å·®å‡åŠ\n\nè®©æˆ‘ä»¬ç”¨å›¾åƒç›´è§‚ç†è§£è¿™ä¸ªè¿‡ç¨‹ï¼š",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼šéªŒè¯ReLUæ–¹å·®å‡åŠ\n\nprint(\"=\" * 70)\nprint(\"ğŸ² è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼šéªŒè¯ReLUæ–¹å·®å‡åŠ\")\nprint(\"=\" * 70)\n\n# å®éªŒå‚æ•°\nn_samples = 1000000  # å¤§æ ·æœ¬é‡ç¡®ä¿ç»Ÿè®¡å‡†ç¡®\nsigma_values = [0.5, 1.0, 2.0]  # æµ‹è¯•ä¸åŒçš„è¾“å…¥æ ‡å‡†å·®\n\nresults = []\n\nfor sigma in sigma_values:\n    # ç”Ÿæˆæ­£æ€åˆ†å¸ƒæ ·æœ¬\n    z = np.random.normal(0, sigma, size=n_samples)\n    \n    # åº”ç”¨ReLU\n    a = np.maximum(0, z)\n    \n    # è®¡ç®—ç»Ÿè®¡é‡\n    z_var = np.var(z)\n    a_var = np.var(a)\n    a_mean = np.mean(a)\n    \n    # ç†è®ºå€¼\n    theoretical_var = sigma**2 / 2\n    theoretical_mean = sigma / np.sqrt(2 * np.pi)\n    \n    # æ–¹å·®æ¯”ç‡\n    var_ratio = a_var / z_var\n    \n    results.append({\n        'sigma': sigma,\n        'z_var': z_var,\n        'a_var': a_var,\n        'a_mean': a_mean,\n        'theoretical_var': theoretical_var,\n        'theoretical_mean': theoretical_mean,\n        'var_ratio': var_ratio\n    })\n    \n    print(f\"\\nğŸ“Š è¾“å…¥æ ‡å‡†å·® Ïƒ = {sigma}\")\n    print(f\"   è¾“å…¥æ–¹å·® Var(z):        {z_var:.6f}\")\n    print(f\"   ReLUåæ–¹å·® Var(a):      {a_var:.6f}\")\n    print(f\"   ç†è®ºæ–¹å·® (ÏƒÂ²/2):       {theoretical_var:.6f}\")\n    print(f\"   ç›¸å¯¹è¯¯å·®:              {abs(a_var - theoretical_var) / theoretical_var * 100:.2f}%\")\n    print(f\"   æ–¹å·®æ¯”ç‡ (a/z):        {var_ratio:.6f} â‰ˆ 0.5 âœ…\")\n    print(f\"\")\n    print(f\"   ReLUåå‡å€¼ E[a]:       {a_mean:.6f}\")\n    print(f\"   ç†è®ºå‡å€¼ (Ïƒ/âˆš2Ï€):      {theoretical_mean:.6f}\")\n\n# å¯è§†åŒ–éªŒè¯\nfig, axes = plt.subplots(2, 3, figsize=(18, 10))\n\nfor idx, sigma in enumerate(sigma_values):\n    # ç”Ÿæˆæ ·æœ¬\n    z = np.random.normal(0, sigma, size=10000)  # ç”¨è¾ƒå°æ ·æœ¬ç”»å›¾\n    a = np.maximum(0, z)\n    \n    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥åˆ†å¸ƒ vs ReLUè¾“å‡ºåˆ†å¸ƒ\n    ax1 = axes[0, idx]\n    ax1.hist(z, bins=100, density=True, alpha=0.5, color='blue', label='è¾“å…¥ z')\n    ax1.hist(a, bins=100, density=True, alpha=0.5, color='red', label='ReLU(z)')\n    ax1.axvline(0, color='black', linestyle='--', linewidth=2, alpha=0.7)\n    ax1.set_xlabel('å€¼', fontsize=11)\n    ax1.set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=11)\n    ax1.set_title(f'Ïƒ={sigma}: è¾“å…¥ vs ReLUè¾“å‡º', fontsize=12, fontweight='bold')\n    ax1.legend(fontsize=10)\n    ax1.grid(True, alpha=0.3)\n    \n    # ç¬¬äºŒè¡Œï¼šæ–¹å·®å¯¹æ¯”æŸ±çŠ¶å›¾\n    ax2 = axes[1, idx]\n    \n    # è·å–ç»Ÿè®¡æ•°æ®\n    result = results[idx]\n    categories = ['è¾“å…¥æ–¹å·®\\nVar(z)', 'ReLUåæ–¹å·®\\nVar(a)', 'ç†è®ºæ–¹å·®\\n(ÏƒÂ²/2)']\n    values = [result['z_var'], result['a_var'], result['theoretical_var']]\n    colors = ['blue', 'red', 'green']\n    \n    bars = ax2.bar(categories, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n    ax2.set_ylabel('æ–¹å·®', fontsize=11)\n    ax2.set_title(f'Ïƒ={sigma}: æ–¹å·®å¯¹æ¯”', fontsize=12, fontweight='bold')\n    ax2.grid(True, alpha=0.3, axis='y')\n    \n    # æ·»åŠ æ•°å€¼æ ‡ç­¾\n    for bar, val in zip(bars, values):\n        height = bar.get_height()\n        ax2.text(bar.get_x() + bar.get_width()/2., height,\n                f'{val:.3f}',\n                ha='center', va='bottom', fontsize=10, fontweight='bold')\n    \n    # æ·»åŠ æ¯”ç‡æ ‡æ³¨\n    ax2.text(0.5, 0.95, f'æ¯”ç‡ = {result[\"var_ratio\"]:.3f} â‰ˆ 0.5',\n            transform=ax2.transAxes, fontsize=11, fontweight='bold',\n            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n            ha='center', va='top')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿç»“è®ºï¼š\")\nprint(\"=\"*70)\nprint(\"1ï¸âƒ£  å®éªŒéªŒè¯ï¼šVar(ReLU(z)) â‰ˆ Var(z) / 2\")\nprint(\"2ï¸âƒ£  ReLUç¡®å®å°†æ–¹å·®å‡åŠï¼ˆçº¦0.5å€ï¼‰\")\nprint(\"3ï¸âƒ£  ç†è®ºä¸å®éªŒé«˜åº¦å»åˆï¼ˆè¯¯å·® < 1%ï¼‰\")\nprint(\"4ï¸âƒ£  è¿™éªŒè¯äº†Heåˆå§‹åŒ–ä¸­ 2/n_in çš„æ¥æºï¼\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### æ–¹æ³•2ï¸âƒ£ï¼šè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼ˆå®éªŒéªŒè¯ï¼‰\n\n**å®éªŒæ€è·¯**ï¼šç”Ÿæˆå¤§é‡éšæœºæ ·æœ¬ï¼Œé€šè¿‡ç»Ÿè®¡éªŒè¯ç†è®ºç»“è®ºã€‚",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n### 3.2.1 ğŸ”¬ æ·±å…¥ç†è§£ï¼šReLUæ–¹å·®æ¨å¯¼çš„3ç§æ–¹æ³•\n\n**æ ¸å¿ƒé—®é¢˜**ï¼šä¸ºä»€ä¹ˆ ReLU ä¼šè®©æ–¹å·®å‡åŠï¼Ÿ\n\nè®©æˆ‘ä»¬ç”¨3ç§ä¸åŒçš„æ–¹æ³•æ¥ç†è§£è¿™ä¸ªå…³é”®ç»“è®ºï¼š\n1. **æ•°å­¦æ¨å¯¼**ï¼ˆç†è®ºï¼‰\n2. **è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ**ï¼ˆå®éªŒéªŒè¯ï¼‰\n3. **å‡ ä½•ç›´è§‰**ï¼ˆå¯è§†åŒ–ç†è§£ï¼‰\n\n#### æ–¹æ³•1ï¸âƒ£ï¼šæ•°å­¦æ¨å¯¼ï¼ˆä¸¥æ ¼è¯æ˜ï¼‰\n\n**å‡è®¾**ï¼šè¾“å…¥ $z \\sim \\mathcal{N}(0, \\sigma^2)$ï¼ˆå‡å€¼0ï¼Œæ–¹å·®$\\sigma^2$çš„æ­£æ€åˆ†å¸ƒï¼‰\n\n**ReLUè¾“å‡º**ï¼š\n$$\na = \\text{ReLU}(z) = \\begin{cases}\nz, & \\text{if } z > 0 \\\\\n0, & \\text{if } z \\leq 0\n\\end{cases}\n$$\n\n**è®¡ç®—æ–¹å·®**ï¼š\n\n$$\n\\begin{align}\n\\text{Var}(a) &= \\mathbb{E}[a^2] - \\mathbb{E}[a]^2\n\\end{align}\n$$\n\n**æ­¥éª¤1ï¼šè®¡ç®— $\\mathbb{E}[a]$**\n\n$$\n\\begin{align}\n\\mathbb{E}[a] &= \\mathbb{E}[\\text{ReLU}(z)] \\\\\n&= \\int_{-\\infty}^{\\infty} \\text{ReLU}(z) \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{z^2}{2\\sigma^2}} dz \\\\\n&= \\int_{0}^{\\infty} z \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{z^2}{2\\sigma^2}} dz \\quad \\text{ï¼ˆè´Ÿå€¼éƒ¨åˆ†ä¸º0ï¼‰}\n\\end{align}\n$$\n\nç”±äºæ­£æ€åˆ†å¸ƒå…³äº0å¯¹ç§°ï¼Œæ­£åŠéƒ¨åˆ†çš„å‡å€¼ä¸ºï¼š\n$$\n\\mathbb{E}[a] = \\frac{\\sigma}{\\sqrt{2\\pi}}\n$$\n\n**æ­¥éª¤2ï¼šè®¡ç®— $\\mathbb{E}[a^2]$**\n\n$$\n\\begin{align}\n\\mathbb{E}[a^2] &= \\int_{0}^{\\infty} z^2 \\cdot \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{z^2}{2\\sigma^2}} dz\n\\end{align}\n$$\n\nåˆ©ç”¨æ­£æ€åˆ†å¸ƒçš„æ€§è´¨ï¼ˆæ­£åŠéƒ¨åˆ†çš„äºŒé˜¶çŸ©ï¼‰ï¼š\n$$\n\\mathbb{E}[a^2] = \\frac{\\sigma^2}{2}\n$$\n\n**æ­¥éª¤3ï¼šè®¡ç®—æ–¹å·®**\n\n$$\n\\begin{align}\n\\text{Var}(a) &= \\mathbb{E}[a^2] - \\mathbb{E}[a]^2 \\\\\n&= \\frac{\\sigma^2}{2} - \\left(\\frac{\\sigma}{\\sqrt{2\\pi}}\\right)^2 \\\\\n&= \\frac{\\sigma^2}{2} - \\frac{\\sigma^2}{2\\pi} \\\\\n&= \\sigma^2 \\left(\\frac{1}{2} - \\frac{1}{2\\pi}\\right) \\\\\n&\\approx \\sigma^2 \\cdot 0.341\n\\end{align}\n$$\n\n**ç®€åŒ–è¿‘ä¼¼**ï¼šåœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¸¸å¸¸å¿½ç•¥å°çš„ä¿®æ­£é¡¹ï¼Œå–ï¼š\n$$\n\\boxed{\\text{Var}(\\text{ReLU}(z)) \\approx \\frac{\\sigma^2}{2}}\n$$\n\nè¿™å°±æ˜¯\"ReLUæ–¹å·®å‡åŠ\"çš„æ•°å­¦æ¥æºï¼\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ç° He åˆå§‹åŒ–\n",
    "\n",
    "def he_uniform(n_in: int, n_out: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Heå‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–\n",
    "    \n",
    "    é€‚ç”¨äºï¼šReLUåŠå…¶å˜ä½“ï¼ˆLeaky ReLUã€PReLUç­‰ï¼‰\n",
    "    \n",
    "    å…¬å¼:\n",
    "    -----\n",
    "    W ~ U[-âˆš(6/n_in), âˆš(6/n_in)]\n",
    "    \n",
    "    ä¸ºä»€ä¹ˆç”¨ n_in è€Œä¸æ˜¯ (n_in + n_out)ï¼Ÿ\n",
    "    - ReLUä¼šå°†è´Ÿå€¼ç½®é›¶ï¼Œç›¸å½“äºåªä¿ç•™ä¸€åŠçš„æ–¹å·®\n",
    "    - éœ€è¦æ›´å¤§çš„åˆå§‹æ–¹å·®æ¥è¡¥å¿\n",
    "    - åªå…³æ³¨å‰å‘ä¼ æ’­ï¼ˆn_inï¼‰ï¼Œå› ä¸ºåå‘ä¼ æ’­æ—¶ReLUæ¢¯åº¦ä¸º0æˆ–1\n",
    "    \n",
    "    å‚æ•°:\n",
    "    -----\n",
    "    n_in : int\n",
    "        è¾“å…¥ç¥ç»å…ƒæ•°é‡\n",
    "    n_out : int\n",
    "        è¾“å‡ºç¥ç»å…ƒæ•°é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    -----\n",
    "    W : ndarray, shape (n_in, n_out)\n",
    "        åˆå§‹åŒ–åçš„æƒé‡çŸ©é˜µ\n",
    "    \"\"\"\n",
    "    # è®¡ç®—å‡åŒ€åˆ†å¸ƒçš„è¾¹ç•Œ\n",
    "    limit = np.sqrt(6 / n_in)\n",
    "    \n",
    "    # ä»å‡åŒ€åˆ†å¸ƒä¸­é‡‡æ ·\n",
    "    W = np.random.uniform(-limit, limit, size=(n_in, n_out))\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "def he_normal(n_in: int, n_out: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Heæ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼ˆæœ€å¸¸ç”¨ï¼‰\n",
    "    \n",
    "    é€‚ç”¨äºï¼šReLUåŠå…¶å˜ä½“\n",
    "    \n",
    "    å…¬å¼:\n",
    "    -----\n",
    "    W ~ N(0, 2/n_in)\n",
    "    \n",
    "    æ ‡å‡†å·®:\n",
    "    -----\n",
    "    std = âˆš(2/n_in)\n",
    "    \n",
    "    å‚æ•°:\n",
    "    -----\n",
    "    n_in : int\n",
    "        è¾“å…¥ç¥ç»å…ƒæ•°é‡\n",
    "    n_out : int\n",
    "        è¾“å‡ºç¥ç»å…ƒæ•°é‡\n",
    "    \n",
    "    è¿”å›:\n",
    "    -----\n",
    "    W : ndarray, shape (n_in, n_out)\n",
    "        åˆå§‹åŒ–åçš„æƒé‡çŸ©é˜µ\n",
    "    \"\"\"\n",
    "    # è®¡ç®—æ ‡å‡†å·®\n",
    "    std = np.sqrt(2 / n_in)\n",
    "    \n",
    "    # ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·\n",
    "    W = np.random.normal(0, std, size=(n_in, n_out))\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "# æµ‹è¯•Heåˆå§‹åŒ–\n",
    "print(\"=\" * 60)\n",
    "print(\"Heåˆå§‹åŒ–æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_in, n_out = 100, 50\n",
    "\n",
    "# Heå‡åŒ€åˆå§‹åŒ–\n",
    "W_he_uniform = he_uniform(n_in, n_out)\n",
    "print(f\"\\nHeå‡åŒ€åˆå§‹åŒ– (n_in={n_in}, n_out={n_out}):\")\n",
    "print(f\"  å½¢çŠ¶: {W_he_uniform.shape}\")\n",
    "print(f\"  å‡å€¼: {np.mean(W_he_uniform):.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {np.std(W_he_uniform):.6f}\")\n",
    "print(f\"  ç†è®ºæ ‡å‡†å·®: {np.sqrt(2 / n_in):.6f}\")\n",
    "print(f\"  æœ€å°å€¼: {np.min(W_he_uniform):.6f}\")\n",
    "print(f\"  æœ€å¤§å€¼: {np.max(W_he_uniform):.6f}\")\n",
    "print(f\"  ç†è®ºè¾¹ç•Œ: Â±{np.sqrt(6 / n_in):.6f}\")\n",
    "\n",
    "# Heæ­£æ€åˆå§‹åŒ–\n",
    "W_he_normal = he_normal(n_in, n_out)\n",
    "print(f\"\\nHeæ­£æ€åˆå§‹åŒ– (n_in={n_in}, n_out={n_out}):\")\n",
    "print(f\"  å½¢çŠ¶: {W_he_normal.shape}\")\n",
    "print(f\"  å‡å€¼: {np.mean(W_he_normal):.6f}\")\n",
    "print(f\"  æ ‡å‡†å·®: {np.std(W_he_normal):.6f}\")\n",
    "print(f\"  ç†è®ºæ ‡å‡†å·®: {np.sqrt(2 / n_in):.6f}\")\n",
    "\n",
    "# å¯¹æ¯”Xavierå’ŒHeåˆå§‹åŒ–\n",
    "W_xavier = xavier_normal(n_in, n_out)\n",
    "\n",
    "print(\"\\n=\" * 60)\n",
    "print(\"Xavier vs He åˆå§‹åŒ–å¯¹æ¯”\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'æ–¹æ³•':<15} {'æ ‡å‡†å·®ï¼ˆå®é™…ï¼‰':<15} {'æ ‡å‡†å·®ï¼ˆç†è®ºï¼‰':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Xavier':<15} {np.std(W_xavier):<15.6f} {np.sqrt(2 / (n_in + n_out)):<15.6f}\")\n",
    "print(f\"{'He':<15} {np.std(W_he_normal):<15.6f} {np.sqrt(2 / n_in):<15.6f}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\n",
    "print(f\"   Heåˆå§‹åŒ–çš„æ ‡å‡†å·®ï¼ˆ{np.sqrt(2 / n_in):.4f}ï¼‰\")\n",
    "print(f\"   æ¯”Xavieråˆå§‹åŒ–ï¼ˆ{np.sqrt(2 / (n_in + n_out)):.4f}ï¼‰\")\n",
    "print(f\"   å¤§çº¦æ˜¯ {np.sqrt(2 / n_in) / np.sqrt(2 / (n_in + n_out)):.2f} å€\")\n",
    "print(\"\\nâœ… è¿™æ˜¯ä¸ºäº†è¡¥å¿ReLUçš„æ–¹å·®å‡åŠæ•ˆåº”ï¼\")\n",
    "\n",
    "# å¯è§†åŒ–å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# æƒé‡åˆ†å¸ƒå¯¹æ¯”\n",
    "axes[0].hist(W_xavier.flatten(), bins=50, density=True, \n",
    "            alpha=0.5, color='blue', label='Xavier', edgecolor='black')\n",
    "axes[0].hist(W_he_normal.flatten(), bins=50, density=True, \n",
    "            alpha=0.5, color='red', label='He', edgecolor='black')\n",
    "axes[0].set_xlabel('æƒé‡å€¼', fontsize=12)\n",
    "axes[0].set_ylabel('æ¦‚ç‡å¯†åº¦', fontsize=12)\n",
    "axes[0].set_title('Xavier vs He åˆå§‹åŒ– - æƒé‡åˆ†å¸ƒå¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# æ ‡å‡†å·®å¯¹æ¯”\n",
    "methods = ['Xavier', 'He']\n",
    "stds = [np.std(W_xavier), np.std(W_he_normal)]\n",
    "colors = ['blue', 'red']\n",
    "axes[1].bar(methods, stds, color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1].set_ylabel('æ ‡å‡†å·®', fontsize=12)\n",
    "axes[1].set_title('Xavier vs He åˆå§‹åŒ– - æ ‡å‡†å·®å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for i, (method, std) in enumerate(zip(methods, stds)):\n",
    "    axes[1].text(i, std + 0.005, f'{std:.4f}', \n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Heåˆå§‹åŒ–å®ç°å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Xavier vs He - ä½•æ—¶ä½¿ç”¨ï¼Ÿ\n",
    "\n",
    "| æ¿€æ´»å‡½æ•° | æ¨èåˆå§‹åŒ– | åŸå›  |\n",
    "|---------|-----------|------|\n",
    "| **ReLU** | **He** | ReLUä¼šå°†è´Ÿå€¼ç½®é›¶ï¼Œéœ€è¦æ›´å¤§çš„åˆå§‹æ–¹å·® |\n",
    "| **Leaky ReLU** | **He** | ç±»ä¼¼ReLUï¼Œä½†è´Ÿå€¼éƒ¨åˆ†æœ‰å°æ–œç‡ |\n",
    "| **PReLU** | **He** | å‚æ•°åŒ–ReLU |\n",
    "| **Tanh** | **Xavier** | è¿‘ä¼¼çº¿æ€§ï¼ˆåœ¨0é™„è¿‘ï¼‰ |\n",
    "| **Sigmoid** | **Xavier** | è¿‘ä¼¼çº¿æ€§ï¼ˆåœ¨0é™„è¿‘ï¼‰ |\n",
    "| **Linear** | **Xavier** | å®Œå…¨çº¿æ€§ |\n",
    "\n",
    "**ç°ä»£å®è·µ**ï¼š\n",
    "- **é»˜è®¤ä½¿ç”¨ He åˆå§‹åŒ–** + ReLUï¼ˆæœ€å¸¸ç”¨ç»„åˆï¼‰\n",
    "- ç‰¹æ®Šæƒ…å†µï¼ˆå¦‚GANã€RNNï¼‰å¯èƒ½éœ€è¦è°ƒæ•´"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 5.5 ğŸ”™ åå‘ä¼ æ’­ä¸­çš„æ¢¯åº¦æ–¹å·®åˆ†æ\n\n**ä¸ºä»€ä¹ˆåå‘ä¼ æ’­ä¹Ÿéœ€è¦è€ƒè™‘æ–¹å·®ï¼Ÿ**\n\nè‰¯å¥½çš„åˆå§‹åŒ–ä¸ä»…è¦ä¿æŒå‰å‘ä¼ æ’­çš„æ¿€æ´»å€¼ç¨³å®šï¼Œè¿˜è¦ä¿æŒåå‘ä¼ æ’­çš„æ¢¯åº¦ç¨³å®šï¼\n\n#### åå‘ä¼ æ’­æ¢¯åº¦å…¬å¼ï¼ˆå›é¡¾ï¼‰\n\nå¯¹äºç¬¬ $l$ å±‚ï¼š\n$$\n\\frac{\\partial L}{\\partial \\mathbf{a}^{(l-1)}} = \\frac{\\partial L}{\\partial \\mathbf{z}^{(l)}} \\cdot \\frac{\\partial \\mathbf{z}^{(l)}}{\\partial \\mathbf{a}^{(l-1)}} = \\delta^{(l)} \\cdot (W^{(l)})^T\n$$\n\nå…¶ä¸­ï¼š\n- $\\delta^{(l)} = \\frac{\\partial L}{\\partial \\mathbf{z}^{(l)}}$ æ˜¯ç¬¬ $l$ å±‚çš„è¯¯å·®ä¿¡å·\n- $(W^{(l)})^T$ æ˜¯æƒé‡çŸ©é˜µçš„è½¬ç½®\n\n#### æ–¹å·®åˆ†æ\n\n**å‡è®¾**ï¼š\n- ç¬¬ $l$ å±‚çš„æ¢¯åº¦æ–¹å·®ä¸º $\\text{Var}(\\delta^{(l)})$\n- æƒé‡åˆå§‹åŒ–ï¼š$W^{(l)} \\sim \\mathcal{N}(0, \\sigma_w^2)$\n- æƒé‡ä¸æ¢¯åº¦ç‹¬ç«‹\n\n**è®¡ç®—ç¬¬ $l-1$ å±‚çš„æ¢¯åº¦æ–¹å·®**ï¼š\n\nå¯¹äºå•ä¸ªç¥ç»å…ƒï¼š\n$$\n\\frac{\\partial L}{\\partial a^{(l-1)}_j} = \\sum_{i=1}^{n_l} \\delta^{(l)}_i \\cdot w^{(l)}_{ij}\n$$\n\næ–¹å·®ï¼ˆå‡è®¾ç‹¬ç«‹ï¼‰ï¼š\n$$\n\\begin{align}\n\\text{Var}\\left(\\frac{\\partial L}{\\partial a^{(l-1)}_j}\\right) &= \\sum_{i=1}^{n_l} \\text{Var}(\\delta^{(l)}_i \\cdot w^{(l)}_{ij}) \\\\\n&= \\sum_{i=1}^{n_l} \\text{Var}(\\delta^{(l)}_i) \\cdot \\text{Var}(w^{(l)}_{ij}) \\\\\n&= n_l \\cdot \\text{Var}(\\delta^{(l)}) \\cdot \\sigma_w^2\n\\end{align}\n$$\n\nå…¶ä¸­ $n_l$ æ˜¯ç¬¬ $l$ å±‚çš„ç¥ç»å…ƒæ•°ï¼ˆå³è¾“å‡ºç»´åº¦ï¼Œ$n_{\\text{out}}$ï¼‰\n\n**è¦ä¿æŒæ¢¯åº¦æ–¹å·®ä¸å˜**ï¼š\n$$\n\\text{Var}\\left(\\frac{\\partial L}{\\partial \\mathbf{a}^{(l-1)}}\\right) = \\text{Var}(\\delta^{(l)})\n$$\n\nå› æ­¤ï¼š\n$$\nn_l \\cdot \\text{Var}(\\delta^{(l)}) \\cdot \\sigma_w^2 = \\text{Var}(\\delta^{(l)})\n$$\n\nè§£å¾—ï¼š\n$$\n\\boxed{\\sigma_w^2 = \\frac{1}{n_{\\text{out}}}}\n$$\n\n#### Xavieråˆå§‹åŒ–çš„æŠ˜ä¸­\n\n- **å‰å‘ä¼ æ’­è¦æ±‚**ï¼š$\\sigma_w^2 = \\frac{1}{n_{\\text{in}}}$\n- **åå‘ä¼ æ’­è¦æ±‚**ï¼š$\\sigma_w^2 = \\frac{1}{n_{\\text{out}}}$\n\n**Xavierçš„è§£å†³æ–¹æ¡ˆ**ï¼ˆå–å¹³å‡ï¼‰ï¼š\n$$\n\\sigma_w^2 = \\frac{2}{n_{\\text{in}} + n_{\\text{out}}}\n$$\n\næˆ–è€…ä½¿ç”¨**åªè€ƒè™‘å‰å‘ä¼ æ’­**ï¼ˆç°ä»£å®è·µä¸­æ›´å¸¸è§ï¼‰ï¼š\n$$\n\\sigma_w^2 = \\frac{1}{n_{\\text{in}}} \\quad \\text{ï¼ˆé€‚ç”¨äºTanh/Sigmoidï¼‰}\n$$\n\n**Heåˆå§‹åŒ–**ï¼ˆé’ˆå¯¹ReLUï¼Œåªè€ƒè™‘å‰å‘ä¼ æ’­ï¼‰ï¼š\n$$\n\\sigma_w^2 = \\frac{2}{n_{\\text{in}}}\n$$\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# åˆå§‹åŒ–æ–¹æ³•é€‰æ‹©æµç¨‹å›¾\n\nprint(\"=\" * 70)\nprint(\"ğŸ—ºï¸  æƒé‡åˆå§‹åŒ–å†³ç­–æµç¨‹å›¾\")\nprint(\"=\" * 70)\n\nfig, ax = plt.subplots(figsize=(16, 12))\nax.axis('off')\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\n\n# é¢œè‰²æ–¹æ¡ˆ\ncolor_start = '#FFE5E5'\ncolor_decision = '#E3F2FD'\ncolor_result_good = '#C8E6C9'\ncolor_result_neutral = '#FFF9C4'\n\n# === èµ·ç‚¹ ===\nax.text(5, 9.5, 'å¼€å§‹ï¼šé€‰æ‹©æƒé‡åˆå§‹åŒ–æ–¹æ³•', \n        ha='center', va='center', fontsize=14, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.5', facecolor=color_start, edgecolor='black', linewidth=2))\n\n# ç®­å¤´1\nax.annotate('', xy=(5, 8.8), xytext=(5, 9.2),\n            arrowprops=dict(arrowstyle='->', lw=2, color='black'))\n\n# === å†³ç­–1ï¼šæ¿€æ´»å‡½æ•°ç±»å‹ ===\nax.text(5, 8.5, 'ä½¿ç”¨ä»€ä¹ˆæ¿€æ´»å‡½æ•°ï¼Ÿ', \n        ha='center', va='center', fontsize=13, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.4', facecolor=color_decision, edgecolor='blue', linewidth=2))\n\n# åˆ†æ”¯ï¼šReLUç³»åˆ—\nax.annotate('', xy=(2, 7.8), xytext=(4.5, 8.3),\n            arrowprops=dict(arrowstyle='->', lw=2, color='red'))\nax.text(3, 8.1, 'ReLU / Leaky ReLU / PReLU', fontsize=10, \n        ha='center', color='red', fontweight='bold')\n\n# åˆ†æ”¯ï¼šTanh/Sigmoid\nax.annotate('', xy=(8, 7.8), xytext=(5.5, 8.3),\n            arrowprops=dict(arrowstyle='->', lw=2, color='blue'))\nax.text(7, 8.1, 'Tanh / Sigmoid', fontsize=10, \n        ha='center', color='blue', fontweight='bold')\n\n# === ReLUè·¯å¾„ ===\nax.text(2, 7.5, 'He åˆå§‹åŒ–', \n        ha='center', va='center', fontsize=12, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.4', facecolor=color_result_good, edgecolor='darkgreen', linewidth=2))\n\n# è¯¦ç»†è¯´æ˜\nax.text(2, 6.9, 'æ¨èï¼šhe_normal', fontsize=10, ha='center', style='italic')\nax.text(2, 6.6, 'W ~ N(0, 2/n_in)', fontsize=9, ha='center',\n        bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='gray'))\n\n# ä»£ç ç¤ºä¾‹\ncode_text = \"W = WeightInitializer.initialize(\\n    (n_in, n_out),\\n    method='he_normal')\"\nax.text(2, 5.9, code_text, fontsize=8, ha='center', family='monospace',\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#f0f0f0', edgecolor='black'))\n\n# === Tanh/Sigmoidè·¯å¾„ ===\nax.text(8, 7.5, 'Xavier åˆå§‹åŒ–', \n        ha='center', va='center', fontsize=12, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.4', facecolor=color_result_good, edgecolor='darkgreen', linewidth=2))\n\n# è¯¦ç»†è¯´æ˜\nax.text(8, 6.9, 'æ¨èï¼šxavier_normal', fontsize=10, ha='center', style='italic')\nax.text(8, 6.6, 'W ~ N(0, 2/(n_in+n_out))', fontsize=9, ha='center',\n        bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='gray'))\n\n# ä»£ç ç¤ºä¾‹\ncode_text2 = \"W = WeightInitializer.initialize(\\n    (n_in, n_out),\\n    method='xavier_normal')\"\nax.text(8, 5.9, code_text2, fontsize=8, ha='center', family='monospace',\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#f0f0f0', edgecolor='black'))\n\n# === ç‰¹æ®Šæƒ…å†µ ===\nax.text(5, 4.8, 'ç‰¹æ®Šæƒ…å†µè€ƒè™‘', \n        ha='center', va='center', fontsize=12, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.3', facecolor=color_result_neutral, edgecolor='orange', linewidth=2))\n\n# ç‰¹æ®Šæƒ…å†µåˆ—è¡¨\nspecial_cases = [\n    ('Batch Normalization', 'åˆå§‹åŒ–ä¸é‚£ä¹ˆå…³é”®ï¼Œå¯ç”¨é»˜è®¤'),\n    ('RNN/LSTM', 'ä½¿ç”¨æ­£äº¤åˆå§‹åŒ– (Orthogonal)'),\n    ('GAN', 'é€šå¸¸ N(0, 0.02Â²)'),\n    ('ResNet', 'Heåˆå§‹åŒ–ï¼Œæ³¨æ„æ®‹å·®è¿æ¥'),\n    ('éå¸¸æ·±çš„ç½‘ç»œ', 'è€ƒè™‘ LSUV æˆ–åŠ¨æ€åˆå§‹åŒ–')\n]\n\ny_pos = 3.9\nfor case, suggestion in special_cases:\n    ax.text(1.5, y_pos, f'â€¢ {case}:', fontsize=9, ha='left', fontweight='bold')\n    ax.text(8.5, y_pos, suggestion, fontsize=9, ha='right', style='italic', color='darkblue')\n    y_pos -= 0.4\n\n# === åç½®åˆå§‹åŒ– ===\nax.text(5, 1.5, 'âš ï¸  åç½® (bias) åˆå§‹åŒ–', \n        ha='center', va='center', fontsize=11, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='#FFE0B2', edgecolor='darkorange', linewidth=2))\n\nax.text(5, 1.0, 'é€šå¸¸åˆå§‹åŒ–ä¸º 0ï¼šb = np.zeros((1, n_out))',\n        fontsize=9, ha='center', family='monospace',\n        bbox=dict(boxstyle='round,pad=0.2', facecolor='white', edgecolor='gray'))\n\nax.text(5, 0.6, 'æŸäº›æƒ…å†µï¼ˆå¦‚LSTMçš„é—å¿˜é—¨ï¼‰å¯èƒ½éœ€è¦ç‰¹æ®Šåˆå§‹åŒ–',\n        fontsize=8, ha='center', style='italic', color='gray')\n\n# === å¿«é€Ÿå‚è€ƒè¡¨ ===\nax.text(5, 0.2, 'ğŸ’¡ å¿«é€Ÿè®°å¿†ï¼šReLU â†’ He | Tanh/Sigmoid â†’ Xavier', \n        ha='center', va='center', fontsize=12, fontweight='bold',\n        bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', edgecolor='red', linewidth=2))\n\nplt.title('æƒé‡åˆå§‹åŒ–å†³ç­–æµç¨‹å›¾', fontsize=16, fontweight='bold', pad=20)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“‹ åˆå§‹åŒ–æ–¹æ³•å¿«é€Ÿå‚è€ƒè¡¨\")\nprint(\"=\"*70)\nprint(f\"{'æ¿€æ´»å‡½æ•°':<20} {'æ¨èåˆå§‹åŒ–':<20} {'å…¬å¼':<30}\")\nprint(\"-\"*70)\nprint(f\"{'ReLU':<20} {'he_normal':<20} {'W ~ N(0, 2/n_in)':<30}\")\nprint(f\"{'Leaky ReLU':<20} {'he_normal':<20} {'W ~ N(0, 2/n_in)':<30}\")\nprint(f\"{'Tanh':<20} {'xavier_normal':<20} {'W ~ N(0, 2/(n_in+n_out))':<30}\")\nprint(f\"{'Sigmoid':<20} {'xavier_normal':<20} {'W ~ N(0, 2/(n_in+n_out))':<30}\")\nprint(f\"{'Linear':<20} {'xavier_normal':<20} {'W ~ N(0, 2/(n_in+n_out))':<30}\")\nprint(\"-\"*70)\nprint(f\"{'åç½® (å…¨éƒ¨)':<20} {'zeros':<20} {'b = 0':<30}\")\nprint(\"=\"*70)\n\nprint(\"\\nğŸ’¡ è®°å¿†æŠ€å·§ï¼š\")\nprint(\"   1ï¸âƒ£  ReLUç±» â†’ Heåˆå§‹åŒ–ï¼ˆå› ä¸ºReLUä¼š'æ€æ­»'ä¸€åŠç¥ç»å…ƒï¼‰\")\nprint(\"   2ï¸âƒ£  å¹³æ»‘å‡½æ•° â†’ Xavieråˆå§‹åŒ–ï¼ˆTanh/Sigmoidåœ¨0é™„è¿‘è¿‘ä¼¼çº¿æ€§ï¼‰\")\nprint(\"   3ï¸âƒ£  ä¸ç¡®å®šæ—¶ â†’ ä½¿ç”¨Heåˆå§‹åŒ–ï¼ˆç°ä»£ç½‘ç»œå¤§å¤šç”¨ReLUï¼‰\")\nprint(\"   4ï¸âƒ£  åç½® â†’ å‡ ä¹æ€»æ˜¯åˆå§‹åŒ–ä¸º0\")\nprint(\"\\nâœ… éµå¾ªè¿™ä¸ªæµç¨‹ï¼Œä½ çš„ç½‘ç»œå°†æœ‰è‰¯å¥½çš„èµ·ç‚¹ï¼\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 6.5 ğŸ—ºï¸ åˆå§‹åŒ–æ–¹æ³•é€‰æ‹©æµç¨‹å›¾\n\n**å¦‚ä½•å¿«é€Ÿé€‰æ‹©åˆé€‚çš„åˆå§‹åŒ–æ–¹æ³•ï¼Ÿ**\n\nè®©æˆ‘ä»¬ç”¨ä¸€ä¸ªå†³ç­–æ ‘å’Œå¯è§†åŒ–æµç¨‹å›¾æ¥å¸®åŠ©ä½ åšå‡ºæ­£ç¡®é€‰æ‹©ï¼š",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n\n## 4ï¸âƒ£ å®Œæ•´çš„åˆå§‹åŒ–å·¥å…·ç±»\n\nè®©æˆ‘ä»¬å®ç°ä¸€ä¸ªç»Ÿä¸€çš„åˆå§‹åŒ–å·¥å…·ç±»ï¼Œæ”¯æŒå¤šç§åˆå§‹åŒ–æ–¹æ³•ï¼š"
  },
  {
   "cell_type": "code",
   "source": "class WeightInitializer:\n    \"\"\"\n    æƒé‡åˆå§‹åŒ–å·¥å…·ç±»\n    \n    æ”¯æŒçš„åˆå§‹åŒ–æ–¹æ³•ï¼š\n    - zeros: å…¨é›¶åˆå§‹åŒ–ï¼ˆä»…ç”¨äºåç½®ï¼Œä¸è¦ç”¨äºæƒé‡ï¼ï¼‰\n    - ones: å…¨ä¸€åˆå§‹åŒ–\n    - constant: å¸¸æ•°åˆå§‹åŒ–\n    - uniform: å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–\n    - normal: æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–\n    - xavier_uniform: Xavierå‡åŒ€åˆå§‹åŒ–ï¼ˆTanh/Sigmoidï¼‰\n    - xavier_normal: Xavieræ­£æ€åˆå§‹åŒ–ï¼ˆTanh/Sigmoidï¼‰\n    - he_uniform: Heå‡åŒ€åˆå§‹åŒ–ï¼ˆReLUï¼‰\n    - he_normal: Heæ­£æ€åˆå§‹åŒ–ï¼ˆReLUï¼‰- æ¨è\n    \"\"\"\n    \n    @staticmethod\n    def initialize(shape: Tuple[int, int], method: str = 'he_normal', gain: float = 1.0) -> np.ndarray:\n        \"\"\"\n        æ ¹æ®æŒ‡å®šæ–¹æ³•åˆå§‹åŒ–æƒé‡\n        \n        å‚æ•°:\n        -----\n        shape : Tuple[int, int]\n            æƒé‡çŸ©é˜µå½¢çŠ¶ (n_in, n_out)\n        method : str\n            åˆå§‹åŒ–æ–¹æ³•åç§°\n        gain : float\n            å¢ç›Šå› å­ï¼ˆç”¨äºè°ƒæ•´åˆå§‹åŒ–å¼ºåº¦ï¼‰\n            - gain > 1: å¢å¤§åˆå§‹åŒ–æ–¹å·®\n            - gain < 1: å‡å°åˆå§‹åŒ–æ–¹å·®\n        \n        è¿”å›:\n        -----\n        weights : ndarray, shape (n_in, n_out)\n            åˆå§‹åŒ–åçš„æƒé‡çŸ©é˜µ\n        \n        ç¤ºä¾‹:\n        -----\n        >>> W = WeightInitializer.initialize((100, 50), method='he_normal')\n        >>> b = WeightInitializer.initialize((1, 50), method='zeros')\n        \"\"\"\n        n_in, n_out = shape\n        \n        if method == 'zeros':\n            # å…¨é›¶åˆå§‹åŒ–ï¼ˆä»…ç”¨äºåç½®ï¼‰\n            return np.zeros(shape)\n        \n        elif method == 'ones':\n            # å…¨ä¸€åˆå§‹åŒ–\n            return np.ones(shape)\n        \n        elif method == 'constant':\n            # å¸¸æ•°åˆå§‹åŒ–ï¼ˆgainä½œä¸ºå¸¸æ•°å€¼ï¼‰\n            return np.full(shape, gain)\n        \n        elif method == 'uniform':\n            # å‡åŒ€åˆ†å¸ƒ U[-gain, gain]\n            return np.random.uniform(-gain, gain, size=shape)\n        \n        elif method == 'normal':\n            # æ­£æ€åˆ†å¸ƒ N(0, gain^2)\n            return np.random.normal(0, gain, size=shape)\n        \n        elif method == 'xavier_uniform':\n            # Xavierå‡åŒ€åˆå§‹åŒ–\n            # W ~ U[-âˆš(6/(n_in + n_out)), âˆš(6/(n_in + n_out))]\n            limit = np.sqrt(6 / (n_in + n_out)) * gain\n            return np.random.uniform(-limit, limit, size=shape)\n        \n        elif method == 'xavier_normal':\n            # Xavieræ­£æ€åˆå§‹åŒ–\n            # W ~ N(0, 2/(n_in + n_out))\n            std = np.sqrt(2 / (n_in + n_out)) * gain\n            return np.random.normal(0, std, size=shape)\n        \n        elif method == 'he_uniform':\n            # Heå‡åŒ€åˆå§‹åŒ–ï¼ˆReLUä¸“ç”¨ï¼‰\n            # W ~ U[-âˆš(6/n_in), âˆš(6/n_in)]\n            limit = np.sqrt(6 / n_in) * gain\n            return np.random.uniform(-limit, limit, size=shape)\n        \n        elif method == 'he_normal':\n            # Heæ­£æ€åˆå§‹åŒ–ï¼ˆReLUä¸“ç”¨ï¼Œæ¨èï¼‰\n            # W ~ N(0, 2/n_in)\n            std = np.sqrt(2 / n_in) * gain\n            return np.random.normal(0, std, size=shape)\n        \n        else:\n            raise ValueError(f\"æœªçŸ¥çš„åˆå§‹åŒ–æ–¹æ³•: {method}\")\n\n\n# æµ‹è¯•åˆå§‹åŒ–å·¥å…·ç±»\nprint(\"=\" * 60)\nprint(\"WeightInitializer å·¥å…·ç±»æµ‹è¯•\")\nprint(\"=\" * 60)\n\n# æµ‹è¯•æ‰€æœ‰åˆå§‹åŒ–æ–¹æ³•\nmethods = ['zeros', 'uniform', 'normal', 'xavier_uniform', 'xavier_normal', \n           'he_uniform', 'he_normal']\n\nshape = (100, 50)\nprint(f\"\\næµ‹è¯•å½¢çŠ¶: {shape} (n_in=100, n_out=50)\\n\")\n\nfor method in methods:\n    W = WeightInitializer.initialize(shape, method=method)\n    print(f\"{method:<20} | å‡å€¼: {np.mean(W):>8.4f} | æ ‡å‡†å·®: {np.std(W):>8.4f} | \"\n          f\"æœ€å°å€¼: {np.min(W):>8.4f} | æœ€å¤§å€¼: {np.max(W):>8.4f}\")\n\nprint(\"\\nâœ… åˆå§‹åŒ–å·¥å…·ç±»æµ‹è¯•å®Œæˆï¼\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 5ï¸âƒ£ å¯è§†åŒ–å®éªŒï¼šæ¿€æ´»å€¼åˆ†å¸ƒå¯¹æ¯”\n\nè¿™æ˜¯æœ€ç›´è§‚çš„å®éªŒï¼šé€šè¿‡10å±‚æ·±çš„ç½‘ç»œï¼Œè§‚å¯Ÿä¸åŒåˆå§‹åŒ–æ–¹æ³•å¯¹æ¿€æ´»å€¼åˆ†å¸ƒçš„å½±å“ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def visualize_activation_distribution(n_layers=10, n_neurons=100, n_samples=1000):\n    \"\"\"\n    å¯è§†åŒ–ä¸åŒåˆå§‹åŒ–æ–¹æ³•å¯¹æ¿€æ´»å€¼åˆ†å¸ƒçš„å½±å“\n    \n    å®éªŒè®¾ç½®ï¼š\n    - æ„å»ºæ·±åº¦ç½‘ç»œï¼ˆ10å±‚ï¼‰\n    - ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°\n    - å¯¹æ¯”ä¸åŒåˆå§‹åŒ–æ–¹æ³•\n    - è§‚å¯Ÿæ¯å±‚æ¿€æ´»å€¼çš„åˆ†å¸ƒ\n    \n    å‚æ•°:\n    -----\n    n_layers : int\n        ç½‘ç»œæ·±åº¦\n    n_neurons : int\n        æ¯å±‚ç¥ç»å…ƒæ•°é‡\n    n_samples : int\n        è¾“å…¥æ ·æœ¬æ•°é‡\n    \"\"\"\n    print(\"=\" * 60)\n    print(f\"å®éªŒï¼šæ¿€æ´»å€¼åˆ†å¸ƒå¯¹æ¯”ï¼ˆ{n_layers}å±‚ç½‘ç»œï¼‰\")\n    print(\"=\" * 60)\n    \n    # è¾“å…¥æ•°æ®ï¼ˆæ ‡å‡†åŒ–ï¼Œå‡å€¼0æ–¹å·®1ï¼‰\n    X = np.random.randn(n_samples, n_neurons)\n    \n    # æµ‹è¯•ä¸‰ç§åˆå§‹åŒ–æ–¹æ³•\n    init_methods = {\n        'è¿‡å°åˆå§‹åŒ– (std=0.01)': ('normal', 0.01),\n        'Xavieråˆå§‹åŒ–': ('xavier_normal', 1.0),\n        'Heåˆå§‹åŒ– (æ¨è)': ('he_normal', 1.0)\n    }\n    \n    # å­˜å‚¨æ¯å±‚çš„æ¿€æ´»å€¼\n    activations_history = {}\n    \n    for name, (method, gain) in init_methods.items():\n        activations = X.copy()\n        layer_activations = [activations.copy()]\n        \n        # é€å±‚å‰å‘ä¼ æ’­\n        for layer in range(n_layers):\n            # åˆå§‹åŒ–æƒé‡\n            if method == 'normal':\n                W = np.random.normal(0, gain, size=(n_neurons, n_neurons))\n            else:\n                W = WeightInitializer.initialize((n_neurons, n_neurons), \n                                                 method=method, gain=gain)\n            \n            # å‰å‘ä¼ æ’­ï¼ˆæ— åç½®ï¼‰\n            z = activations @ W\n            activations = np.maximum(0, z)  # ReLUæ¿€æ´»\n            \n            layer_activations.append(activations.copy())\n        \n        activations_history[name] = layer_activations\n    \n    # å¯è§†åŒ–ï¼šç»˜åˆ¶æ¯å±‚çš„æ¿€æ´»å€¼åˆ†å¸ƒ\n    fig, axes = plt.subplots(3, 4, figsize=(18, 12))\n    axes = axes.flatten()\n    \n    # é€‰æ‹©è¦å¯è§†åŒ–çš„å±‚ï¼ˆç¬¬1, 2, 3, 5, 7, 10å±‚ï¼‰\n    layers_to_plot = [0, 1, 2, 4, 6, 9]\n    \n    for idx, layer_idx in enumerate(layers_to_plot):\n        ax_idx = idx * 2\n        \n        # å­å›¾1ï¼šæ¿€ï¿½ï¿½å€¼åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰\n        for name, layer_activations in activations_history.items():\n            acts = layer_activations[layer_idx + 1].flatten()\n            axes[ax_idx].hist(acts, bins=50, alpha=0.5, density=True, label=name)\n        \n        axes[ax_idx].set_xlabel('æ¿€æ´»å€¼', fontsize=10)\n        axes[ax_idx].set_ylabel('å¯†åº¦', fontsize=10)\n        axes[ax_idx].set_title(f'ç¬¬{layer_idx + 1}å±‚æ¿€æ´»å€¼åˆ†å¸ƒ', fontsize=11, fontweight='bold')\n        axes[ax_idx].legend(fontsize=8)\n        axes[ax_idx].grid(True, alpha=0.3)\n        axes[ax_idx].set_xlim(-0.5, 5)\n        \n        # å­å›¾2ï¼šæ¿€æ´»å€¼ç»Ÿè®¡ï¼ˆå‡å€¼å’Œæ ‡å‡†å·®ï¼‰\n        stats = []\n        for name, layer_activations in activations_history.items():\n            acts = layer_activations[layer_idx + 1]\n            mean_val = np.mean(acts)\n            std_val = np.std(acts)\n            stats.append((name, mean_val, std_val))\n        \n        names = [s[0] for s in stats]\n        means = [s[1] for s in stats]\n        stds = [s[2] for s in stats]\n        \n        x_pos = np.arange(len(names))\n        axes[ax_idx + 1].bar(x_pos - 0.2, means, width=0.4, label='å‡å€¼', alpha=0.7)\n        axes[ax_idx + 1].bar(x_pos + 0.2, stds, width=0.4, label='æ ‡å‡†å·®', alpha=0.7)\n        axes[ax_idx + 1].set_xticks(x_pos)\n        axes[ax_idx + 1].set_xticklabels(['è¿‡å°', 'Xavier', 'He'], fontsize=9)\n        axes[ax_idx + 1].set_ylabel('å€¼', fontsize=10)\n        axes[ax_idx + 1].set_title(f'ç¬¬{layer_idx + 1}å±‚ç»Ÿè®¡é‡', fontsize=11, fontweight='bold')\n        axes[ax_idx + 1].legend(fontsize=8)\n        axes[ax_idx + 1].grid(True, alpha=0.3, axis='y')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # æ‰“å°æœ€åä¸€å±‚çš„ç»Ÿè®¡ä¿¡æ¯\n    print(f\"\\næœ€åä¸€å±‚ï¼ˆç¬¬{n_layers}å±‚ï¼‰çš„æ¿€æ´»å€¼ç»Ÿè®¡ï¼š\")\n    print(\"-\" * 70)\n    print(f\"{'åˆå§‹åŒ–æ–¹æ³•':<25} {'å‡å€¼':<15} {'æ ‡å‡†å·®':<15} {'éé›¶æ¯”ä¾‹':<15}\")\n    print(\"-\" * 70)\n    \n    for name, layer_activations in activations_history.items():\n        last_acts = layer_activations[-1]\n        mean_val = np.mean(last_acts)\n        std_val = np.std(last_acts)\n        non_zero_ratio = np.mean(last_acts > 1e-6)  # éé›¶å…ƒç´ æ¯”ä¾‹\n        print(f\"{name:<25} {mean_val:<15.6f} {std_val:<15.6f} {non_zero_ratio:<15.2%}\")\n    \n    print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\n    print(\"   1. è¿‡å°åˆå§‹åŒ–ï¼šæ¿€æ´»å€¼å¿«é€Ÿè¡°å‡åˆ°0ï¼Œåé¢çš„å±‚å‡ ä¹æ²¡æœ‰æ¿€æ´»\")\n    print(\"   2. Xavieråˆå§‹åŒ–ï¼šåœ¨ReLUç½‘ç»œä¸­ï¼Œæ¿€æ´»å€¼é€å±‚è¡°å‡ï¼ˆå› ä¸ºReLUæ€æ­»ä¸€åŠç¥ç»å…ƒï¼‰\")\n    print(\"   3. Heåˆå§‹åŒ–ï¼šæ¿€æ´»å€¼åˆ†å¸ƒä¿æŒç›¸å¯¹ç¨³å®šï¼Œé€‚åˆReLUç½‘ç»œ\")\n    print(\"\\nâœ… ç»“è®ºï¼šä½¿ç”¨ReLUæ—¶ï¼Œå¿…é¡»ä½¿ç”¨Heåˆå§‹åŒ–ï¼\")\n\n# è¿è¡Œå®éªŒ\nvisualize_activation_distribution(n_layers=10, n_neurons=100, n_samples=1000)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 6ï¸âƒ£ æ¢¯åº¦æµåˆ†æ\n\nè§‚å¯Ÿåå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦å¦‚ä½•åœ¨æ·±å±‚ç½‘ç»œä¸­ä¼ æ’­ã€‚å¥½çš„åˆå§‹åŒ–åº”è¯¥ä¿æŒæ¢¯åº¦èŒƒæ•°ç›¸å¯¹ç¨³å®šã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def analyze_gradient_flow(n_layers=6, n_neurons=100):\n    \"\"\"\n    åˆ†æä¸åŒåˆå§‹åŒ–æ–¹æ³•å¯¹æ¢¯åº¦æµçš„å½±å“\n    \n    å®éªŒè®¾ç½®ï¼š\n    - æ„å»ºæ·±åº¦ç½‘ç»œ\n    - å‰å‘ä¼ æ’­\n    - æ¨¡æ‹Ÿåå‘ä¼ æ’­ï¼Œè®¡ç®—æ¯å±‚çš„æ¢¯åº¦èŒƒæ•°\n    - è§‚å¯Ÿæ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ç°è±¡\n    \n    å‚æ•°:\n    -----\n    n_layers : int\n        ç½‘ç»œæ·±åº¦\n    n_neurons : int\n        æ¯å±‚ç¥ç»å…ƒæ•°é‡\n    \"\"\"\n    print(\"=\" * 60)\n    print(f\"å®éªŒï¼šæ¢¯åº¦æµåˆ†æï¼ˆ{n_layers}å±‚ç½‘ç»œï¼‰\")\n    print(\"=\" * 60)\n    \n    # è¾“å…¥æ•°æ®\n    X = np.random.randn(100, n_neurons)\n    \n    # æµ‹è¯•ä¸‰ç§åˆå§‹åŒ–æ–¹æ³•\n    init_methods = {\n        'è¿‡å°åˆå§‹åŒ–': ('normal', 0.01),\n        'Xavieråˆå§‹åŒ–': ('xavier_normal', 1.0),\n        'Heåˆå§‹åŒ–': ('he_normal', 1.0)\n    }\n    \n    # å­˜å‚¨æ¢¯åº¦èŒƒæ•°\n    gradient_norms = {}\n    \n    for name, (method, gain) in init_methods.items():\n        # æ„å»ºç½‘ç»œ\n        weights = []\n        activations = [X.copy()]\n        \n        # å‰å‘ä¼ æ’­\n        for layer in range(n_layers):\n            if method == 'normal':\n                W = np.random.normal(0, gain, size=(n_neurons, n_neurons))\n            else:\n                W = WeightInitializer.initialize((n_neurons, n_neurons), \n                                                 method=method, gain=gain)\n            weights.append(W)\n            \n            z = activations[-1] @ W\n            a = np.maximum(0, z)  # ReLU\n            activations.append(a)\n        \n        # æ¨¡æ‹Ÿåå‘ä¼ æ’­ï¼šè®¡ç®—æ¯å±‚æƒé‡çš„æ¢¯åº¦èŒƒæ•°\n        # å‡è®¾æœ€åä¸€å±‚çš„æ¢¯åº¦ä¸º1ï¼ˆç®€åŒ–ï¼‰\n        grad_output = np.ones_like(activations[-1])\n        \n        layer_grad_norms = []\n        \n        # ä»åå‘å‰è®¡ç®—æ¢¯åº¦\n        for layer in range(n_layers - 1, -1, -1):\n            # ReLUçš„æ¢¯åº¦ï¼ˆ0æˆ–1ï¼‰\n            a = activations[layer + 1]\n            grad_relu = (a > 0).astype(float)\n            grad_z = grad_output * grad_relu\n            \n            # æƒé‡æ¢¯åº¦: âˆ‚L/âˆ‚W = a^T @ grad_z\n            grad_W = activations[layer].T @ grad_z\n            grad_norm = np.linalg.norm(grad_W)\n            layer_grad_norms.append(grad_norm)\n            \n            # ä¼ æ’­åˆ°å‰ä¸€å±‚: grad_output = grad_z @ W^T\n            grad_output = grad_z @ weights[layer].T\n        \n        # åè½¬ï¼ˆå› ä¸ºæ˜¯ä»åå‘å‰è®¡ç®—çš„ï¼‰\n        layer_grad_norms = list(reversed(layer_grad_norms))\n        gradient_norms[name] = layer_grad_norms\n    \n    # å¯è§†åŒ–æ¢¯åº¦æµ\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    \n    # å­å›¾1ï¼šæ¢¯åº¦èŒƒæ•°ï¼ˆçº¿æ€§åæ ‡ï¼‰\n    for name, norms in gradient_norms.items():\n        axes[0].plot(range(1, n_layers + 1), norms, \n                    marker='o', linewidth=2, label=name)\n    axes[0].set_xlabel('å±‚æ•°', fontsize=12)\n    axes[0].set_ylabel('æ¢¯åº¦èŒƒæ•°', fontsize=12)\n    axes[0].set_title('æ¢¯åº¦æµåˆ†æ - çº¿æ€§åæ ‡', fontsize=14, fontweight='bold')\n    axes[0].legend()\n    axes[0].grid(True, alpha=0.3)\n    \n    # å­å›¾2ï¼šæ¢¯åº¦èŒƒæ•°ï¼ˆå¯¹æ•°åæ ‡ï¼Œæ›´æ¸…æ¥šï¼‰\n    for name, norms in gradient_norms.items():\n        axes[1].plot(range(1, n_layers + 1), norms, \n                    marker='o', linewidth=2, label=name)\n    axes[1].set_xlabel('å±‚æ•°', fontsize=12)\n    axes[1].set_ylabel('æ¢¯åº¦èŒƒæ•°ï¼ˆå¯¹æ•°ï¼‰', fontsize=12)\n    axes[1].set_title('æ¢¯åº¦æµåˆ†æ - å¯¹æ•°åæ ‡', fontsize=14, fontweight='bold')\n    axes[1].set_yscale('log')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # æ‰“å°æ¢¯åº¦ç»Ÿè®¡\n    print(\"\\nå„å±‚æ¢¯åº¦èŒƒæ•°ç»Ÿè®¡ï¼š\")\n    print(\"-\" * 80)\n    print(f\"{'åˆå§‹åŒ–æ–¹æ³•':<20} | {'ç¬¬1å±‚':<12} | {'ç¬¬3å±‚':<12} | {'ç¬¬6å±‚':<12} | {'å¹³å‡å€¼':<12}\")\n    print(\"-\" * 80)\n    \n    for name, norms in gradient_norms.items():\n        layer1 = norms[0]\n        layer3 = norms[2] if len(norms) > 2 else 0\n        layer6 = norms[5] if len(norms) > 5 else 0\n        avg = np.mean(norms)\n        print(f\"{name:<20} | {layer1:<12.4f} | {layer3:<12.4f} | {layer6:<12.4f} | {avg:<12.4f}\")\n    \n    print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\n    print(\"   1. è¿‡å°åˆå§‹åŒ–ï¼šæ¢¯åº¦å¿«é€Ÿè¡°å‡ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰\")\n    print(\"   2. Xavieråˆå§‹åŒ–ï¼šæ¢¯åº¦æœ‰ä¸€å®šè¡°å‡ï¼ˆReLUç½‘ç»œä¸­ä¸å¤Ÿç†æƒ³ï¼‰\")\n    print(\"   3. Heåˆå§‹åŒ–ï¼šæ¢¯åº¦ä¿æŒç›¸å¯¹ç¨³å®šï¼ˆæœ€ä½³ï¼‰\")\n    print(\"\\nâœ… ç»“è®ºï¼šHeåˆå§‹åŒ–æœ‰æ•ˆé˜²æ­¢äº†æ¢¯åº¦æ¶ˆå¤±ï¼\")\n\n# è¿è¡Œå®éªŒ\nanalyze_gradient_flow(n_layers=6, n_neurons=100)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 7ï¸âƒ£ æ€»ç»“ä¸æœ€ä½³å®è·µ\n\n### ğŸ“Œ æ ¸å¿ƒè¦ç‚¹\n\n| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |\n|------|------|----------|\n| **å¯¹ç§°æ€§é—®é¢˜** | å…¨é›¶åˆå§‹åŒ–å¯¼è‡´æ‰€æœ‰ç¥ç»å…ƒç›¸åŒ | éšæœºåˆå§‹åŒ– |\n| **æ¢¯åº¦æ¶ˆå¤±** | åˆå§‹åŒ–è¿‡å°ï¼Œæ¿€æ´»å€¼/æ¢¯åº¦é€å±‚è¡°å‡ | Xavier/Heåˆå§‹åŒ– |\n| **æ¢¯åº¦çˆ†ç‚¸** | åˆå§‹åŒ–è¿‡å¤§ï¼Œæ¿€æ´»å€¼/æ¢¯åº¦é€å±‚æ”¾å¤§ | é™ä½åˆå§‹åŒ–æ–¹å·® + æ¢¯åº¦è£å‰ª |\n\n### ğŸ¯ åˆå§‹åŒ–é€‰æ‹©æŒ‡å—\n\n```python\n# å†³ç­–æ ‘ï¼š\nif æ¿€æ´»å‡½æ•° == 'ReLU' or 'Leaky ReLU' or 'PReLU':\n    ä½¿ç”¨ Heåˆå§‹åŒ– (he_normal)\nelif æ¿€æ´»å‡½æ•° == 'Tanh' or 'Sigmoid':\n    ä½¿ç”¨ Xavieråˆå§‹åŒ– (xavier_normal)\nelif æ¿€æ´»å‡½æ•° == 'Linear':\n    ä½¿ç”¨ Xavieråˆå§‹åŒ– (xavier_normal)\nelse:\n    # é»˜è®¤æ¨è\n    ä½¿ç”¨ Heåˆå§‹åŒ– (he_normal)\n```\n\n### ğŸ’¡ å…³é”®å…¬å¼é€ŸæŸ¥\n\n| åˆå§‹åŒ–æ–¹æ³• | å…¬å¼ | é€‚ç”¨åœºæ™¯ |\n|-----------|------|---------|\n| **Xavieræ­£æ€** | $W \\\\sim \\\\mathcal{N}(0, \\\\frac{2}{n_{\\\\text{in}} + n_{\\\\text{out}}})$ | Tanh/Sigmoid |\n| **Xavierå‡åŒ€** | $W \\\\sim \\\\mathcal{U}[-\\\\sqrt{\\\\frac{6}{n_{\\\\text{in}} + n_{\\\\text{out}}}}, \\\\sqrt{\\\\frac{6}{n_{\\\\text{in}} + n_{\\\\text{out}}}}]$ | Tanh/Sigmoid |\n| **Heæ­£æ€** â­ | $W \\\\sim \\\\mathcal{N}(0, \\\\frac{2}{n_{\\\\text{in}}})$ | ReLUï¼ˆæœ€å¸¸ç”¨ï¼‰ |\n| **Heå‡åŒ€** | $W \\\\sim \\\\mathcal{U}[-\\\\sqrt{\\\\frac{6}{n_{\\\\text{in}}}}, \\\\sqrt{\\\\frac{6}{n_{\\\\text{in}}}}]$ | ReLU |\n\n### ğŸ”‘ æ ¸å¿ƒç†è§£\n\n1. **Xavieråˆå§‹åŒ–**ï¼šå‡è®¾æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„ï¼Œä¿æŒå‰å‘å’Œåå‘ä¼ æ’­çš„æ–¹å·®ä¸€è‡´\n   - å…¬å¼æ¨å¯¼ï¼š$\\\\text{Var}(z) = n_{\\\\text{in}} \\\\cdot \\\\sigma_w^2 \\\\cdot \\\\text{Var}(a) \\\\Rightarrow \\\\sigma_w^2 = \\\\frac{1}{n_{\\\\text{in}}}$\n   - æŠ˜ä¸­æ–¹æ¡ˆï¼šè€ƒè™‘åå‘ä¼ æ’­ï¼Œå– $\\\\sigma_w^2 = \\\\frac{2}{n_{\\\\text{in}} + n_{\\\\text{out}}}$\n\n2. **Heåˆå§‹åŒ–**ï¼šè€ƒè™‘ReLUä¼šå°†ä¸€åŠç¥ç»å…ƒç½®é›¶ï¼Œæ–¹å·®å‡åŠ\n   - è¡¥å¿ç­–ç•¥ï¼šå°†Xavierçš„æ–¹å·®ä¹˜ä»¥2 â†’ $\\\\sigma_w^2 = \\\\frac{2}{n_{\\\\text{in}}}$\n   - åªç”¨ $n_{\\\\text{in}}$ è€Œä¸æ˜¯ $(n_{\\\\text{in}} + n_{\\\\text{out}})$\n\n3. **ä¸ºä»€ä¹ˆé‡è¦**ï¼š\n   - å¥½çš„åˆå§‹åŒ– = æ›´å¿«æ”¶æ•› + æ›´é«˜æœ€ç»ˆå‡†ç¡®ç‡\n   - åçš„åˆå§‹åŒ– = è®­ç»ƒå¤±è´¥ / éœ€è¦æ›´å¤šepoch / æ€§èƒ½å·®\n\n### âš™ï¸ å®è·µå»ºè®®\n\n1. **é»˜è®¤é€‰æ‹©**ï¼š\n   ```python\n   # ç°ä»£æ·±åº¦å­¦ä¹ çš„æ ‡å‡†ç»„åˆ\n   W = WeightInitializer.initialize((n_in, n_out), method='he_normal')\n   b = WeightInitializer.initialize((1, n_out), method='zeros')\n   activation = ReLU\n   ```\n\n2. **åç½®åˆå§‹åŒ–**ï¼š\n   - é€šå¸¸åˆå§‹åŒ–ä¸º0ï¼š`b = np.zeros((1, n_out))`\n   - æŸäº›æƒ…å†µï¼ˆå¦‚LSTMï¼‰å¯èƒ½éœ€è¦ç‰¹æ®Šåˆå§‹åŒ–\n\n3. **ç‰¹æ®Šæƒ…å†µ**ï¼š\n   - **RNN/LSTM**ï¼šä½¿ç”¨æ­£äº¤åˆå§‹åŒ–ï¼ˆorthogonal initializationï¼‰\n   - **GAN**ï¼šé€šå¸¸ä½¿ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–ï¼Œstd=0.02\n   - **Batch Normalizationä¹‹å**ï¼šåˆå§‹åŒ–ä¸é‚£ä¹ˆå…³é”®ï¼ˆBNä¼šå½’ä¸€åŒ–ï¼‰\n\n4. **è°ƒè¯•æŠ€å·§**ï¼š\n   - è®­ç»ƒå‰æ£€æŸ¥æ¿€æ´»å€¼åˆ†å¸ƒï¼ˆåº”è¯¥ä¸ä¸º0ä¹Ÿä¸å¤ªå¤§ï¼‰\n   - è®­ç»ƒå‰æ£€æŸ¥æ¢¯åº¦ï¼ˆåº”è¯¥ä¸ä¸º0ä¹Ÿä¸çˆ†ç‚¸ï¼‰\n   - å¦‚æœé‡åˆ°NaNï¼šé™ä½å­¦ä¹ ç‡ OR å‡å°åˆå§‹åŒ–æ–¹å·®\n\n### ğŸ“Š å®éªŒç»“è®º\n\né€šè¿‡æœ¬ç« å®éªŒï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼š\n\n1. **æ¿€æ´»å€¼ä¼ æ’­**ï¼š\n   - è¿‡å°åˆå§‹åŒ– â†’ æ¿€æ´»å€¼å¿«é€Ÿè¡°å‡åˆ°0\n   - Xavieråˆå§‹åŒ– â†’ ReLUç½‘ç»œä¸­é€å±‚è¡°å‡\n   - Heåˆå§‹åŒ– â†’ æ¿€æ´»å€¼åˆ†å¸ƒä¿æŒç¨³å®š âœ…\n\n2. **æ¢¯åº¦æµ**ï¼š\n   - è¿‡å°åˆå§‹åŒ– â†’ æ¢¯åº¦æ¶ˆå¤±\n   - Xavieråˆå§‹åŒ– â†’ æ¢¯åº¦æœ‰ä¸€å®šè¡°å‡\n   - Heåˆå§‹åŒ– â†’ æ¢¯åº¦ä¿æŒç›¸å¯¹ç¨³å®š âœ…\n\n3. **è®­ç»ƒæ•ˆæœ**ï¼š\n   - å¥½çš„åˆå§‹åŒ–èƒ½æ˜¾è‘—æå‡æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 8ï¸âƒ£ ç»ƒä¹ é¢˜\n\n### ç»ƒä¹ 1ï¼šæ•°å­¦æ¨å¯¼ â­â­\n**é—®é¢˜**ï¼šä¸ºä»€ä¹ˆ Xavier å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ä½¿ç”¨ $\\sqrt{6/(n_{in} + n_{out})}$ ä½œä¸ºè¾¹ç•Œï¼Ÿ\n\n**æç¤º**ï¼š\n1. å‡åŒ€åˆ†å¸ƒ $U[-a, a]$ çš„æ–¹å·®å…¬å¼ï¼š$\\text{Var} = \\frac{(2a)^2}{12} = \\frac{a^2}{3}$\n2. Xavierè¦æ±‚çš„æ–¹å·®ï¼š$\\sigma_w^2 = \\frac{2}{n_{in} + n_{out}}$\n3. ä»¤ä¸¤è€…ç›¸ç­‰ï¼Œæ±‚è§£ $a$\n\n**è§£ç­”åŒºåŸŸ**ï¼š\n```python\n# åœ¨è¿™é‡Œå†™å‡ºä½ çš„æ¨å¯¼è¿‡ç¨‹\n```\n\n---\n\n### ç»ƒä¹ 2ï¼šå®ç° Leaky ReLU ä¸“ç”¨åˆå§‹åŒ– â­â­â­\n**é—®é¢˜**ï¼šLeaky ReLUå®šä¹‰ä¸ºï¼š\n$$\n\\text{LeakyReLU}(z) = \\begin{cases}\nz, & \\text{if } z > 0 \\\\\n\\alpha z, & \\text{if } z \\leq 0\n\\end{cases}\n$$\n\nå…¶ä¸­ $\\alpha$ é€šå¸¸å– 0.01 æˆ– 0.1ã€‚æ¨å¯¼é€‚åˆ Leaky ReLU çš„åˆå§‹åŒ–æ–¹å·®ã€‚\n\n**æç¤º**ï¼š\n- Leaky ReLU ä¸ä¼šå®Œå…¨æ€æ­»è´Ÿå€¼ï¼Œåªæ˜¯ç¼©å° $\\alpha$ å€\n- æ–¹å·®å‡å°‘å› å­ä¸æ˜¯ 1/2ï¼Œè€Œæ˜¯ $(1 + \\alpha^2) / 2$\n\n**ä»»åŠ¡**ï¼šå®ç° `leaky_relu_init()` å‡½æ•°\n```python\ndef leaky_relu_init(n_in: int, n_out: int, alpha: float = 0.01) -> np.ndarray:\n    \\\"\\\"\\\"\n    Leaky ReLUä¸“ç”¨åˆå§‹åŒ–\n    \n    æ¨å¯¼ï¼š\n    E[LeakyReLU(z)^2] = ... ï¼ˆè¯·å®Œæˆï¼‰\n    \\\"\\\"\\\"\n    # åœ¨è¿™é‡Œå®ç°\n    pass\n```\n\n---\n\n### ç»ƒä¹ 3ï¼šæ£€éªŒåˆå§‹åŒ–çš„æœ‰æ•ˆæ€§ â­â­â­â­\n**ä»»åŠ¡**ï¼šå®ç°ä¸€ä¸ªå‡½æ•°ï¼Œæ£€æŸ¥ç»™å®šçš„åˆå§‹åŒ–æ–¹æ³•æ˜¯å¦åˆé€‚ï¼š\n\n```python\ndef check_initialization(weights_list: List[np.ndarray], \n                         activations_list: List[np.ndarray]) -> dict:\n    \\\"\\\"\\\"\n    æ£€æŸ¥åˆå§‹åŒ–çš„æœ‰æ•ˆæ€§\n    \n    æ£€æŸ¥é¡¹ï¼š\n    1. æ¿€æ´»å€¼æ˜¯å¦ä¿æŒç¨³å®šï¼ˆä¸è¡°å‡/ä¸çˆ†ç‚¸ï¼‰\n    2. æ¿€æ´»å€¼æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§ï¼ˆä¸å…¨ä¸º0ï¼‰\n    3. æƒé‡åˆ†å¸ƒæ˜¯å¦åˆç†\n    \n    å‚æ•°:\n    -----\n    weights_list : List[np.ndarray]\n        å„å±‚æƒé‡çŸ©é˜µåˆ—è¡¨\n    activations_list : List[np.ndarray]\n        å„å±‚æ¿€æ´»å€¼åˆ—è¡¨\n    \n    è¿”å›:\n    -----\n    report : dict\n        åŒ…å«æ£€æŸ¥ç»“æœçš„å­—å…¸\n        {\n            'activation_stable': bool,\n            'activation_diverse': bool,\n            'weights_reasonable': bool,\n            'recommendations': List[str]\n        }\n    \\\"\\\"\\\"\n    # åœ¨è¿™é‡Œå®ç°\n    pass\n```\n\n---\n\n### ç»ƒä¹ 4ï¼šå¯¹æ¯”å®éªŒ â­â­â­â­â­\n**ä»»åŠ¡**ï¼šåœ¨MNISTæ•°æ®é›†ä¸Šè®­ç»ƒ3å±‚MLPï¼Œå¯¹æ¯”ä»¥ä¸‹åˆå§‹åŒ–æ–¹æ³•ï¼š\n\n1. éšæœºåˆå§‹åŒ–ï¼ˆstd=0.01ï¼‰\n2. éšæœºåˆå§‹åŒ–ï¼ˆstd=1.0ï¼‰\n3. Xavieråˆå§‹åŒ–\n4. Heåˆå§‹åŒ–\n\n**è¦æ±‚**ï¼š\n- ä½¿ç”¨ç›¸åŒçš„ç½‘ç»œç»“æ„ï¼š[784, 256, 128, 10]\n- ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°\n- è®­ç»ƒ10ä¸ªepoch\n- ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¯¹æ¯”å›¾\n- æŠ¥å‘Šæœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡\n\n```python\n# å®ç°åŒºåŸŸ\n# æç¤ºï¼šå¯ä»¥ä½¿ç”¨å‰é¢ç« èŠ‚å®ç°çš„MLPç±»\n```\n\n---\n\n### ç»ƒä¹ 5ï¼šæ€è€ƒé¢˜ â­â­â­â­â­\n\n1. **ä¸ºä»€ä¹ˆåç½®ï¼ˆbiasï¼‰é€šå¸¸åˆå§‹åŒ–ä¸º0ï¼Œè€Œä¸æ˜¯éšæœºåˆå§‹åŒ–ï¼Ÿ**\n   - æ€è€ƒï¼šåç½®æ˜¯å¦å­˜åœ¨å¯¹ç§°æ€§é—®é¢˜ï¼Ÿ\n   - åç½®çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\n\n2. **Batch Normalization ä¹‹åï¼Œåˆå§‹åŒ–è¿˜é‡è¦å—ï¼Ÿ**\n   - BNçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ\n   - BNå¦‚ä½•å½±å“æ¿€æ´»å€¼åˆ†å¸ƒï¼Ÿ\n\n3. **ä¸ºä»€ä¹ˆ He åˆå§‹åŒ–ä½¿ç”¨ $n_{in}$ è€Œä¸æ˜¯ $(n_{in} + n_{out})$ï¼Ÿ**\n   - å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­å“ªä¸ªæ›´é‡è¦ï¼Ÿ\n   - ReLUçš„åå‘ä¼ æ’­ç‰¹æ€§æ˜¯ä»€ä¹ˆï¼Ÿ\n\n4. **æ·±åº¦æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰éœ€è¦ç‰¹æ®Šçš„åˆå§‹åŒ–å—ï¼Ÿ**\n   - æ®‹å·®è¿æ¥å¦‚ä½•æ”¹å˜æ¢¯åº¦æµï¼Ÿ\n   - æ˜¯å¦è¿˜ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±ï¼Ÿ\n\n**è¯·åœ¨ä¸‹æ–¹å†™ä¸‹ä½ çš„æ€è€ƒï¼š**\n```\nä½ çš„ç­”æ¡ˆ...\n```\n\n---\n\n## ğŸ“ å­¦ä¹ æ£€æŸ¥ç‚¹\n\nå®Œæˆæœ¬ç« åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š\n\n- [ ] è§£é‡Šä¸ºä»€ä¹ˆå…¨é›¶åˆå§‹åŒ–ä¼šå¯¼è‡´å¯¹ç§°æ€§é—®é¢˜\n- [ ] ç†è§£æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ä¸åˆå§‹åŒ–çš„å…³ç³»\n- [ ] æ¨å¯¼ Xavier åˆå§‹åŒ–çš„æ•°å­¦å…¬å¼\n- [ ] è§£é‡Šä¸ºä»€ä¹ˆ ReLU éœ€è¦ He åˆå§‹åŒ–\n- [ ] æ ¹æ®æ¿€æ´»å‡½æ•°é€‰æ‹©åˆé€‚çš„åˆå§‹åŒ–æ–¹æ³•\n- [ ] å®ç° Xavier å’Œ He åˆå§‹åŒ–\n- [ ] åˆ†ææ¿€æ´»å€¼åˆ†å¸ƒå’Œæ¢¯åº¦æµ\n- [ ] è¯Šæ–­åˆå§‹åŒ–å¯¼è‡´çš„è®­ç»ƒé—®é¢˜\n\n---\n\n## ğŸ“š å‚è€ƒèµ„æ–™\n\n1. **Xavier Glorot & Yoshua Bengio (2010)**  \n   *Understanding the difficulty of training deep feedforward neural networks*  \n   [è®ºæ–‡é“¾æ¥](http://proceedings.mlr.press/v9/glorot10a.html)\n\n2. **Kaiming He et al. (2015)**  \n   *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification*  \n   [è®ºæ–‡é“¾æ¥](https://arxiv.org/abs/1502.01852)\n\n3. **Andrew Ng - Deep Learning Specialization**  \n   Coursera è¯¾ç¨‹ä¸­å…³äºåˆå§‹åŒ–çš„è®²è§£\n\n4. **Deep Learning Book - Ian Goodfellow**  \n   Chapter 8: Optimization for Training Deep Models\n\n---\n\n## ğŸ‰ æ­å–œï¼\n\nä½ å·²ç»å®Œæˆäº†æƒé‡åˆå§‹åŒ–è¿™ä¸€é‡è¦ç« èŠ‚ï¼\n\n**ä¸‹ä¸€æ­¥**ï¼š\n- ç¬¬9ç« ï¼šæ·±åº¦ç½‘ç»œè®­ç»ƒæŠ€å·§ä¸è¯Šæ–­\n- å­¦ä¹ æ›´å¤šæå‡è®­ç»ƒæ•ˆæœçš„æ–¹æ³•\n\n**Keep Learning! ğŸš€**",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}