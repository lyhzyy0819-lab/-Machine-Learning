{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬ 3 ç« ï¼šBPTT åå‘ä¼ æ’­ç®—æ³•\n",
    "\n",
    "> Backpropagation Through Time - RNN çš„è®­ç»ƒæ ¸å¿ƒ\n",
    "\n",
    "---\n",
    "\n",
    "## æœ¬ç« ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬ç« åï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "\n",
    "- [ ] ç†è§£ BPTT çš„æ ¸å¿ƒæ€æƒ³ï¼šæ—¶é—´å±•å¼€ + é“¾å¼æ³•åˆ™\n",
    "- [ ] æ¨å¯¼ RNN å„å‚æ•°çš„æ¢¯åº¦å…¬å¼\n",
    "- [ ] ç”¨ NumPy ä»é›¶å®ç° BPTT ç®—æ³•\n",
    "- [ ] ç†è§£æˆªæ–­ BPTTï¼ˆTruncated BPTTï¼‰åŠå…¶å¿…è¦æ€§\n",
    "- [ ] å®Œæˆä¸€ä¸ªå¯è®­ç»ƒçš„ RNN ç½‘ç»œ\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸ºä»€ä¹ˆéœ€è¦ BPTTï¼Ÿ\n",
    "\n",
    "æ™®é€šç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­ï¼šæ¢¯åº¦åœ¨**å±‚ä¸å±‚ä¹‹é—´**ä¼ é€’\n",
    "\n",
    "RNN çš„ç‰¹æ®Šæ€§ï¼šæ¢¯åº¦è¿˜éœ€è¦åœ¨**æ—¶é—´æ­¥ä¹‹é—´**ä¼ é€’\n",
    "\n",
    "```\n",
    "æ™®é€š NN:     Layer1 â†’ Layer2 â†’ Layer3 â†’ Loss\n",
    "                â†‘        â†‘        â†‘\n",
    "              æ¢¯åº¦     æ¢¯åº¦     æ¢¯åº¦\n",
    "\n",
    "RNN:         hâ‚€ â†’ hâ‚ â†’ hâ‚‚ â†’ hâ‚ƒ â†’ ... â†’ hâ‚œ â†’ Loss\n",
    "             â†‘    â†‘    â†‘    â†‘          â†‘\n",
    "           æ¢¯åº¦  æ¢¯åº¦  æ¢¯åº¦  æ¢¯åº¦       æ¢¯åº¦\n",
    "             â†–    â†–    â†–    â†–\n",
    "            æ—¶é—´åå‘ä¼ æ’­\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬ä¸€éƒ¨åˆ†ï¼šBPTT æ ¸å¿ƒæ€æƒ³\n",
    "\n",
    "### 1.1 æ—¶é—´å±•å¼€ï¼ˆUnrolling Through Timeï¼‰\n",
    "\n",
    "BPTT çš„ç¬¬ä¸€æ­¥ï¼šå°† RNN æ²¿æ—¶é—´è½´\"å±•å¼€\"æˆä¸€ä¸ªå¾ˆæ·±çš„å‰é¦ˆç½‘ç»œ\n",
    "\n",
    "```\n",
    "æŠ˜å è§†å›¾ï¼ˆå®é™…ç»“æ„ï¼‰:            å±•å¼€è§†å›¾ï¼ˆè®¡ç®—å›¾ï¼‰:\n",
    "\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”\n",
    "    â”‚       â”‚                   â”‚hâ‚€ â”‚â”€â”€â–¶â”‚hâ‚ â”‚â”€â”€â–¶â”‚hâ‚‚ â”‚â”€â”€â–¶â”‚hâ‚ƒ â”‚\n",
    " â”€â”€â–¶â”‚  RNN  â”‚â”€â”€â–¶                â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜\n",
    "    â”‚       â”‚                     â–²       â–²       â–²       â–²\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚       â”‚       â”‚       â”‚\n",
    "        â–²                       â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”\n",
    "        â”‚                       â”‚xâ‚€ â”‚   â”‚xâ‚ â”‚   â”‚xâ‚‚ â”‚   â”‚xâ‚ƒ â”‚\n",
    "        â””â”€â”€â”€â”€                   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜   â””â”€â”€â”€â”˜\n",
    "\n",
    "å…³é”®æ´å¯Ÿï¼š\n",
    "- å±•å¼€åçš„æ¯ä¸€\"å±‚\"å…±äº«ç›¸åŒçš„æƒé‡ W_xh, W_hh\n",
    "- è¿™ä¸æ™®é€šæ·±åº¦ç½‘ç»œçš„ä¸»è¦åŒºåˆ«ï¼šæƒé‡å…±äº«\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šRNN çš„æ—¶é—´å±•å¼€\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# å·¦å›¾ï¼šæŠ˜å è§†å›¾\n",
    "ax = axes[0]\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# RNN å•å…ƒ\n",
    "rect = plt.Rectangle((3, 3), 4, 4, fill=True, facecolor='lightblue', edgecolor='blue', linewidth=2)\n",
    "ax.add_patch(rect)\n",
    "ax.text(5, 5, 'RNN\\nCell', ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# è¾“å…¥\n",
    "ax.annotate('', xy=(3, 5), xytext=(1, 5),\n",
    "            arrowprops=dict(arrowstyle='->', color='green', lw=2))\n",
    "ax.text(0.5, 5, '$x_t$', fontsize=14, va='center')\n",
    "\n",
    "# è¾“å‡º\n",
    "ax.annotate('', xy=(9, 5), xytext=(7, 5),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "ax.text(9.2, 5, '$h_t$', fontsize=14, va='center')\n",
    "\n",
    "# å¾ªç¯è¿æ¥\n",
    "ax.annotate('', xy=(5, 7), xytext=(5, 8.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='orange', lw=2,\n",
    "                           connectionstyle='arc3,rad=0.3'))\n",
    "ax.annotate('', xy=(5, 8.5), xytext=(5, 7),\n",
    "            arrowprops=dict(arrowstyle='->', color='orange', lw=2,\n",
    "                           connectionstyle='arc3,rad=0.3'))\n",
    "ax.text(6.5, 8, '$h_{t-1}$', fontsize=12)\n",
    "\n",
    "ax.set_title('æŠ˜å è§†å›¾ (Folded View)', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# å³å›¾ï¼šå±•å¼€è§†å›¾\n",
    "ax = axes[1]\n",
    "ax.set_xlim(0, 16)\n",
    "ax.set_ylim(0, 10)\n",
    "\n",
    "# 4 ä¸ªæ—¶é—´æ­¥\n",
    "positions = [2, 5, 8, 11, 14]\n",
    "for i, x_pos in enumerate(positions[:4]):\n",
    "    # RNN å•å…ƒ\n",
    "    rect = plt.Rectangle((x_pos-0.8, 4), 1.6, 2, fill=True, \n",
    "                          facecolor='lightblue', edgecolor='blue', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x_pos, 5, f'$h_{i}$', ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    # è¾“å…¥\n",
    "    ax.annotate('', xy=(x_pos, 4), xytext=(x_pos, 2),\n",
    "                arrowprops=dict(arrowstyle='->', color='green', lw=1.5))\n",
    "    ax.text(x_pos, 1.5, f'$x_{i}$', ha='center', fontsize=11)\n",
    "    \n",
    "    # è¾“å‡º\n",
    "    ax.annotate('', xy=(x_pos, 8), xytext=(x_pos, 6),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "    ax.text(x_pos, 8.5, f'$y_{i}$', ha='center', fontsize=11)\n",
    "    \n",
    "    # æ°´å¹³è¿æ¥\n",
    "    if i < 3:\n",
    "        ax.annotate('', xy=(x_pos+1.8, 5), xytext=(x_pos+0.8, 5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='orange', lw=2))\n",
    "\n",
    "# çœç•¥å·\n",
    "ax.text(14, 5, '...', fontsize=20, ha='center', va='center')\n",
    "\n",
    "# æ ‡æ³¨æƒé‡å…±äº«\n",
    "ax.text(8, 0.3, 'æ‰€æœ‰å•å…ƒå…±äº«ç›¸åŒçš„ $W_{xh}$, $W_{hh}$, $W_{hy}$', \n",
    "        ha='center', fontsize=11, style='italic', color='purple')\n",
    "\n",
    "ax.set_title('å±•å¼€è§†å›¾ (Unrolled View)', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 é“¾å¼æ³•åˆ™å›é¡¾\n",
    "\n",
    "åå‘ä¼ æ’­çš„æ•°å­¦åŸºç¡€æ˜¯é“¾å¼æ³•åˆ™ï¼ˆChain Ruleï¼‰ï¼š\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial y} \\cdot \\frac{\\partial y}{\\partial x}$$\n",
    "\n",
    "å¯¹äºå¤åˆå‡½æ•° $L = f(g(h(x)))$ï¼š\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial f} \\cdot \\frac{\\partial f}{\\partial g} \\cdot \\frac{\\partial g}{\\partial h} \\cdot \\frac{\\partial h}{\\partial x}$$\n",
    "\n",
    "**RNN ä¸­çš„é“¾å¼æ³•åˆ™**ï¼šæ¢¯åº¦éœ€è¦é€šè¿‡æ‰€æœ‰æ—¶é—´æ­¥ä¼ é€’å›å»\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W} = \\sum_{t=1}^{T} \\frac{\\partial L_t}{\\partial W}$$\n",
    "\n",
    "å…¶ä¸­æ¯ä¸ª $\\frac{\\partial L_t}{\\partial W}$ éƒ½æ¶‰åŠä»æ—¶é—´ $t$ å›æº¯åˆ°æ—¶é—´ $1$ çš„é“¾å¼å±•å¼€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹ï¼šç®€å•é“¾å¼æ³•åˆ™\n",
    "\n",
    "def chain_rule_demo():\n",
    "    \"\"\"\n",
    "    æ¼”ç¤ºé“¾å¼æ³•åˆ™\n",
    "    \n",
    "    è®¡ç®—å›¾: x â†’ [*2] â†’ a â†’ [+3] â†’ b â†’ [^2] â†’ L\n",
    "    å³: L = (2x + 3)Â²\n",
    "    \"\"\"\n",
    "    x = 2.0  # è¾“å…¥\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    a = 2 * x        # a = 2x = 4\n",
    "    b = a + 3        # b = a + 3 = 7  \n",
    "    L = b ** 2       # L = bÂ² = 49\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"é“¾å¼æ³•åˆ™æ¼”ç¤º: L = (2x + 3)Â²\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nå‰å‘ä¼ æ’­: x={x} â†’ a={a} â†’ b={b} â†’ L={L}\")\n",
    "    \n",
    "    # åå‘ä¼ æ’­ï¼ˆä½¿ç”¨é“¾å¼æ³•åˆ™ï¼‰\n",
    "    # æ­¥éª¤ 1: dL/dL = 1\n",
    "    dL_dL = 1\n",
    "    \n",
    "    # æ­¥éª¤ 2: dL/db = dL/dL * d(bÂ²)/db = 1 * 2b = 2*7 = 14\n",
    "    dL_db = dL_dL * (2 * b)\n",
    "    \n",
    "    # æ­¥éª¤ 3: dL/da = dL/db * d(a+3)/da = 14 * 1 = 14\n",
    "    dL_da = dL_db * 1\n",
    "    \n",
    "    # æ­¥éª¤ 4: dL/dx = dL/da * d(2x)/dx = 14 * 2 = 28\n",
    "    dL_dx = dL_da * 2\n",
    "    \n",
    "    print(f\"\\nåå‘ä¼ æ’­:\")\n",
    "    print(f\"  dL/dL = {dL_dL}\")\n",
    "    print(f\"  dL/db = dL/dL Ã— 2b = {dL_dL} Ã— {2*b} = {dL_db}\")\n",
    "    print(f\"  dL/da = dL/db Ã— 1 = {dL_db} Ã— 1 = {dL_da}\")\n",
    "    print(f\"  dL/dx = dL/da Ã— 2 = {dL_da} Ã— 2 = {dL_dx}\")\n",
    "    \n",
    "    # éªŒè¯ï¼šè§£æè§£ dL/dx = d[(2x+3)Â²]/dx = 2(2x+3)*2 = 4(2x+3)\n",
    "    analytical = 4 * (2 * x + 3)\n",
    "    print(f\"\\nè§£æéªŒè¯: dL/dx = 4(2x+3) = 4Ã—{2*x+3} = {analytical} âœ“\")\n",
    "\n",
    "chain_rule_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬äºŒéƒ¨åˆ†ï¼šBPTT æ•°å­¦æ¨å¯¼\n",
    "\n",
    "### 2.1 RNN å‰å‘ä¼ æ’­å›é¡¾\n",
    "\n",
    "$$h_t = \\tanh(W_{xh} \\cdot x_t + W_{hh} \\cdot h_{t-1} + b_h)$$\n",
    "$$y_t = W_{hy} \\cdot h_t + b_y$$\n",
    "\n",
    "æŸå¤±å‡½æ•°ï¼ˆä»¥äº¤å‰ç†µä¸ºä¾‹ï¼‰ï¼š\n",
    "$$L = \\sum_{t=1}^{T} L_t = -\\sum_{t=1}^{T} \\sum_k y_{t,k}^{true} \\log(\\hat{y}_{t,k})$$\n",
    "\n",
    "### 2.2 éœ€è¦è®¡ç®—çš„æ¢¯åº¦\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦è®¡ç®—ä»¥ä¸‹æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ï¼š\n",
    "\n",
    "| å‚æ•° | æ¢¯åº¦ | ç”¨é€” |\n",
    "|------|------|------|\n",
    "| $W_{hy}$ | $\\frac{\\partial L}{\\partial W_{hy}}$ | æ›´æ–°è¾“å‡ºå±‚æƒé‡ |\n",
    "| $b_y$ | $\\frac{\\partial L}{\\partial b_y}$ | æ›´æ–°è¾“å‡ºå±‚åç½® |\n",
    "| $W_{xh}$ | $\\frac{\\partial L}{\\partial W_{xh}}$ | æ›´æ–°è¾“å…¥å±‚æƒé‡ |\n",
    "| $W_{hh}$ | $\\frac{\\partial L}{\\partial W_{hh}}$ | æ›´æ–°éšå±‚æƒé‡ |\n",
    "| $b_h$ | $\\frac{\\partial L}{\\partial b_h}$ | æ›´æ–°éšå±‚åç½® |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 è¯¦ç»†æ¨å¯¼\n",
    "\n",
    "#### Step 1: è¾“å‡ºå±‚æ¢¯åº¦ï¼ˆç®€å•ï¼‰\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W_{hy}} = \\sum_{t=1}^{T} \\frac{\\partial L_t}{\\partial y_t} \\cdot \\frac{\\partial y_t}{\\partial W_{hy}} = \\sum_{t=1}^{T} \\delta_t^y \\cdot h_t^T$$\n",
    "\n",
    "å…¶ä¸­ $\\delta_t^y = \\frac{\\partial L_t}{\\partial y_t} = \\hat{y}_t - y_t^{true}$ï¼ˆå¯¹äº softmax + äº¤å‰ç†µï¼‰\n",
    "\n",
    "#### Step 2: éšå±‚æ¢¯åº¦ï¼ˆå¤æ‚ - BPTT æ ¸å¿ƒï¼‰\n",
    "\n",
    "å…³é”®éš¾ç‚¹ï¼š$h_t$ ä¸ä»…å½±å“ $L_t$ï¼Œè¿˜é€šè¿‡ $h_{t+1}, h_{t+2}, ...$ å½±å“åç»­çš„æ‰€æœ‰æŸå¤±ï¼\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial h_t} = \\frac{\\partial L_t}{\\partial h_t} + \\frac{\\partial L}{\\partial h_{t+1}} \\cdot \\frac{\\partial h_{t+1}}{\\partial h_t}$$\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ª**é€’å½’å…³ç³»**ï¼š\n",
    "\n",
    "```\n",
    "æ—¶é—´ T:   Î´_T = (âˆ‚L_T/âˆ‚h_T)\n",
    "æ—¶é—´ T-1: Î´_{T-1} = (âˆ‚L_{T-1}/âˆ‚h_{T-1}) + Î´_T Ã— (âˆ‚h_T/âˆ‚h_{T-1})\n",
    "æ—¶é—´ T-2: Î´_{T-2} = (âˆ‚L_{T-2}/âˆ‚h_{T-2}) + Î´_{T-1} Ã— (âˆ‚h_{T-1}/âˆ‚h_{T-2})\n",
    "...\n",
    "```\n",
    "\n",
    "#### Step 3: æƒé‡æ¢¯åº¦ç´¯ç§¯\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W_{hh}} = \\sum_{t=1}^{T} \\delta_t^h \\cdot h_{t-1}^T \\cdot \\text{diag}(1 - h_t^2)$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial W_{xh}} = \\sum_{t=1}^{T} \\delta_t^h \\cdot x_t^T \\cdot \\text{diag}(1 - h_t^2)$$\n",
    "\n",
    "å…¶ä¸­ $\\text{diag}(1 - h_t^2)$ æ˜¯ tanh çš„å¯¼æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šBPTT æ¢¯åº¦æµåŠ¨\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.set_xlim(0, 20)\n",
    "ax.set_ylim(0, 12)\n",
    "\n",
    "# ç»˜åˆ¶æ—¶é—´æ­¥\n",
    "times = [3, 7, 11, 15]\n",
    "labels = ['t=1', 't=2', 't=3', 't=T']\n",
    "\n",
    "for i, (x_pos, label) in enumerate(zip(times, labels)):\n",
    "    # éšçŠ¶æ€èŠ‚ç‚¹\n",
    "    circle_h = plt.Circle((x_pos, 6), 0.8, fill=True, facecolor='lightblue', edgecolor='blue', linewidth=2)\n",
    "    ax.add_patch(circle_h)\n",
    "    ax.text(x_pos, 6, f'$h_{{{i+1 if i<3 else \"T\"}}}$', ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    # è¾“å‡ºèŠ‚ç‚¹\n",
    "    circle_y = plt.Circle((x_pos, 9), 0.6, fill=True, facecolor='lightgreen', edgecolor='green', linewidth=2)\n",
    "    ax.add_patch(circle_y)\n",
    "    ax.text(x_pos, 9, f'$y_{{{i+1 if i<3 else \"T\"}}}$', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # æŸå¤±èŠ‚ç‚¹\n",
    "    circle_L = plt.Circle((x_pos, 11), 0.5, fill=True, facecolor='lightyellow', edgecolor='orange', linewidth=2)\n",
    "    ax.add_patch(circle_L)\n",
    "    ax.text(x_pos, 11, f'$L_{{{i+1 if i<3 else \"T\"}}}$', ha='center', va='center', fontsize=9)\n",
    "    \n",
    "    # è¾“å…¥èŠ‚ç‚¹\n",
    "    circle_x = plt.Circle((x_pos, 3), 0.6, fill=True, facecolor='lightcoral', edgecolor='red', linewidth=2)\n",
    "    ax.add_patch(circle_x)\n",
    "    ax.text(x_pos, 3, f'$x_{{{i+1 if i<3 else \"T\"}}}$', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # å‰å‘è¿æ¥ (é»‘è‰²å®çº¿)\n",
    "    ax.annotate('', xy=(x_pos, 5.2), xytext=(x_pos, 3.6),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "    ax.annotate('', xy=(x_pos, 8.4), xytext=(x_pos, 6.8),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "    ax.annotate('', xy=(x_pos, 10.5), xytext=(x_pos, 9.6),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "    \n",
    "    # æ—¶é—´æ­¥è¿æ¥\n",
    "    if i < 3:\n",
    "        next_x = times[i+1] if i < 2 else times[i] + 2\n",
    "        # å‰å‘ (é»‘è‰²)\n",
    "        ax.annotate('', xy=(next_x-1, 6), xytext=(x_pos+0.8, 6),\n",
    "                    arrowprops=dict(arrowstyle='->', color='black', lw=1.5))\n",
    "\n",
    "# åå‘æ¢¯åº¦æµåŠ¨ (çº¢è‰²è™šçº¿)\n",
    "for i in range(len(times)-1, 0, -1):\n",
    "    x_curr = times[i]\n",
    "    x_prev = times[i-1]\n",
    "    \n",
    "    # æ—¶é—´åå‘ä¼ æ’­\n",
    "    ax.annotate('', xy=(x_prev+1, 5.5), xytext=(x_curr-1, 5.5),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=2, linestyle='--'))\n",
    "\n",
    "# ä» L åˆ° h çš„æ¢¯åº¦\n",
    "for x_pos in times:\n",
    "    ax.annotate('', xy=(x_pos-0.3, 6.8), xytext=(x_pos-0.3, 10.5),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=1.5, linestyle='--'))\n",
    "\n",
    "# å›¾ä¾‹\n",
    "ax.plot([], [], 'k-', lw=2, label='å‰å‘ä¼ æ’­')\n",
    "ax.plot([], [], 'r--', lw=2, label='åå‘ä¼ æ’­ (BPTT)')\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "\n",
    "# è¯´æ˜æ–‡å­—\n",
    "ax.text(10, 1, \n",
    "        'å…³é”®: $\\\\frac{\\\\partial L}{\\\\partial h_t}$ éœ€è¦ç´¯ç§¯ä» $L_t, L_{t+1}, ..., L_T$ çš„æ¢¯åº¦',\n",
    "        ha='center', fontsize=12, style='italic', color='darkred',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "ax.set_title('BPTT æ¢¯åº¦æµåŠ¨ç¤ºæ„å›¾', fontsize=14, fontweight='bold')\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šNumPy å®ç° BPTT\n",
    "\n",
    "### 3.1 å®Œæ•´çš„ RNN ç±»ï¼ˆå«å‰å‘å’Œåå‘ä¼ æ’­ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNWithBPTT:\n",
    "    \"\"\"\n",
    "    ä»é›¶å®ç°çš„ RNNï¼ŒåŒ…å«å®Œæ•´çš„ BPTT åå‘ä¼ æ’­\n",
    "    \n",
    "    æ•°å­¦å…¬å¼ï¼š\n",
    "        h_t = tanh(W_xh @ x_t + W_hh @ h_{t-1} + b_h)\n",
    "        y_t = W_hy @ h_t + b_y\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "        input_size: è¾“å…¥ç‰¹å¾ç»´åº¦\n",
    "        hidden_size: éšè—çŠ¶æ€ç»´åº¦\n",
    "        output_size: è¾“å‡ºç»´åº¦\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # ========================================\n",
    "        # å‚æ•°åˆå§‹åŒ–ï¼ˆXavier åˆå§‹åŒ–ï¼‰\n",
    "        # ========================================\n",
    "        \n",
    "        # è¾“å…¥åˆ°éšå±‚çš„æƒé‡, shape: (hidden_size, input_size)\n",
    "        scale_xh = np.sqrt(2.0 / (input_size + hidden_size))\n",
    "        self.W_xh = np.random.randn(hidden_size, input_size) * scale_xh\n",
    "        \n",
    "        # éšå±‚åˆ°éšå±‚çš„æƒé‡, shape: (hidden_size, hidden_size)\n",
    "        scale_hh = np.sqrt(2.0 / (hidden_size + hidden_size))\n",
    "        self.W_hh = np.random.randn(hidden_size, hidden_size) * scale_hh\n",
    "        \n",
    "        # éšå±‚åç½®, shape: (hidden_size,)\n",
    "        self.b_h = np.zeros(hidden_size)\n",
    "        \n",
    "        # éšå±‚åˆ°è¾“å‡ºçš„æƒé‡, shape: (output_size, hidden_size)\n",
    "        scale_hy = np.sqrt(2.0 / (hidden_size + output_size))\n",
    "        self.W_hy = np.random.randn(output_size, hidden_size) * scale_hy\n",
    "        \n",
    "        # è¾“å‡ºåç½®, shape: (output_size,)\n",
    "        self.b_y = np.zeros(output_size)\n",
    "        \n",
    "        # ä¿å­˜ç»´åº¦ä¿¡æ¯\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # ç¼“å­˜ä¸­é—´ç»“æœï¼ˆåå‘ä¼ æ’­éœ€è¦ï¼‰\n",
    "        self.cache = {}\n",
    "    \n",
    "    def forward(self, X, h_prev=None):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            X: è¾“å…¥åºåˆ—, shape: (seq_len, input_size)\n",
    "            h_prev: åˆå§‹éšçŠ¶æ€, shape: (hidden_size,)\n",
    "        \n",
    "        è¿”å›:\n",
    "            Y: è¾“å‡ºåºåˆ—, shape: (seq_len, output_size)\n",
    "            h_last: æœ€åçš„éšçŠ¶æ€, shape: (hidden_size,)\n",
    "        \"\"\"\n",
    "        seq_len = X.shape[0]\n",
    "        \n",
    "        # åˆå§‹åŒ–éšçŠ¶æ€\n",
    "        if h_prev is None:\n",
    "            h_prev = np.zeros(self.hidden_size)\n",
    "        \n",
    "        # ========================================\n",
    "        # å­˜å‚¨æ‰€æœ‰æ—¶é—´æ­¥çš„ä¸­é—´å€¼ï¼ˆåå‘ä¼ æ’­éœ€è¦ï¼‰\n",
    "        # ========================================\n",
    "        h_states = [h_prev]  # h_0, h_1, ..., h_T\n",
    "        y_outputs = []       # y_1, ..., y_T\n",
    "        pre_activations = [] # tanh ä¹‹å‰çš„å€¼ï¼ˆç”¨äºè®¡ç®—æ¢¯åº¦ï¼‰\n",
    "        \n",
    "        h_t = h_prev\n",
    "        \n",
    "        # ========================================\n",
    "        # é€æ—¶é—´æ­¥å‰å‘ä¼ æ’­\n",
    "        # ========================================\n",
    "        for t in range(seq_len):\n",
    "            x_t = X[t]  # å½“å‰è¾“å…¥, shape: (input_size,)\n",
    "            \n",
    "            # è®¡ç®— tanh å‰çš„å€¼: z_t = W_xh @ x_t + W_hh @ h_{t-1} + b_h\n",
    "            # z_t shape: (hidden_size,)\n",
    "            z_t = self.W_xh @ x_t + self.W_hh @ h_t + self.b_h\n",
    "            pre_activations.append(z_t)\n",
    "            \n",
    "            # è®¡ç®—æ–°çš„éšçŠ¶æ€: h_t = tanh(z_t)\n",
    "            h_t = np.tanh(z_t)\n",
    "            h_states.append(h_t)\n",
    "            \n",
    "            # è®¡ç®—è¾“å‡º: y_t = W_hy @ h_t + b_y\n",
    "            y_t = self.W_hy @ h_t + self.b_y\n",
    "            y_outputs.append(y_t)\n",
    "        \n",
    "        # è½¬æ¢ä¸º numpy æ•°ç»„\n",
    "        Y = np.array(y_outputs)  # shape: (seq_len, output_size)\n",
    "        \n",
    "        # ========================================\n",
    "        # ç¼“å­˜ä¸­é—´ç»“æœï¼ˆåå‘ä¼ æ’­ä½¿ç”¨ï¼‰\n",
    "        # ========================================\n",
    "        self.cache = {\n",
    "            'X': X,                           # è¾“å…¥åºåˆ—\n",
    "            'h_states': h_states,             # æ‰€æœ‰éšçŠ¶æ€ [h_0, h_1, ..., h_T]\n",
    "            'pre_activations': pre_activations,  # tanh å‰çš„å€¼\n",
    "            'seq_len': seq_len\n",
    "        }\n",
    "        \n",
    "        return Y, h_states[-1]\n",
    "    \n",
    "    def backward(self, dL_dY):\n",
    "        \"\"\"\n",
    "        BPTT åå‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            dL_dY: æŸå¤±å¯¹è¾“å‡ºçš„æ¢¯åº¦, shape: (seq_len, output_size)\n",
    "                   å³ âˆ‚L/âˆ‚y_t for each t\n",
    "        \n",
    "        è¿”å›:\n",
    "            grads: å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦\n",
    "        \"\"\"\n",
    "        # è·å–ç¼“å­˜çš„ä¸­é—´ç»“æœ\n",
    "        X = self.cache['X']\n",
    "        h_states = self.cache['h_states']\n",
    "        pre_activations = self.cache['pre_activations']\n",
    "        seq_len = self.cache['seq_len']\n",
    "        \n",
    "        # ========================================\n",
    "        # åˆå§‹åŒ–æ¢¯åº¦ç´¯ç§¯å™¨\n",
    "        # ========================================\n",
    "        dW_xh = np.zeros_like(self.W_xh)  # (hidden_size, input_size)\n",
    "        dW_hh = np.zeros_like(self.W_hh)  # (hidden_size, hidden_size)\n",
    "        db_h = np.zeros_like(self.b_h)   # (hidden_size,)\n",
    "        dW_hy = np.zeros_like(self.W_hy)  # (output_size, hidden_size)\n",
    "        db_y = np.zeros_like(self.b_y)   # (output_size,)\n",
    "        \n",
    "        # ========================================\n",
    "        # å…³é”®å˜é‡ï¼šä»æœªæ¥ä¼ æ¥çš„éšçŠ¶æ€æ¢¯åº¦\n",
    "        # ========================================\n",
    "        # dh_next è¡¨ç¤ºä»æ—¶é—´ t+1 ä¼ å›åˆ°æ—¶é—´ t çš„æ¢¯åº¦\n",
    "        # åˆå§‹ä¸º 0ï¼ˆå› ä¸º T æ—¶åˆ»ä¹‹åæ²¡æœ‰æ›´å¤šæ—¶é—´æ­¥ï¼‰\n",
    "        dh_next = np.zeros(self.hidden_size)\n",
    "        \n",
    "        # ========================================\n",
    "        # ä»åå‘å‰éå†æ¯ä¸ªæ—¶é—´æ­¥ï¼ˆBPTT æ ¸å¿ƒï¼‰\n",
    "        # ========================================\n",
    "        for t in reversed(range(seq_len)):\n",
    "            # è·å–å½“å‰æ—¶é—´æ­¥çš„å€¼\n",
    "            x_t = X[t]                    # è¾“å…¥\n",
    "            h_t = h_states[t + 1]         # å½“å‰éšçŠ¶æ€ï¼ˆæ³¨æ„ç´¢å¼•åç§»ï¼‰\n",
    "            h_prev = h_states[t]          # ä¸Šä¸€æ—¶åˆ»éšçŠ¶æ€\n",
    "            dy_t = dL_dY[t]               # è¾“å‡ºå±‚çš„æ¢¯åº¦\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # Step 1: è¾“å‡ºå±‚æ¢¯åº¦\n",
    "            # y_t = W_hy @ h_t + b_y\n",
    "            # ------------------------------------------\n",
    "            # dL/dW_hy = dL/dy_t * dy_t/dW_hy = dy_t @ h_t^T\n",
    "            # ç´¯ç§¯æ¯ä¸ªæ—¶é—´æ­¥çš„æ¢¯åº¦\n",
    "            dW_hy += np.outer(dy_t, h_t)  # (output_size, hidden_size)\n",
    "            \n",
    "            # dL/db_y = dL/dy_t * 1\n",
    "            db_y += dy_t  # (output_size,)\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # Step 2: éšå±‚æ¢¯åº¦ï¼ˆå…³é”®ï¼éœ€è¦ç´¯ç§¯æ¥è‡ªä¸¤ä¸ªæ–¹å‘çš„æ¢¯åº¦ï¼‰\n",
    "            # ------------------------------------------\n",
    "            # æ¢¯åº¦æ¥æº 1: ä»å½“å‰è¾“å‡ºå±‚ä¼ æ¥ (W_hy^T @ dy_t)\n",
    "            # æ¢¯åº¦æ¥æº 2: ä»ä¸‹ä¸€æ—¶åˆ»ä¼ æ¥ (dh_next)\n",
    "            dh_t = self.W_hy.T @ dy_t + dh_next  # (hidden_size,)\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # Step 3: é€šè¿‡ tanh çš„æ¢¯åº¦\n",
    "            # h_t = tanh(z_t), æ‰€ä»¥ dz_t = dh_t * (1 - h_t^2)\n",
    "            # ------------------------------------------\n",
    "            # tanh çš„å¯¼æ•°: d(tanh(x))/dx = 1 - tanhÂ²(x) = 1 - h_tÂ²\n",
    "            dtanh = 1 - h_t ** 2  # (hidden_size,)\n",
    "            dz_t = dh_t * dtanh   # (hidden_size,)\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # Step 4: è®¡ç®—å„å‚æ•°çš„æ¢¯åº¦\n",
    "            # z_t = W_xh @ x_t + W_hh @ h_{t-1} + b_h\n",
    "            # ------------------------------------------\n",
    "            # dL/dW_xh = dz_t @ x_t^T\n",
    "            dW_xh += np.outer(dz_t, x_t)  # (hidden_size, input_size)\n",
    "            \n",
    "            # dL/dW_hh = dz_t @ h_{t-1}^T\n",
    "            dW_hh += np.outer(dz_t, h_prev)  # (hidden_size, hidden_size)\n",
    "            \n",
    "            # dL/db_h = dz_t\n",
    "            db_h += dz_t  # (hidden_size,)\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # Step 5: è®¡ç®—ä¼ é€’ç»™ä¸Šä¸€æ—¶åˆ»çš„æ¢¯åº¦\n",
    "            # h_{t-1} å¯¹ z_t çš„è´¡çŒ®: z_t = ... + W_hh @ h_{t-1}\n",
    "            # æ‰€ä»¥ dh_{t-1} = W_hh^T @ dz_t\n",
    "            # ------------------------------------------\n",
    "            dh_next = self.W_hh.T @ dz_t  # (hidden_size,)\n",
    "        \n",
    "        # ========================================\n",
    "        # è¿”å›æ‰€æœ‰æ¢¯åº¦\n",
    "        # ========================================\n",
    "        grads = {\n",
    "            'dW_xh': dW_xh,\n",
    "            'dW_hh': dW_hh,\n",
    "            'db_h': db_h,\n",
    "            'dW_hy': dW_hy,\n",
    "            'db_y': db_y\n",
    "        }\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def update_params(self, grads, learning_rate):\n",
    "        \"\"\"\n",
    "        ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°å‚æ•°\n",
    "        \n",
    "        å‚æ•°:\n",
    "            grads: backward() è¿”å›çš„æ¢¯åº¦å­—å…¸\n",
    "            learning_rate: å­¦ä¹ ç‡\n",
    "        \"\"\"\n",
    "        self.W_xh -= learning_rate * grads['dW_xh']\n",
    "        self.W_hh -= learning_rate * grads['dW_hh']\n",
    "        self.b_h -= learning_rate * grads['db_h']\n",
    "        self.W_hy -= learning_rate * grads['dW_hy']\n",
    "        self.b_y -= learning_rate * grads['db_y']\n",
    "\n",
    "\n",
    "print(\"RNNWithBPTT ç±»å®šä¹‰å®Œæˆï¼\")\n",
    "print(\"åŒ…å«æ–¹æ³•ï¼šforward(), backward(), update_params()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 éªŒè¯æ¢¯åº¦ï¼šæ•°å€¼æ¢¯åº¦ vs è§£ææ¢¯åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(rnn, X, Y_true, param_name, eps=1e-5):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨æ•°å€¼å¾®åˆ†è®¡ç®—æ¢¯åº¦ï¼ˆç”¨äºéªŒè¯è§£ææ¢¯åº¦ï¼‰\n",
    "    \n",
    "    æ•°å€¼æ¢¯åº¦å…¬å¼ï¼ˆä¸­å¿ƒå·®åˆ†ï¼‰:\n",
    "        dL/dw â‰ˆ [L(w+Îµ) - L(w-Îµ)] / (2Îµ)\n",
    "    \n",
    "    è¿™ç§æ–¹æ³•è™½ç„¶æ…¢ï¼Œä½†éå¸¸å‡†ç¡®ï¼Œå¸¸ç”¨äºè°ƒè¯•\n",
    "    \"\"\"\n",
    "    # è·å–å‚æ•°å¼•ç”¨\n",
    "    param = getattr(rnn, param_name)\n",
    "    grad = np.zeros_like(param)\n",
    "    \n",
    "    # éå†å‚æ•°çš„æ¯ä¸ªå…ƒç´ \n",
    "    it = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        original_value = param[idx]\n",
    "        \n",
    "        # è®¡ç®— L(w + Îµ)\n",
    "        param[idx] = original_value + eps\n",
    "        Y_plus, _ = rnn.forward(X)\n",
    "        loss_plus = 0.5 * np.sum((Y_plus - Y_true) ** 2)  # MSE æŸå¤±\n",
    "        \n",
    "        # è®¡ç®— L(w - Îµ)\n",
    "        param[idx] = original_value - eps\n",
    "        Y_minus, _ = rnn.forward(X)\n",
    "        loss_minus = 0.5 * np.sum((Y_minus - Y_true) ** 2)\n",
    "        \n",
    "        # æ•°å€¼æ¢¯åº¦\n",
    "        grad[idx] = (loss_plus - loss_minus) / (2 * eps)\n",
    "        \n",
    "        # æ¢å¤åŸå€¼\n",
    "        param[idx] = original_value\n",
    "        it.iternext()\n",
    "    \n",
    "    return grad\n",
    "\n",
    "\n",
    "def gradient_check():\n",
    "    \"\"\"\n",
    "    æ¢¯åº¦æ£€éªŒï¼šæ¯”è¾ƒæ•°å€¼æ¢¯åº¦å’Œè§£ææ¢¯åº¦\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"æ¢¯åº¦æ£€éªŒï¼šæ•°å€¼æ¢¯åº¦ vs è§£ææ¢¯åº¦ï¼ˆBPTTï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ›å»ºå°å‹ RNNï¼ˆä¾¿äºæ£€éªŒï¼‰\n",
    "    input_size = 3\n",
    "    hidden_size = 4\n",
    "    output_size = 2\n",
    "    seq_len = 5\n",
    "    \n",
    "    rnn = RNNWithBPTT(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºè¾“å…¥å’Œç›®æ ‡\n",
    "    X = np.random.randn(seq_len, input_size)\n",
    "    Y_true = np.random.randn(seq_len, output_size)\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    Y_pred, _ = rnn.forward(X)\n",
    "    \n",
    "    # è®¡ç®—æŸå¤±å¯¹è¾“å‡ºçš„æ¢¯åº¦ï¼ˆMSE æŸå¤±: L = 0.5 * ||Y_pred - Y_true||^2ï¼‰\n",
    "    # dL/dY = Y_pred - Y_true\n",
    "    dL_dY = Y_pred - Y_true\n",
    "    \n",
    "    # BPTT è§£ææ¢¯åº¦\n",
    "    grads = rnn.backward(dL_dY)\n",
    "    \n",
    "    # æ£€éªŒæ¯ä¸ªå‚æ•°çš„æ¢¯åº¦\n",
    "    param_names = ['W_xh', 'W_hh', 'b_h', 'W_hy', 'b_y']\n",
    "    \n",
    "    print(f\"\\nè¾“å…¥ç»´åº¦: {input_size}, éšè—ç»´åº¦: {hidden_size}, è¾“å‡ºç»´åº¦: {output_size}\")\n",
    "    print(f\"åºåˆ—é•¿åº¦: {seq_len}\")\n",
    "    print(\"\\n\" + \"-\" * 60)\n",
    "    \n",
    "    all_passed = True\n",
    "    for name in param_names:\n",
    "        # æ•°å€¼æ¢¯åº¦\n",
    "        num_grad = numerical_gradient(rnn, X, Y_true, name)\n",
    "        # è§£ææ¢¯åº¦\n",
    "        ana_grad = grads[f'd{name}']\n",
    "        \n",
    "        # è®¡ç®—ç›¸å¯¹è¯¯å·®\n",
    "        diff = np.abs(num_grad - ana_grad)\n",
    "        norm = np.abs(num_grad) + np.abs(ana_grad) + 1e-8\n",
    "        relative_error = np.max(diff / norm)\n",
    "        \n",
    "        # åˆ¤æ–­æ˜¯å¦é€šè¿‡\n",
    "        passed = relative_error < 1e-5\n",
    "        status = \"âœ“ PASS\" if passed else \"âœ— FAIL\"\n",
    "        all_passed = all_passed and passed\n",
    "        \n",
    "        print(f\"{name:8s}: ç›¸å¯¹è¯¯å·® = {relative_error:.2e}  {status}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    if all_passed:\n",
    "        print(\"ğŸ‰ æ‰€æœ‰æ¢¯åº¦æ£€éªŒé€šè¿‡ï¼BPTT å®ç°æ­£ç¡®ï¼\")\n",
    "    else:\n",
    "        print(\"âŒ éƒ¨åˆ†æ¢¯åº¦æ£€éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°\")\n",
    "\n",
    "\n",
    "# è¿è¡Œæ¢¯åº¦æ£€éªŒ\n",
    "gradient_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 è®­ç»ƒç¤ºä¾‹ï¼šå­¦ä¹ ç®€å•åºåˆ—æ¨¡å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_example():\n",
    "    \"\"\"\n",
    "    è®­ç»ƒ RNN å­¦ä¹ ä¸€ä¸ªç®€å•çš„åºåˆ—ä»»åŠ¡ï¼š\n",
    "    è¾“å…¥: éšæœºåºåˆ—\n",
    "    è¾“å‡º: åºåˆ—çš„ç´¯è®¡å‡å€¼\n",
    "    \n",
    "    ä¾‹å¦‚:\n",
    "        è¾“å…¥: [0.5, 0.3, 0.7, 0.2]\n",
    "        è¾“å‡º: [0.5, 0.4, 0.5, 0.425]  (ç´¯è®¡å¹³å‡)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"RNN è®­ç»ƒç¤ºä¾‹ï¼šå­¦ä¹ è®¡ç®—ç´¯è®¡å‡å€¼\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ========================================\n",
    "    # ç”Ÿæˆè®­ç»ƒæ•°æ®\n",
    "    # ========================================\n",
    "    def generate_data(n_samples, seq_len):\n",
    "        \"\"\"ç”Ÿæˆç´¯è®¡å‡å€¼ä»»åŠ¡çš„æ•°æ®\"\"\"\n",
    "        X = np.random.randn(n_samples, seq_len, 1)  # éšæœºè¾“å…¥\n",
    "        Y = np.zeros_like(X)                        # ç›®æ ‡ï¼šç´¯è®¡å‡å€¼\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            cumsum = np.cumsum(X[i], axis=0)        # ç´¯è®¡å’Œ\n",
    "            counts = np.arange(1, seq_len + 1).reshape(-1, 1)  # 1, 2, 3, ...\n",
    "            Y[i] = cumsum / counts                  # ç´¯è®¡å‡å€¼\n",
    "        \n",
    "        return X, Y\n",
    "    \n",
    "    # å‚æ•°è®¾ç½®\n",
    "    n_train = 100\n",
    "    n_test = 20\n",
    "    seq_len = 10\n",
    "    input_size = 1\n",
    "    hidden_size = 16\n",
    "    output_size = 1\n",
    "    \n",
    "    # ç”Ÿæˆæ•°æ®\n",
    "    X_train, Y_train = generate_data(n_train, seq_len)\n",
    "    X_test, Y_test = generate_data(n_test, seq_len)\n",
    "    \n",
    "    print(f\"\\nè®­ç»ƒæ•°æ®: {n_train} ä¸ªåºåˆ—ï¼Œæ¯ä¸ªé•¿åº¦ {seq_len}\")\n",
    "    print(f\"æµ‹è¯•æ•°æ®: {n_test} ä¸ªåºåˆ—\")\n",
    "    \n",
    "    # ========================================\n",
    "    # åˆ›å»ºå¹¶è®­ç»ƒ RNN\n",
    "    # ========================================\n",
    "    rnn = RNNWithBPTT(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # è®­ç»ƒå‚æ•°\n",
    "    n_epochs = 200\n",
    "    learning_rate = 0.01\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    print(f\"\\nå¼€å§‹è®­ç»ƒ (epochs={n_epochs}, lr={learning_rate})...\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        # éå†æ¯ä¸ªè®­ç»ƒæ ·æœ¬\n",
    "        for i in range(n_train):\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            X = X_train[i].reshape(seq_len, input_size)\n",
    "            Y_true = Y_train[i].reshape(seq_len, output_size)\n",
    "            Y_pred, _ = rnn.forward(X)\n",
    "            \n",
    "            # è®¡ç®— MSE æŸå¤±\n",
    "            loss = 0.5 * np.mean((Y_pred - Y_true) ** 2)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            # åå‘ä¼ æ’­\n",
    "            dL_dY = (Y_pred - Y_true) / seq_len  # MSE æ¢¯åº¦\n",
    "            grads = rnn.backward(dL_dY)\n",
    "            \n",
    "            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰\n",
    "            for key in grads:\n",
    "                np.clip(grads[key], -5, 5, out=grads[key])\n",
    "            \n",
    "            # æ›´æ–°å‚æ•°\n",
    "            rnn.update_params(grads, learning_rate)\n",
    "        \n",
    "        train_loss = epoch_loss / n_train\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # è®¡ç®—æµ‹è¯•æŸå¤±\n",
    "        test_loss = 0\n",
    "        for i in range(n_test):\n",
    "            X = X_test[i].reshape(seq_len, input_size)\n",
    "            Y_true = Y_test[i].reshape(seq_len, output_size)\n",
    "            Y_pred, _ = rnn.forward(X)\n",
    "            test_loss += 0.5 * np.mean((Y_pred - Y_true) ** 2)\n",
    "        test_loss /= n_test\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # æ‰“å°è¿›åº¦\n",
    "        if (epoch + 1) % 40 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}: è®­ç»ƒæŸå¤± = {train_loss:.6f}, æµ‹è¯•æŸå¤± = {test_loss:.6f}\")\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(\"è®­ç»ƒå®Œæˆï¼\")\n",
    "    \n",
    "    # ========================================\n",
    "    # å¯è§†åŒ–è®­ç»ƒç»“æœ\n",
    "    # ========================================\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # å·¦å›¾ï¼šæŸå¤±æ›²çº¿\n",
    "    ax = axes[0]\n",
    "    ax.plot(train_losses, label='è®­ç»ƒæŸå¤±', color='blue')\n",
    "    ax.plot(test_losses, label='æµ‹è¯•æŸå¤±', color='orange')\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('MSE Loss', fontsize=12)\n",
    "    ax.set_title('è®­ç»ƒè¿‡ç¨‹ï¼šæŸå¤±æ›²çº¿', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # å³å›¾ï¼šé¢„æµ‹ vs çœŸå®å€¼\n",
    "    ax = axes[1]\n",
    "    \n",
    "    # é€‰æ‹©ä¸€ä¸ªæµ‹è¯•æ ·æœ¬\n",
    "    idx = 0\n",
    "    X = X_test[idx].reshape(seq_len, input_size)\n",
    "    Y_true = Y_test[idx].flatten()\n",
    "    Y_pred, _ = rnn.forward(X)\n",
    "    Y_pred = Y_pred.flatten()\n",
    "    \n",
    "    time_steps = np.arange(1, seq_len + 1)\n",
    "    ax.plot(time_steps, Y_true, 'o-', label='çœŸå®å€¼ï¼ˆç´¯è®¡å‡å€¼ï¼‰', color='green', markersize=8)\n",
    "    ax.plot(time_steps, Y_pred, 's--', label='é¢„æµ‹å€¼', color='red', markersize=8)\n",
    "    ax.bar(time_steps, X.flatten(), alpha=0.3, label='è¾“å…¥å€¼', color='blue')\n",
    "    ax.set_xlabel('æ—¶é—´æ­¥', fontsize=12)\n",
    "    ax.set_ylabel('å€¼', fontsize=12)\n",
    "    ax.set_title('æµ‹è¯•æ ·æœ¬ï¼šé¢„æµ‹ vs çœŸå®', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return rnn, train_losses, test_losses\n",
    "\n",
    "\n",
    "# è¿è¡Œè®­ç»ƒ\n",
    "trained_rnn, train_losses, test_losses = train_rnn_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬å››éƒ¨åˆ†ï¼šæˆªæ–­ BPTT (Truncated BPTT)\n",
    "\n",
    "### 4.1 ä¸ºä»€ä¹ˆéœ€è¦æˆªæ–­ï¼Ÿ\n",
    "\n",
    "**é—®é¢˜**ï¼šå®Œæ•´ BPTT çš„è®¡ç®—å¤æ‚åº¦\n",
    "\n",
    "- å†…å­˜ï¼šéœ€è¦å­˜å‚¨æ‰€æœ‰æ—¶é—´æ­¥çš„ä¸­é—´å€¼ â†’ $O(T \\times H)$\n",
    "- æ—¶é—´ï¼šåå‘ä¼ æ’­éœ€è¦éå†æ‰€æœ‰æ—¶é—´æ­¥ â†’ $O(T)$\n",
    "- æ¢¯åº¦ï¼šé•¿åºåˆ—å®¹æ˜“å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆ**ï¼šæˆªæ–­ BPTT\n",
    "\n",
    "```\n",
    "å®Œæ•´ BPTT (åºåˆ—é•¿åº¦ = 100):\n",
    "    [t=1] â† [t=2] â† ... â† [t=99] â† [t=100] â† Loss\n",
    "    â†‘ éœ€è¦å­˜å‚¨ 100 ä¸ªæ—¶é—´æ­¥çš„ä¸­é—´å€¼\n",
    "    â†‘ æ¢¯åº¦è¦åå‘ä¼ æ’­ 100 æ­¥\n",
    "\n",
    "æˆªæ–­ BPTT (æˆªæ–­é•¿åº¦ k = 20):\n",
    "    [t=1..20]   [t=21..40]   [t=41..60]   ...\n",
    "        â†‘           â†‘            â†‘\n",
    "    åå‘20æ­¥    åå‘20æ­¥     åå‘20æ­¥\n",
    "    \n",
    "    éšçŠ¶æ€ç»§ç»­ä¼ é€’ï¼Œä½†æ¢¯åº¦æ¯ 20 æ­¥æˆªæ–­\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_bptt_demo():\n",
    "    \"\"\"\n",
    "    æˆªæ–­ BPTT æ¼”ç¤º\n",
    "    \n",
    "    æ€è·¯ï¼š\n",
    "    1. å°†é•¿åºåˆ—åˆ†æˆå¤šä¸ªå°æ®µ\n",
    "    2. æ¯æ®µç‹¬ç«‹è¿›è¡Œå‰å‘-åå‘ä¼ æ’­\n",
    "    3. ä½†éšçŠ¶æ€åœ¨æ®µä¹‹é—´ä¼ é€’ï¼ˆdetach æ¢¯åº¦ï¼‰\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"æˆªæ–­ BPTT (Truncated BPTT) æ¼”ç¤º\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ä½¿ç”¨ PyTorch æ¼”ç¤ºï¼ˆæ›´ç›´è§‚ï¼‰\n",
    "    class RNNWithTruncatedBPTT(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super().__init__()\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "            self.hidden_size = hidden_size\n",
    "        \n",
    "        def forward(self, x, h=None):\n",
    "            out, h_new = self.rnn(x, h)\n",
    "            out = self.fc(out)\n",
    "            return out, h_new\n",
    "    \n",
    "    # å‚æ•°\n",
    "    input_size = 1\n",
    "    hidden_size = 32\n",
    "    output_size = 1\n",
    "    total_seq_len = 100\n",
    "    truncation_len = 20  # æˆªæ–­é•¿åº¦\n",
    "    \n",
    "    model = RNNWithTruncatedBPTT(input_size, hidden_size, output_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # ç”Ÿæˆé•¿åºåˆ—æ•°æ®\n",
    "    X = torch.randn(1, total_seq_len, input_size)  # ä¸€ä¸ªé•¿åºåˆ—\n",
    "    Y = torch.cumsum(X, dim=1) / torch.arange(1, total_seq_len + 1).float().view(1, -1, 1)\n",
    "    \n",
    "    print(f\"\\nåºåˆ—æ€»é•¿åº¦: {total_seq_len}\")\n",
    "    print(f\"æˆªæ–­é•¿åº¦: {truncation_len}\")\n",
    "    print(f\"åˆ†æ®µæ•°: {total_seq_len // truncation_len}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # æˆªæ–­ BPTT è®­ç»ƒå¾ªç¯\n",
    "    # ========================================\n",
    "    n_epochs = 50\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        h = None  # åˆå§‹éšçŠ¶æ€\n",
    "        total_loss = 0\n",
    "        \n",
    "        # å°†åºåˆ—åˆ†æˆå¤šä¸ªæ®µ\n",
    "        for i in range(0, total_seq_len, truncation_len):\n",
    "            # è·å–å½“å‰æ®µ\n",
    "            X_chunk = X[:, i:i+truncation_len, :]\n",
    "            Y_chunk = Y[:, i:i+truncation_len, :]\n",
    "            \n",
    "            # å…³é”®æ“ä½œï¼šdetach éšçŠ¶æ€\n",
    "            # è¿™ä¼šåˆ‡æ–­æ¢¯åº¦é“¾ï¼Œä½†ä¿ç•™éšçŠ¶æ€çš„å€¼\n",
    "            if h is not None:\n",
    "                h = h.detach()  # æˆªæ–­æ¢¯åº¦ï¼\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­\n",
    "            Y_pred, h = model(X_chunk, h)\n",
    "            \n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = criterion(Y_pred, Y_chunk)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # åå‘ä¼ æ’­ï¼ˆåªåœ¨å½“å‰æ®µå†…ï¼‰\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # æ¢¯åº¦è£å‰ª\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        losses.append(total_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}: Loss = {total_loss:.6f}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # å¯è§†åŒ–\n",
    "    # ========================================\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # å·¦å›¾ï¼šæˆªæ–­ BPTT ç¤ºæ„\n",
    "    ax = axes[0]\n",
    "    n_segments = total_seq_len // truncation_len\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, n_segments))\n",
    "    \n",
    "    for i, color in enumerate(colors):\n",
    "        start = i * truncation_len\n",
    "        end = start + truncation_len\n",
    "        ax.axvspan(start, end, alpha=0.3, color=color, label=f'æ®µ {i+1}' if i < 5 else '')\n",
    "        \n",
    "        # ç»˜åˆ¶æˆªæ–­çº¿\n",
    "        if i > 0:\n",
    "            ax.axvline(x=start, color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    ax.plot(range(total_seq_len), X[0, :, 0].numpy(), 'b-', alpha=0.7, linewidth=1)\n",
    "    ax.set_xlabel('æ—¶é—´æ­¥', fontsize=12)\n",
    "    ax.set_ylabel('å€¼', fontsize=12)\n",
    "    ax.set_title(f'æˆªæ–­ BPTT: æ¯ {truncation_len} æ­¥æˆªæ–­æ¢¯åº¦', fontsize=14)\n",
    "    ax.legend(loc='upper right', ncol=2)\n",
    "    \n",
    "    # æ·»åŠ è¯´æ˜\n",
    "    ax.text(50, ax.get_ylim()[1] * 0.9, \n",
    "            'çº¢è‰²è™šçº¿: æ¢¯åº¦æˆªæ–­ç‚¹\\néšçŠ¶æ€ç»§ç»­ä¼ é€’', \n",
    "            ha='center', fontsize=10,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    \n",
    "    # å³å›¾ï¼šæŸå¤±æ›²çº¿\n",
    "    ax = axes[1]\n",
    "    ax.plot(losses, 'b-', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('è®­ç»ƒæŸå¤±ï¼ˆä½¿ç”¨æˆªæ–­ BPTTï¼‰', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model, losses\n",
    "\n",
    "\n",
    "# è¿è¡Œæˆªæ–­ BPTT æ¼”ç¤º\n",
    "model_tbptt, losses_tbptt = truncated_bptt_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æˆªæ–­ BPTT çš„å…³é”®ä»£ç \n",
    "\n",
    "```python\n",
    "# PyTorch ä¸­çš„æˆªæ–­ BPTT å…³é”®æ“ä½œ\n",
    "\n",
    "h = None\n",
    "for chunk in chunks:\n",
    "    # å…³é”®ï¼šdetach éšçŠ¶æ€\n",
    "    if h is not None:\n",
    "        h = h.detach()  # åˆ‡æ–­æ¢¯åº¦é“¾ï¼Œä½†ä¿ç•™å€¼\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    output, h = model(chunk, h)\n",
    "    \n",
    "    # åå‘ä¼ æ’­ï¼ˆåªåœ¨å½“å‰æ®µå†…ï¼‰\n",
    "    loss.backward()\n",
    "```\n",
    "\n",
    "**`detach()` çš„ä½œç”¨**ï¼š\n",
    "- åˆ›å»ºä¸€ä¸ªæ–° tensorï¼Œå€¼ç›¸åŒä½†åˆ‡æ–­äº†è®¡ç®—å›¾\n",
    "- éšçŠ¶æ€çš„**å€¼**ç»§ç»­ä¼ é€’ï¼ˆä¿æŒä¸Šä¸‹æ–‡ï¼‰\n",
    "- éšçŠ¶æ€çš„**æ¢¯åº¦**ä¸å†å›ä¼ ï¼ˆé™åˆ¶è®¡ç®—ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 å®Œæ•´ BPTT vs æˆªæ–­ BPTT æ¯”è¾ƒ\n",
    "\n",
    "| ç‰¹æ€§ | å®Œæ•´ BPTT | æˆªæ–­ BPTT (k) |\n",
    "|------|-----------|---------------|\n",
    "| å†…å­˜ | O(T Ã— H) | O(k Ã— H) |\n",
    "| æ—¶é—´ | O(T) | O(k) Ã— (T/k) = O(T) |\n",
    "| é•¿æœŸä¾èµ– | ç†è®ºä¸Šå®Œæ•´ | åªèƒ½æ•è· k æ­¥ |\n",
    "| æ¢¯åº¦ç¨³å®šæ€§ | å¯èƒ½æ¶ˆå¤±/çˆ†ç‚¸ | æ›´ç¨³å®š |\n",
    "| å®é™…åº”ç”¨ | çŸ­åºåˆ— | é•¿åºåˆ—è®­ç»ƒæ ‡å‡†æ–¹æ³• |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ç¬¬äº”éƒ¨åˆ†ï¼šPyTorch å®ç°å¯¹æ¯”\n",
    "\n",
    "éªŒè¯æˆ‘ä»¬çš„ NumPy å®ç°ä¸ PyTorch çš„ä¸€è‡´æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_bptt_comparison():\n",
    "    \"\"\"\n",
    "    æ¯”è¾ƒ NumPy å®ç°çš„ BPTT ä¸ PyTorch autograd çš„ç»“æœ\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"NumPy BPTT vs PyTorch autograd å¯¹æ¯”\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # å‚æ•°\n",
    "    input_size = 4\n",
    "    hidden_size = 5\n",
    "    output_size = 3\n",
    "    seq_len = 6\n",
    "    \n",
    "    # å›ºå®šéšæœºç§å­\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # åˆ›å»º NumPy RNN\n",
    "    rnn_np = RNNWithBPTT(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # åˆ›å»º PyTorch RNNï¼ˆä½¿ç”¨ç›¸åŒçš„æƒé‡ï¼‰\n",
    "    class PyTorchRNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.W_xh = nn.Parameter(torch.tensor(rnn_np.W_xh, dtype=torch.float32))\n",
    "            self.W_hh = nn.Parameter(torch.tensor(rnn_np.W_hh, dtype=torch.float32))\n",
    "            self.b_h = nn.Parameter(torch.tensor(rnn_np.b_h, dtype=torch.float32))\n",
    "            self.W_hy = nn.Parameter(torch.tensor(rnn_np.W_hy, dtype=torch.float32))\n",
    "            self.b_y = nn.Parameter(torch.tensor(rnn_np.b_y, dtype=torch.float32))\n",
    "            self.hidden_size = hidden_size\n",
    "        \n",
    "        def forward(self, X):\n",
    "            seq_len = X.shape[0]\n",
    "            h = torch.zeros(self.hidden_size)\n",
    "            outputs = []\n",
    "            \n",
    "            for t in range(seq_len):\n",
    "                h = torch.tanh(self.W_xh @ X[t] + self.W_hh @ h + self.b_h)\n",
    "                y = self.W_hy @ h + self.b_y\n",
    "                outputs.append(y)\n",
    "            \n",
    "            return torch.stack(outputs)\n",
    "    \n",
    "    rnn_pt = PyTorchRNN()\n",
    "    \n",
    "    # ç”Ÿæˆè¾“å…¥\n",
    "    X_np = np.random.randn(seq_len, input_size).astype(np.float32)\n",
    "    X_pt = torch.tensor(X_np, requires_grad=False)\n",
    "    Y_true_np = np.random.randn(seq_len, output_size).astype(np.float32)\n",
    "    Y_true_pt = torch.tensor(Y_true_np)\n",
    "    \n",
    "    # ========================================\n",
    "    # NumPy å‰å‘ + BPTT\n",
    "    # ========================================\n",
    "    Y_np, _ = rnn_np.forward(X_np)\n",
    "    dL_dY_np = (Y_np - Y_true_np) / seq_len\n",
    "    grads_np = rnn_np.backward(dL_dY_np)\n",
    "    \n",
    "    # ========================================\n",
    "    # PyTorch å‰å‘ + autograd\n",
    "    # ========================================\n",
    "    Y_pt = rnn_pt(X_pt)\n",
    "    loss_pt = 0.5 * torch.mean((Y_pt - Y_true_pt) ** 2)\n",
    "    loss_pt.backward()\n",
    "    \n",
    "    # ========================================\n",
    "    # æ¯”è¾ƒç»“æœ\n",
    "    # ========================================\n",
    "    print(f\"\\nåºåˆ—é•¿åº¦: {seq_len}, éšè—ç»´åº¦: {hidden_size}\")\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"å‰å‘ä¼ æ’­è¾“å‡ºæ¯”è¾ƒ:\")\n",
    "    print(f\"  æœ€å¤§å·®å¼‚: {np.max(np.abs(Y_np - Y_pt.detach().numpy())):.2e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"æ¢¯åº¦æ¯”è¾ƒ (NumPy BPTT vs PyTorch autograd):\")\n",
    "    \n",
    "    grad_comparisons = [\n",
    "        ('dW_xh', 'W_xh'),\n",
    "        ('dW_hh', 'W_hh'),\n",
    "        ('db_h', 'b_h'),\n",
    "        ('dW_hy', 'W_hy'),\n",
    "        ('db_y', 'b_y')\n",
    "    ]\n",
    "    \n",
    "    for np_name, pt_name in grad_comparisons:\n",
    "        np_grad = grads_np[np_name]\n",
    "        pt_grad = getattr(rnn_pt, pt_name).grad.numpy()\n",
    "        \n",
    "        max_diff = np.max(np.abs(np_grad - pt_grad))\n",
    "        status = \"âœ“\" if max_diff < 1e-5 else \"âœ—\"\n",
    "        \n",
    "        print(f\"  {np_name:8s}: æœ€å¤§å·®å¼‚ = {max_diff:.2e}  {status}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"ğŸ‰ NumPy BPTT å®ç°ä¸ PyTorch autograd ç»“æœä¸€è‡´ï¼\")\n",
    "\n",
    "\n",
    "pytorch_bptt_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## æœ¬ç« æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "1. **BPTT åŸç†**ï¼š\n",
    "   - å°† RNN æ²¿æ—¶é—´å±•å¼€\n",
    "   - ä½¿ç”¨é“¾å¼æ³•åˆ™åå‘ä¼ æ’­æ¢¯åº¦\n",
    "   - æ¢¯åº¦éœ€è¦é€šè¿‡æ‰€æœ‰æ—¶é—´æ­¥ç´¯ç§¯\n",
    "\n",
    "2. **å…³é”®å…¬å¼**ï¼š\n",
    "   $$\\frac{\\partial L}{\\partial h_t} = \\frac{\\partial L_t}{\\partial h_t} + \\frac{\\partial L}{\\partial h_{t+1}} \\cdot \\frac{\\partial h_{t+1}}{\\partial h_t}$$\n",
    "\n",
    "3. **æˆªæ–­ BPTT**ï¼š\n",
    "   - é™åˆ¶åå‘ä¼ æ’­çš„æ—¶é—´æ­¥æ•°\n",
    "   - å‡å°‘å†…å­˜å’Œè®¡ç®—å¼€é”€\n",
    "   - å…³é”®æ“ä½œï¼š`h = h.detach()`\n",
    "\n",
    "### ä»£ç æ¨¡æ¿\n",
    "\n",
    "```python\n",
    "# BPTT åå‘ä¼ æ’­æ ¸å¿ƒæ­¥éª¤\n",
    "dh_next = np.zeros(hidden_size)  # ä»æœªæ¥ä¼ æ¥çš„æ¢¯åº¦\n",
    "\n",
    "for t in reversed(range(seq_len)):\n",
    "    # ç´¯ç§¯æ¢¯åº¦ï¼šå½“å‰è¾“å‡º + æœªæ¥ä¼ å›\n",
    "    dh_t = W_hy.T @ dy_t + dh_next\n",
    "    \n",
    "    # é€šè¿‡ tanh\n",
    "    dz_t = dh_t * (1 - h_t ** 2)\n",
    "    \n",
    "    # ç´¯ç§¯å‚æ•°æ¢¯åº¦\n",
    "    dW_xh += np.outer(dz_t, x_t)\n",
    "    dW_hh += np.outer(dz_t, h_prev)\n",
    "    \n",
    "    # ä¼ é€’ç»™ä¸Šä¸€æ—¶åˆ»\n",
    "    dh_next = W_hh.T @ dz_t\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ä¸‹ä¸€ç« é¢„å‘Š\n",
    "\n",
    "**ç¬¬ 4 ç« ï¼šæ¢¯åº¦æ¶ˆå¤±ä¸æ¢¯åº¦çˆ†ç‚¸**\n",
    "\n",
    "BPTT æœ‰ä¸€ä¸ªä¸¥é‡é—®é¢˜ï¼šæ¢¯åº¦åœ¨é•¿åºåˆ—ä¸­å®¹æ˜“æ¶ˆå¤±æˆ–çˆ†ç‚¸ï¼\n",
    "\n",
    "ä¸‹ä¸€ç« æˆ‘ä»¬å°†ï¼š\n",
    "- åˆ†ææ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸çš„æ•°å­¦åŸå› \n",
    "- å¯è§†åŒ–é•¿åºåˆ—ä¸­çš„æ¢¯åº¦è¡Œä¸º\n",
    "- æ¢ç´¢è§£å†³æ–¹æ¡ˆï¼ˆä¸º LSTM/GRU åšé“ºå«ï¼‰\n",
    "\n",
    "ğŸ‘‰ [04_gradient_problems.ipynb](./04_gradient_problems.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
