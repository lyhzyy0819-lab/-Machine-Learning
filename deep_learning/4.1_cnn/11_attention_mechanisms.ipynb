{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 æ³¨æ„åŠ›æœºåˆ¶å…¥é—¨\n",
    "\n",
    "> ä» SE-Net åˆ° CBAMï¼šè®© CNN å­¦ä¼šã€Œå…³æ³¨ã€é‡è¦ç‰¹å¾\n",
    "\n",
    "---\n",
    "\n",
    "**æœ¬ç« é‡ç‚¹**ï¼šç†è§£æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•å¢å¼º CNN çš„ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ï¼Œä¸ºåç»­å­¦ä¹  Transformer æ‰“ä¸‹åŸºç¡€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- [ ] ç†è§£æ³¨æ„åŠ›æœºåˆ¶çš„ç›´è§‰å’ŒåŠ¨æœº\n",
    "- [ ] **æ·±å…¥ç†è§£é€šé“æ³¨æ„åŠ›ï¼ˆSE-Netï¼‰**\n",
    "- [ ] **ä»é›¶å®ç° SE æ¨¡å—**\n",
    "- [ ] ç†è§£ç©ºé—´æ³¨æ„åŠ›çš„è®¾è®¡\n",
    "- [ ] **å®ç°å®Œæ•´çš„ CBAM æ¨¡å—**\n",
    "- [ ] å°†æ³¨æ„åŠ›æ¨¡å—é›†æˆåˆ° ResNet ä¸­\n",
    "- [ ] åœ¨ CIFAR-10 ä¸ŠéªŒè¯æ³¨æ„åŠ›çš„æ•ˆæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” å‰ç½®çŸ¥è¯†\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»æŒæ¡ï¼š\n",
    "\n",
    "- **07_classic_architectures.ipynb** - ResNet å’Œæ®‹å·®è¿æ¥\n",
    "- **10_modern_efficient_architectures.ipynb** - æ·±åº¦å¯åˆ†ç¦»å·ç§¯å’Œ MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®è®¾å¤‡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ\n",
    "\n",
    "## 1.1 äººç±»è§†è§‰çš„é€‰æ‹©æ€§æ³¨æ„\n",
    "\n",
    "äººç±»è§†è§‰ç³»ç»Ÿæœ‰ä¸€ä¸ªé‡è¦ç‰¹ç‚¹ï¼š**é€‰æ‹©æ€§æ³¨æ„ï¼ˆSelective Attentionï¼‰**\n",
    "\n",
    "å½“æˆ‘ä»¬çœ‹ä¸€å¼ å›¾ç‰‡æ—¶ï¼š\n",
    "- ä¸æ˜¯å‡åŒ€åœ°çœ‹æ¯ä¸ªåƒç´ \n",
    "- è€Œæ˜¯**èšç„¦äºæœ€é‡è¦çš„åŒºåŸŸ**\n",
    "- å¿½ç•¥æ— å…³æˆ–å†—ä½™çš„ä¿¡æ¯\n",
    "\n",
    "### ä¾‹å­ï¼šè¯†åˆ«ä¸€åªçŒ«\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”                            â”‚\n",
    "â”‚  â”‚ çŒ«  â”‚ â† é«˜æ³¨æ„åŠ›ï¼ˆé‡è¦åŒºåŸŸï¼‰     â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”˜                            â”‚\n",
    "â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
    "â”‚  èƒŒæ™¯è‰åœ°...        â”‚ èŠ±æœµ   â”‚      â”‚\n",
    "â”‚  â†‘                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
    "â”‚  ä½æ³¨æ„åŠ›ï¼ˆä¸é‡è¦ï¼‰  ä¸­ç­‰æ³¨æ„åŠ›     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**æ³¨æ„åŠ›æœºåˆ¶**å°±æ˜¯è®©ç¥ç»ç½‘ç»œå­¦ä¼šè¿™ç§ã€Œå…³æ³¨é‡è¦ä¿¡æ¯ã€çš„èƒ½åŠ›ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 é€šé“æ³¨æ„åŠ› vs ç©ºé—´æ³¨æ„åŠ›\n",
    "\n",
    "åœ¨ CNN ä¸­ï¼Œæ³¨æ„åŠ›å¯ä»¥ä»ä¸¤ä¸ªç»´åº¦æ€è€ƒï¼š\n",
    "\n",
    "### é€šé“æ³¨æ„åŠ›ï¼ˆChannel Attentionï¼‰\n",
    "\n",
    "**é—®é¢˜**ï¼šå“ªäº›ç‰¹å¾é€šé“æ›´é‡è¦ï¼Ÿ\n",
    "\n",
    "```\n",
    "ç‰¹å¾å›¾ (C, H, W)\n",
    "\n",
    "Channel 0: è¾¹ç¼˜æ£€æµ‹å™¨  â†’ é‡è¦æ€§: 0.8\n",
    "Channel 1: é¢œè‰²æ£€æµ‹å™¨  â†’ é‡è¦æ€§: 0.3\n",
    "Channel 2: çº¹ç†æ£€æµ‹å™¨  â†’ é‡è¦æ€§: 0.6\n",
    "Channel 3: å½¢çŠ¶æ£€æµ‹å™¨  â†’ é‡è¦æ€§: 0.9  â† å¯¹äºè¯†åˆ«çŒ«æœ€é‡è¦ï¼\n",
    "...\n",
    "```\n",
    "\n",
    "### ç©ºé—´æ³¨æ„åŠ›ï¼ˆSpatial Attentionï¼‰\n",
    "\n",
    "**é—®é¢˜**ï¼šç‰¹å¾å›¾çš„å“ªäº›ä½ç½®æ›´é‡è¦ï¼Ÿ\n",
    "\n",
    "```\n",
    "ç‰¹å¾å›¾ (C, H, W)\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 0.1  0.2  0.1  0.1â”‚  â† èƒŒæ™¯åŒºåŸŸï¼Œä½æ³¨æ„åŠ›\n",
    "â”‚ 0.3  0.9  0.8  0.2â”‚  â† çŒ«æ‰€åœ¨ä½ç½®ï¼Œé«˜æ³¨æ„åŠ›ï¼\n",
    "â”‚ 0.2  0.7  0.6  0.1â”‚\n",
    "â”‚ 0.1  0.1  0.1  0.1â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### ä¸¤ç§æ³¨æ„åŠ›çš„å…³ç³»\n",
    "\n",
    "| ç±»å‹ | é—®é¢˜ | è¾“å‡ºå½¢çŠ¶ |\n",
    "|------|------|----------|\n",
    "| é€šé“æ³¨æ„åŠ› | å“ªä¸ªé€šé“é‡è¦ | (C, 1, 1) |\n",
    "| ç©ºé—´æ³¨æ„åŠ› | å“ªä¸ªä½ç½®é‡è¦ | (1, H, W) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ï¼šé€šé“æ³¨æ„åŠ› vs ç©ºé—´æ³¨æ„åŠ›çš„æ¦‚å¿µ\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# 1. åŸå§‹ç‰¹å¾å›¾ï¼ˆæ¨¡æ‹Ÿï¼‰\n",
    "np.random.seed(42)\n",
    "feature_map = np.random.rand(4, 8, 8)  # 4 é€šé“ï¼Œ8Ã—8\n",
    "\n",
    "# æ˜¾ç¤ºç¬¬ä¸€ä¸ªé€šé“\n",
    "axes[0].imshow(feature_map[0], cmap='viridis')\n",
    "axes[0].set_title('åŸå§‹ç‰¹å¾å›¾ (1ä¸ªé€šé“)')\n",
    "axes[0].set_xlabel('W')\n",
    "axes[0].set_ylabel('H')\n",
    "\n",
    "# 2. é€šé“æ³¨æ„åŠ›æƒé‡\n",
    "channel_weights = np.array([0.3, 0.9, 0.5, 0.7])  # 4ä¸ªé€šé“çš„æƒé‡\n",
    "axes[1].bar(range(4), channel_weights, color=['steelblue', 'coral', 'steelblue', 'steelblue'])\n",
    "axes[1].set_xticks(range(4))\n",
    "axes[1].set_xticklabels(['Ch0', 'Ch1', 'Ch2', 'Ch3'])\n",
    "axes[1].set_ylabel('æ³¨æ„åŠ›æƒé‡')\n",
    "axes[1].set_title('é€šé“æ³¨æ„åŠ›\\n(å“ªä¸ªé€šé“é‡è¦ï¼Ÿ)')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. ç©ºé—´æ³¨æ„åŠ›æƒé‡\n",
    "spatial_weights = np.zeros((8, 8))\n",
    "# æ¨¡æ‹Ÿä¸­å¿ƒåŒºåŸŸæ›´é‡è¦\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        dist = np.sqrt((i-3.5)**2 + (j-3.5)**2)\n",
    "        spatial_weights[i, j] = np.exp(-dist/3)\n",
    "spatial_weights = (spatial_weights - spatial_weights.min()) / (spatial_weights.max() - spatial_weights.min())\n",
    "\n",
    "im = axes[2].imshow(spatial_weights, cmap='hot')\n",
    "axes[2].set_title('ç©ºé—´æ³¨æ„åŠ›\\n(å“ªä¸ªä½ç½®é‡è¦ï¼Ÿ)')\n",
    "axes[2].set_xlabel('W')\n",
    "axes[2].set_ylabel('H')\n",
    "plt.colorbar(im, ax=axes[2], fraction=0.046)\n",
    "\n",
    "plt.suptitle('æ³¨æ„åŠ›æœºåˆ¶çš„ä¸¤ä¸ªç»´åº¦', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ å…³é”®ç†è§£ï¼š\")\n",
    "print(\"   - é€šé“æ³¨æ„åŠ›ï¼šä¸ºæ¯ä¸ªé€šé“åˆ†é…ä¸€ä¸ªæƒé‡ï¼ˆ0~1ï¼‰\")\n",
    "print(\"   - ç©ºé—´æ³¨æ„åŠ›ï¼šä¸ºæ¯ä¸ªç©ºé—´ä½ç½®åˆ†é…ä¸€ä¸ªæƒé‡ï¼ˆ0~1ï¼‰\")\n",
    "print(\"   - ä¸¤è€…å¯ä»¥ç»“åˆä½¿ç”¨ï¼ˆå¦‚ CBAMï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: é€šé“æ³¨æ„åŠ› SE-Net â­æ ¸å¿ƒ\n",
    "\n",
    "## 2.1 SE-Net ç®€ä»‹\n",
    "\n",
    "**SE-Netï¼ˆSqueeze-and-Excitation Networkï¼‰** æ˜¯ ImageNet 2017 å† å†›ï¼Œæ ¸å¿ƒåˆ›æ–°æ˜¯ **SE æ¨¡å—**ã€‚\n",
    "\n",
    "### SE æ¨¡å—çš„è®¾è®¡æ€æƒ³\n",
    "\n",
    "1. **Squeezeï¼ˆå‹ç¼©ï¼‰**ï¼šå°†ç©ºé—´ç»´åº¦å‹ç¼©æˆä¸€ä¸ªæ•°ï¼Œå¾—åˆ°æ¯ä¸ªé€šé“çš„ã€Œå…¨å±€æè¿°ã€\n",
    "2. **Excitationï¼ˆæ¿€åŠ±ï¼‰**ï¼šé€šè¿‡ä¸¤ä¸ªå…¨è¿æ¥å±‚å­¦ä¹ é€šé“ä¹‹é—´çš„å…³ç³»\n",
    "3. **Scaleï¼ˆç¼©æ”¾ï¼‰**ï¼šç”¨å­¦åˆ°çš„æƒé‡å¯¹åŸç‰¹å¾è¿›è¡Œé€šé“åŠ æƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 æ•°å­¦å…¬å¼æ¨å¯¼\n",
    "\n",
    "è®¾è¾“å…¥ç‰¹å¾ä¸º $X \\in \\mathbb{R}^{C \\times H \\times W}$\n",
    "\n",
    "### Step 1: Squeezeï¼ˆå…¨å±€å¹³å‡æ± åŒ–ï¼‰\n",
    "\n",
    "$$z_c = \\frac{1}{H \\times W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} X_c(i, j)$$\n",
    "\n",
    "å¾—åˆ° $z \\in \\mathbb{R}^{C}$ï¼Œæ¯ä¸ªé€šé“ä¸€ä¸ªæ ‡é‡ã€‚\n",
    "\n",
    "### Step 2: Excitationï¼ˆä¸¤å±‚ FCï¼‰\n",
    "\n",
    "$$s = \\sigma(W_2 \\cdot \\text{ReLU}(W_1 \\cdot z))$$\n",
    "\n",
    "å…¶ä¸­ï¼š\n",
    "- $W_1 \\in \\mathbb{R}^{C/r \\times C}$ï¼šé™ç»´ï¼ˆå‹ç¼©æ¯” rï¼Œé€šå¸¸ r=16ï¼‰\n",
    "- $W_2 \\in \\mathbb{R}^{C \\times C/r}$ï¼šå‡ç»´\n",
    "- $\\sigma$ï¼šSigmoid å‡½æ•°ï¼Œè¾“å‡ºèŒƒå›´ [0, 1]\n",
    "\n",
    "å¾—åˆ° $s \\in \\mathbb{R}^{C}$ï¼Œæ¯ä¸ªé€šé“ä¸€ä¸ªæ³¨æ„åŠ›æƒé‡ã€‚\n",
    "\n",
    "### Step 3: Scaleï¼ˆé€šé“åŠ æƒï¼‰\n",
    "\n",
    "$$\\tilde{X}_c = s_c \\cdot X_c$$\n",
    "\n",
    "è¾“å‡º $\\tilde{X} \\in \\mathbb{R}^{C \\times H \\times W}$ï¼Œä¸è¾“å…¥å½¢çŠ¶ç›¸åŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE æ¨¡å—çš„å·¥ä½œæµç¨‹å›¾ç¤º\n",
    "\n",
    "print(\"\"\"\n",
    "SE æ¨¡å—å·¥ä½œæµç¨‹\n",
    "================================================================================\n",
    "\n",
    "è¾“å…¥ X: (C, H, W)\n",
    "    â”‚\n",
    "    â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Squeeze: Global Average Pooling                                            â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚\n",
    "â”‚  z = GAP(X)                                                                  â”‚\n",
    "â”‚  å°† (C, H, W) å‹ç¼©ä¸º (C,)                                                    â”‚\n",
    "â”‚  æ¯ä¸ªé€šé“çš„ HÃ—W ä¸ªå€¼å–å¹³å‡                                                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â”‚\n",
    "    â–¼  z: (C,)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Excitation: FC â†’ ReLU â†’ FC â†’ Sigmoid                                       â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚\n",
    "â”‚  FC1: (C,) â†’ (C/r,)    é™ç»´ï¼Œå‡å°‘å‚æ•°                                        â”‚\n",
    "â”‚  ReLU: éçº¿æ€§                                                                â”‚\n",
    "â”‚  FC2: (C/r,) â†’ (C,)    å‡ç»´å›åŸé€šé“æ•°                                        â”‚\n",
    "â”‚  Sigmoid: è¾“å‡º [0,1] çš„æ³¨æ„åŠ›æƒé‡                                            â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â”‚\n",
    "    â–¼  s: (C,) æ³¨æ„åŠ›æƒé‡\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Scale: é€šé“åŠ æƒ                                                             â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                           â”‚\n",
    "â”‚  XÌƒ = s Ã— X  (å¹¿æ’­ä¹˜æ³•)                                                       â”‚\n",
    "â”‚  æ¯ä¸ªé€šé“ä¹˜ä»¥å¯¹åº”çš„æƒé‡                                                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â”‚\n",
    "    â–¼\n",
    "è¾“å‡º XÌƒ: (C, H, W)  å½¢çŠ¶ä¸å˜\n",
    "\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ä»é›¶å®ç° SE æ¨¡å—ï¼ˆNumPyï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_module_numpy(x, W1, W2):\n",
    "    \"\"\"\n",
    "    SE æ¨¡å—çš„ NumPy ä»é›¶å®ç°\n",
    "    \n",
    "    å‚æ•°:\n",
    "        x: è¾“å…¥ç‰¹å¾, shape (C, H, W)\n",
    "        W1: ç¬¬ä¸€å±‚å…¨è¿æ¥æƒé‡, shape (C/r, C)\n",
    "        W2: ç¬¬äºŒå±‚å…¨è¿æ¥æƒé‡, shape (C, C/r)\n",
    "    \n",
    "    è¿”å›:\n",
    "        output: åŠ æƒåçš„ç‰¹å¾, shape (C, H, W)\n",
    "        attention: é€šé“æ³¨æ„åŠ›æƒé‡, shape (C,)\n",
    "    \"\"\"\n",
    "    C, H, W = x.shape\n",
    "    \n",
    "    # ========================================\n",
    "    # Step 1: Squeezeï¼ˆå…¨å±€å¹³å‡æ± åŒ–ï¼‰\n",
    "    # å°†æ¯ä¸ªé€šé“çš„ HÃ—W ä¸ªå€¼å‹ç¼©æˆä¸€ä¸ªå€¼\n",
    "    # ========================================\n",
    "    z = np.mean(x, axis=(1, 2))  # (C, H, W) â†’ (C,)\n",
    "    \n",
    "    # ========================================\n",
    "    # Step 2: Excitationï¼ˆä¸¤å±‚å…¨è¿æ¥ï¼‰\n",
    "    # ========================================\n",
    "    # FC1: é™ç»´ + ReLU\n",
    "    h = np.maximum(0, W1 @ z)  # (C/r, C) Ã— (C,) â†’ (C/r,)\n",
    "    \n",
    "    # FC2: å‡ç»´ + Sigmoid\n",
    "    s = 1 / (1 + np.exp(-(W2 @ h)))  # (C, C/r) Ã— (C/r,) â†’ (C,)\n",
    "    \n",
    "    # ========================================\n",
    "    # Step 3: Scaleï¼ˆé€šé“åŠ æƒï¼‰\n",
    "    # æ¯ä¸ªé€šé“ä¹˜ä»¥å¯¹åº”çš„æƒé‡\n",
    "    # ========================================\n",
    "    # å°† s æ‰©å±•ä¸º (C, 1, 1) ä»¥ä¾¿å¹¿æ’­\n",
    "    s_expanded = s.reshape(C, 1, 1)\n",
    "    output = x * s_expanded  # é€å…ƒç´ ä¹˜æ³•\n",
    "    \n",
    "    return output, s\n",
    "\n",
    "\n",
    "# æµ‹è¯• SE æ¨¡å—\n",
    "print(\"SE æ¨¡å— NumPy å®ç°æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•è¾“å…¥\n",
    "np.random.seed(42)\n",
    "C, H, W = 16, 8, 8  # 16 é€šé“ï¼Œ8Ã—8 ç‰¹å¾å›¾\n",
    "reduction = 4  # å‹ç¼©æ¯”\n",
    "\n",
    "x = np.random.randn(C, H, W)\n",
    "W1 = np.random.randn(C // reduction, C) * 0.1  # (4, 16)\n",
    "W2 = np.random.randn(C, C // reduction) * 0.1  # (16, 4)\n",
    "\n",
    "# æ‰§è¡Œ SE æ¨¡å—\n",
    "output, attention = se_module_numpy(x, W1, W2)\n",
    "\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {x.shape}\")\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "print(f\"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention.shape}\")\n",
    "print(f\"\\næ³¨æ„åŠ›æƒé‡èŒƒå›´: [{attention.min():.3f}, {attention.max():.3f}]\")\n",
    "print(f\"æ³¨æ„åŠ›æƒé‡: {attention[:8]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– SE æ¨¡å—çš„æ•ˆæœ\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "# 1. è¾“å…¥ç‰¹å¾ï¼ˆç¬¬ä¸€ä¸ªé€šé“ï¼‰\n",
    "axes[0].imshow(x[0], cmap='viridis')\n",
    "axes[0].set_title('è¾“å…¥ç‰¹å¾\\n(Channel 0)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 2. æ³¨æ„åŠ›æƒé‡\n",
    "axes[1].bar(range(C), attention, color='coral')\n",
    "axes[1].set_xlabel('Channel')\n",
    "axes[1].set_ylabel('Attention')\n",
    "axes[1].set_title('é€šé“æ³¨æ„åŠ›æƒé‡')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. è¾“å‡ºç‰¹å¾ï¼ˆç¬¬ä¸€ä¸ªé€šé“ï¼‰\n",
    "axes[2].imshow(output[0], cmap='viridis')\n",
    "axes[2].set_title(f'è¾“å‡ºç‰¹å¾\\n(Channel 0, weight={attention[0]:.2f})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 4. è¾“å…¥ vs è¾“å‡ºå¯¹æ¯”ï¼ˆå¤šé€šé“å¹³å‡ï¼‰\n",
    "input_mean = np.mean(np.abs(x), axis=0)\n",
    "output_mean = np.mean(np.abs(output), axis=0)\n",
    "axes[3].imshow(output_mean - input_mean, cmap='RdBu_r', vmin=-0.5, vmax=0.5)\n",
    "axes[3].set_title('è¾“å‡º-è¾“å…¥å·®å¼‚\\n(è¢«æŠ‘åˆ¶çš„åŒºåŸŸä¸ºè“è‰²)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.suptitle('SE æ¨¡å—æ•ˆæœå¯è§†åŒ–', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ SE æ¨¡å—çš„ä½œç”¨ï¼š\")\n",
    "print(f\"   - æƒé‡é«˜çš„é€šé“ï¼ˆå¦‚ {np.argmax(attention)}ï¼‰è¢«å¼ºåŒ–\")\n",
    "print(f\"   - æƒé‡ä½çš„é€šé“ï¼ˆå¦‚ {np.argmin(attention)}ï¼‰è¢«æŠ‘åˆ¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 PyTorch å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation æ¨¡å—çš„ PyTorch å®ç°\n",
    "    \n",
    "    å‚æ•°:\n",
    "        channels: è¾“å…¥é€šé“æ•°\n",
    "        reduction: å‹ç¼©æ¯”ï¼ˆé»˜è®¤ 16ï¼‰\n",
    "    \n",
    "    è¾“å…¥:\n",
    "        x: (N, C, H, W)\n",
    "    \n",
    "    è¾“å‡º:\n",
    "        åŠ æƒåçš„ç‰¹å¾: (N, C, H, W)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        # ========================================\n",
    "        # Squeeze: å…¨å±€å¹³å‡æ± åŒ–\n",
    "        # ========================================\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        # ========================================\n",
    "        # Excitation: ä¸¤å±‚å…¨è¿æ¥\n",
    "        # ========================================\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # Squeeze: (N, C, H, W) â†’ (N, C, 1, 1) â†’ (N, C)\n",
    "        z = self.squeeze(x).view(N, C)\n",
    "        \n",
    "        # Excitation: (N, C) â†’ (N, C)\n",
    "        s = self.excitation(z)\n",
    "        \n",
    "        # Scale: æ‰©å±•æƒé‡å¹¶ä¸è¾“å…¥ç›¸ä¹˜\n",
    "        # (N, C) â†’ (N, C, 1, 1)\n",
    "        s = s.view(N, C, 1, 1)\n",
    "        \n",
    "        return x * s\n",
    "\n",
    "\n",
    "# æµ‹è¯• SE æ¨¡å—\n",
    "print(\"SE æ¨¡å— PyTorch æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "se = SEModule(channels=64, reduction=16)\n",
    "x = torch.randn(2, 64, 16, 16)\n",
    "y = se(x)\n",
    "\n",
    "print(f\"è¾“å…¥: {x.shape}\")\n",
    "print(f\"è¾“å‡º: {y.shape}\")\n",
    "print(f\"å‚æ•°é‡: {sum(p.numel() for p in se.parameters()):,}\")\n",
    "\n",
    "# è®¡ç®—å‚æ•°é‡å…¬å¼\n",
    "C, r = 64, 16\n",
    "expected_params = C * (C // r) + (C // r) * C\n",
    "print(f\"ç†è®ºå‚æ•°é‡: 2 Ã— C Ã— (C/r) = 2 Ã— {C} Ã— {C//r} = {expected_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 é›†æˆåˆ° ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    å¸¦ SE æ¨¡å—çš„ ResNet BasicBlock\n",
    "    \n",
    "    ç»“æ„:\n",
    "        x â†’ Conv â†’ BN â†’ ReLU â†’ Conv â†’ BN â†’ SE â†’ (+x) â†’ ReLU\n",
    "    \"\"\"\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ä¸»è·¯å¾„\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # SE æ¨¡å—\n",
    "        self.se = SEModule(out_channels, reduction)\n",
    "        \n",
    "        # è·³è·ƒè¿æ¥\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        # åº”ç”¨ SE æ³¨æ„åŠ›\n",
    "        out = self.se(out)\n",
    "        \n",
    "        out = out + identity\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class SE_ResNet18(nn.Module):\n",
    "    \"\"\"å¸¦ SE æ¨¡å—çš„ ResNet-18\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(64, 64, 2, 1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, 2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, 2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_ch, out_ch, num_blocks, stride):\n",
    "        layers = [SEBasicBlock(in_ch, out_ch, stride)]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(SEBasicBlock(out_ch, out_ch, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# å¯¹æ¯”å‚æ•°é‡\n",
    "print(\"ResNet vs SE-ResNet å‚æ•°é‡å¯¹æ¯”\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ç®€å•çš„ ResNet-18 (å¤ç”¨ä¹‹å‰çš„å®šä¹‰)\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = out + self.shortcut(x)\n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(64, 64, 2, 1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, 2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, 2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, in_ch, out_ch, num_blocks, stride):\n",
    "        layers = [BasicBlock(in_ch, out_ch, stride)]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(BasicBlock(out_ch, out_ch, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "resnet = ResNet18()\n",
    "se_resnet = SE_ResNet18()\n",
    "\n",
    "resnet_params = sum(p.numel() for p in resnet.parameters())\n",
    "se_resnet_params = sum(p.numel() for p in se_resnet.parameters())\n",
    "\n",
    "print(f\"ResNet-18:    {resnet_params:>12,} å‚æ•°\")\n",
    "print(f\"SE-ResNet-18: {se_resnet_params:>12,} å‚æ•°\")\n",
    "print(f\"å¢åŠ æ¯”ä¾‹:     {(se_resnet_params - resnet_params) / resnet_params * 100:.2f}%\")\n",
    "print(f\"\\nğŸ’¡ SE æ¨¡å—åªå¢åŠ çº¦ 2.5% çš„å‚æ•°ï¼Œä½†èƒ½æ˜¾è‘—æå‡å‡†ç¡®ç‡ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 å¯è§†åŒ–é€šé“æƒé‡çƒ­åŠ›å›¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– SE æ¨¡å—å­¦åˆ°çš„é€šé“æ³¨æ„åŠ›\n",
    "\n",
    "def visualize_se_attention(model, x):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ– SE æ¨¡å—çš„é€šé“æ³¨æ„åŠ›\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: åŒ…å« SE æ¨¡å—çš„æ¨¡å‹\n",
    "        x: è¾“å…¥å›¾åƒ (1, C, H, W)\n",
    "    \n",
    "    è¿”å›:\n",
    "        attention_maps: æ¯ä¸ª SE æ¨¡å—çš„æ³¨æ„åŠ›æƒé‡\n",
    "    \"\"\"\n",
    "    attention_maps = {}\n",
    "    \n",
    "    # æ³¨å†Œ hook æ¥æ•è· SE æ¨¡å—çš„è¾“å‡º\n",
    "    def hook_fn(name):\n",
    "        def hook(module, input, output):\n",
    "            # è·å– excitation è¾“å‡ºï¼ˆåœ¨ sigmoid ä¹‹åï¼‰\n",
    "            with torch.no_grad():\n",
    "                z = module.squeeze(input[0]).view(input[0].size(0), -1)\n",
    "                s = module.excitation(z)\n",
    "                attention_maps[name] = s.cpu().numpy()[0]\n",
    "        return hook\n",
    "    \n",
    "    # ä¸ºæ¯ä¸ª SE æ¨¡å—æ³¨å†Œ hook\n",
    "    hooks = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, SEModule):\n",
    "            hooks.append(module.register_forward_hook(hook_fn(name)))\n",
    "    \n",
    "    # å‰å‘ä¼ æ’­\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "    \n",
    "    # ç§»é™¤ hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "    \n",
    "    return attention_maps\n",
    "\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•\n",
    "model = SE_ResNet18()\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "attention_maps = visualize_se_attention(model, x)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "n_layers = len(attention_maps)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, attn) in enumerate(attention_maps.items()):\n",
    "    if idx >= 8:\n",
    "        break\n",
    "    ax = axes[idx]\n",
    "    ax.bar(range(len(attn)), attn, color='coral', alpha=0.7)\n",
    "    ax.set_title(f'{name.split(\".\")[-2]}\\n({len(attn)} channels)', fontsize=9)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    if idx >= 4:\n",
    "        ax.set_xlabel('Channel')\n",
    "    if idx % 4 == 0:\n",
    "        ax.set_ylabel('Attention')\n",
    "\n",
    "plt.suptitle('SE-ResNet18 å„å±‚çš„é€šé“æ³¨æ„åŠ›åˆ†å¸ƒ', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ è§‚å¯Ÿï¼š\")\n",
    "print(\"   - ä¸åŒå±‚å­¦åˆ°çš„æ³¨æ„åŠ›åˆ†å¸ƒä¸åŒ\")\n",
    "print(\"   - æœ‰äº›é€šé“è¢«å¼ºåŒ–ï¼ˆ>0.5ï¼‰ï¼Œæœ‰äº›è¢«æŠ‘åˆ¶ï¼ˆ<0.5ï¼‰\")\n",
    "print(\"   - ç½‘ç»œè‡ªåŠ¨å­¦ä¼šå“ªäº›ç‰¹å¾æ›´é‡è¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: ç©ºé—´æ³¨æ„åŠ›\n",
    "\n",
    "## 3.1 è®¾è®¡åŸç†\n",
    "\n",
    "ç©ºé—´æ³¨æ„åŠ›å›ç­”çš„é—®é¢˜æ˜¯ï¼š**ç‰¹å¾å›¾çš„å“ªäº›ä½ç½®æ›´é‡è¦ï¼Ÿ**\n",
    "\n",
    "### è®¾è®¡æ€è·¯\n",
    "\n",
    "1. **è·¨é€šé“èšåˆ**ï¼šå°†æ‰€æœ‰é€šé“çš„ä¿¡æ¯èšåˆåˆ°ä¸€ä¸ªå¹³é¢ä¸Š\n",
    "   - ä½¿ç”¨é€šé“ç»´åº¦çš„æœ€å¤§å€¼å’Œå¹³å‡å€¼\n",
    "2. **ç©ºé—´å·ç§¯**ï¼šç”¨ä¸€ä¸ªå¤§æ ¸ï¼ˆå¦‚ 7Ã—7ï¼‰å·ç§¯å­¦ä¹ ç©ºé—´å…³ç³»\n",
    "3. **Sigmoid**ï¼šè¾“å‡ºæ¯ä¸ªä½ç½®çš„æ³¨æ„åŠ›æƒé‡ [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    ç©ºé—´æ³¨æ„åŠ›æ¨¡å—\n",
    "    \n",
    "    è®¾è®¡:\n",
    "        1. æ²¿é€šé“ç»´åº¦è®¡ç®— max å’Œ avg\n",
    "        2. æ‹¼æ¥æˆ 2 é€šé“\n",
    "        3. ç”¨ 7Ã—7 å·ç§¯ç”Ÿæˆç©ºé—´æ³¨æ„åŠ›å›¾\n",
    "    \n",
    "    è¾“å…¥:\n",
    "        x: (N, C, H, W)\n",
    "    \n",
    "    è¾“å‡º:\n",
    "        åŠ æƒåçš„ç‰¹å¾: (N, C, H, W)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ç¡®ä¿ padding ä½¿è¾“å‡ºå°ºå¯¸ä¸å˜\n",
    "        padding = kernel_size // 2\n",
    "        \n",
    "        # 2 é€šé“è¾“å…¥ï¼ˆmax + avgï¼‰ï¼Œ1 é€šé“è¾“å‡ºï¼ˆç©ºé—´æ³¨æ„åŠ›å›¾ï¼‰\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ========================================\n",
    "        # Step 1: è·¨é€šé“èšåˆ\n",
    "        # è®¡ç®—æ¯ä¸ªä½ç½®åœ¨æ‰€æœ‰é€šé“ä¸Šçš„ max å’Œ avg\n",
    "        # ========================================\n",
    "        # (N, C, H, W) â†’ (N, 1, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        \n",
    "        # ========================================\n",
    "        # Step 2: æ‹¼æ¥\n",
    "        # (N, 1, H, W) + (N, 1, H, W) â†’ (N, 2, H, W)\n",
    "        # ========================================\n",
    "        concat = torch.cat([avg_out, max_out], dim=1)\n",
    "        \n",
    "        # ========================================\n",
    "        # Step 3: å·ç§¯ + Sigmoid\n",
    "        # (N, 2, H, W) â†’ (N, 1, H, W)\n",
    "        # ========================================\n",
    "        attention = self.sigmoid(self.conv(concat))\n",
    "        \n",
    "        # ========================================\n",
    "        # Step 4: Scale\n",
    "        # ========================================\n",
    "        return x * attention\n",
    "\n",
    "\n",
    "# æµ‹è¯•ç©ºé—´æ³¨æ„åŠ›\n",
    "print(\"ç©ºé—´æ³¨æ„åŠ›æ¨¡å—æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sa = SpatialAttention(kernel_size=7)\n",
    "x = torch.randn(1, 64, 16, 16)\n",
    "y = sa(x)\n",
    "\n",
    "print(f\"è¾“å…¥: {x.shape}\")\n",
    "print(f\"è¾“å‡º: {y.shape}\")\n",
    "print(f\"å‚æ•°é‡: {sum(p.numel() for p in sa.parameters()):,}\")\n",
    "print(f\"ç†è®ºå‚æ•°é‡: 2 Ã— 1 Ã— 7 Ã— 7 = {2 * 1 * 7 * 7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç©ºé—´æ³¨æ„åŠ›\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæœ‰æ˜æ˜¾ç»“æ„çš„è¾“å…¥\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(1, 64, 32, 32)\n",
    "\n",
    "# åœ¨ä¸­å¿ƒåŒºåŸŸæ·»åŠ é«˜å“åº”\n",
    "x[:, :, 10:22, 10:22] += 2.0\n",
    "\n",
    "# è·å–ç©ºé—´æ³¨æ„åŠ›å›¾\n",
    "sa = SpatialAttention(kernel_size=7)\n",
    "sa.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # æ‰‹åŠ¨æå–æ³¨æ„åŠ›å›¾\n",
    "    avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "    max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "    concat = torch.cat([avg_out, max_out], dim=1)\n",
    "    attention_map = torch.sigmoid(sa.conv(concat))\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3))\n",
    "\n",
    "# 1. è¾“å…¥ç‰¹å¾ï¼ˆå¹³å‡ï¼‰\n",
    "im0 = axes[0].imshow(x[0].mean(0).numpy(), cmap='viridis')\n",
    "axes[0].set_title('è¾“å…¥ç‰¹å¾ (é€šé“å¹³å‡)')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im0, ax=axes[0], fraction=0.046)\n",
    "\n",
    "# 2. é€šé“å¹³å‡\n",
    "im1 = axes[1].imshow(avg_out[0, 0].numpy(), cmap='viridis')\n",
    "axes[1].set_title('é€šé“ Average')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[1], fraction=0.046)\n",
    "\n",
    "# 3. é€šé“æœ€å¤§\n",
    "im2 = axes[2].imshow(max_out[0, 0].numpy(), cmap='viridis')\n",
    "axes[2].set_title('é€šé“ Max')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im2, ax=axes[2], fraction=0.046)\n",
    "\n",
    "# 4. ç©ºé—´æ³¨æ„åŠ›å›¾\n",
    "im3 = axes[3].imshow(attention_map[0, 0].numpy(), cmap='hot')\n",
    "axes[3].set_title('ç©ºé—´æ³¨æ„åŠ›å›¾')\n",
    "axes[3].axis('off')\n",
    "plt.colorbar(im3, ax=axes[3], fraction=0.046)\n",
    "\n",
    "plt.suptitle('ç©ºé—´æ³¨æ„åŠ›ï¼šå…³æ³¨ã€Œå“ªé‡Œã€é‡è¦', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ ç©ºé—´æ³¨æ„åŠ›çš„ä½œç”¨ï¼š\")\n",
    "print(\"   - è‡ªåŠ¨å‘ç°ç‰¹å¾å›¾ä¸­å“åº”å¼ºçš„åŒºåŸŸ\")\n",
    "print(\"   - å¯¹é‡è¦ä½ç½®èµ‹äºˆé«˜æƒé‡ï¼ŒæŠ‘åˆ¶èƒŒæ™¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: CBAM æ¨¡å—\n",
    "\n",
    "## 4.1 CBAM è®¾è®¡\n",
    "\n",
    "**CBAMï¼ˆConvolutional Block Attention Moduleï¼‰** å°†é€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›**ä¸²è”**ä½¿ç”¨ã€‚\n",
    "\n",
    "```\n",
    "è¾“å…¥ F\n",
    "    â†“\n",
    "é€šé“æ³¨æ„åŠ› â†’ F' = Mc(F) âŠ— F\n",
    "    â†“\n",
    "ç©ºé—´æ³¨æ„åŠ› â†’ F'' = Ms(F') âŠ— F'\n",
    "    â†“\n",
    "è¾“å‡º F''\n",
    "```\n",
    "\n",
    "å…¶ä¸­ âŠ— è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    CBAM ä¸­çš„é€šé“æ³¨æ„åŠ›æ¨¡å—\n",
    "    ä¸ SE ç±»ä¼¼ï¼Œä½†åŒæ—¶ä½¿ç”¨ max pool å’Œ avg pool\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        # å…±äº«çš„ MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        \n",
    "        # ä¸¤ç§æ± åŒ–æ–¹å¼\n",
    "        avg_out = self.avg_pool(x).view(N, C)\n",
    "        max_out = self.max_pool(x).view(N, C)\n",
    "        \n",
    "        # å…±äº« MLP åç›¸åŠ \n",
    "        attention = self.sigmoid(self.mlp(avg_out) + self.mlp(max_out))\n",
    "        \n",
    "        return x * attention.view(N, C, 1, 1)\n",
    "\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Block Attention Module\n",
    "    \n",
    "    ç»“æ„ï¼šé€šé“æ³¨æ„åŠ› â†’ ç©ºé—´æ³¨æ„åŠ›ï¼ˆä¸²è”ï¼‰\n",
    "    \n",
    "    å‚æ•°:\n",
    "        channels: è¾“å…¥é€šé“æ•°\n",
    "        reduction: é€šé“æ³¨æ„åŠ›çš„å‹ç¼©æ¯”\n",
    "        kernel_size: ç©ºé—´æ³¨æ„åŠ›çš„å·ç§¯æ ¸å¤§å°\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.channel_attention = ChannelAttention(channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å…ˆé€šé“æ³¨æ„åŠ›\n",
    "        x = self.channel_attention(x)\n",
    "        # å†ç©ºé—´æ³¨æ„åŠ›\n",
    "        x = self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# æµ‹è¯• CBAM\n",
    "print(\"CBAM æ¨¡å—æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cbam = CBAM(channels=64, reduction=16, kernel_size=7)\n",
    "x = torch.randn(1, 64, 16, 16)\n",
    "y = cbam(x)\n",
    "\n",
    "print(f\"è¾“å…¥: {x.shape}\")\n",
    "print(f\"è¾“å‡º: {y.shape}\")\n",
    "print(f\"å‚æ•°é‡: {sum(p.numel() for p in cbam.parameters()):,}\")\n",
    "\n",
    "# åˆ†åˆ«ç»Ÿè®¡\n",
    "ca_params = sum(p.numel() for p in cbam.channel_attention.parameters())\n",
    "sa_params = sum(p.numel() for p in cbam.spatial_attention.parameters())\n",
    "print(f\"  é€šé“æ³¨æ„åŠ›: {ca_params:,}\")\n",
    "print(f\"  ç©ºé—´æ³¨æ„åŠ›: {sa_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBAM é›†æˆåˆ° ResNet\n",
    "\n",
    "class CBAMBasicBlock(nn.Module):\n",
    "    \"\"\"å¸¦ CBAM çš„ ResNet BasicBlock\"\"\"\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # CBAM æ¨¡å—\n",
    "        self.cbam = CBAM(out_channels, reduction)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.cbam(out)  # åº”ç”¨ CBAM\n",
    "        \n",
    "        out = out + identity\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "class CBAM_ResNet18(nn.Module):\n",
    "    \"\"\"å¸¦ CBAM çš„ ResNet-18\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, 1, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = self._make_layer(64, 64, 2, 1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, 2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, 2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, in_ch, out_ch, num_blocks, stride):\n",
    "        layers = [CBAMBasicBlock(in_ch, out_ch, stride)]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(CBAMBasicBlock(out_ch, out_ch, 1))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# å¯¹æ¯”ä¸‰ç§æ¶æ„\n",
    "print(\"ä¸‰ç§æ¶æ„å‚æ•°é‡å¯¹æ¯”\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "cbam_resnet = CBAM_ResNet18()\n",
    "cbam_params = sum(p.numel() for p in cbam_resnet.parameters())\n",
    "\n",
    "print(f\"{'æ¶æ„':<20} {'å‚æ•°é‡':>12}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"{'ResNet-18':<20} {resnet_params:>12,}\")\n",
    "print(f\"{'SE-ResNet-18':<20} {se_resnet_params:>12,}\")\n",
    "print(f\"{'CBAM-ResNet-18':<20} {cbam_params:>12,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: å®æˆ˜å¯¹æ¯”\n",
    "\n",
    "åœ¨ CIFAR-10 ä¸Šå¯¹æ¯”ä¸‰ç§æ³¨æ„åŠ›æœºåˆ¶çš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "print(\"åŠ è½½ CIFAR-10 æ•°æ®é›†...\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "test_data = datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs=5, lr=0.01):\n",
    "    \"\"\"è®­ç»ƒæ¨¡å‹å¹¶è¿”å›å†å²è®°å½•\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_acc': [], 'test_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒ\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # æµ‹è¯•\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train={train_acc:.1f}%, Test={test_acc:.1f}%\")\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# è®­ç»ƒä¸‰ç§æ¨¡å‹\n",
    "EPOCHS = 5\n",
    "\n",
    "models = {\n",
    "    'ResNet-18': ResNet18(),\n",
    "    'SE-ResNet-18': SE_ResNet18(),\n",
    "    'CBAM-ResNet-18': CBAM_ResNet18()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"è®­ç»ƒ {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    results[name] = train_model(model, train_loader, test_loader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç»“æœ\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "colors = {'ResNet-18': 'steelblue', 'SE-ResNet-18': 'coral', 'CBAM-ResNet-18': 'seagreen'}\n",
    "\n",
    "# 1. æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿\n",
    "for name, history in results.items():\n",
    "    axes[0].plot(range(1, EPOCHS+1), history['test_acc'], \n",
    "                 label=name, color=colors[name], linewidth=2, marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('æµ‹è¯•å‡†ç¡®ç‡å¯¹æ¯”')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. æœ€ç»ˆå‡†ç¡®ç‡ vs å‚æ•°é‡\n",
    "names = list(results.keys())\n",
    "final_acc = [results[n]['test_acc'][-1] for n in names]\n",
    "params = [sum(p.numel() for p in models[n].parameters()) / 1e6 for n in names]\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    axes[1].scatter(params[i], final_acc[i], s=150, color=colors[name], \n",
    "                    label=name, zorder=5, edgecolors='black')\n",
    "    axes[1].annotate(f'{final_acc[i]:.1f}%', (params[i], final_acc[i]), \n",
    "                     textcoords=\"offset points\", xytext=(10, 5))\n",
    "\n",
    "axes[1].set_xlabel('å‚æ•°é‡ (M)')\n",
    "axes[1].set_ylabel('Test Accuracy (%)')\n",
    "axes[1].set_title('å‡†ç¡®ç‡ vs å‚æ•°é‡')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('æ³¨æ„åŠ›æœºåˆ¶æ•ˆæœå¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ€»ç»“è¡¨æ ¼\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"å®éªŒæ€»ç»“\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'æ¨¡å‹':<20} {'å‚æ•°é‡':>12} {'æœ€ç»ˆå‡†ç¡®ç‡':>12} {'æå‡':>10}\")\n",
    "print(\"-\" * 56)\n",
    "baseline_acc = results['ResNet-18']['test_acc'][-1]\n",
    "for name in names:\n",
    "    p = sum(p.numel() for p in models[name].parameters())\n",
    "    acc = results[name]['test_acc'][-1]\n",
    "    diff = acc - baseline_acc\n",
    "    diff_str = f\"+{diff:.1f}%\" if diff > 0 else f\"{diff:.1f}%\"\n",
    "    print(f\"{name:<20} {p/1e6:>11.2f}M {acc:>11.1f}% {diff_str:>10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æœ¬ç« å°ç»“\n",
    "\n",
    "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "1. **æ³¨æ„åŠ›æœºåˆ¶çš„ä¸¤ä¸ªç»´åº¦**ï¼š\n",
    "   - é€šé“æ³¨æ„åŠ›ï¼šã€Œå“ªä¸ªç‰¹å¾ã€é‡è¦\n",
    "   - ç©ºé—´æ³¨æ„åŠ›ï¼šã€Œå“ªä¸ªä½ç½®ã€é‡è¦\n",
    "\n",
    "2. **SE æ¨¡å—**ï¼ˆSqueeze-and-Excitationï¼‰ï¼š\n",
    "   - Squeezeï¼šå…¨å±€å¹³å‡æ± åŒ– (C,H,W) â†’ (C,)\n",
    "   - Excitationï¼šFC â†’ ReLU â†’ FC â†’ Sigmoid\n",
    "   - Scaleï¼šé€šé“åŠ æƒ\n",
    "   - å‚æ•°é‡å¢åŠ çº¦ 2-3%\n",
    "\n",
    "3. **ç©ºé—´æ³¨æ„åŠ›**ï¼š\n",
    "   - è·¨é€šé“èšåˆï¼ˆmax + avgï¼‰\n",
    "   - 7Ã—7 å·ç§¯ç”Ÿæˆç©ºé—´æƒé‡\n",
    "\n",
    "4. **CBAM**ï¼š\n",
    "   - é€šé“æ³¨æ„åŠ› + ç©ºé—´æ³¨æ„åŠ›ï¼ˆä¸²è”ï¼‰\n",
    "   - æ¯” SE æ•ˆæœæ›´å¥½\n",
    "\n",
    "### å…³é”®ä»£ç \n",
    "\n",
    "```python\n",
    "# SE æ¨¡å—æ ¸å¿ƒ\n",
    "z = self.squeeze(x).view(N, C)  # (N, C, H, W) â†’ (N, C)\n",
    "s = self.excitation(z)           # (N, C) â†’ (N, C)\n",
    "return x * s.view(N, C, 1, 1)    # é€šé“åŠ æƒ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ç»ƒä¹ \n",
    "\n",
    "### ç»ƒä¹  1ï¼šSE å‚æ•°é‡è®¡ç®—\n",
    "**éš¾åº¦**ï¼šâ­\n",
    "\n",
    "è®¡ç®—ä»¥ä¸‹æƒ…å†µ SE æ¨¡å—å¢åŠ çš„å‚æ•°é‡ï¼š\n",
    "1. é€šé“æ•° 256ï¼Œreduction=16\n",
    "2. é€šé“æ•° 512ï¼Œreduction=32\n",
    "\n",
    "### ç»ƒä¹  2ï¼šä¸åŒ reduction ratio\n",
    "**éš¾åº¦**ï¼šâ­â­\n",
    "\n",
    "ä¿®æ”¹ SE æ¨¡å—çš„ reduction ratioï¼ˆ4, 8, 16, 32ï¼‰ï¼Œåœ¨ CIFAR-10 ä¸Šå¯¹æ¯”å‡†ç¡®ç‡å’Œå‚æ•°é‡ã€‚\n",
    "\n",
    "### ç»ƒä¹  3ï¼šCBAM é›†æˆåˆ° VGG\n",
    "**éš¾åº¦**ï¼šâ­â­\n",
    "\n",
    "å°† CBAM æ¨¡å—é›†æˆåˆ° VGG ç½‘ç»œä¸­ï¼Œå¯¹æ¯”æ•ˆæœã€‚\n",
    "\n",
    "### ç»ƒä¹  4ï¼šè®¾è®¡è‡ªå·±çš„æ³¨æ„åŠ›æ¨¡å—\n",
    "**éš¾åº¦**ï¼šâ­â­â­\n",
    "\n",
    "è®¾è®¡ä¸€ä¸ªæ–°çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¯ä»¥å°è¯•ï¼š\n",
    "1. å¹¶è”ï¼ˆè€Œéä¸²è”ï¼‰é€šé“å’Œç©ºé—´æ³¨æ„åŠ›\n",
    "2. ä½¿ç”¨ä¸åŒçš„æ± åŒ–æ–¹å¼\n",
    "3. æ·»åŠ å¤šå°ºåº¦ç‰¹å¾\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç»§ç»­å­¦ä¹  **12_detection_segmentation_intro.ipynb** - ç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²å…¥é—¨\n",
    "\n",
    "å­¦ä¹ å¦‚ä½•å°† CNN åº”ç”¨äºç›®æ ‡æ£€æµ‹ï¼ˆYOLOï¼‰å’Œè¯­ä¹‰åˆ†å‰²ï¼ˆU-Netï¼‰ä»»åŠ¡ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
