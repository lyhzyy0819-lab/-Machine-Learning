{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 CNN ç½‘ç»œæ¶æ„\n",
    "\n",
    "> ç»„åˆå·ç§¯å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥å±‚ï¼Œæ„å»ºå®Œæ•´ CNN\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- [ ] ç†è§£ CNN çš„æ ‡å‡†æ¶æ„æ¨¡å¼\n",
    "- [ ] è¿½è¸ªç‰¹å¾å›¾å½¢çŠ¶å˜åŒ–\n",
    "- [ ] ä»é›¶å®ç°å®Œæ•´çš„ CNN ç±»\n",
    "- [ ] ä½¿ç”¨ PyTorch æ„å»º CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# å°è¯•å¯¼å…¥ PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    HAS_TORCH = True\n",
    "    print(\"PyTorch å·²å¯¼å…¥\")\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\"PyTorch æœªå®‰è£…ï¼Œéƒ¨åˆ†ä»£ç æ— æ³•è¿è¡Œ\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ CNN çš„æ ‡å‡†æ¶æ„\n",
    "\n",
    "```\n",
    "è¾“å…¥å›¾åƒ\n",
    "    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  ç‰¹å¾æå–éƒ¨åˆ†ï¼ˆé‡å¤å¤šæ¬¡ï¼‰           â”‚\n",
    "â”‚  Conv â†’ ReLU â†’ Pool              â”‚\n",
    "â”‚  Conv â†’ ReLU â†’ Pool              â”‚\n",
    "â”‚  ...                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â†“\n",
    "  Flattenï¼ˆå±•å¹³ï¼‰\n",
    "    â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  åˆ†ç±»éƒ¨åˆ†                         â”‚\n",
    "â”‚  FC â†’ ReLU â†’ Dropout            â”‚\n",
    "â”‚  FC â†’ Softmax                   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    â†“\n",
    "  è¾“å‡ºï¼ˆç±»åˆ«æ¦‚ç‡ï¼‰\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š ç‰¹å¾å›¾å½¢çŠ¶å˜åŒ–è¿½è¸ª\n",
    "\n",
    "ä»¥ MNIST (28Ã—28Ã—1) ä¸ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_output_size(H_in, k, p=0, s=1):\n",
    "    \"\"\"è®¡ç®—å·ç§¯/æ± åŒ–åçš„è¾“å‡ºå°ºå¯¸\"\"\"\n",
    "    return (H_in + 2*p - k) // s + 1\n",
    "\n",
    "# MNIST å›¾åƒå¤„ç†æµç¨‹\n",
    "print(\"MNIST CNN å½¢çŠ¶å˜åŒ–è¿½è¸ª\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# åˆå§‹è¾“å…¥\n",
    "H, W, C = 28, 28, 1\n",
    "print(f\"è¾“å…¥: {C}Ã—{H}Ã—{W}\")\n",
    "\n",
    "# Conv1: 1â†’32, 3Ã—3, same padding\n",
    "H = calc_output_size(H, 3, p=1)\n",
    "C = 32\n",
    "print(f\"Conv1 (32, 3Ã—3, p=1): {C}Ã—{H}Ã—{H}\")\n",
    "\n",
    "# Pool1: 2Ã—2\n",
    "H = calc_output_size(H, 2, s=2)\n",
    "print(f\"MaxPool (2Ã—2): {C}Ã—{H}Ã—{H}\")\n",
    "\n",
    "# Conv2: 32â†’64, 3Ã—3, same padding\n",
    "H = calc_output_size(H, 3, p=1)\n",
    "C = 64\n",
    "print(f\"Conv2 (64, 3Ã—3, p=1): {C}Ã—{H}Ã—{H}\")\n",
    "\n",
    "# Pool2: 2Ã—2\n",
    "H = calc_output_size(H, 2, s=2)\n",
    "print(f\"MaxPool (2Ã—2): {C}Ã—{H}Ã—{H}\")\n",
    "\n",
    "# Flatten\n",
    "flat = C * H * H\n",
    "print(f\"Flatten: {flat}\")\n",
    "\n",
    "# FC\n",
    "print(f\"FC1: {flat} â†’ 128\")\n",
    "print(f\"FC2: 128 â†’ 10 (è¾“å‡ºç±»åˆ«)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» NumPy å®ç°å®Œæ•´ CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    \"\"\"\n",
    "    ç®€å•çš„ CNN å®ç°ï¼ˆä»…å‰å‘ä¼ æ’­ï¼‰\n",
    "    \n",
    "    æ¶æ„:\n",
    "        Conv(1â†’8, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)\n",
    "        Conv(8â†’16, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)\n",
    "        Flatten â†’ FC(400â†’64) â†’ ReLU â†’ FC(64â†’10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # åˆå§‹åŒ–æƒé‡ï¼ˆéšæœºï¼‰\n",
    "        # Conv1: 8 ä¸ª 3Ã—3 æ ¸ï¼Œ1 ä¸ªè¾“å…¥é€šé“\n",
    "        self.conv1_w = np.random.randn(8, 1, 3, 3) * 0.1\n",
    "        self.conv1_b = np.zeros(8)\n",
    "        \n",
    "        # Conv2: 16 ä¸ª 3Ã—3 æ ¸ï¼Œ8 ä¸ªè¾“å…¥é€šé“\n",
    "        self.conv2_w = np.random.randn(16, 8, 3, 3) * 0.1\n",
    "        self.conv2_b = np.zeros(16)\n",
    "        \n",
    "        # FC1: 5Ã—5Ã—16 = 400 â†’ 64\n",
    "        self.fc1_w = np.random.randn(400, 64) * 0.1\n",
    "        self.fc1_b = np.zeros(64)\n",
    "        \n",
    "        # FC2: 64 â†’ 10\n",
    "        self.fc2_w = np.random.randn(64, 10) * 0.1\n",
    "        self.fc2_b = np.zeros(10)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def conv2d(self, x, w, b, padding=1):\n",
    "        \"\"\"ç®€åŒ–çš„å·ç§¯ï¼ˆå•æ ·æœ¬ï¼‰\"\"\"\n",
    "        C_out, C_in, k_h, k_w = w.shape\n",
    "        _, H, W = x.shape\n",
    "        \n",
    "        if padding > 0:\n",
    "            x = np.pad(x, ((0,0), (padding,padding), (padding,padding)))\n",
    "        \n",
    "        out_h = H\n",
    "        out_w = W\n",
    "        output = np.zeros((C_out, out_h, out_w))\n",
    "        \n",
    "        for c_out in range(C_out):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    window = x[:, i:i+k_h, j:j+k_w]\n",
    "                    output[c_out, i, j] = np.sum(window * w[c_out]) + b[c_out]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def max_pool(self, x, size=2):\n",
    "        \"\"\"æœ€å¤§æ± åŒ–\"\"\"\n",
    "        C, H, W = x.shape\n",
    "        out_h, out_w = H // size, W // size\n",
    "        output = np.zeros((C, out_h, out_w))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    window = x[c, i*size:(i+1)*size, j*size:(j+1)*size]\n",
    "                    output[c, i, j] = np.max(window)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: è¾“å…¥å›¾åƒ, shape (1, 28, 28)\n",
    "        \n",
    "        è¿”å›:\n",
    "            logits: æœªå½’ä¸€åŒ–çš„ç±»åˆ«åˆ†æ•°, shape (10,)\n",
    "        \"\"\"\n",
    "        # Conv1 â†’ ReLU â†’ Pool\n",
    "        x = self.conv2d(x, self.conv1_w, self.conv1_b)  # (8, 28, 28)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)  # (8, 14, 14)\n",
    "        \n",
    "        # Conv2 â†’ ReLU â†’ Pool\n",
    "        x = self.conv2d(x, self.conv2_w, self.conv2_b)  # (16, 14, 14)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)  # (16, 7, 7)\n",
    "        \n",
    "        # å±•å¹³\n",
    "        x = x.flatten()  # (784,) ä½†æˆ‘ä»¬è®¾è®¡ä¸º (400,)\n",
    "        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…å°ºå¯¸å¯èƒ½ä¸åŒ\n",
    "        \n",
    "        # FC1 â†’ ReLU\n",
    "        x = x[:400]  # æˆªæ–­åˆ° 400\n",
    "        x = x @ self.fc1_w + self.fc1_b\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # FC2\n",
    "        x = x @ self.fc2_w + self.fc2_b\n",
    "        \n",
    "        return x\n",
    "\n",
    "# æµ‹è¯•\n",
    "cnn = SimpleCNN()\n",
    "dummy_input = np.random.randn(1, 28, 28)\n",
    "output = cnn.forward(dummy_input)\n",
    "print(f\"è¾“å…¥å½¢çŠ¶: {dummy_input.shape}\")\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "print(f\"è¾“å‡ºå€¼: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» PyTorch å®ç° CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    class MNISTNet(nn.Module):\n",
    "        \"\"\"\n",
    "        MNIST åˆ†ç±» CNN\n",
    "        \n",
    "        æ¶æ„:\n",
    "            Conv(1â†’32, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)\n",
    "            Conv(32â†’64, 3Ã—3) â†’ ReLU â†’ MaxPool(2Ã—2)\n",
    "            FC(1600â†’128) â†’ ReLU â†’ Dropout\n",
    "            FC(128â†’10)\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            # å·ç§¯å±‚\n",
    "            self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "            self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "            \n",
    "            # æ± åŒ–å±‚\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            \n",
    "            # å…¨è¿æ¥å±‚\n",
    "            # 28â†’14â†’7, æ‰€ä»¥å±•å¹³åæ˜¯ 64Ã—7Ã—7 = 3136\n",
    "            self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "            \n",
    "            # Dropout\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Conv1 â†’ ReLU â†’ Pool\n",
    "            x = self.pool(F.relu(self.conv1(x)))  # (N, 32, 14, 14)\n",
    "            \n",
    "            # Conv2 â†’ ReLU â†’ Pool\n",
    "            x = self.pool(F.relu(self.conv2(x)))  # (N, 64, 7, 7)\n",
    "            \n",
    "            # å±•å¹³\n",
    "            x = x.view(-1, 64 * 7 * 7)  # (N, 3136)\n",
    "            \n",
    "            # FC1 â†’ ReLU â†’ Dropout\n",
    "            x = self.dropout(F.relu(self.fc1(x)))  # (N, 128)\n",
    "            \n",
    "            # FC2\n",
    "            x = self.fc2(x)  # (N, 10)\n",
    "            \n",
    "            return x\n",
    "    \n",
    "    # æµ‹è¯•\n",
    "    model = MNISTNet()\n",
    "    dummy = torch.randn(4, 1, 28, 28)  # batch_size=4\n",
    "    out = model(dummy)\n",
    "    print(f\"è¾“å…¥å½¢çŠ¶: {dummy.shape}\")\n",
    "    print(f\"è¾“å‡ºå½¢çŠ¶: {out.shape}\")\n",
    "    \n",
    "    # æ‰“å°æ¨¡å‹ç»“æ„\n",
    "    print(\"\\næ¨¡å‹ç»“æ„:\")\n",
    "    print(model)\n",
    "    \n",
    "    # å‚æ•°é‡\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\næ€»å‚æ•°é‡: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æœ¬ç« å°ç»“\n",
    "\n",
    "### CNN æ¶æ„æ¨¡å¼\n",
    "\n",
    "```\n",
    "[Conv â†’ ReLU â†’ Pool] Ã— N â†’ Flatten â†’ [FC â†’ ReLU â†’ Dropout] Ã— M â†’ Output\n",
    "```\n",
    "\n",
    "### è®¾è®¡åŸåˆ™\n",
    "\n",
    "1. ç©ºé—´å°ºå¯¸é€æ¸å‡å°ï¼ˆé€šè¿‡æ± åŒ–æˆ– stride=2ï¼‰\n",
    "2. é€šé“æ•°é€æ¸å¢åŠ ï¼ˆ32 â†’ 64 â†’ 128 â†’ ...ï¼‰\n",
    "3. æœ€åç”¨å…¨è¿æ¥æˆ–å…¨å±€å¹³å‡æ± åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç»§ç»­å­¦ä¹  **06_cnn_backprop.ipynb** - CNN åå‘ä¼ æ’­"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
