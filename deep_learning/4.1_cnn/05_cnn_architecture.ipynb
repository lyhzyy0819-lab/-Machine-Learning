{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 CNN 网络架构\n",
    "\n",
    "> 深入理解 CNN 的每一层：Conv、ReLU、Pool、Flatten、FC、Dropout、Softmax\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 学习目标\n",
    "\n",
    "在本章结束后，你将能够：\n",
    "\n",
    "- [ ] 理解 CNN 各层的作用和原理\n",
    "- [ ] 理解**全连接层 (FC)** 是什么\n",
    "- [ ] 理解为什么需要 **Flatten**\n",
    "- [ ] 理解 **ReLU、Dropout、Softmax** 的作用\n",
    "- [ ] 追踪特征图形状变化\n",
    "- [ ] 用 PyTorch 构建完整 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 前置知识\n",
    "\n",
    "请确保已完成：\n",
    "\n",
    "- ✅ **03_convolution_from_scratch.ipynb** - 理解卷积操作\n",
    "- ✅ **04_pooling_layers.ipynb** - 理解池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 尝试导入 PyTorch\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    HAS_TORCH = True\n",
    "    print(\"PyTorch 已导入\")\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\"PyTorch 未安装，部分代码无法运行\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💡 1. CNN 架构概述\n",
    "\n",
    "### CNN 的标准架构\n",
    "\n",
    "```\n",
    "输入图像 (1, 28, 28)\n",
    "    ↓\n",
    "┌─────────────────────────────────────┐\n",
    "│  特征提取部分（学习\"看什么\"）          │\n",
    "│                                     │\n",
    "│  Conv → ReLU → Pool                 │\n",
    "│  Conv → ReLU → Pool                 │\n",
    "│  ...                                │\n",
    "└─────────────────────────────────────┘\n",
    "    ↓\n",
    "  Flatten（3D → 1D）\n",
    "    ↓\n",
    "┌─────────────────────────────────────┐\n",
    "│  分类部分（学习\"怎么判断\"）           │\n",
    "│                                     │\n",
    "│  FC → ReLU → Dropout               │\n",
    "│  FC → Softmax                      │\n",
    "└─────────────────────────────────────┘\n",
    "    ↓\n",
    "  输出（类别概率）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🏭 工厂流水线比喻\n",
    "\n",
    "把 CNN 想象成一个工厂流水线：\n",
    "\n",
    "| 层 | 角色 | 工作内容 |\n",
    "|---|---|---|\n",
    "| **卷积层 (Conv)** | 特征检测员 | 发现边缘、颜色、纹理等特征 |\n",
    "| **ReLU** | 过滤器 | 只保留\"有用\"的信号（正值） |\n",
    "| **池化层 (Pool)** | 压缩员 | 把信息压缩，保留重要的，扔掉冗余 |\n",
    "| **Flatten** | 汇总员 | 把所有检测结果摊开成一张清单 |\n",
    "| **全连接层 (FC)** | 决策者 | 综合所有信息做最终判断 |\n",
    "| **Dropout** | 抽查员 | 随机关闭一些神经元，防止\"死记硬背\" |\n",
    "| **Softmax** | 概率转换器 | 把分数变成\"有多大把握是这个类别\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 2. CNN 各层详解\n",
    "\n",
    "### 2.1 卷积层 (Conv) - 特征检测器\n",
    "\n",
    "前面已经学过，这里简单回顾：\n",
    "\n",
    "```\n",
    "作用：用小滤波器扫描图像，检测局部特征\n",
    "\n",
    "输入：(C_in, H, W)   例如 (1, 28, 28)\n",
    "输出：(C_out, H', W') 例如 (32, 28, 28)\n",
    "\n",
    "关键参数：\n",
    "  - in_channels：输入通道数\n",
    "  - out_channels：输出通道数（滤波器数量）\n",
    "  - kernel_size：核大小（如 3x3）\n",
    "  - padding：填充（same padding 用 1）\n",
    "  - stride：步幅（默认 1）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ReLU 激活函数 - 引入非线性\n",
    "\n",
    "#### 为什么需要激活函数？\n",
    "\n",
    "**没有激活函数的问题：**\n",
    "\n",
    "```\n",
    "层1: y1 = W1 * x + b1\n",
    "层2: y2 = W2 * y1 + b2\n",
    "     y2 = W2 * (W1 * x + b1) + b2\n",
    "     y2 = (W2 * W1) * x + (W2 * b1 + b2)\n",
    "     y2 = W' * x + b'   <-- 还是线性变换！\n",
    "\n",
    "无论多少层，都只能表示线性关系！\n",
    "但现实世界的问题（图像分类）是非线性的。\n",
    "```\n",
    "\n",
    "#### ReLU 是什么？\n",
    "\n",
    "```\n",
    "ReLU(x) = max(0, x)\n",
    "\n",
    "  输入 x < 0  -->  输出 0\n",
    "  输入 x >= 0 -->  输出 x（不变）\n",
    "```\n",
    "\n",
    "**图示：**\n",
    "```\n",
    "     y |\n",
    "       |      /\n",
    "       |     /\n",
    "       |    /\n",
    "-------+---/-------> x\n",
    "       |  0\n",
    "       |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyh/miniconda3/envs/ml_env/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 28608 (\\N{CJK UNIFIED IDEOGRAPH-6FC0}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/lyh/miniconda3/envs/ml_env/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 27963 (\\N{CJK UNIFIED IDEOGRAPH-6D3B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/lyh/miniconda3/envs/ml_env/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 20989 (\\N{CJK UNIFIED IDEOGRAPH-51FD}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/lyh/miniconda3/envs/ml_env/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAGJCAYAAACZ7rtNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNMUlEQVR4nO3dd3wUdf7H8fcmIYWSUEyhBKSJIh0EAhxF0YCIxhKxICDl0AMVURA8RdHT6CGChWYjnopUKT8FlGJApCgREFA4QRApIaElIZCEZOb3x1wCKyEkYbOTTV7Px2Mfd9/Z2ZnPftyEN1++O+MwTdMUAAAA4IG87C4AAAAAKCrCLAAAADwWYRYAAAAeizALAAAAj0WYBQAAgMcizAIAAMBjEWYBAADgsQizAAAA8FiEWQAAAHgswiwAAAA8FmEWAPIRGxsrh8OR+/Dx8VHNmjU1YMAAHTp0qEjHjIuLk8Ph0Pz58y+5j8Ph0PDhw/N8bv78+XI4HIqLiyvS+QGgNPGxuwAA8AQvvfSS6tatq/T0dG3cuFGxsbFat26dduzYIX9/f7vLu8jOnTvVsmVL+fr65vl8Zmamfv31V6Wnp9uyX/369Yv2xgDgLwizAFAAPXv2VJs2bSRJgwcP1lVXXaXXX39dS5Ys0b333mtzdRczTVNt27bVunXr8ny+ffv2Mk3Ttv0AwFVYZgAARfC3v/1NkrR3716n7bt27dI999yjqlWryt/fX23atNGSJUvsKBEAygTCLAAUwf79+yVJVapUyd22c+dOtW/fXr/++qvGjBmjiRMnqkKFCoqKitLChQttqhQASjeWGQBAASQnJ+vYsWNKT0/Xpk2bNH78ePn5+em2227L3eeJJ55Q7dq19eOPP8rPz0+S9I9//EOdOnXSM888ozvvvNOu8gGg1GJmFgAKoHv37goODlZ4eLjuueceVahQQUuWLFGtWrUkSSdOnNDq1at17733KjU1VceOHdOxY8d0/PhxRUZG6rfffivy1Q8AAJfGzCwAFMCUKVN0zTXXKDk5WR999JHWrl2bO/sqSXv27JFpmnr++ef1/PPP53mMxMRE1axZ02U1ORwOlx0LADwVYRYACqBt27a5VzOIiopSp06d9MADD2j37t2qWLGiDMOQJD399NOKjIzM8xgNGjQo8Pn8/Px09uzZPJ87c+aMJJXIS4IBgLsRZgGgkLy9vRUTE6Nu3brp3Xff1ZgxY1SvXj1JUrly5dS9e/crPkedOnW0e/fuPJ/L2V6nTp0rPg8AeDrWzAJAEXTt2lVt27bV5MmTlZ6erpCQEHXt2lUzZszQkSNHLto/KSmpUMe/9dZbtXHjRsXHxzttP3XqlD777DO1aNFCYWFhV/QeAKA0YGYWAIpo1KhRio6OVmxsrB555BFNmTJFnTp1UtOmTTVkyBDVq1dPR48e1YYNG3Tw4EFt27bN6fULFizQrl27Ljpu//79NWbMGM2bN0+dO3fW0KFDde211+rw4cOKjY3VkSNHNHPmTHe9TQAo0QizAFBEd911l+rXr6833nhDQ4YMUePGjbV582aNHz9esbGxOn78uEJCQtSyZUuNGzfuotfPnj07z+N27dpVnTp10qZNm/Tiiy9q7ty5Onr0qAIDA9WhQwfNmTNH7dq1K+63BwAegTALAPkYMGCABgwYkOdzXl5e2rNnj9O2evXq6eOPP873mF27di3QLV1r1qyp999/v8C1AkBZxJpZAAAAeCxmZgGglNq4caMqV66c53OnT5+2fT8AcAWHWZB/6wIAAABKIJYZAAAAwGMRZgEAAOCxCLMAAADwWGXuC2CGYejw4cOqVKmSHA6H3eUAAADgL0zTVGpqqmrUqCEvr/znXstcmD18+LDCw8PtLgMAAACX8eeff6pWrVr57lPmwmylSpUkWc0JDAws9vMZhqGkpCQFBwdf9m8WcB36bg/6bg/DMHT33XdrwYIF9N2N+Lzbg77bw919T0lJUXh4eG5uy0+ZC7M5SwsCAwPdFmbT09MVGBjID50b0Xd70Hd7GIYhHx8f+u5mfN7tQd/tYVffC7IklE8BAAAAPBZhFgAAAB6LMAsAAACPVebWzBaEaZrKyspSdnb2FR/LMAydO3dO6enprO1xI/peOOXKlZO3t7fdZQAAUGiE2b/IzMzUkSNHdObMGZcczzRNGYah1NRUrmvrRvS9cBwOh2rVqqWKFSvaXQoAAIVCmL2AYRjat2+fvL29VaNGDfn6+l5xEMqZ5fXx8SFUuRF9LzjTNJWUlKSDBw+qYcOGzNACADwKYfYCmZmZMgxD4eHhKl++vEuOSaiyB30vnODgYO3fv1/nzp0jzAIAPIqtiwmnTZumZs2a5V7zNSIiQsuWLcv3NfPmzdO1114rf39/NW3aVEuXLnV5XayxRFlD4AcAeCpbU1utWrX02muvKT4+Xps3b9aNN96oO+64Qzt37sxz//Xr1+v+++/XoEGDtGXLFkVFRSkqKko7duxwc+UAAABlR3a2dPp0yZz4sDXM9u7dW7feeqsaNmyoa665Rq+88ooqVqyojRs35rn/W2+9pR49emjUqFG67rrr9PLLL6tVq1Z699133Vw5AABA2ZCdLQ0Y4FCfPlWUnGx3NRcrMWtms7OzNW/ePKWlpSkiIiLPfTZs2KCRI0c6bYuMjNSiRYsuedyMjAxlZGTkjlNSUiRZX/YyDMNpX8MwZJpm7sNVco7lymOWdB9++KHmzp2rr7/+ukD7L1++XGPHjlV8fLzLlnmUxL4///zzOnr0qN577z23nTMzM1ONGjXSvHnz1KZNmzz3yfnM5/VzURg5P0NXcgwUHn23B323B313r6wsK8h+/rlDkq/uuMPUt98aKu7VaYX572t7mN2+fbsiIiKUnp6uihUrauHChWrcuHGe+yYkJCg0NNRpW2hoqBISEi55/JiYGI0fP/6i7UlJSUpPT3fadu7cORmGoaysLGVlZRXh3VzMNM3c69UW57rEQYMG6ZNPPpEk+fj4qFatWrrrrrv04osvyt/fv0DH2L9/v6655hr98MMPatGihdNza9as0c0336zExERVrlzZ6bmGDRvqscce0+OPPy5JSk9P17hx4/T5558XuI/du3fX888/r//85z/q27dvgV6TH3f1vTASEhL09ttv66effnLqy7Rp0/Tmm28qISFBzZo10+TJk3XDDTe47LxeXl568skn9cwzz1zyLxdZWVkyDEPHjx9XuXLlinwuwzCUnJws0zRZe+5GOb+3EhMT6bsb8Xm3B313n6ws6fHHg7RwYYAkycfH1MMPn1RSUmaxnzs1NbXA+9oeZhs1aqStW7cqOTlZ8+fPV//+/bVmzZpLBtrCGjt2rNNsbkpKisLDwxUcHKzAwECnfdPT05WamiofHx/5+Li2NVcSEArCy8tLPXr00EcffaRz584pPj5eAwYMkLe3t15//fUCHSPnPef1/nO+4X6p3nh5eeVuX7RokQIDA9W5c+dCvYcBAwZo6tSpGjBgQKFel5/i7nthxMbGqkOHDqpfv37utjlz5mjUqFGaNm2a2rVrp8mTJ6tXr17atWuXQkJCXHbuhx56SKNHj9bu3bt1/fXXX/S8j4+PvLy8VK1atQL/5ScvhmHI4XAoODiYP2TcyDAM+fj4KCQkhL67EZ93e9B398jKkvr1c2jhQmtCqFw5U++/f1IPPhjolr4X5s8i2z8Fvr6+atCggVq3bq2YmBg1b95cb731Vp77hoWF6ejRo07bjh49qrCwsEse38/PL/dqCTkPyQpfeT0cDodLH5Kc/re4HjnvtXr16qpdu7buvPNOde/eXStXrszdxzRNvfbaa6pXr57Kly+vFi1aaMGCBXnWm997udz2OXPmqHfv3rnjjIwMNWnSREOHDs3d9vvvvyswMFAzZ87M3Xb77bdr8+bN+v3334ut7w8//LDuvPNOxcTEKCwsTFWqVNHLL7+s7OxsjR49WtWqVVN4eLhiY2OdXjdmzBg1atRIFSpUUP369TVu3DhlZWXlnuPmm29Wjx49cs938uRJhYeH64UXXrhkXxwOhyZNmqQhQ4Zo4MCBuv766zVjxgyVL1/eqS+Xe7z88suqWbOmTpw4kbvttttu04033ijTNOVwOFS1alV17NhRc+bMyfdYl/q5KMzDVcfhQd894UHf6XtpfBiGlx56yEtz5jj+l9Wk+fNNRUZmurWOgrJ9ZvavDMNwWuN6oYiICK1atUojRozI3bZixYpLrrF1lTZtpHxWMhRA0docFiZt3ly0M+7YsUPr169XnTp1crfFxMTo008/1fTp09WwYUOtXbtWffv2VXBwsLp06VK0E+Vh3bp1euihh3LH/v7++uyzz9SuXTv16tVLt912m/r27aubb75ZAwcOzN2vdu3aCg0N1Xfffec0e3mhzz77TEOHDs33/MuWLVOnTp0u+fzq1atVq1YtrV27Vt9//70GDRqk9evXq3Pnztq0aZPmzJmjoUOH6uabb1atWrUkSZUqVVJsbKxq1Kih7du3a8iQIapUqZJGjx4th8Ohjz/+WE2bNtXbb7+tJ554Qo888ohq1qypcePGSZJOnDihX375xWnNamZmpuLj4zV27NjcbV5eXurevbs2bNiQ73u80D//+U8tX75cgwcP1sKFCzVlyhStX79e27Ztc/pl0LZtW3333XcFPi4AoOw5d0568EFp3jxr7OsrffGF1LOnlJhob22XYmuYHTt2rHr27KnatWsrNTVVs2bNUlxcXO66vn79+qlmzZqKiYmRJD3xxBPq0qWLJk6cqF69emn27NnavHlzsX+ZJiFBOnSoqK9233rNL7/8UhUrVlRWVpYyMjLk5eWVe6WHjIwMvfrqq1q5cmVu+K9Xr57WrVunGTNmuCzMnjp1SsnJyapRo4bT9hYtWuhf//qXBg8erPvuu09//PGHvvzyy4teX6NGDf3xxx+XPP7tt9+udu3a5VtDzZo1832+atWqevvtt+Xl5aVGjRrp3//+t86cOaNnn31WkvW5fO2117Ru3Trdd999kqTnnnsu9/VXX321nn76ac2ePVujR4/OPeeMGTPUr18/JSQkaOnSpdqyZUvu0osDBw7INE2nvhw7dkzZ2dl5rgPftWtXvu/hQt7e3vr000/VokULjRkzRm+//bY++OAD1a5d22m/y/UWAFC2nTsn3X+/tGCBNfb1lRYulG69VSrJ37ezNcwmJiaqX79+OnLkiIKCgtSsWTN9/fXXuvnmmyVZAeDCmaUOHTpo1qxZeu655/Tss8+qYcOGWrRokZo0aVKsdeaziqEALvwmfeGCbWHP261bN02bNk1paWmaNGmSfHx8dPfdd0uS9uzZozNnzuT2NkdmZqZatmxZuBPl4+zZs5LyXuvy1FNPadGiRXr33Xe1bNkyVatW7aJ9AgICdObMmUsev1KlSqpUqdJl68jvCgbXX3+90+cqNDTU6TPk7e2tatWqKfGCv4LOmTNHb7/9tvbu3avTp08rKyvrojXX0dHRWrhwoV577TVNmzZNDRs2zH0uv764Qr169fTGG29o6NCh6tOnjx544IGL9rlcbwEAZde5c9J991mzsJLk5yctWiT9bwVdiWZrmP3www/zfT4uLu6ibdHR0YqOji6mivJW1H/qlyTT1AW3VXVdTXmpUKGCGjRoIEn66KOP1Lx5c3344YcaNGiQTp8+LUn66quvLpq59PPzu+yxc4JbcnLyRVczOHXqlIKCgiRJ1apVy10z+leJiYn673//K29vb/3222+5a0wvdOLECQUHB1+yDlcsM/jrl8IcDkee23IuC7JhwwY9+OCDGj9+vCIjIxUUFKTZs2dr4sSJTq85c+aM4uPjc9/fha666ipJ0smTJ3Pf31VXXSVvb+9CrwO/lLVr18rb21v79+/P/cxd6HK9BQCUTZmZVpBduNAa+/lJixdLkZH21lVQtn8BDMXDy8tLzz77rJ577jmdPXtWjRs3lp+fnw4cOKAGDRo4PcLDwy97vIYNG8rLy0vx8fFO23///XclJyfrmmuukWR9oa9x48b65ZdfLjrGwIED1bRpU3388cd65pln9Ouvvzo9n56err179+Y7U3z77bdr69at+T4udS3VospZe/zPf/5Tbdq0UcOGDfP85/qnnnpKXl5eWrZsmd5++22tXr0697n69esrMDDQqS++vr5q3bq1Vq1albvNMAytWrWq0OvA58yZoy+++EJxcXE6cOCAXn755Yv22bFjh0tn4QEAni8zU7r33vNB1t9fWrLEc4KsVAK/AAbXiY6O1qhRozRlyhQ9/fTTevrpp/Xkk0/KMAx16tRJycnJ+v777xUYGKj+/fvnvm737t0XHev666/X4MGD9dRTT8nHx0dNmzbVn3/+qWeeeUbt27dXhw4dcveNjIzUunXrnL6oN2XKFG3YsEE///yzwsPD9dVXX+nBBx/Uxo0b5evrK0nauHGj/Pz88g1yrlhmUFgNGzbUgQMHNHv2bN1www366quvtDDnp/5/vvrqK3300UfasGGDWrVqpVGjRql///76+eefVaVKldwvdq1bt05RUVG5rxs5cqT69++vNm3aqG3btpo8ebLS0tL08MMPF7i+gwcP6tFHH9Xrr7+uTp06aebMmbrtttvUs2dPtW/fPne/7777Ls+QCwAomzIzpehoK7xK54PsX1YklnxmGZOcnGxKMpOTky967uzZs+Yvv/xinj171mXnMwzDzMzMNA3DcNkx89K/f3/zjjvuuGh7TEyMGRwcbJ4+fdo0DMOcPHmy2ahRI7NcuXJmcHCwGRkZaa5Zs8Y0TdPct2+fKWuR70WPP//80zx79qz5wgsvmNdee60ZEBBg1q1b1/z73/9uJiUlOZ1z586dZkBAgHnq1CnTNE3z119/NQMCAsxZs2bl7nPy5EkzPDzcHD16dO62v//97+bQoUNd0o9L9T2vPnXp0sV84oknnLbVqVPHnDRpUu541KhRZrVq1cyKFSuaffr0MSdNmmQGBQWZpmmaiYmJZmhoqPnqq6/m7p+ZmWm2bt3avPfee3O3LV261KxZs6aZnZ3tdK533nnHrF27tunr62u2bdvW3Lhx40U1d+nS5ZLv86abbjIjIyOd3utjjz1m1q9f30xNTTVN0zTXr19vVq5c2Txz5kyex3HVZz87O9s8cuTIRe8RxSs7O9u85ZZb6Lub8Xm3B313jfR00+zd2zStBZGmGRBgmitXXnp/d/c9v7z2Vw7TLEH3+nSDlJQUBQUFKTk5Oc+bJuzbt09169Z12Rd1TNO8YM1sybgTlTtER0erVatWTpedys+xY8fUqFEjbd68WXXr1r3i85fEvpumqXbt2unJJ5/U/fffX+DXdenSRd26ddOLL75Y5HP36dNHzZs3z71iw1+56rNvGIYSExO5eL+bGYahnj17atmyZfTdjfi824O+X7mMDOmee6SciwoFBFj//8YbL/0ad/c9v7z2V3wKUCwmTJigihUrFnj//fv3a+rUqS4JsiWVw+HQe++9V6hbJScnJ2vv3r16+umni3zezMxMNW3aVE8++WSRjwEAKB3S06W77nIOsl99lX+QLelYM4ticfXVV+uxxx4r8P5t2rRx+Re3SqIWLVqoRYsWBd4/KChIBw8evKJz+vr6Ol0nFwBQNuUE2WXLrHH58laQ7drV1rKuGGEWAACglEtPl+68U1q+3BpXqCAtXSp17mxvXa5AmAUAACjFzp6VoqKkb76xxhUqWLOzf/ubrWW5DGE2D2XsO3EAn3kAKKXOnpXuuENascIal7YgK/EFMCc5d4Hilp8oazIzMyVZt/IFAJQOZ85It99+PshWrGgtMyhNQVZiZtaJt7e3KleurMTERElS+fLlr/iyTiXxElFlAX0vOMMwlJSUpPLly190C1wAgGfKCbI5N5nMCbIdO9pbV3HgT66/CAsLk6TcQHulTNOUYRjy8vIiVLkRfS8cLy8v1a5dm14BQCmQlib17i19+601rlTJCrIX3KyzVCHM/oXD4VD16tUVEhKic+fOXfHxDMPQ8ePHVa1aNS7u7Eb0vXB8fX3pEwCUAmlp0m23SXFx1jgwUPr6a+mCu5uXOoTZS/D29nbJ+kHDMFSuXDn5+/sTFtyIvgMAypq0NKlXL2nNGmscGGhdwaBdO3vrKm78KQ8AAODhTp+Wbr31fJANCrK++FXag6zEzCwAAIBHywmy331njStXtoJsGbixpiRmZgEAADxWaqrUs2fZDbISM7MAAAAeKSfIfv+9Na5SRVq5UmrVyt663I2ZWQAAAA+TkiL16HE+yFatal1TtqwFWYmZWQAAAI+SnGzNyG7YYI1zgmyLFraWZRvCLAAAgIdITpYiI6VNm6xxtWpWkG3e3N667MQyAwAAAA9w6pR0yy0E2b9iZhYAAKCEywmyP/5oja+6ygqyzZrZWlaJQJgFAAAowU6etILs5s3WODhYWr1aatLE3rpKCsIsAABACXXypHTzzVJ8vDUmyF6MMAsAAFACnTghde8ubdlijUNCrCB7/fX21lXS8AUwAACAEub4cemmm84H2dBQ6dtvCbJ5YWYWAACgBDl+3JqR3brVGucE2euus7WsEouZWQAAgBLi2DFrRjYnyIaFSXFxBNn8MDMLAABQAuQE2Z9/tsbVq1szso0a2VtXScfMLAAAgM2SkqQbbzwfZGvUsGZkCbKXx8wsAACAjRITrRnZHTuscU6QbdjQ1rI8BjOzAAAANklMtGZkc4JszZoE2cIizAIAANjg6FGpWzdp505rXKsWQbYoCLMAAABulpBgBdlffrHG4eFWkG3QwNayPJKtYTYmJkY33HCDKlWqpJCQEEVFRWn37t35viY2NlYOh8Pp4e/v76aKAQAArsyRI1aQ/fVXa1y7thVk69e3tSyPZWuYXbNmjYYNG6aNGzdqxYoVOnfunG655RalpaXl+7rAwEAdOXIk9/HHH3+4qWIAAICiywmyu3ZZ4zp1rCBbr56tZXk0W69msHz5cqdxbGysQkJCFB8fr86dO1/ydQ6HQ2FhYcVdHgAAgMscPmwF2f/+1xrnBNmrr7azKs9Xoi7NlZycLEmqWrVqvvudPn1aderUkWEYatWqlV599VVdf4mbFWdkZCgjIyN3nJKSIkkyDEOGYbio8kszDEOmabrlXDiPvtuDvtuDvtuDvtvDU/t+6JB0000O/fabQ5J09dWmVq82Vbu25Alvxd19L8x5SkyYNQxDI0aMUMeOHdWkSZNL7teoUSN99NFHatasmZKTk/XGG2+oQ4cO2rlzp2rVqnXR/jExMRo/fvxF25OSkpSenu7S95AXwzCUnJws0zTl5cX37dyFvtuDvtvDMAxlZWUpMTGRvrsRn3d7eGLfDx/20j33VNW+fVbsql07S/PmnVBAgKHERJuLKyB39z01NbXA+zpM0zSLsZYCe/TRR7Vs2TKtW7cuz1B6KefOndN1112n+++/Xy+//PJFz+c1MxseHq6TJ08qMDDQJbXnxzAMJSUlKTg42GN+6EoD+m4P+m4PwzB06623aunSpfTdjfi828PT+v7nn9aM7N691oxsvXqmVq2yZmQ9ibv7npKSoipVqig5Ofmyea1EzMwOHz5cX375pdauXVuoICtJ5cqVU8uWLbVnz548n/fz85Ofn99F2728vNz2Q+BwONx6Pljouz3ouz3ouz3ouz08pe9//mndEOH3361x/frSt986FB7usLewInJn3wtzDls/BaZpavjw4Vq4cKFWr16tunXrFvoY2dnZ2r59u6pXr14MFQIAABTegQNS167OQTYuzrqeLFzL1pnZYcOGadasWVq8eLEqVaqkhIQESVJQUJACAgIkSf369VPNmjUVExMjSXrppZfUvn17NWjQQKdOndKECRP0xx9/aPDgwba9DwAAgBx//GFdtWDfPmvcsKH07bfWrWrheraG2WnTpkmSunbt6rR95syZGjBggCTpwIEDTlPNJ0+e1JAhQ5SQkKAqVaqodevWWr9+vRo3buyusgEAAPK0f78VZPfvt8YE2eJna5gtyHfP4uLinMaTJk3SpEmTiqkiAACAotm3zwqyOfdyuuYaK8jWqGFvXaVdyV45DQAA4AF+/91aI5sTZBs1stbIEmSLX4m4mgEAAICnygmyf/5pja+91pqR5Wal7sHMLAAAQBHt3St16XI+yF53HUHW3QizAAAARbBnjxVkDx60xo0bE2TtQJgFAAAopN9+s5YWHDpkja+/3gqyoaG2llUmEWYBAAAK4a9BtkkTafVqKSTE1rLKLMIsAABAAf33v9bSgsOHrXHTpgRZuxFmAQAACmD3bmtG9sgRa9ysmRVkg4NtLavMI8wCAABcxq5dzkG2eXMryF51la1lQYRZAACAfP36qxVkExKscYsW0qpVUrVqdlaFHIRZAACAS/jlF+sWtUePWuOWLQmyJQ1hFgAAIA87dzoH2VatpJUrpapV7a0LzgizAAAAf7FjhxVkExOtcevWBNmSijALAABwge3bpRtvlJKSrPENN1hBtkoVe+tC3gizAAAA//Pzz85Btm1b6ZtvpMqVbS0L+fCxuwAAAICSYNs26aabpOPHrXFOkA0Ksrcu5I+ZWQAAUOZt3eocZNu3J8h6CsIsAAAo07ZscQ6yERHS118TZD0FYRYAAJRZP/1kBdkTJ6xxhw7S8uVSYKC9daHgCLMAAKBMio+XuneXTp60xh07EmQ9EWEWAACUOZs3OwfZTp2kZcukSpXsrQuFR5gFAABlyo8/WkH21Clr/Le/EWQ9GWEWAACUGT/8IN18s5ScbI07d5aWLpUqVrS3LhQdYRYAAJQJmzY5B9muXQmypQFhFgAAlHobN0q33CKlpFjjbt2kL7+UKlSwty5cOcIsAAAo1davdw6yN95IkC1NCLMAAKDU+v57KTJSSk21xjfdJP3f/0nly9tbF1yHMAsAAEqldeukHj2k06etcffu0pIlBNnShjALAABKne++cw6yN99MkC2tCLMAAKBUWbtW6tlTSkuzxpGR0uLFUkCAvXWheBBmAQBAqbFmjXOQ7dFDWrSIIFuaEWYBAECpEBcn3XqrdOaMNb71VmnhQsnf39ayUMwIswAAwOOtXu0cZHv1kr74giBbFhBmAQCAR1u1SrrtNunsWWt8223SggWSn5+9dcE9CLMAAMBjrVzpHGRvv12aP58gW5YQZgEAgEdasULq3VtKT7fGd9whzZtHkC1rbA2zMTExuuGGG1SpUiWFhIQoKipKu3fvvuzr5s2bp2uvvVb+/v5q2rSpli5d6oZqAQBASfH119YsbE6QvfNOae5cydfX3rrgfraG2TVr1mjYsGHauHGjVqxYoXPnzumWW25RWs71NPKwfv163X///Ro0aJC2bNmiqKgoRUVFaceOHW6sHAAA2GX1al/deacjN8jedZc0Zw5BtqzysfPky5cvdxrHxsYqJCRE8fHx6ty5c56veeutt9SjRw+NGjVKkvTyyy9rxYoVevfddzV9+vRirxkAANhn2TJp4MAqyshwSJLuvlv6/HOpXDmbC4NtbA2zf5WcnCxJqlq16iX32bBhg0aOHOm0LTIyUosWLcpz/4yMDGVkZOSOU1JSJEmGYcgwjCus+PIMw5Bpmm45F86j7/ag7/ag7/ag7+63dKl0990OZWZaQfaee0x9+qkpb2+J/wzFy92f98Kcp8SEWcMwNGLECHXs2FFNmjS55H4JCQkKDQ112hYaGqqEhIQ894+JidH48eMv2p6UlKT0nH+fKEaGYSg5OVmmacrLi+/buQt9twd9t4dhGMrKylJiYiJ9dyM+7+61cqWfBg2qnBtke/c+qzffTNbJkzYXVka4+/Oemppa4H1LTJgdNmyYduzYoXXr1rn0uGPHjnWayU1JSVF4eLiCg4MVGBjo0nPlxTAMORwOBQcH88vOjei7Pei7PQzDkI+Pj0JCQui7G/F5d58vv5QGDnTo3DkryN5xx1nNnl1Ovr4hNldWdrj78+5fiLtdlIgwO3z4cH355Zdau3atatWqle++YWFhOnr0qNO2o0ePKiwsLM/9/fz85JfHNTq8vLzc9svH4XC49Xyw0Hd70Hd70Hd70Pfit2SJdM890rlz1vi++0xNmJAsX1/+8uZu7vy8F+Yctn4KTNPU8OHDtXDhQq1evVp169a97GsiIiK0atUqp20rVqxQREREcZUJAABssHixc5B94AHp449N+ZSIqTiUFLZ+HIYNG6ZZs2Zp8eLFqlSpUu6616CgIAUEBEiS+vXrp5o1ayomJkaS9MQTT6hLly6aOHGievXqpdmzZ2vz5s167733bHsfAADAtRYulO69V8rKssYPPih9/LHkcNhbF0oeW2dmp02bpuTkZHXt2lXVq1fPfcyZMyd3nwMHDujIkSO54w4dOmjWrFl677331Lx5c82fP1+LFi3K90tjAADAc3zxhXOQfeghK8h6e9tbF0omW2dmTdO87D5xcXEXbYuOjlZ0dHQxVAQAAOw0f750331SdrY17tdP+ugjgiwujZXTAACgRPhrkO3fnyCLyyPMAgAA282d6xxkH35Y+vBDgiwujzALAABsNWeOdaWCnCA7cKD0wQcEWRQMYRYAANjm88+dg+zgwdL770tcQhYFxUcFAADYYtYsqW9fyTCs8ZAh0owZBFkUDh8XAADgdp9+al1yKyfI/v3v0vTpBFkUHh8ZAADgVp9+al2pICfIPvKING0aQRZFw8cGAAC4zccfW9eOzQmyjz4qTZ1KkEXR8dEBAABuERtrXXIr555J//iHNGUKt6jFlSHMAgCAYjdzpnXJrZwg+9hj0rvvEmRx5QizAACgWH34oTRo0Pkg+/jj0ltvEWThGoRZAABQbD74wLp2bE6QfeIJafJkgixchzALAACKxXvvWdeOzfHkk9KkSQRZuBZhFgAAuNyMGdLQoefHTz0lTZxIkIXrEWYBAIBLTZtmXTs2x6hR0oQJBFkUD8IsAABwmalTrUtu5Rg9Wnr9dYIsig9hFgAAuMS770rDhp0fjxkjvfYaQRbFy6eoL9y3b5++++47/fHHHzpz5oyCg4PVsmVLRUREyN/f35U1AgCAEu6dd6xLbuV49lnpX/8iyKL4FTrMfvbZZ3rrrbe0efNmhYaGqkaNGgoICNCJEye0d+9e+fv768EHH9QzzzyjOnXqFEfNAACgBHnrLWnEiPPjf/5Tevllgizco1BhtmXLlvL19dWAAQO0YMEChYeHOz2fkZGhDRs2aPbs2WrTpo2mTp2q6OholxYMAABKjkmTpJEjz4+fe0566SWCLNynUGH2tddeU2Rk5CWf9/PzU9euXdW1a1e98sor2r9//5XWBwAASqg337QuuZVj3DjpxRcJsnCvQoXZ/ILsX1WrVk3VqlUrdEEAAKDke+MN65JbOV54wQqygLsV+WoGsbGxeW7PysrS2LFji3pYAABQwk2Y4BxkX3yRIAv7FDnMPv7444qOjtbJkydzt+3evVvt2rXT559/7pLiAABAyfL669a1Y3O89JI1KwvYpchhdsuWLTp48KCaNm2qFStWaMqUKWrVqpWuvfZabdu2zZU1AgCAEiAmxrp2bI5//Ut6/nn76gGkK7jObP369fX9999rxIgR6tGjh7y9vfXxxx/r/vvvd2V9AACgBHj1VeuSWzleecW6lixgtyu6A9hXX32l2bNnKyIiQpUrV9aHH36ow4cPu6o2AABQArzyinOQjYkhyKLkKHKYHTp0qKKjo/XMM8/ou+++088//yxfX181bdpUc+fOdWWNAADAJi+/bF07NsfrrzsvNQDsVuRlBt9//702bdqk5s2bS5LCwsK0dOlSTZkyRQMHDtS9997rsiIBAID7/fXLXRMmSE8/bV89QF6KHGbj4+Pl5+d30fZhw4ape/fuV1QUAACw14svSuPHnx+/8YbzDRKAkqLIYTavIJujUaNGRT0sAACwkWlaQfall85ve/NN6cknbSsJyFeh1sz26NFDGzduvOx+qampev311zVlypQiFwYAANzLNK1lBRcG2UmTCLIo2Qo1MxsdHa27775bQUFB6t27t9q0aaMaNWrI399fJ0+e1C+//KJ169Zp6dKl6tWrlyZMmFBcdQMAABcyTeuasa+8cn7bW29Jjz9uX01AQRQqzA4aNEh9+/bVvHnzNGfOHL333ntKTk6WJDkcDjVu3FiRkZH68ccfdd111xVLwQAAwLVM07r0VkzM+W3vvCMNH25fTUBBFXrNrJ+fn/r27au+fftKkpKTk3X27FlVq1ZN5cqVc3mBAACg+JimNHasdcmtHO++Kw0bZl9NQGEU+QtgOYKCghQUFOSKWgAAgBuZpnXN2H//+/y2KVOkf/zDvpqAwip0mH377bfz3B4UFKRrrrlGERERBT7W2rVrNWHCBMXHx+vIkSNauHChoqKiLrl/XFycunXrdtH2I0eOKCwsrMDnBQCgrDNNafRo65JbOaZOlR591L6agKIodJidNGlSnttPnTql5ORkdejQQUuWLFHVqlUve6y0tDQ1b95cAwcO1F133VXgGnbv3q3AwMDccUhISIFfCwBAWWea0qhR0sSJ57dNny4NHWpfTUBRFTrM7tu375LP/f777+rbt6+ee+45TZ069bLH6tmzp3r27FnYEhQSEqLKlSsX+nUAAJR1pmnd/ODCuan33pOGDLGvJuBKXPGa2QvVq1dPr732mgYOHOjKw16kRYsWysjIUJMmTfTiiy+qY8eOl9w3IyNDGRkZueOUlBRJkmEYMgyjWOvMOY9pmm45F86j7/ag7/ag7/bwxL6bpjRypENvv+2QJDkcpmbMMDVokOQpb8MT+14auLvvhTmPS8OsJNWuXVsJCQmuPqwkqXr16po+fbratGmjjIwMffDBB+ratas2bdqkVq1a5fmamJgYjb/wfnz/k5SUpPT09GKp80KGYSg5OVmmacrLq1D3qMAVoO/2oO/2MAxDWVlZSkxMpO9u5Gmfd+s6spX04YcVJFlBduLEFPXufVaJiTYXVwie1vfSwt19T01NLfC+Lg+z27dvV506dVx9WEnWbXIvvFVuhw4dtHfvXk2aNEmffPJJnq8ZO3asRo4cmTtOSUlReHi4goODndbdFhfDMORwOBQcHMwPnRvRd3vQd3sYhiEfHx+FhITQdzfypM+7aUpPPOHQhx+en5H94ANTAwZUklTJ3uIKyZP6Xpq4u+/+/v4F3rfQYTbnn+n/Kjk5WfHx8XrqqafUv3//wh62yNq2bat169Zd8nk/Pz/5+fldtN3Ly8ttPwQOh8Ot54OFvtuDvtuDvtvDE/pumtJjj1lXKpAkh0OaOdOh/v0d9hZ2BTyh76WRO/temHMUOsxWrlxZDkfePwAOh0ODBw/WmDFjCnvYItu6dauqV6/utvMBAOApDMO6i9e0adbY4ZBiY6V+/WwtC3CpQofZb7/9Ns/tgYGBatiwofz9/ZWYmKgaNWpc9linT5/Wnj17csf79u3T1q1bVbVqVdWuXVtjx47VoUOH9J///EeSNHnyZNWtW1fXX3+90tPT9cEHH2j16tX65ptvCvs2AAAo1QzDuovX9OnW2MtL+vhj6X838ARKjUKH2S5duuT7/LZt29SqVStlZ2df9libN292uglCztrW/v37KzY2VkeOHNGBAwdyn8/MzNRTTz2lQ4cOqXz58mrWrJlWrlyZ540UAAAoqwzDuvnBe+9ZYy8v6T//kR580N66gOLg8i+AFUbXrl1lmuYln4+NjXUajx49WqNHjy7mqgAA8FyGYd384IMPrLGXl/TJJ9IDD9hbF1BcbA2zAADAdQxD+vvfpQ8/tMZeXtKnn0r3329vXUBxIswCAFAKGIY0eLA0c6Y19vaWPvtM6tPH3rqA4lboMPvzzz/n+/zu3buLXAwAACi87GwryOaszvP2lj7/XIqOtrUswC0KHWZbtGghh8OR51rXnO2XunQXAABwrexsadAg60oFkhVkZ8+W7rnH3roAdyl0mN23b19x1AEAAAopO1saONC6UoEk+fhYQfbuu+2tC3CnQofZ4rpVLQAAKLjsbGnAAOsLXpIVZOfOle6809ayALe7ovuRfffdd+rbt68iIiJ06NAhSdInn3yS7+1lAQDAlcnKsu7idWGQnTePIIuyqchhdsGCBYqMjFRAQIC2bNmijIwMSVJycrJeffVVlxUIAADOywmys2ZZ43LlpPnzpagoW8sCbFPkMPuvf/1L06dP1/vvv69y5crlbu/YsaN++uknlxQHAADOy8qybkf7+efWuFw5acEC6Y477K0LsFORrzO7e/dude7c+aLtQUFBOnXq1JXUBAAA/iIry7od7dy51tjX1wqyt91mb12A3Yo8MxsWFqY9e/ZctH3dunWqV6/eFRUFAADOO3fOuh3thUH2iy8IsoB0BWF2yJAheuKJJ7Rp0yY5HA4dPnxYn332mZ566ik9+uijrqwRAIAy69w563a08+ZZY19faeFCqVcve+sCSooiLzMYM2aMDMPQTTfdpDNnzqhz587y8/PTqFGjNHjwYFfWCABAmXTunHTffdYsrCT5+VlBtmdPe+sCSpIiz8w6HA7985//1IkTJ7Rjxw5t3LhRSUlJCgoKUt26dV1ZIwAAZU5mptSnj3OQXbyYIAv8VaHDbEZGhsaOHas2bdqoY8eOWrp0qRo3bqydO3eqUaNGeuutt/Tkk08WR60AAJQJmZnSvfdas7CS5O8vLVkiRUbaWxdQEhV6mcG4ceM0Y8YMde/eXevXr1d0dLQefvhhbdy4URMnTlR0dLS8vb2Lo1YAAEq9nCC7eLE19veX/u//pO7d7a0LKKkKHWbnzZun//znP7r99tu1Y8cONWvWTFlZWdq2bZscDkdx1AgAQJmQkSFFR1vhVZICAqz/f9NN9tYFlGSFDrMHDx5U69atJUlNmjSRn5+fnnzySYIsAABXICNDuvtu6auvrHFAgPTll9KNN9pbF1DSFTrMZmdny9fX9/wBfHxUsWJFlxYFAEBZkp5uBdmlS61xQIAVart1s7cuwBMUOsyapqkBAwbIz89PkpSenq5HHnlEFSpUcNrvi5yvXwIAgEtKT5fuuktatswaly9vBdmuXW0tC/AYhQ6z/fv3dxr37dvXZcUAAFCWpKdLUVHS119b4/LlrdnZLl1sLQvwKIUOszNnziyOOgAAKFPOnrWC7DffWOMKFawg27mzrWUBHqfIdwADAABFc/asdMcd0ooV1rhCBWuZwd/+Zm9dgCcq8h3AAABA4Z05I91++/kgW7GitHw5QRYoKmZmAQBwkzNnpN69pdWrrXFOkO3Y0d66AE/GzCwAAG6Qlibddtv5IFupkvXFL4IscGWYmQUAoJjlBNm4OGscGGgF2fbtbS0LKBUIswAAFKO0NKlXL2nNGmscGGhdwaBdO3vrAkoLlhkAAFBMTp+Wbr31fJANCrK++EWQBVyHmVkAAIpBaqoVZNets8Y5QfaGG+ytCyhtCLMAALhYaqrUs6f0/ffWuHJlK8i2aWNrWUCpxDIDAABcKCVF6tHjfJCtUkVauZIgCxQXZmYBAHCRnCC7YYM1zgmyrVrZWxdQmjEzCwCACyQnS5GR54Ns1arSqlUEWaC4MTMLAMAVygmymzZZ45wg26KFrWUBZYKtM7Nr165V7969VaNGDTkcDi1atOiyr4mLi1OrVq3k5+enBg0aKDY2ttjrBADgUk6dkm655XyQrVbNussXQRZwD1vDbFpampo3b64pU6YUaP99+/apV69e6tatm7Zu3aoRI0Zo8ODB+vrrr4u5UgAALpac7FCPHg798IM1vuoqK8g2b25vXUBZYusyg549e6pnz54F3n/69OmqW7euJk6cKEm67rrrtG7dOk2aNEmRkZHFVSYAABc5eVLq06eqtm1zSDofZJs2tbkwoIzxqDWzGzZsUPfu3Z22RUZGasSIEZd8TUZGhjIyMnLHKSkpkiTDMGQYRrHUeSHDMGSaplvOhfPouz3ouz3ou/udPCndcotD27aVkyQFB5taudLU9ddL/GcoXnze7eHuvhfmPB4VZhMSEhQaGuq0LTQ0VCkpKTp79qwCAgIuek1MTIzGjx9/0fakpCSlp6cXW605DMNQcnKyTNOUlxcXj3AX+m4P+m4PwzCUlZWlxMRE+u4GJ0861KdPVW3fbgXZq67K1rx5JxUSkqXERJuLKwP4PWMPd/c9NTW1wPt6VJgtirFjx2rkyJG545SUFIWHhys4OFiBgYHFfn7DMORwOBQcHMwPnRvRd3vQd3sYhiEfHx+FhITQ92J2/Lj0wAMObd9uLS0IDs7WypWmmjSpanNlZQe/Z+zh7r77+/sXeF+PCrNhYWE6evSo07ajR48qMDAwz1lZSfLz85Ofn99F2728vNz2Q+BwONx6Pljouz3ouz3oe/E7fty6asHWrdY4NNTU3Lkn1KRJNfruZnze7eHOvhfmHB4VZiMiIrR06VKnbStWrFBERIRNFQEAyoJjx6Tu3aVt26xxWJi0apWpqlWz7S0MgL2X5jp9+rS2bt2qrf/7a+6+ffu0detWHThwQJK1RKBfv365+z/yyCP6/fffNXr0aO3atUtTp07V3Llz9eSTT9pRPgCgDDh2TLrppvNBtnp1KS5OuvZaW8sC8D+2htnNmzerZcuWatmypSRp5MiRatmypcaNGydJOnLkSG6wlaS6devqq6++0ooVK9S8eXNNnDhRH3zwAZflAgAUi6Qk6cYbpZ9/tsY1alhBtlEjW8sCcAFblxl07dpVpmle8vm87u7VtWtXbdmypRirAgBASky0ZmR37LDGOUG2YUNbywLwF6ycBgDgL44elbp1Ox9ka9YkyAIlFWEWAIALHD1qLS345RdrXKsWQRYoyQizAAD8T0KCNSObE2TDw60g26CBrWUByAdhFgAASUeOWEH211+tce3aVpCtX9/WsgBchkddZxYAgOKQE2R377bGdepI334r1a1rb10ALo8wCwAo0w4ftoLsf/9rjevUsWZkr77azqoAFBTLDAAAZdahQ1LXrueD7NVXS2vWEGQBT0KYBQCUSQcPWkH2t9+scd26VpCtU8fWsgAUEmEWAFDm5ATZPXuscb161tKC2rXtrApAURBmAQBlyp9/WkF2715rXL8+QRbwZHwBDABQZhw4YH3Z6/ffrXFOkK1Vy9ayAFwBZmYBAGXCH39YM7I5QbZhQ4IsUBowMwsAKPX277dmZPfvt8YNG1rXka1Z086qALgCYRYAUKrt32/NyP7xhzW+5horyNaoYWdVAFyFZQYAgFJr3z6pS5fzQbZRI2tpAUEWKD0IswCAUun3360Z2QMHrPG111pBtnp1O6sC4GqEWQBAqbN3r3OQve46K8iGhdlZFYDiQJgFAJQqe/ZYQfbPP61x48bWGtnQUFvLAlBM+AIYAKDUyAmyhw5Z4+uvl1avlkJCbC0LQDFiZhYAUCr89pv1Za+cINukiTUjS5AFSjfCLADA4/33v9aM7OHD1rhpU2tGNjjY1rIAuAFhFgDg0Xbvdg6yzZoRZIGyhDALAPBYu3ZZQfbIEWvcvLm0apV01VW2lgXAjQizAACP9OuvVpBNSLDGLVoQZIGyiDALAPA4v/widesmHT1qjVu2tIJstWr21gXA/QizAACPsnOnc5Bt1UpauVKqWtXeugDYgzALAPAYO3ZYQTYx0Rq3bk2QBco6wiwAwCNs324F2aQka3zDDVaQrVLF3roA2IswCwAo8X7+WbrxRunYMWvctq30zTdS5cq2lgWgBCDMAgBKtG3bnINsu3YEWQDnEWYBACXW1q3STTdJx49b4/btpa+/loKCbC0LQAlCmAUAlEhbtjgH2YgIgiyAixFmAQAlzk8/WUH2xAlr3KGDtHy5FBhob10ASh7CLACgRImPl7p3l06etMYdOxJkAVwaYRYAUGJs3uwcZDt1kpYtkypVsrcuACUXYRYAUCL8+KMVZE+dssZ/+xtBFsDllYgwO2XKFF199dXy9/dXu3bt9MMPP1xy39jYWDkcDqeHv7+/G6sFALjaDz9YQTY52Rp36SItXSpVrGhvXQBKPtvD7Jw5czRy5Ei98MIL+umnn9S8eXNFRkYqMedehXkIDAzUkSNHch9//PGHGysGALjSpk3SzTdLKSnWuGtX6auvCLIACsb2MPvmm29qyJAhevjhh9W4cWNNnz5d5cuX10cffXTJ1zgcDoWFheU+QkND3VgxAMBVNmxwDrLdullBtkIFe+sC4Dl87Dx5Zmam4uPjNXbs2NxtXl5e6t69uzZs2HDJ150+fVp16tSRYRhq1aqVXn31VV1//fV57puRkaGMjIzcccr/fmMahiHDMFz0Ti7NMAyZpumWc+E8+m4P+m4PT+37+vXSrbc6lJrqkCTdeKOpxYtN+ftLnvBWPLXvno6+28PdfS/MeWwNs8eOHVN2dvZFM6uhoaHatWtXnq9p1KiRPvroIzVr1kzJycl644031KFDB+3cuVO1atW6aP+YmBiNHz/+ou1JSUlKT093zRvJh2EYSk5Olmma8vKyfSK8zKDv9qDv9jAMQ1lZWUpMTPSYvv/wQzk98EAVpaVZQbZz5wy9//5JnT4tnT5tc3EFxOfdHvTdHu7ue2pqaoH3tTXMFkVERIQiIiJyxx06dNB1112nGTNm6OWXX75o/7Fjx2rkyJG545SUFIWHhys4OFiBbrhooWEYcjgcCg4O5ofOjei7Pei7PQzDkI+Pj0JCQjyi7+vWSQ8+6MgNst27m1q0qJwCAkJsrqxw+Lzbg77bw919L8yX+20Ns1dddZW8vb119OhRp+1Hjx5VWFhYgY5Rrlw5tWzZUnv27MnzeT8/P/n5+V203cvLy20/BA6Hw63ng4W+24O+28NT+v7dd9Ktt0ppadb4llukRYscCghw2FtYEXlK30sb+m4Pd/a9MOew9VPg6+ur1q1ba9WqVbnbDMPQqlWrnGZf85Odna3t27erevXqxVUmAMAF1q6VevY8H2QjI6VFi6SAAFvLAuDhbF9mMHLkSPXv319t2rRR27ZtNXnyZKWlpenhhx+WJPXr1081a9ZUTEyMJOmll15S+/bt1aBBA506dUoTJkzQH3/8ocGDB9v5NgAA+VizxpqRPXPGGvfoIS1cKHGZcABXyvYw26dPHyUlJWncuHFKSEhQixYttHz58twvhR04cMBpqvnkyZMaMmSIEhISVKVKFbVu3Vrr169X48aN7XoLAIB8xMVJvXqdD7I9e0pffEGQBeAatodZSRo+fLiGDx+e53NxcXFO40mTJmnSpEluqAoAcKVWr5Zuu006e9Ya9+olLVgg5fFVBgAoElZOAwCKxapVzkH2ttsIsgBcjzALAHC5lSudg2zv3tL8+QRZAK5HmAUAuNQ331jhNee+NHfcQZAFUHwIswAAl/n6a+n2288H2agoae5cydfX1rIAlGKEWQCASyxfbs3CZmRY4zvvJMgCKH6EWQDAFVu2zJqFzQmyd98tzZkjlStna1kAygDCLADgiixd6hxk77lH+vxzgiwA9yDMAgCK7KuvrOUEmZnWODpamjWLIAvAfQizAIAi+b//cw6yffoQZAG4H2EWAFBoS5ZY62LPnbPGffpIn34q+ZSI+0oCKEsIswCAQlm82FoXmxNk77+fIAvAPoRZAECBLVzoHGQffFD6z38IsgDsQ5gFABTIF19I994rZWVZ44cekj7+mCALwF6EWQDAZS1YYK2LzQmy/fpJM2dK3t721gUAhFkAQL7mzXMOsv37Sx99RJAFUDIQZgEAlzR3rvUFr+xsazxggPThhwRZACUHYRYAkKc5c6QHHjgfZAcOJMgCKHkIswCAi3z+uXOQHTxYev99yYs/NQCUMPxaAgA4mTVL6ttXMgxrPGSINGMGQRZAycSvJgBArk8/tS65lRNk//53afp0giyAkotfTwAASdInn1hXKsgJso88Ik2bRpAFULLxKwoAoI8/dg6yjz4qTZ1KkAVQ8vFrCgDKuNhY6eGHJdO0xsOGSVOmSA6HrWUBQIEQZgGgDPvoI+uSWzlB9rHHpHfeIcgC8ByEWQAooz780LrkVk6QfeIJ6a23CLIAPAthFgDKoA8+cA6yI0ZIkyYRZAF4HsIsAJQx771nXTs2x5NPSm++SZAF4JkIswBQhsyYIQ0den781FPSxIkEWQCeizALAGXE9OnWtWNzjBolTZhAkAXg2QizAFAGTJ1qXTs2x+jR0uuvE2QBeD7CLACUclOnWteOzTFmjPTaawRZAKUDYRYASrF33nEOss8+K736KkEWQOlBmAWAUurtt6XHHz8/fvZZ6V//IsgCKF0IswBQCk2ebN0EIcfzzxNkAZROhFkAKGUmTbKuHZvjhRekl14iyAIonQizAFBKZGdLMTHSyJHnt734ovUAgNKqRITZKVOm6Oqrr5a/v7/atWunH374Id/9582bp2uvvVb+/v5q2rSpli5d6qZKAaDkycqSDh/2UtOmDj377Pnt48dbs7IAUJrZHmbnzJmjkSNH6oUXXtBPP/2k5s2bKzIyUomJiXnuv379et1///0aNGiQtmzZoqioKEVFRWnHjh1urhwA7JWVJX3yidSkiUM7dpTT7t3n1xG8/LI0bpyNxQGAmzhM0zTtLKBdu3a64YYb9O6770qSDMNQeHi4HnvsMY0ZM+ai/fv06aO0tDR9+eWXudvat2+vFi1aaPr06Zc9X0pKioKCgpScnKzAwEDXvZFLGDDA1PHjGfLz85ODBWtuY5qmMjLou7vRd/faulXasydndLukJerc2VpW0K2bbWWVGYZhKDExUSEhIfLysn1uqMyg7/Zwd98Lk9d8ir2afGRmZio+Pl5jx47N3ebl5aXu3btrw4YNeb5mw4YNGnnhgjBJkZGRWrRoUZ77Z2RkKCMjI3eckpIiyfqPYhjGFb6Dy1uyxKGTJ/2L/Tz4K4ck+u5+9N0uVaoYmjcvW926WX+JcMOvtzLPMAyZpumWP0twHn23h7v7Xpjz2Bpmjx07puzsbIWGhjptDw0N1a5du/J8TUJCQp77JyQk5Ll/TEyMxo8ff9H2u+++Wz4+xf/2U1N9Zf0BDwCuV6WKofr1s7Rv32a9/npP/fvf/L5xF9M0lZWVJR8fH/4lwo3ouz3c3fesrKwC72trmHWHsWPHOs3kpqSkKDw8XAsWLHDLMoM//zR07NhxVatWjX8OcSPDMHT8OH13N/ruXgEBUrVqVt9vvfVWLV26lL67kWEYSkpKUnBwMH13I/puD3f3PSUlRVWqVCnQvraG2auuukre3t46evSo0/ajR48qLCwsz9eEhYUVan8/Pz/5+fldtN3Ly8st/zHCwyU/P1MhIe45HyyGIfn703d3o+/2cTgcbvu9hvPouz3ouz3c2ffCnMPWT4Gvr69at26tVatW5W4zDEOrVq1SREREnq+JiIhw2l+SVqxYccn9AQAAUHrZvsxg5MiR6t+/v9q0aaO2bdtq8uTJSktL08MPPyxJ6tevn2rWrKmYmBhJ0hNPPKEuXbpo4sSJ6tWrl2bPnq3Nmzfrvffes/NtAAAAwAa2h9k+ffooKSlJ48aNU0JCglq0aKHly5fnfsnrwIEDTlPNHTp00KxZs/Tcc8/p2WefVcOGDbVo0SI1adLErrcAAAAAm9geZiVp+PDhGj58eJ7PxcXFXbQtOjpa0dHRxVwVAAAASjpWTgMAAMBjEWYBAADgsQizAAAA8FiEWQAAAHgswiwAAAA8FmEWAAAAHqtEXJrLnUzTlGTd89cdDMNQamqq/P39ue2eG9F3e9B3exiGoaysLKWkpNB3N+Lzbg/6bg939z0np+XktvyUuTCbmpoqSQoPD7e5EgBwrSpVqthdAgC4VGpqqoKCgvLdx2EWJPKWIoZh6PDhw6pUqZIcDkexny8lJUXh4eH6888/FRgYWOzng4W+24O+24O+24O+24O+28PdfTdNU6mpqapRo8ZlZ4LL3Mysl5eXatWq5fbzBgYG8kNnA/puD/puD/puD/puD/puD3f2/XIzsjlYbAIAAACPRZgFAACAxyLMFjM/Pz+98MIL8vPzs7uUMoW+24O+24O+24O+24O+26Mk973MfQEMAAAApQczswAAAPBYhFkAAAB4LMIsAAAAPBZhFgAAAB6LMOtmt99+u2rXri1/f39Vr15dDz30kA4fPmx3WaXa/v37NWjQINWtW1cBAQGqX7++XnjhBWVmZtpdWqn3yiuvqEOHDipfvrwqV65sdzml1pQpU3T11VfL399f7dq10w8//GB3SaXa2rVr1bt3b9WoUUMOh0OLFi2yu6QyISYmRjfccIMqVaqkkJAQRUVFaffu3XaXVepNmzZNzZo1y71ZQkREhJYtW2Z3WU4Is27WrVs3zZ07V7t379aCBQu0d+9e3XPPPXaXVart2rVLhmFoxowZ2rlzpyZNmqTp06fr2Weftbu0Ui8zM1PR0dF69NFH7S6l1JozZ45GjhypF154QT/99JOaN2+uyMhIJSYm2l1aqZWWlqbmzZtrypQpdpdSpqxZs0bDhg3Txo0btWLFCp07d0633HKL0tLS7C6tVKtVq5Zee+01xcfHa/Pmzbrxxht1xx13aOfOnXaXlotLc9lsyZIlioqKUkZGhsqVK2d3OWXGhAkTNG3aNP3+++92l1ImxMbGasSIETp16pTdpZQ67dq10w033KB3331XkmQYhsLDw/XYY49pzJgxNldX+jkcDi1cuFBRUVF2l1LmJCUlKSQkRGvWrFHnzp3tLqdMqVq1qiZMmKBBgwbZXYokZmZtdeLECX322Wfq0KEDQdbNkpOTVbVqVbvLAK5IZmam4uPj1b1799xtXl5e6t69uzZs2GBjZUDxS05OliR+l7tRdna2Zs+erbS0NEVERNhdTi7CrA2eeeYZVahQQdWqVdOBAwe0ePFiu0sqU/bs2aN33nlHQ4cOtbsU4IocO3ZM2dnZCg0NddoeGhqqhIQEm6oCip9hGBoxYoQ6duyoJk2a2F1Oqbd9+3ZVrFhRfn5+euSRR7Rw4UI1btzY7rJyEWZdYMyYMXI4HPk+du3albv/qFGjtGXLFn3zzTfy9vZWv379xGqPwits3yXp0KFD6tGjh6KjozVkyBCbKvdsRek7ALjSsGHDtGPHDs2ePdvuUsqERo0aaevWrdq0aZMeffRR9e/fX7/88ovdZeVizawLJCUl6fjx4/nuU69ePfn6+l60/eDBgwoPD9f69etL1JS9Jyhs3w8fPqyuXbuqffv2io2NlZcXf5criqJ83lkzWzwyMzNVvnx5zZ8/32nNZv/+/XXq1Cn+1ccNWDPrfsOHD9fixYu1du1a1a1b1+5yyqTu3burfv36mjFjht2lSJJ87C6gNAgODlZwcHCRXmsYhiQpIyPDlSWVCYXp+6FDh9StWze1bt1aM2fOJMhegSv5vMO1fH191bp1a61atSo3TBmGoVWrVmn48OH2Fge4mGmaeuyxx7Rw4ULFxcURZG1kGEaJyi2EWTfatGmTfvzxR3Xq1ElVqlTR3r179fzzz6t+/frMyhajQ4cOqWvXrqpTp47eeOMNJSUl5T4XFhZmY2Wl34EDB3TixAkdOHBA2dnZ2rp1qySpQYMGqlixor3FlRIjR45U//791aZNG7Vt21aTJ09WWlqaHn74YbtLK7VOnz6tPXv25I737dunrVu3qmrVqqpdu7aNlZVuw4YN06xZs7R48WJVqlQpd114UFCQAgICbK6u9Bo7dqx69uyp2rVrKzU1VbNmzVJcXJy+/vpru0s7z4Tb/Pzzz2a3bt3MqlWrmn5+fubVV19tPvLII+bBgwftLq1UmzlzpikpzweKV//+/fPs+7fffmt3aaXKO++8Y9auXdv09fU127Zta27cuNHukkq1b7/9Ns/Pdf/+/e0urVS71O/xmTNn2l1aqTZw4ECzTp06pq+vrxkcHGzedNNN5jfffGN3WU5YMwsAAACPxcJBAAAAeCzCLAAAADwWYRYAAAAeizALAAAAj0WYBQAAgMcizAIAAMBjEWYBAADgsQizAAAA8FiEWQAAAHgswiwAAAA8FmEWAAAAHoswCwAeKikpSWFhYXr11Vdzt61fv16+vr5atWqVjZUBgPs4TNM07S4CAFA0S5cuVVRUlNavX69GjRqpRYsWuuOOO/Tmm2/aXRoAuAVhFgA83LBhw7Ry5Uq1adNG27dv148//ig/Pz+7ywIAtyDMAoCHO3v2rJo0aaI///xT8fHxatq0qd0lAYDbsGYWADzc3r17dfjwYRmGof3799tdDgC4FTOzAODBMjMz1bZtW7Vo0UKNGjXS5MmTtX37doWEhNhdGgC4BWEWADzYqFGjNH/+fG3btk0VK1ZUly5dFBQUpC+//NLu0gDALVhmAAAeKi4uTpMnT9Ynn3yiwMBAeXl56ZNPPtF3332nadOm2V0eALgFM7MAAADwWMzMAgAAwGMRZgEAAOCxCLMAAADwWIRZAAAAeCzCLAAAADwWYRYAAAAeizALAAAAj0WYBQAAgMcizAIAAMBjEWYBAADgsQizAAAA8Fj/D/bRqt72oDQuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU 的特点：\n",
      "  1. 计算简单：只需比较和取最大值\n",
      "  2. 梯度不会消失：正区间梯度恒为 1\n",
      "  3. 稀疏激活：负值变成 0，网络更高效\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ReLU 可视化\n",
    "# ============================================================\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU 激活函数: max(0, x)\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x = np.linspace(-3, 3, 100)\n",
    "y = relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y, 'b-', linewidth=2, label='ReLU(x) = max(0, x)')\n",
    "plt.axhline(y=0, color='k', linestyle='-', linewidth=0.5)\n",
    "plt.axvline(x=0, color='k', linestyle='-', linewidth=0.5)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ReLU(x)')\n",
    "plt.title('ReLU 激活函数')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"ReLU 的特点：\")\n",
    "print(\"  1. 计算简单：只需比较和取最大值\")\n",
    "print(\"  2. 梯度不会消失：正区间梯度恒为 1\")\n",
    "print(\"  3. 稀疏激活：负值变成 0，网络更高效\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么用 ReLU 而不是 Sigmoid？\n",
    "\n",
    "| 激活函数 | 公式 | 优点 | 缺点 |\n",
    "|---------|------|------|------|\n",
    "| Sigmoid | 1/(1+e^(-x)) | 输出在(0,1) | 梯度消失，计算慢 |\n",
    "| Tanh | (e^x-e^(-x))/(e^x+e^(-x)) | 输出在(-1,1) | 梯度消失 |\n",
    "| **ReLU** | max(0, x) | 梯度不消失，快 | 负区间\"死亡\" |\n",
    "\n",
    "**梯度消失问题：**\n",
    "- Sigmoid 的梯度最大只有 0.25\n",
    "- 10 层网络：0.25^10 = 0.0000001\n",
    "- 梯度几乎为 0，无法学习！\n",
    "\n",
    "**ReLU 的解决：**\n",
    "- 正区间梯度恒为 1\n",
    "- 梯度可以顺利传播到深层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 池化层 (Pool) - 下采样压缩\n",
    "\n",
    "前面已经学过，简单回顾：\n",
    "\n",
    "```\n",
    "最大池化 (MaxPool)：取窗口内最大值\n",
    "平均池化 (AvgPool)：取窗口内平均值\n",
    "\n",
    "例如 2x2 MaxPool：\n",
    "  [1, 3]      \n",
    "  [2, 4]  -->  [4]  （取最大值）\n",
    "\n",
    "作用：\n",
    "  1. 减小尺寸，降低计算量\n",
    "  2. 增加平移不变性\n",
    "  3. 扩大感受野\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Flatten - 3D 转 1D 展平\n",
    "\n",
    "#### 为什么需要 Flatten？\n",
    "\n",
    "```\n",
    "问题：\n",
    "  卷积层输出是 3D 张量：(C, H, W) 如 (64, 7, 7)\n",
    "  全连接层输入是 1D 向量：(n,)\n",
    "\n",
    "解决：\n",
    "  Flatten 把 3D 张量\"摊开\"成 1D 向量\n",
    "\n",
    "例子：\n",
    "  输入: (64, 7, 7)  = 64 个通道，每个 7x7\n",
    "  展平: 64 x 7 x 7 = 3136 个数\n",
    "  输出: (3136,)\n",
    "```\n",
    "\n",
    "#### 图示\n",
    "\n",
    "```\n",
    "  3D 特征图 (2, 2, 2)          1D 向量 (8,)\n",
    "  \n",
    "  通道0:    通道1:              \n",
    "  +--+--+  +--+--+            +--+--+--+--+--+--+--+--+\n",
    "  |a |b |  |e |f |    -->     |a |b |c |d |e |f |g |h |\n",
    "  +--+--+  +--+--+            +--+--+--+--+--+--+--+--+\n",
    "  |c |d |  |g |h |\n",
    "  +--+--+  +--+--+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten 前（3D 特征图）:\n",
      "形状: (2, 3, 3)\n",
      "\n",
      "通道 0:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "通道 1:\n",
      "[[10 11 12]\n",
      " [13 14 15]\n",
      " [16 17 18]]\n",
      "\n",
      "Flatten 后（1D 向量）:\n",
      "形状: (18,)\n",
      "内容: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18]\n",
      "\n",
      "元素总数不变: 2 x 3 x 3 = 18 = 18\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Flatten 演示\n",
    "# ============================================================\n",
    "\n",
    "# 模拟 CNN 的特征图输出 (2个通道, 3x3)\n",
    "feature_map = np.array([\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]],\n",
    "    \n",
    "    [[10, 11, 12],\n",
    "     [13, 14, 15],\n",
    "     [16, 17, 18]]\n",
    "])\n",
    "\n",
    "print(\"Flatten 前（3D 特征图）:\")\n",
    "print(f\"形状: {feature_map.shape}\")\n",
    "print(f\"\\n通道 0:\\n{feature_map[0]}\")\n",
    "print(f\"\\n通道 1:\\n{feature_map[1]}\")\n",
    "\n",
    "# Flatten 操作\n",
    "flattened = feature_map.flatten()\n",
    "\n",
    "print(f\"\\nFlatten 后（1D 向量）:\")\n",
    "print(f\"形状: {flattened.shape}\")\n",
    "print(f\"内容: {flattened}\")\n",
    "\n",
    "print(f\"\\n元素总数不变: 2 x 3 x 3 = {2*3*3} = {len(flattened)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten 前: torch.Size([2, 64, 7, 7])\n",
      "x.view(batch, -1): torch.Size([2, 3136])\n",
      "x.flatten(start_dim=1): torch.Size([2, 3136])\n",
      "nn.Flatten(): torch.Size([2, 3136])\n",
      "\n",
      "64 x 7 x 7 = 3136\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 中的 Flatten\n",
    "if HAS_TORCH:\n",
    "    # 模拟 batch 的特征图 (batch_size=2, channels=64, height=7, width=7)\n",
    "    x = torch.randn(2, 64, 7, 7)\n",
    "    print(f\"Flatten 前: {x.shape}\")\n",
    "    \n",
    "    # 方法1: view() - 最常用\n",
    "    x_flat1 = x.view(x.size(0), -1)  # -1 表示自动计算\n",
    "    print(f\"x.view(batch, -1): {x_flat1.shape}\")\n",
    "    \n",
    "    # 方法2: flatten() - 更直观\n",
    "    x_flat2 = x.flatten(start_dim=1)  # 从第1维开始展平，保留batch维\n",
    "    print(f\"x.flatten(start_dim=1): {x_flat2.shape}\")\n",
    "    \n",
    "    # 方法3: nn.Flatten() - 作为层使用\n",
    "    flatten_layer = nn.Flatten()\n",
    "    x_flat3 = flatten_layer(x)\n",
    "    print(f\"nn.Flatten(): {x_flat3.shape}\")\n",
    "    \n",
    "    print(f\"\\n64 x 7 x 7 = {64*7*7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 全连接层 (FC/Linear) - 综合决策\n",
    "\n",
    "#### 什么是全连接层？\n",
    "\n",
    "```\n",
    "FC = Fully Connected = 全连接\n",
    "也叫：\n",
    "  - Dense 层（Keras/TensorFlow）\n",
    "  - Linear 层（PyTorch）\n",
    "\n",
    "核心特点：每个输入连接到每个输出\n",
    "```\n",
    "\n",
    "#### 数学公式\n",
    "\n",
    "$$y = Wx + b$$\n",
    "\n",
    "```\n",
    "其中：\n",
    "  x: 输入向量, shape (n,)\n",
    "  W: 权重矩阵, shape (m, n)\n",
    "  b: 偏置向量, shape (m,)\n",
    "  y: 输出向量, shape (m,)\n",
    "\n",
    "例子：\n",
    "  输入 x = [x1, x2, x3]     (3个输入)\n",
    "  输出 y = [y1, y2]         (2个输出)\n",
    "  \n",
    "  y1 = w11*x1 + w12*x2 + w13*x3 + b1\n",
    "  y2 = w21*x1 + w22*x2 + w23*x3 + b2\n",
    "```\n",
    "\n",
    "#### 图示\n",
    "\n",
    "```\n",
    "  输入 (3)              输出 (2)\n",
    "  \n",
    "    x1 o-----------------o y1\n",
    "        \\   \\      /  /\n",
    "    x2 o-----\\----/-----o y2\n",
    "        \\     \\/\\/\n",
    "    x3 o-----------------\n",
    "    \n",
    "  每个输入都连接到每个输出\n",
    "  --> 这就是\"全连接\"的含义！\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全连接层示例：\n",
      "输入 x: [1. 2. 3.]  shape=(3,)\n",
      "权重 W:\n",
      "[[0.1 0.2 0.3]\n",
      " [0.4 0.5 0.6]]  shape=(2, 3)\n",
      "偏置 b: [0.1 0.2]  shape=(2,)\n",
      "\n",
      "输出 y = Wx + b: [1.5 3.4]  shape=(2,)\n",
      "\n",
      "手动验证：\n",
      "y0 = 0.1*1 + 0.2*2 + 0.3*3 + 0.1 = 1.5\n",
      "y1 = 0.4*1 + 0.5*2 + 0.6*3 + 0.2 = 3.4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 全连接层演示\n",
    "# ============================================================\n",
    "\n",
    "def fully_connected(x, W, b):\n",
    "    \"\"\"\n",
    "    全连接层的前向传播\n",
    "    \n",
    "    公式: y = Wx + b\n",
    "    \n",
    "    参数:\n",
    "        x: 输入向量, shape (n,)\n",
    "        W: 权重矩阵, shape (m, n)\n",
    "        b: 偏置向量, shape (m,)\n",
    "    \n",
    "    返回:\n",
    "        y: 输出向量, shape (m,)\n",
    "    \"\"\"\n",
    "    return np.dot(W, x) + b\n",
    "\n",
    "# 示例：3 个输入 -> 2 个输出\n",
    "x = np.array([1.0, 2.0, 3.0])  # 输入\n",
    "W = np.array([[0.1, 0.2, 0.3],\n",
    "              [0.4, 0.5, 0.6]])  # 权重\n",
    "b = np.array([0.1, 0.2])  # 偏置\n",
    "\n",
    "y = fully_connected(x, W, b)\n",
    "\n",
    "print(\"全连接层示例：\")\n",
    "print(f\"输入 x: {x}  shape={x.shape}\")\n",
    "print(f\"权重 W:\\n{W}  shape={W.shape}\")\n",
    "print(f\"偏置 b: {b}  shape={b.shape}\")\n",
    "print(f\"\\n输出 y = Wx + b: {y}  shape={y.shape}\")\n",
    "\n",
    "# 手动验证\n",
    "y0 = 0.1*1 + 0.2*2 + 0.3*3 + 0.1\n",
    "y1 = 0.4*1 + 0.5*2 + 0.6*3 + 0.2\n",
    "print(f\"\\n手动验证：\")\n",
    "print(f\"y0 = 0.1*1 + 0.2*2 + 0.3*3 + 0.1 = {y0}\")\n",
    "print(f\"y1 = 0.4*1 + 0.5*2 + 0.6*3 + 0.2 = {y1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全连接 vs 卷积：核心区别\n",
    "\n",
    "| 特性 | 卷积层 (Conv) | 全连接层 (FC) |\n",
    "|------|--------------|---------------|\n",
    "| 连接方式 | **局部连接**（只看 3x3 窗口） | **全部连接**（每个输入都参与） |\n",
    "| 参数共享 | **是**（同一个核扫遍全图） | **否**（每个连接独立权重） |\n",
    "| 保留空间结构 | **是**（输出还是 2D） | **否**（输出是 1D） |\n",
    "| 适合任务 | 特征提取 | 分类决策 |\n",
    "| 参数量 | 较少 | 较多 |\n",
    "\n",
    "**为什么 CNN 最后用 FC？**\n",
    "- 卷积层提取的是\"局部特征\"\n",
    "- FC 层综合\"所有特征\"做最终决策\n",
    "- 例：\"有耳朵 + 有胡须 + 有尾巴 --> 这是猫\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.Linear(3136, 128) 详解：\n",
      "  in_features = 3136  (输入维度，来自 Flatten)\n",
      "  out_features = 128  (输出维度，自己设定)\n",
      "\n",
      "参数量计算：\n",
      "  权重 W: torch.Size([128, 3136]) = 401,408 个\n",
      "  偏置 b: torch.Size([128]) = 128 个\n",
      "  总计: 401,536 个\n",
      "\n",
      "测试：\n",
      "  输入: torch.Size([4, 3136])\n",
      "  输出: torch.Size([4, 128])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PyTorch 中的 nn.Linear\n",
    "# ============================================================\n",
    "\n",
    "if HAS_TORCH:\n",
    "    # nn.Linear(in_features, out_features)\n",
    "    # 等价于: y = x @ W.T + b\n",
    "    \n",
    "    fc = nn.Linear(in_features=3136, out_features=128)\n",
    "    \n",
    "    print(\"nn.Linear(3136, 128) 详解：\")\n",
    "    print(f\"  in_features = 3136  (输入维度，来自 Flatten)\")\n",
    "    print(f\"  out_features = 128  (输出维度，自己设定)\")\n",
    "    print(f\"\\n参数量计算：\")\n",
    "    print(f\"  权重 W: {fc.weight.shape} = {fc.weight.numel():,} 个\")\n",
    "    print(f\"  偏置 b: {fc.bias.shape} = {fc.bias.numel():,} 个\")\n",
    "    print(f\"  总计: {fc.weight.numel() + fc.bias.numel():,} 个\")\n",
    "    \n",
    "    # 测试\n",
    "    x = torch.randn(4, 3136)  # batch_size=4\n",
    "    y = fc(x)\n",
    "    print(f\"\\n测试：\")\n",
    "    print(f\"  输入: {x.shape}\")\n",
    "    print(f\"  输出: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dropout - 防止过拟合\n",
    "\n",
    "#### 什么是 Dropout？\n",
    "\n",
    "```\n",
    "训练时：随机\"关闭\"一部分神经元\n",
    "  - 每次前向传播，随机选择 p% 的神经元\n",
    "  - 将它们的输出设为 0\n",
    "\n",
    "测试时：不 Dropout\n",
    "  - 所有神经元都工作\n",
    "  - 但输出要乘以 (1-p) 来保持期望一致\n",
    "```\n",
    "\n",
    "#### 图示 (Dropout=0.5)\n",
    "\n",
    "```\n",
    "训练时（随机关闭 50%）：      测试时（全部开启）：\n",
    "\n",
    "  o x o x o                   o o o o o\n",
    "    \\ x | x /                   | | | | |\n",
    "  x o x o x                   o o o o o\n",
    "  \n",
    "  o = 激活   x = 关闭         全部激活但权重缩放\n",
    "```\n",
    "\n",
    "#### 为什么有效？\n",
    "\n",
    "1. **防止\"死记硬背\"**：神经元不能依赖特定的其他神经元\n",
    "2. **集成学习效果**：相当于同时训练多个不同的子网络\n",
    "3. **强迫冗余表示**：多个神经元学习相似的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout 演示 (p=0.5):\n",
      "输入:        [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "训练 #1:   [0. 2. 2. 2. 0. 0. 0. 2. 2. 2.]\n",
      "训练 #2:   [0. 2. 2. 0. 0. 0. 0. 2. 0. 0.]\n",
      "训练 #3:   [2. 0. 0. 0. 0. 2. 0. 2. 2. 0.]\n",
      "测试时:      [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "注意：\n",
      "  - 训练时每次不同的神经元被关闭\n",
      "  - 保留的值被放大 2 倍（因为 p=0.5）\n",
      "  - 测试时输出不变\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Dropout 演示\n",
    "# ============================================================\n",
    "\n",
    "def dropout_numpy(x, p=0.5, training=True):\n",
    "    \"\"\"\n",
    "    Dropout 的 NumPy 实现\n",
    "    \n",
    "    参数:\n",
    "        x: 输入\n",
    "        p: 关闭概率（drop probability）\n",
    "        training: 是否在训练模式\n",
    "    \n",
    "    返回:\n",
    "        dropout 后的输出\n",
    "    \"\"\"\n",
    "    if not training:\n",
    "        return x  # 测试时不 dropout\n",
    "    \n",
    "    # 生成 mask：以 (1-p) 的概率保留\n",
    "    mask = np.random.binomial(1, 1-p, size=x.shape)\n",
    "    \n",
    "    # 应用 mask 并缩放（inverted dropout）\n",
    "    # 缩放是为了让训练和测试时的期望值一致\n",
    "    return x * mask / (1 - p)\n",
    "\n",
    "# 演示\n",
    "np.random.seed(42)\n",
    "x = np.ones(10)  # 全 1 的输入\n",
    "\n",
    "print(\"Dropout 演示 (p=0.5):\")\n",
    "print(f\"输入:        {x}\")\n",
    "\n",
    "for i in range(3):\n",
    "    y = dropout_numpy(x, p=0.5, training=True)\n",
    "    print(f\"训练 #{i+1}:   {y}\")\n",
    "\n",
    "y_test = dropout_numpy(x, p=0.5, training=False)\n",
    "print(f\"测试时:      {y_test}\")\n",
    "\n",
    "print(\"\\n注意：\")\n",
    "print(\"  - 训练时每次不同的神经元被关闭\")\n",
    "print(\"  - 保留的值被放大 2 倍（因为 p=0.5）\")\n",
    "print(\"  - 测试时输出不变\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Dropout:\n",
      "输入: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "训练模式:\n",
      "  输出 #1: tensor([[0., 2., 0., 0., 2., 2., 2., 0., 2., 0.]])\n",
      "  输出 #2: tensor([[0., 2., 2., 2., 2., 0., 0., 2., 2., 2.]])\n",
      "  输出 #3: tensor([[2., 2., 0., 0., 0., 0., 2., 2., 2., 2.]])\n",
      "\n",
      "评估模式:\n",
      "  输出: tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "提示: model.train() 和 model.eval() 会切换 Dropout 行为\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 中的 Dropout\n",
    "if HAS_TORCH:\n",
    "    dropout = nn.Dropout(p=0.5)  # 50% 概率关闭\n",
    "    \n",
    "    x = torch.ones(1, 10)\n",
    "    \n",
    "    print(\"PyTorch Dropout:\")\n",
    "    print(f\"输入: {x}\")\n",
    "    \n",
    "    # 训练模式\n",
    "    dropout.train()\n",
    "    print(f\"\\n训练模式:\")\n",
    "    for i in range(3):\n",
    "        y = dropout(x)\n",
    "        print(f\"  输出 #{i+1}: {y}\")\n",
    "    \n",
    "    # 评估模式\n",
    "    dropout.eval()\n",
    "    y = dropout(x)\n",
    "    print(f\"\\n评估模式:\")\n",
    "    print(f\"  输出: {y}\")\n",
    "    \n",
    "    print(\"\\n提示: model.train() 和 model.eval() 会切换 Dropout 行为\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Softmax - 输出概率\n",
    "\n",
    "#### 什么是 Softmax？\n",
    "\n",
    "```\n",
    "将任意实数向量转换为概率分布：\n",
    "  - 所有输出值在 (0, 1) 之间\n",
    "  - 所有输出值加起来 = 1\n",
    "```\n",
    "\n",
    "#### 公式\n",
    "\n",
    "$$\\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^{x_j}}$$\n",
    "\n",
    "**步骤拆解：**\n",
    "1. 对每个元素求指数 $e^{x_i}$（保证为正）\n",
    "2. 除以所有指数的和（归一化）\n",
    "\n",
    "#### 例子\n",
    "\n",
    "```\n",
    "输入 (logits):  [2.0, 1.0, 0.1]\n",
    "  | 指数运算\n",
    "  v\n",
    "              [e^2.0, e^1.0, e^0.1] = [7.39, 2.72, 1.11]\n",
    "  | 归一化 (除以总和 11.22)\n",
    "  v\n",
    "              [7.39/11.22, 2.72/11.22, 1.11/11.22]\n",
    "            = [0.66, 0.24, 0.10]\n",
    "              \n",
    "输出 (概率):   66% 是类别0, 24% 是类别1, 10% 是类别2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Softmax 演示\n",
    "# ============================================================\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Softmax 函数\n",
    "    \n",
    "    公式: softmax(x_i) = exp(x_i) / sum(exp(x_j))\n",
    "    \n",
    "    注意: 为了数值稳定性，先减去最大值\n",
    "    \"\"\"\n",
    "    x_shifted = x - np.max(x)  # 数值稳定性\n",
    "    exp_x = np.exp(x_shifted)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "# 示例：3分类问题\n",
    "logits = np.array([2.0, 1.0, 0.1])\n",
    "probs = softmax(logits)\n",
    "\n",
    "print(\"Softmax 详细计算：\")\n",
    "print(f\"\\n输入 (logits): {logits}\")\n",
    "print(f\"\\n步骤 1: 指数运算\")\n",
    "print(f\"  e^{logits[0]} = {np.exp(logits[0]):.4f}\")\n",
    "print(f\"  e^{logits[1]} = {np.exp(logits[1]):.4f}\")\n",
    "print(f\"  e^{logits[2]} = {np.exp(logits[2]):.4f}\")\n",
    "print(f\"  总和 = {np.sum(np.exp(logits)):.4f}\")\n",
    "\n",
    "print(f\"\\n步骤 2: 归一化\")\n",
    "for i, p in enumerate(probs):\n",
    "    print(f\"  类别 {i}: {p:.4f} = {p*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n验证: 概率和 = {np.sum(probs):.4f}\")\n",
    "print(f\"预测类别: {np.argmax(probs)}（概率最高的类别）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重要提示：训练时不需要显式调用 Softmax\n",
    "\n",
    "```\n",
    "PyTorch 的 CrossEntropyLoss 已经内置了 Softmax！\n",
    "\n",
    "正确做法：\n",
    "  output = model(x)  # 输出 logits（未归一化的分数）\n",
    "  loss = criterion(output, target)  # CrossEntropyLoss 内部做 Softmax\n",
    "\n",
    "推理时获取概率：\n",
    "  probs = F.softmax(output, dim=1)  # 手动调用\n",
    "  predicted = torch.argmax(probs, dim=1)  # 取最大概率的类别\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 各层作用对比表\n",
    "\n",
    "| 层 | 作用 | 输入形状 | 输出形状 | 参数 |\n",
    "|---|---|---|---|---|\n",
    "| **Conv2d** | 提取局部特征 | (C, H, W) | (C', H', W') | 有 |\n",
    "| **ReLU** | 引入非线性 | 任意 | 不变 | 无 |\n",
    "| **MaxPool2d** | 下采样 | (C, H, W) | (C, H/2, W/2) | 无 |\n",
    "| **Flatten** | 3D转1D | (C, H, W) | (C*H*W,) | 无 |\n",
    "| **Linear** | 全连接 | (n,) | (m,) | 有 |\n",
    "| **Dropout** | 正则化 | 任意 | 不变 | 无 |\n",
    "| **Softmax** | 概率化 | (n,) | (n,) | 无 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 形状变化详细追踪\n",
    "\n",
    "以 MNIST (28x28 灰度图, 10分类) 为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST CNN 形状变化追踪\n",
      "======================================================================\n",
      "输入:                  (1, 28, 28)\n",
      "\n",
      "Conv(1->32, 3x3, p=1): (32, 28, 28)  参数: 320\n",
      "ReLU:                (32, 28, 28)  参数: 0\n",
      "MaxPool(2x2):        (32, 14, 14)  参数: 0\n",
      "\n",
      "Conv(32->64, 3x3, p=1): (64, 14, 14)  参数: 18,496\n",
      "ReLU:                (64, 14, 14)  参数: 0\n",
      "MaxPool(2x2):        (64, 7, 7)  参数: 0\n",
      "\n",
      "Flatten:             (3136,)  参数: 0\n",
      "  计算: 64 x 7 x 7 = 3136\n",
      "\n",
      "Linear(3136->128):   (128,)  参数: 401,536\n",
      "ReLU:                (128,)  参数: 0\n",
      "Dropout(0.5):        (128,)  参数: 0\n",
      "\n",
      "Linear(128->10):     (10,)  参数: 1,290\n",
      "\n",
      "======================================================================\n",
      "总参数量: 421,642\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MNIST CNN 形状变化追踪\n",
    "# ============================================================\n",
    "\n",
    "def calc_conv_output(H, k, p=0, s=1):\n",
    "    \"\"\"计算卷积输出尺寸\"\"\"\n",
    "    return (H + 2*p - k) // s + 1\n",
    "\n",
    "print(\"MNIST CNN 形状变化追踪\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 记录参数量\n",
    "total_params = 0\n",
    "\n",
    "# 初始输入\n",
    "C, H, W = 1, 28, 28\n",
    "print(f\"{'输入:':<20} ({C}, {H}, {W})\")\n",
    "print()\n",
    "\n",
    "# Conv1: 1->32, 3x3, padding=1\n",
    "C_out, k = 32, 3\n",
    "H = calc_conv_output(H, k, p=1)\n",
    "params = C * C_out * k * k + C_out  # 权重 + 偏置\n",
    "total_params += params\n",
    "C = C_out\n",
    "print(f\"{'Conv(1->32, 3x3, p=1):':<20} ({C}, {H}, {H})  参数: {params:,}\")\n",
    "\n",
    "# ReLU\n",
    "print(f\"{'ReLU:':<20} ({C}, {H}, {H})  参数: 0\")\n",
    "\n",
    "# MaxPool 2x2\n",
    "H = H // 2\n",
    "print(f\"{'MaxPool(2x2):':<20} ({C}, {H}, {H})  参数: 0\")\n",
    "print()\n",
    "\n",
    "# Conv2: 32->64, 3x3, padding=1\n",
    "C_in = C\n",
    "C_out, k = 64, 3\n",
    "H = calc_conv_output(H, k, p=1)\n",
    "params = C_in * C_out * k * k + C_out\n",
    "total_params += params\n",
    "C = C_out\n",
    "print(f\"{'Conv(32->64, 3x3, p=1):':<20} ({C}, {H}, {H})  参数: {params:,}\")\n",
    "\n",
    "# ReLU\n",
    "print(f\"{'ReLU:':<20} ({C}, {H}, {H})  参数: 0\")\n",
    "\n",
    "# MaxPool 2x2\n",
    "H = H // 2\n",
    "print(f\"{'MaxPool(2x2):':<20} ({C}, {H}, {H})  参数: 0\")\n",
    "print()\n",
    "\n",
    "# Flatten\n",
    "flat_size = C * H * H\n",
    "print(f\"{'Flatten:':<20} ({flat_size},)  参数: 0\")\n",
    "print(f\"  计算: {C} x {H} x {H} = {flat_size}\")\n",
    "print()\n",
    "\n",
    "# FC1: 3136->128\n",
    "fc1_in, fc1_out = flat_size, 128\n",
    "params = fc1_in * fc1_out + fc1_out\n",
    "total_params += params\n",
    "print(f\"{'Linear(3136->128):':<20} ({fc1_out},)  参数: {params:,}\")\n",
    "\n",
    "# ReLU\n",
    "print(f\"{'ReLU:':<20} ({fc1_out},)  参数: 0\")\n",
    "\n",
    "# Dropout\n",
    "print(f\"{'Dropout(0.5):':<20} ({fc1_out},)  参数: 0\")\n",
    "print()\n",
    "\n",
    "# FC2: 128->10\n",
    "fc2_in, fc2_out = fc1_out, 10\n",
    "params = fc2_in * fc2_out + fc2_out\n",
    "total_params += params\n",
    "print(f\"{'Linear(128->10):':<20} ({fc2_out},)  参数: {params:,}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(f\"总参数量: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. NumPy 从零实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy CNN 测试:\n",
      "输入形状: (1, 28, 28)\n",
      "输出形状: (10,)\n",
      "输出值: [ 0.09508174  1.73528619 -2.64636071  0.37759022  1.68438305  4.57012829\n",
      " -3.45077384 -1.77040876  3.6401879   0.29042578]\n",
      "\n",
      "预测类别: 5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# NumPy 实现完整 CNN（仅前向传播）\n",
    "# ============================================================\n",
    "\n",
    "class SimpleCNN_NumPy:\n",
    "    \"\"\"\n",
    "    简单 CNN 的 NumPy 实现（教学用）\n",
    "    \n",
    "    架构:\n",
    "        输入 (1, 28, 28)\n",
    "          |\n",
    "        Conv(1->8, 3x3, p=1) -> ReLU -> MaxPool(2x2)\n",
    "          | (8, 14, 14)\n",
    "        Conv(8->16, 3x3, p=1) -> ReLU -> MaxPool(2x2)\n",
    "          | (16, 7, 7)\n",
    "        Flatten\n",
    "          | (784,)\n",
    "        FC(784->64) -> ReLU\n",
    "          | (64,)\n",
    "        FC(64->10)\n",
    "          | (10,) logits\n",
    "    \n",
    "    注意：这是简化版本，用于理解原理。\n",
    "          实际训练请使用 PyTorch/TensorFlow。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ========================================\n",
    "        # 初始化权重（随机）\n",
    "        # 使用 He 初始化: std = sqrt(2/n_in)\n",
    "        # ========================================\n",
    "        \n",
    "        # Conv1: 8个滤波器, 1个输入通道, 3x3核\n",
    "        self.conv1_w = np.random.randn(8, 1, 3, 3) * np.sqrt(2.0 / (1*3*3))\n",
    "        self.conv1_b = np.zeros(8)\n",
    "        \n",
    "        # Conv2: 16个滤波器, 8个输入通道, 3x3核\n",
    "        self.conv2_w = np.random.randn(16, 8, 3, 3) * np.sqrt(2.0 / (8*3*3))\n",
    "        self.conv2_b = np.zeros(16)\n",
    "        \n",
    "        # FC1: 784 -> 64\n",
    "        self.fc1_w = np.random.randn(784, 64) * np.sqrt(2.0 / 784)\n",
    "        self.fc1_b = np.zeros(64)\n",
    "        \n",
    "        # FC2: 64 -> 10\n",
    "        self.fc2_w = np.random.randn(64, 10) * np.sqrt(2.0 / 64)\n",
    "        self.fc2_b = np.zeros(10)\n",
    "    \n",
    "    def relu(self, x):\n",
    "        \"\"\"ReLU 激活函数: max(0, x)\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def conv2d(self, x, w, b, padding=1):\n",
    "        \"\"\"\n",
    "        2D 卷积（简化版，单样本）\n",
    "        \n",
    "        参数:\n",
    "            x: 输入, shape (C_in, H, W)\n",
    "            w: 权重, shape (C_out, C_in, k_h, k_w)\n",
    "            b: 偏置, shape (C_out,)\n",
    "            padding: 填充\n",
    "        \n",
    "        返回:\n",
    "            输出, shape (C_out, H', W')\n",
    "        \"\"\"\n",
    "        C_out, C_in, k_h, k_w = w.shape\n",
    "        _, H, W = x.shape\n",
    "        \n",
    "        # 添加 padding\n",
    "        if padding > 0:\n",
    "            x = np.pad(x, ((0, 0), (padding, padding), (padding, padding)))\n",
    "        \n",
    "        _, H_pad, W_pad = x.shape\n",
    "        out_h = H_pad - k_h + 1\n",
    "        out_w = W_pad - k_w + 1\n",
    "        \n",
    "        output = np.zeros((C_out, out_h, out_w))\n",
    "        \n",
    "        for c_out in range(C_out):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    # 提取感受野 (C_in, k_h, k_w)\n",
    "                    window = x[:, i:i+k_h, j:j+k_w]\n",
    "                    # 卷积 + 偏置\n",
    "                    output[c_out, i, j] = np.sum(window * w[c_out]) + b[c_out]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def max_pool(self, x, size=2):\n",
    "        \"\"\"\n",
    "        最大池化\n",
    "        \n",
    "        参数:\n",
    "            x: 输入, shape (C, H, W)\n",
    "            size: 池化窗口大小\n",
    "        \n",
    "        返回:\n",
    "            输出, shape (C, H//size, W//size)\n",
    "        \"\"\"\n",
    "        C, H, W = x.shape\n",
    "        out_h, out_w = H // size, W // size\n",
    "        output = np.zeros((C, out_h, out_w))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    window = x[c, i*size:(i+1)*size, j*size:(j+1)*size]\n",
    "                    output[c, i, j] = np.max(window)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        \n",
    "        参数:\n",
    "            x: 输入图像, shape (1, 28, 28)\n",
    "        \n",
    "        返回:\n",
    "            logits: 未归一化的类别分数, shape (10,)\n",
    "        \"\"\"\n",
    "        # ========================================\n",
    "        # 特征提取部分\n",
    "        # ========================================\n",
    "        \n",
    "        # Conv1 -> ReLU -> Pool\n",
    "        x = self.conv2d(x, self.conv1_w, self.conv1_b)  # (8, 28, 28)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)  # (8, 14, 14)\n",
    "        \n",
    "        # Conv2 -> ReLU -> Pool\n",
    "        x = self.conv2d(x, self.conv2_w, self.conv2_b)  # (16, 14, 14)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)  # (16, 7, 7)\n",
    "        \n",
    "        # ========================================\n",
    "        # 分类部分\n",
    "        # ========================================\n",
    "        \n",
    "        # Flatten: 3D -> 1D\n",
    "        x = x.flatten()  # (784,)\n",
    "        \n",
    "        # FC1 -> ReLU\n",
    "        x = x @ self.fc1_w + self.fc1_b  # (64,)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        # FC2 (输出层)\n",
    "        x = x @ self.fc2_w + self.fc2_b  # (10,)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 测试\n",
    "cnn_numpy = SimpleCNN_NumPy()\n",
    "dummy_input = np.random.randn(1, 28, 28)\n",
    "output = cnn_numpy.forward(dummy_input)\n",
    "\n",
    "print(\"NumPy CNN 测试:\")\n",
    "print(f\"输入形状: {dummy_input.shape}\")\n",
    "print(f\"输出形状: {output.shape}\")\n",
    "print(f\"输出值: {output}\")\n",
    "print(f\"\\n预测类别: {np.argmax(output)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. PyTorch 实现（带详细注释）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CNN 测试:\n",
      "输入形状: torch.Size([4, 1, 28, 28])\n",
      "输出形状: torch.Size([4, 10])\n",
      "\n",
      "模型结构:\n",
      "MNISTNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "\n",
      "参数统计:\n",
      "  总参数量: 421,642\n",
      "  可训练参数: 421,642\n"
     ]
    }
   ],
   "source": [
    "if HAS_TORCH:\n",
    "    class MNISTNet(nn.Module):\n",
    "        \"\"\"\n",
    "        MNIST 分类 CNN\n",
    "        \n",
    "        架构:\n",
    "            输入: (N, 1, 28, 28)  N=batch_size\n",
    "              |\n",
    "            Conv(1->32, 3x3, p=1) -> ReLU -> MaxPool(2x2)\n",
    "              | (N, 32, 14, 14)\n",
    "            Conv(32->64, 3x3, p=1) -> ReLU -> MaxPool(2x2)\n",
    "              | (N, 64, 7, 7)\n",
    "            Flatten\n",
    "              | (N, 3136)\n",
    "            FC(3136->128) -> ReLU -> Dropout(0.5)\n",
    "              | (N, 128)\n",
    "            FC(128->10)\n",
    "              | (N, 10) logits\n",
    "        \"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            # ========================================\n",
    "            # 特征提取层\n",
    "            # ========================================\n",
    "            \n",
    "            # Conv1: 1个输入通道 -> 32个输出通道\n",
    "            # kernel_size=3: 使用 3x3 的卷积核\n",
    "            # padding=1: 填充1圈0，保持尺寸不变 (same padding)\n",
    "            self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,    # MNIST 是灰度图，1个通道\n",
    "                out_channels=32,  # 输出32个特征图\n",
    "                kernel_size=3,    # 3x3 卷积核\n",
    "                padding=1         # same padding\n",
    "            )\n",
    "            \n",
    "            # Conv2: 32个输入通道 -> 64个输出通道\n",
    "            self.conv2 = nn.Conv2d(\n",
    "                in_channels=32,   # 来自 conv1 的输出\n",
    "                out_channels=64,  # 输出64个特征图\n",
    "                kernel_size=3,\n",
    "                padding=1\n",
    "            )\n",
    "            \n",
    "            # 池化层: 2x2 最大池化，尺寸减半\n",
    "            self.pool = nn.MaxPool2d(\n",
    "                kernel_size=2,  # 2x2 窗口\n",
    "                stride=2        # 步幅2，所以尺寸减半\n",
    "            )\n",
    "            \n",
    "            # ========================================\n",
    "            # 分类层\n",
    "            # ========================================\n",
    "            \n",
    "            # FC1: 全连接层\n",
    "            # 输入: 64 x 7 x 7 = 3136 (来自 Flatten)\n",
    "            # 输出: 128\n",
    "            self.fc1 = nn.Linear(\n",
    "                in_features=64 * 7 * 7,  # 3136\n",
    "                out_features=128\n",
    "            )\n",
    "            \n",
    "            # FC2: 输出层\n",
    "            # 输入: 128\n",
    "            # 输出: 10 (对应 0-9 十个数字)\n",
    "            self.fc2 = nn.Linear(\n",
    "                in_features=128,\n",
    "                out_features=10\n",
    "            )\n",
    "            \n",
    "            # Dropout: 训练时随机关闭 50% 的神经元\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            \"\"\"\n",
    "            前向传播\n",
    "            \n",
    "            参数:\n",
    "                x: 输入图像, shape (N, 1, 28, 28)\n",
    "                   N = batch_size\n",
    "            \n",
    "            返回:\n",
    "                logits: 类别分数, shape (N, 10)\n",
    "                        注意: 返回的是 logits，不是概率！\n",
    "                        CrossEntropyLoss 会自动处理 Softmax\n",
    "            \"\"\"\n",
    "            # ========================================\n",
    "            # 特征提取\n",
    "            # ========================================\n",
    "            \n",
    "            # 第一个卷积块: Conv -> ReLU -> Pool\n",
    "            # (N, 1, 28, 28) -> (N, 32, 28, 28) -> (N, 32, 14, 14)\n",
    "            x = self.conv1(x)      # 卷积\n",
    "            x = F.relu(x)          # 激活\n",
    "            x = self.pool(x)       # 池化\n",
    "            \n",
    "            # 第二个卷积块: Conv -> ReLU -> Pool\n",
    "            # (N, 32, 14, 14) -> (N, 64, 14, 14) -> (N, 64, 7, 7)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.pool(x)\n",
    "            \n",
    "            # ========================================\n",
    "            # 分类\n",
    "            # ========================================\n",
    "            \n",
    "            # Flatten: 3D -> 1D\n",
    "            # (N, 64, 7, 7) -> (N, 3136)\n",
    "            x = x.view(x.size(0), -1)  # 保留 batch 维度，展平其余\n",
    "            \n",
    "            # FC1 -> ReLU -> Dropout\n",
    "            # (N, 3136) -> (N, 128)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)  # 只在训练时生效\n",
    "            \n",
    "            # FC2 (输出层)\n",
    "            # (N, 128) -> (N, 10)\n",
    "            x = self.fc2(x)\n",
    "            \n",
    "            return x\n",
    "    \n",
    "    # ========================================\n",
    "    # 测试模型\n",
    "    # ========================================\n",
    "    model = MNISTNet()\n",
    "    \n",
    "    # 创建假数据: batch_size=4, 1通道, 28x28\n",
    "    dummy = torch.randn(4, 1, 28, 28)\n",
    "    \n",
    "    # 前向传播\n",
    "    out = model(dummy)\n",
    "    \n",
    "    print(\"PyTorch CNN 测试:\")\n",
    "    print(f\"输入形状: {dummy.shape}\")\n",
    "    print(f\"输出形状: {out.shape}\")\n",
    "    \n",
    "    # 打印模型结构\n",
    "    print(\"\\n模型结构:\")\n",
    "    print(model)\n",
    "    \n",
    "    # 计算参数量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\n参数统计:\")\n",
    "    print(f\"  总参数量: {total_params:,}\")\n",
    "    print(f\"  可训练参数: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 各层参数量详细统计\n",
    "# ============================================================\n",
    "\n",
    "if HAS_TORCH:\n",
    "    print(\"各层参数量详细统计:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name:<30} {str(param.shape):<20} {param.numel():>10,}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'总计':<50} {total_params:>10,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 本章小结\n",
    "\n",
    "### CNN 架构模式\n",
    "\n",
    "```\n",
    "[Conv -> ReLU -> Pool] x N  ->  Flatten  ->  [FC -> ReLU -> Dropout] x M  ->  FC\n",
    "   特征提取部分                                 分类部分\n",
    "```\n",
    "\n",
    "### 各层总结\n",
    "\n",
    "| 层 | 作用 | 要点 |\n",
    "|---|---|---|\n",
    "| **Conv** | 提取局部特征 | 局部连接，参数共享 |\n",
    "| **ReLU** | 引入非线性 | max(0, x)，防止梯度消失 |\n",
    "| **Pool** | 下采样 | 减少计算，增加不变性 |\n",
    "| **Flatten** | 3D转1D | 准备进入全连接层 |\n",
    "| **FC** | 综合决策 | y = Wx + b，全部连接 |\n",
    "| **Dropout** | 防止过拟合 | 训练时随机关闭神经元 |\n",
    "| **Softmax** | 输出概率 | 训练时由 CrossEntropyLoss 处理 |\n",
    "\n",
    "### 设计原则\n",
    "\n",
    "1. **空间尺寸**：逐渐减小（通过池化或 stride=2）\n",
    "2. **通道数**：逐渐增加（32 -> 64 -> 128）\n",
    "3. **参数量**：FC 层占主要部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 下一步\n",
    "\n",
    "继续学习 **06_cnn_backprop.ipynb** - CNN 反向传播\n",
    "\n",
    "你将学到：\n",
    "- 卷积层的梯度如何计算\n",
    "- 池化层的梯度如何传播\n",
    "- 完整的 CNN 反向传播实现"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
