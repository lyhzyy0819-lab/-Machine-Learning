{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 è¿ç§»å­¦ä¹ \n",
    "\n",
    "> ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- [ ] ç†è§£è¿ç§»å­¦ä¹ çš„åŸç†\n",
    "- [ ] ä½¿ç”¨ PyTorch é¢„è®­ç»ƒæ¨¡å‹\n",
    "- [ ] æŒæ¡ç‰¹å¾æå–å’Œå¾®è°ƒä¸¤ç§æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torchvision.models as models\n",
    "    import torchvision.transforms as transforms\n",
    "    HAS_TORCH = True\n",
    "except ImportError:\n",
    "    HAS_TORCH = False\n",
    "    print(\"è¯·å®‰è£… PyTorch å’Œ torchvision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¡ ä¸ºä»€ä¹ˆè¿ç§»å­¦ä¹ æœ‰æ•ˆï¼Ÿ\n",
    "\n",
    "### CNN çš„ç‰¹å¾å±‚æ¬¡\n",
    "\n",
    "```\n",
    "æµ…å±‚ï¼ˆé è¿‘è¾“å…¥ï¼‰      æ·±å±‚ï¼ˆé è¿‘è¾“å‡ºï¼‰\n",
    "     â†“                    â†“\n",
    "  è¾¹ç¼˜ã€é¢œè‰²    â†’    çº¹ç†ã€å½¢çŠ¶    â†’    é«˜çº§è¯­ä¹‰\n",
    "     â†“                    â†“                â†“\n",
    "  é€šç”¨ç‰¹å¾            é¢†åŸŸç‰¹å®š         ä»»åŠ¡ç‰¹å®š\n",
    "```\n",
    "\n",
    "**å…³é”®æ´å¯Ÿ**ï¼šæµ…å±‚ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ï¼‰åœ¨ä¸åŒä»»åŠ¡ä¸­æ˜¯é€šç”¨çš„ï¼\n",
    "\n",
    "### è¿ç§»å­¦ä¹ ç­–ç•¥\n",
    "\n",
    "1. **ç‰¹å¾æå– (Feature Extraction)**ï¼šå†»ç»“é¢„è®­ç»ƒå±‚ï¼Œåªè®­ç»ƒæ–°çš„åˆ†ç±»å¤´\n",
    "2. **å¾®è°ƒ (Fine-tuning)**ï¼šè§£å†»éƒ¨åˆ†/å…¨éƒ¨å±‚ï¼Œç”¨å°å­¦ä¹ ç‡ç»§ç»­è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/lyh/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [01:30<00:00, 519kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet-18 ç»“æ„ï¼ˆæœ€åå‡ å±‚ï¼‰:\n",
      "...\n",
      "layer4: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "avgpool: AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "fc: Linear(in_features=512, out_features=1000, bias=True)\n",
      "\n",
      "åŸå§‹åˆ†ç±»å¤´: 512 â†’ 1000 (ImageNet 1000ç±»)\n"
     ]
    }
   ],
   "source": [
    "if HAS_TORCH:\n",
    "    # åŠ è½½é¢„è®­ç»ƒçš„ ResNet-18\n",
    "    # weights='DEFAULT' ä½¿ç”¨ ImageNet é¢„è®­ç»ƒæƒé‡\n",
    "    resnet = models.resnet18(weights='DEFAULT')\n",
    "    \n",
    "    print(\"ResNet-18 ç»“æ„ï¼ˆæœ€åå‡ å±‚ï¼‰:\")\n",
    "    print(\"...\")\n",
    "    for name, module in list(resnet.named_children())[-3:]:\n",
    "        print(f\"{name}: {module}\")\n",
    "    \n",
    "    print(f\"\\nåŸå§‹åˆ†ç±»å¤´: {resnet.fc.in_features} â†’ {resnet.fc.out_features} (ImageNet 1000ç±»)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» æ–¹æ³•1ï¼šç‰¹å¾æå–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç‰¹å¾æå–æ¨¡å¼:\n",
      "  æ€»å‚æ•°: 11,179,077\n",
      "  å¯è®­ç»ƒå‚æ•°: 2,565\n",
      "  å†»ç»“æ¯”ä¾‹: 100.0%\n",
      "\n",
      "ğŸ’¡ åªéœ€è¦è®­ç»ƒæœ€åä¸€å±‚ï¼\n"
     ]
    }
   ],
   "source": [
    "if HAS_TORCH:\n",
    "    # å¤åˆ¶æ¨¡å‹\n",
    "    model_feature_extract = models.resnet18(weights='DEFAULT')\n",
    "    \n",
    "    # å†»ç»“æ‰€æœ‰å±‚\n",
    "    for param in model_feature_extract.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # æ›¿æ¢åˆ†ç±»å¤´ï¼ˆå‡è®¾æ–°ä»»åŠ¡æ˜¯ 5 åˆ†ç±»ï¼‰\n",
    "    num_classes = 5\n",
    "    num_features = model_feature_extract.fc.in_features\n",
    "    model_feature_extract.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    # ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°\n",
    "    trainable_params = sum(p.numel() for p in model_feature_extract.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model_feature_extract.parameters())\n",
    "    \n",
    "    print(\"ç‰¹å¾æå–æ¨¡å¼:\")\n",
    "    print(f\"  æ€»å‚æ•°: {total_params:,}\")\n",
    "    print(f\"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "    print(f\"  å†»ç»“æ¯”ä¾‹: {(1 - trainable_params/total_params)*100:.1f}%\")\n",
    "    print(f\"\\nğŸ’¡ åªéœ€è¦è®­ç»ƒæœ€åä¸€å±‚ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» æ–¹æ³•2ï¼šå¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    # å¤åˆ¶æ¨¡å‹\n",
    "    model_finetune = models.resnet18(weights='DEFAULT')\n",
    "    \n",
    "    # å†»ç»“å‰é¢çš„å±‚ï¼ˆlayer1, layer2ï¼‰\n",
    "    for name, param in model_finetune.named_parameters():\n",
    "        if 'layer3' not in name and 'layer4' not in name and 'fc' not in name:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # æ›¿æ¢åˆ†ç±»å¤´\n",
    "    model_finetune.fc = nn.Linear(model_finetune.fc.in_features, num_classes)\n",
    "    \n",
    "    # ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°\n",
    "    trainable_params = sum(p.numel() for p in model_finetune.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(\"å¾®è°ƒæ¨¡å¼ (è§£å†» layer3, layer4, fc):\")\n",
    "    print(f\"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}\")\n",
    "    \n",
    "    # åˆ—å‡ºå¯è®­ç»ƒçš„å±‚\n",
    "    print(\"\\nå¯è®­ç»ƒçš„å±‚:\")\n",
    "    for name, param in model_finetune.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"  {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: å®Œæ•´è¿ç§»å­¦ä¹ é¡¹ç›®\n",
    "\n",
    "> ä½¿ç”¨ **Oxford Flowers 102** æ•°æ®é›†ï¼Œå¯¹æ¯”ä¸‰ç§ç­–ç•¥çš„å®é™…æ•ˆæœ\n",
    "\n",
    "## 2.1 æ•°æ®å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2.1 åŠ è½½ Flowers-102 æ•°æ®é›†\n",
    "# ============================================================\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# æ•°æ®å¢å¼º\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ä¸‹è½½æ•°æ®é›†\n",
    "print(\"ä¸‹è½½ Flowers-102 æ•°æ®é›†...\")\n",
    "train_dataset = datasets.Flowers102(root='./data', split='train', transform=train_transform, download=True)\n",
    "val_dataset = datasets.Flowers102(root='./data', split='val', transform=test_transform, download=True)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {len(train_dataset)} å¼ , éªŒè¯é›†: {len(val_dataset)} å¼ , ç±»åˆ«æ•°: 102\")\n",
    "\n",
    "# åˆ›å»º DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.2 å®šä¹‰ä¸‰ç§ç­–ç•¥çš„æ¨¡å‹\n",
    "\n",
    "æˆ‘ä»¬å°†å¯¹æ¯”ä¸‰ç§è¿ç§»å­¦ä¹ ç­–ç•¥ï¼š\n",
    "1. **ä»é›¶è®­ç»ƒ (Scratch)**ï¼šéšæœºåˆå§‹åŒ–ï¼Œè®­ç»ƒæ‰€æœ‰å±‚\n",
    "2. **ç‰¹å¾æå– (Feature Extraction)**ï¼šå†»ç»“é¢„è®­ç»ƒå±‚ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´\n",
    "3. **å¾®è°ƒ (Fine-tuning)**ï¼šä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œè§£å†»éƒ¨åˆ†å±‚ç»§ç»­è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å®šä¹‰ä¸‰ç§ç­–ç•¥çš„æ¨¡å‹\n",
    "# ============================================================\n",
    "\n",
    "num_classes = 102\n",
    "\n",
    "def create_model_scratch():\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def create_model_feature_extract():\n",
    "    model = models.resnet18(weights='DEFAULT')\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def create_model_finetune():\n",
    "    model = models.resnet18(weights='DEFAULT')\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'layer4' not in name and 'fc' not in name:\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# å‚æ•°ç»Ÿè®¡\n",
    "print(\"å‚æ•°ç»Ÿè®¡ï¼š\")\n",
    "for name, fn in [('Scratch', create_model_scratch), ('Feature Extract', create_model_feature_extract), ('Fine-tune', create_model_finetune)]:\n",
    "    m = fn()\n",
    "    trainable = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "    print(f\"  {name}: {trainable:,} å¯è®­ç»ƒå‚æ•°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.3 è®­ç»ƒä¸å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# è®­ç»ƒå‡½æ•°\n",
    "# ============================================================\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    return 100. * correct / total\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100. * correct / total\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, device, name):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    \n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    print(f\"\\nè®­ç»ƒ: {name}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        print(f\"  Epoch {epoch+1}: Train={train_acc:.1f}%, Val={val_acc:.1f}%\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# è®­ç»ƒä¸‰ç§ç­–ç•¥å¹¶å¯¹æ¯”\n",
    "# ============================================================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "EPOCHS = 5  # æ¼”ç¤ºç”¨ï¼Œå®é™…å¯å¢åŠ åˆ° 20-50\n",
    "LR = 1e-3\n",
    "\n",
    "all_histories = {}\n",
    "\n",
    "# 1. ä»é›¶è®­ç»ƒ\n",
    "model1 = create_model_scratch()\n",
    "h1 = train_model(model1, train_loader, val_loader, EPOCHS, LR, device, \"ä»é›¶è®­ç»ƒ (Scratch)\")\n",
    "all_histories['Scratch'] = h1\n",
    "\n",
    "# 2. ç‰¹å¾æå–\n",
    "model2 = create_model_feature_extract()\n",
    "h2 = train_model(model2, train_loader, val_loader, EPOCHS, LR, device, \"ç‰¹å¾æå– (Feature Extract)\")\n",
    "all_histories['Feature Extract'] = h2\n",
    "\n",
    "# 3. å¾®è°ƒ\n",
    "model3 = create_model_finetune()\n",
    "h3 = train_model(model3, train_loader, val_loader, EPOCHS, LR*0.1, device, \"å¾®è°ƒ (Fine-tune)\")\n",
    "all_histories['Fine-tune'] = h3\n",
    "\n",
    "print(\"\\nâœ… è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# å¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = {'Scratch': 'red', 'Feature Extract': 'blue', 'Fine-tune': 'green'}\n",
    "epochs_range = range(1, EPOCHS + 1)\n",
    "\n",
    "# è®­ç»ƒæ›²çº¿\n",
    "ax = axes[0]\n",
    "for name, history in all_histories.items():\n",
    "    ax.plot(epochs_range, history['train_acc'], color=colors[name], \n",
    "            linestyle='-', linewidth=2, label=f'{name} (Train)')\n",
    "    ax.plot(epochs_range, history['val_acc'], color=colors[name],\n",
    "            linestyle='--', linewidth=2, label=f'{name} (Val)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title('è®­ç»ƒæ›²çº¿å¯¹æ¯”')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# æœ€ç»ˆå‡†ç¡®ç‡æŸ±çŠ¶å›¾\n",
    "ax = axes[1]\n",
    "names = list(all_histories.keys())\n",
    "final_val_acc = [all_histories[n]['val_acc'][-1] for n in names]\n",
    "\n",
    "bars = ax.bar(names, final_val_acc, color=[colors[n] for n in names])\n",
    "ax.set_ylabel('Validation Accuracy (%)')\n",
    "ax.set_title('æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡å¯¹æ¯”')\n",
    "\n",
    "for bar, acc in zip(bars, final_val_acc):\n",
    "    ax.annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width()/2, acc),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ‰“å°æ€»ç»“\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ç»“æœæ€»ç»“\")\n",
    "print(\"=\"*50)\n",
    "for name in names:\n",
    "    print(f\"  {name:<20}: {all_histories[name]['val_acc'][-1]:.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ’¡ å…³é”®å‘ç°ï¼š\")\n",
    "print(\"   - è¿ç§»å­¦ä¹ æ¯”ä»é›¶è®­ç»ƒæ”¶æ•›æ›´å¿«\")\n",
    "print(\"   - é¢„è®­ç»ƒæƒé‡æä¾›äº†å¾ˆå¥½çš„åˆå§‹åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: è¿›é˜¶è¯é¢˜\n",
    "\n",
    "## 3.1 åŸŸå·®å¼‚ (Domain Shift)\n",
    "\n",
    "å½“æºåŸŸï¼ˆé¢„è®­ç»ƒæ•°æ®ï¼‰å’Œç›®æ ‡åŸŸï¼ˆä½ çš„æ•°æ®ï¼‰å·®å¼‚è¾ƒå¤§æ—¶ï¼Œè¿ç§»æ•ˆæœä¼šä¸‹é™ã€‚\n",
    "\n",
    "```\n",
    "åŸŸå·®å¼‚ç¤ºä¾‹ï¼š\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  å°åŸŸå·®å¼‚                          å¤§åŸŸå·®å¼‚                â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚\n",
    "â”‚  ImageNet â†’ èŠ±å‰åˆ†ç±»              ImageNet â†’ åŒ»å­¦å½±åƒ      â”‚\n",
    "â”‚  ImageNet â†’ å® ç‰©åˆ†ç±»              ImageNet â†’ å«æ˜Ÿå›¾åƒ      â”‚\n",
    "â”‚  ImageNet â†’ é£Ÿç‰©åˆ†ç±»              ImageNet â†’ æ˜¾å¾®é•œå›¾åƒ    â”‚\n",
    "â”‚                                                             â”‚\n",
    "â”‚  ç­–ç•¥ï¼šå†»ç»“æ›´å¤šå±‚                  ç­–ç•¥ï¼šè§£å†»æ›´å¤šå±‚         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## 3.2 è´Ÿè¿ç§» (Negative Transfer)\n",
    "\n",
    "**è´Ÿè¿ç§»**ï¼šä½¿ç”¨é¢„è®­ç»ƒæƒé‡åè€Œæ¯”ä»é›¶è®­ç»ƒæ•ˆæœæ›´å·®ã€‚\n",
    "\n",
    "**å¸¸è§åŸå› **ï¼š\n",
    "1. æºåŸŸå’Œç›®æ ‡åŸŸå·®å¼‚å¤ªå¤§\n",
    "2. é¢„è®­ç»ƒæ¨¡å‹è¿‡äºå¤æ‚ï¼ˆç›®æ ‡æ•°æ®å¤ªå°‘ï¼‰\n",
    "3. å­¦ä¹ ç‡è®¾ç½®ä¸å½“\n",
    "\n",
    "**å¦‚ä½•é¿å…**ï¼š\n",
    "- å…ˆåšå°è§„æ¨¡å®éªŒå¯¹æ¯”\n",
    "- ä»å†»ç»“æ›´å¤šå±‚å¼€å§‹ï¼Œé€æ­¥è§£å†»\n",
    "- ç›‘æ§éªŒè¯é›†è¡¨ç°\n",
    "\n",
    "## 3.3 åˆ†å±‚å­¦ä¹ ç‡\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**ï¼šä¸åŒå±‚ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡\n",
    "- æµ…å±‚ï¼ˆé€šç”¨ç‰¹å¾ï¼‰ï¼šå°å­¦ä¹ ç‡\n",
    "- æ·±å±‚ï¼ˆä»»åŠ¡ç‰¹å¾ï¼‰ï¼šå¤§å­¦ä¹ ç‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.4 ä¸åŒé¢„è®­ç»ƒæ¨¡å‹å¯¹æ¯”\n",
    "\n",
    "ResNet å®¶æ—æœ‰å¤šä¸ªç‰ˆæœ¬ï¼Œå‚æ•°é‡å’Œæ€§èƒ½ä¸åŒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet å®¶æ—å‚æ•°é‡å¯¹æ¯”ï¼š\n",
      "============================================================\n",
      "æ¨¡å‹                          å‚æ•°é‡  ImageNet Top-1\n",
      "------------------------------------------------------------\n",
      "ResNet-18               11.7M           69.8%\n",
      "ResNet-34               21.8M           73.3%\n",
      "ResNet-50               25.6M           76.1%\n",
      "ResNet-101              44.5M           77.4%\n",
      "ResNet-152              60.2M           78.3%\n",
      "\n",
      "ğŸ’¡ é€‰æ‹©å»ºè®®ï¼š\n",
      "   - å°æ•°æ®é›†/å¿«é€Ÿå®éªŒ: ResNet-18 (å‚æ•°å°‘ï¼Œè®­ç»ƒå¿«)\n",
      "   - è¿½æ±‚ç²¾åº¦: ResNet-50 (æ€§ä»·æ¯”æœ€é«˜)\n",
      "   - æè‡´ç²¾åº¦: ResNet-101/152 (éœ€è¦æ›´å¤šæ•°æ®å’Œç®—åŠ›)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ä¸åŒ ResNet ç‰ˆæœ¬å¯¹æ¯”\n",
    "# ============================================================\n",
    "\n",
    "# ResNet å®¶æ—\n",
    "resnet_models = {\n",
    "    'ResNet-18': models.resnet18,\n",
    "    'ResNet-34': models.resnet34,\n",
    "    'ResNet-50': models.resnet50,\n",
    "    'ResNet-101': models.resnet101,\n",
    "    'ResNet-152': models.resnet152,\n",
    "}\n",
    "\n",
    "print(\"ResNet å®¶æ—å‚æ•°é‡å¯¹æ¯”ï¼š\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'æ¨¡å‹':<15} {'å‚æ•°é‡':>15} {'ImageNet Top-1':>15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# ImageNet å‡†ç¡®ç‡æ•°æ®ï¼ˆæ¥è‡ª PyTorch å®˜æ–¹ï¼‰\n",
    "imagenet_acc = {\n",
    "    'ResNet-18': 69.8,\n",
    "    'ResNet-34': 73.3,\n",
    "    'ResNet-50': 76.1,\n",
    "    'ResNet-101': 77.4,\n",
    "    'ResNet-152': 78.3,\n",
    "}\n",
    "\n",
    "for name, model_fn in resnet_models.items():\n",
    "    model = model_fn(weights=None)  # ä¸ä¸‹è½½æƒé‡ï¼Œåªçœ‹ç»“æ„\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    acc = imagenet_acc[name]\n",
    "    print(f\"{name:<15} {params/1e6:>12.1f}M {acc:>14.1f}%\")\n",
    "\n",
    "print(\"\\nğŸ’¡ é€‰æ‹©å»ºè®®ï¼š\")\n",
    "print(\"   - å°æ•°æ®é›†/å¿«é€Ÿå®éªŒ: ResNet-18 (å‚æ•°å°‘ï¼Œè®­ç»ƒå¿«)\")\n",
    "print(\"   - è¿½æ±‚ç²¾åº¦: ResNet-50 (æ€§ä»·æ¯”æœ€é«˜)\")\n",
    "print(\"   - æè‡´ç²¾åº¦: ResNet-101/152 (éœ€è¦æ›´å¤šæ•°æ®å’Œç®—åŠ›)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸åŒ ResNet åšè¿ç§»å­¦ä¹ ï¼ˆ102 ç±»èŠ±å‰ï¼‰ï¼š\n",
      "============================================================\n",
      "\n",
      "RESNET18:\n",
      "  åˆ†ç±»å¤´è¾“å…¥: 512 ç»´\n",
      "  æ€»å‚æ•°: 11.2M\n",
      "  å¯è®­ç»ƒå‚æ•°: 8.4M (75.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /Users/lyh/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [01:01<00:00, 1.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESNET50:\n",
      "  åˆ†ç±»å¤´è¾“å…¥: 2048 ç»´\n",
      "  æ€»å‚æ•°: 23.7M\n",
      "  å¯è®­ç»ƒå‚æ•°: 15.2M (64.0%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ä½¿ç”¨ä¸åŒ ResNet åšè¿ç§»å­¦ä¹ \n",
    "# ============================================================\n",
    "\n",
    "def create_transfer_model(model_name='resnet18', num_classes=102, mode='finetune'):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºè¿ç§»å­¦ä¹ æ¨¡å‹\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model_name: 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'\n",
    "        num_classes: ç›®æ ‡ç±»åˆ«æ•°\n",
    "        mode: 'feature_extract' æˆ– 'finetune'\n",
    "    \"\"\"\n",
    "    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "    model_fn = getattr(models, model_name)\n",
    "    model = model_fn(weights='DEFAULT')\n",
    "    \n",
    "    # è·å–åˆ†ç±»å¤´çš„è¾“å…¥ç‰¹å¾æ•°\n",
    "    # ResNet-18/34: fc.in_features = 512\n",
    "    # ResNet-50/101/152: fc.in_features = 2048\n",
    "    in_features = model.fc.in_features\n",
    "    \n",
    "    if mode == 'feature_extract':\n",
    "        # å†»ç»“æ‰€æœ‰å±‚\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    elif mode == 'finetune':\n",
    "        # å†»ç»“æ—©æœŸå±‚ï¼Œè§£å†»åæœŸå±‚\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'layer4' not in name and 'fc' not in name:\n",
    "                param.requires_grad = False\n",
    "    \n",
    "    # æ›¿æ¢åˆ†ç±»å¤´\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# æ¼”ç¤ºï¼šåˆ›å»ºä¸åŒç‰ˆæœ¬çš„è¿ç§»å­¦ä¹ æ¨¡å‹\n",
    "print(\"ä¸åŒ ResNet åšè¿ç§»å­¦ä¹ ï¼ˆ102 ç±»èŠ±å‰ï¼‰ï¼š\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name in ['resnet18', 'resnet50']:\n",
    "    model = create_transfer_model(model_name, num_classes=102, mode='finetune')\n",
    "    \n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    print(f\"  åˆ†ç±»å¤´è¾“å…¥: {model.fc.in_features} ç»´\")\n",
    "    print(f\"  æ€»å‚æ•°: {total/1e6:.1f}M\")\n",
    "    print(f\"  å¯è®­ç»ƒå‚æ•°: {trainable/1e6:.1f}M ({trainable/total*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet-18 vs ResNet-50 å…³é”®åŒºåˆ«\n",
    "\n",
    "```\n",
    "ResNet-18/34: ä½¿ç”¨ BasicBlock (2å±‚å·ç§¯)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Conv 3Ã—3 â†’ BN â†’ ReLU â”‚\n",
    "â”‚ Conv 3Ã—3 â†’ BN       â”‚\n",
    "â”‚        + x          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "fc.in_features = 512\n",
    "\n",
    "ResNet-50/101/152: ä½¿ç”¨ Bottleneck (3å±‚å·ç§¯)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Conv 1Ã—1 â†’ BN â†’ ReLU â”‚  â† é™ç»´\n",
    "â”‚ Conv 3Ã—3 â†’ BN â†’ ReLU â”‚  â† æç‰¹å¾\n",
    "â”‚ Conv 1Ã—1 â†’ BN       â”‚  â† å‡ç»´\n",
    "â”‚        + x          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "fc.in_features = 2048\n",
    "```\n",
    "\n",
    "**å®é™…ä½¿ç”¨å»ºè®®**ï¼š\n",
    "- å¿«é€ŸéªŒè¯æƒ³æ³• â†’ ResNet-18\n",
    "- æ­£å¼é¡¹ç›® â†’ ResNet-50ï¼ˆæ€§ä»·æ¯”æœ€é«˜ï¼‰\n",
    "- è®¡ç®—èµ„æºå……è¶³ â†’ ResNet-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# åˆ†å±‚å­¦ä¹ ç‡ç¤ºä¾‹\n",
    "# ============================================================\n",
    "\n",
    "def create_layerwise_optimizer(model, base_lr=1e-3):\n",
    "    \"\"\"\n",
    "    ä¸ºä¸åŒå±‚è®¾ç½®ä¸åŒå­¦ä¹ ç‡\n",
    "    \n",
    "    - æ—©æœŸå±‚: base_lr * 0.01\n",
    "    - ä¸­é—´å±‚: base_lr * 0.1  \n",
    "    - åæœŸå±‚: base_lr * 0.5\n",
    "    - åˆ†ç±»å¤´: base_lr\n",
    "    \"\"\"\n",
    "    param_groups = [\n",
    "        {'params': [p for n, p in model.named_parameters() \n",
    "                   if any(x in n for x in ['conv1', 'bn1', 'layer1', 'layer2'])],\n",
    "         'lr': base_lr * 0.01, 'name': 'early_layers'},\n",
    "        {'params': model.layer3.parameters(), 'lr': base_lr * 0.1, 'name': 'layer3'},\n",
    "        {'params': model.layer4.parameters(), 'lr': base_lr * 0.5, 'name': 'layer4'},\n",
    "        {'params': model.fc.parameters(), 'lr': base_lr, 'name': 'fc'},\n",
    "    ]\n",
    "    return torch.optim.Adam(param_groups)\n",
    "\n",
    "# æ¼”ç¤º\n",
    "demo_model = models.resnet18(weights='DEFAULT')\n",
    "demo_model.fc = nn.Linear(512, num_classes)\n",
    "opt = create_layerwise_optimizer(demo_model)\n",
    "\n",
    "print(\"åˆ†å±‚å­¦ä¹ ç‡é…ç½®ï¼š\")\n",
    "for g in opt.param_groups:\n",
    "    print(f\"  {g.get('name', 'unknown')}: lr = {g['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.4 å®ç”¨å»ºè®®æ¸…å•\n",
    "\n",
    "### è¿ç§»å­¦ä¹ å†³ç­–æµç¨‹\n",
    "\n",
    "```\n",
    "æ•°æ®é‡å¤§ï¼Ÿ â”€â”€æ˜¯â”€â”€â†’ åŸŸå·®å¼‚å¤§ï¼Ÿ â”€â”€æ˜¯â”€â”€â†’ ä»é›¶è®­ç»ƒ\n",
    "    â”‚                  â”‚\n",
    "   å¦                 å¦\n",
    "    â”‚                  â”‚\n",
    "    â–¼                  â–¼\n",
    "ç‰¹å¾æå–          å¾®è°ƒï¼ˆè§£å†»éƒ¨åˆ†å±‚ï¼‰\n",
    "```\n",
    "\n",
    "### å…³é”®å»ºè®®è¡¨\n",
    "\n",
    "| åœºæ™¯ | æ¨èç­–ç•¥ | å­¦ä¹ ç‡ |\n",
    "|------|----------|--------|\n",
    "| æ•°æ®å°‘ + åŸŸå·®å¼‚å° | ç‰¹å¾æå– | 1e-3 |\n",
    "| æ•°æ®ä¸­ç­‰ | å¾®è°ƒåå‡ å±‚ | 1e-4 ~ 1e-3 |\n",
    "| æ•°æ®å¤š + åŸŸå·®å¼‚å¤§ | å¾®è°ƒå…¨éƒ¨ / ä»é›¶è®­ç»ƒ | 1e-4 |\n",
    "\n",
    "### å¸¸è§é”™è¯¯\n",
    "\n",
    "1. âŒ å¾®è°ƒæ—¶å­¦ä¹ ç‡å¤ªå¤§ â†’ ç ´åé¢„è®­ç»ƒç‰¹å¾\n",
    "2. âŒ æ•°æ®é¢„å¤„ç†ä¸ä¸€è‡´ â†’ ç‰¹å¾ä¸åŒ¹é…\n",
    "3. âŒ åªçœ‹è®­ç»ƒå‡†ç¡®ç‡ â†’ è¿‡æ‹Ÿåˆä¸¥é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æœ¬ç« å°ç»“\n",
    "\n",
    "### æ ¸å¿ƒçŸ¥è¯†ç‚¹\n",
    "\n",
    "1. **ä¸‰ç§è¿ç§»ç­–ç•¥**ï¼šä»é›¶è®­ç»ƒã€ç‰¹å¾æå–ã€å¾®è°ƒ\n",
    "2. **å…³é”®æŠ€å·§**ï¼šImageNet é¢„å¤„ç†ã€åˆ†å±‚å­¦ä¹ ç‡\n",
    "3. **å†³ç­–å› ç´ **ï¼šæ•°æ®é‡ã€åŸŸå·®å¼‚\n",
    "\n",
    "### å®éªŒç»“è®º\n",
    "\n",
    "åœ¨ Flowers-102 ä¸Šï¼šè¿ç§»å­¦ä¹  > ä»é›¶è®­ç»ƒï¼Œå°æ•°æ®é›†ä¼˜åŠ¿æ˜æ˜¾ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç»§ç»­å­¦ä¹  **09_feature_visualization.ipynb** - ç‰¹å¾å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HAS_TORCH:\n",
    "    # è®­ç»ƒé…ç½®\n",
    "    def get_optimizer(model, mode='feature_extract'):\n",
    "        \"\"\"\n",
    "        æ ¹æ®è¿ç§»å­¦ä¹ æ¨¡å¼é…ç½®ä¼˜åŒ–å™¨\n",
    "        \n",
    "        - feature_extract: åªè®­ç»ƒ fc å±‚\n",
    "        - finetune: ä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡\n",
    "        \"\"\"\n",
    "        if mode == 'feature_extract':\n",
    "            # åªä¼˜åŒ– fc å±‚\n",
    "            return torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "        \n",
    "        elif mode == 'finetune':\n",
    "            # ä¸åŒå±‚ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡\n",
    "            # è¶Šé è¿‘è¾“å‡ºçš„å±‚ï¼Œå­¦ä¹ ç‡è¶Šé«˜\n",
    "            param_groups = [\n",
    "                {'params': model.layer3.parameters(), 'lr': 1e-5},\n",
    "                {'params': model.layer4.parameters(), 'lr': 1e-4},\n",
    "                {'params': model.fc.parameters(), 'lr': 1e-3},\n",
    "            ]\n",
    "            return torch.optim.Adam(param_groups)\n",
    "    \n",
    "    print(\"ä¼˜åŒ–å™¨é…ç½®:\")\n",
    "    print(\"  ç‰¹å¾æå–: fc å±‚ lr=1e-3\")\n",
    "    print(\"  å¾®è°ƒ: layer3 lr=1e-5, layer4 lr=1e-4, fc lr=1e-3\")\n",
    "    print(\"\\nğŸ’¡ è¶Šé è¿‘è¾“å…¥çš„å±‚ï¼Œå­¦ä¹ ç‡è¶Šå°ï¼ˆä¿ç•™é€šç”¨ç‰¹å¾ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç»§ç»­å­¦ä¹  **09_feature_visualization.ipynb** - ç‰¹å¾å¯è§†åŒ–"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
