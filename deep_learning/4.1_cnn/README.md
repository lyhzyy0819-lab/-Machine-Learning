# 4.1 卷积神经网络 (CNN)

> 从直觉到实现，掌握计算机视觉的核心架构

---

## 为什么学习 CNN？

CNN（Convolutional Neural Network）是计算机视觉的基石：

- **图像分类**：识别图像中的物体（猫、狗、汽车...）
- **目标检测**：找出图像中物体的位置
- **图像分割**：像素级别的分类
- **人脸识别**：身份验证系统
- **医学影像**：辅助诊断

> 理解 CNN 是进入计算机视觉领域的必经之路！

---

## 学习目标

完成本模块后，你将能够：

1. **理解卷积原理**：知道卷积为什么对图像有效
2. **手写卷积层**：用 NumPy 从零实现 2D 卷积
3. **构建 CNN 架构**：搭建完整的卷积神经网络
4. **理解反向传播**：推导并实现 CNN 的梯度计算
5. **了解经典模型**：LeNet → AlexNet → VGG → ResNet 的演进
6. **应用迁移学习**：使用预训练模型解决实际问题
7. **可视化理解**：知道 CNN "看到了什么"

---

## 前置知识

在学习本模块前，请确保已掌握：

- [x] **阶段3 神经网络基础**：前向传播、反向传播、激活函数
- [x] **PyTorch/TensorFlow 基础**：张量操作、自动微分
- [x] **NumPy 熟练使用**：矩阵运算、广播机制
- [x] **基本的线性代数**：矩阵乘法、转置

---

## 模块结构

```
4.1_cnn/
│
├── 📖 基础概念 (01-02)
│   ├── 01_why_convolution.ipynb      # 为什么需要卷积？
│   └── 02_convolution_math.ipynb     # 卷积的数学原理
│
├── 💻 从零实现 (03-06)
│   ├── 03_convolution_from_scratch.ipynb  # 手写卷积层
│   ├── 04_pooling_layers.ipynb       # 池化层详解
│   ├── 05_cnn_architecture.ipynb     # 完整 CNN 架构
│   └── 06_cnn_backprop.ipynb         # CNN 反向传播
│
├── 🏛️ 经典与应用 (07-09)
│   ├── 07_classic_architectures.ipynb # 经典 CNN 架构
│   ├── 08_transfer_learning.ipynb    # 迁移学习
│   └── 09_feature_visualization.ipynb # 特征可视化
│
└── 🎯 实战项目
    └── project_mnist_classifier.py   # MNIST 手写数字分类
```

---

## 学习路径

### 推荐顺序

```
01 为什么需要卷积？
    ↓
02 卷积的数学原理
    ↓
03 从零实现卷积  ← 核心！务必手写实现
    ↓
04 池化层详解
    ↓
05 完整 CNN 架构
    ↓
06 CNN 反向传播  ← 理解梯度流
    ↓
07 经典 CNN 架构  ← 了解历史演进
    ↓
08 迁移学习  ← 实战必备技能
    ↓
09 特征可视化  ← 理解模型行为
    ↓
🎯 项目：MNIST 分类器
```

### 时间估计

| 章节 | 内容 | 预计时间 |
|------|------|----------|
| 01-02 | 概念与数学 | 2-3 小时 |
| 03-04 | 卷积与池化实现 | 4-5 小时 |
| 05-06 | 完整架构与反向传播 | 4-5 小时 |
| 07-09 | 经典架构与应用 | 3-4 小时 |
| 项目 | MNIST 分类器 | 2-3 小时 |
| **总计** | | **15-20 小时** |

---

## 核心概念速览

### CNN vs MLP 对比

| 特性 | MLP (全连接) | CNN (卷积) |
|------|-------------|-----------|
| 参数量 | 巨大（与输入大小成正比） | 较小（与核大小相关） |
| 局部性 | 无（每个输入连接每个神经元） | 有（只看局部区域） |
| 平移不变性 | 无 | 有（同一个核扫描全图） |
| 适用场景 | 表格数据、简单分类 | 图像、视频、信号 |

### 关键组件

```
输入图像 → [卷积层] → [激活函数] → [池化层] → ... → [全连接层] → 输出
              ↓           ↓            ↓
          特征提取      非线性        下采样
```

- **卷积层 (Conv)**：提取局部特征
- **激活函数 (ReLU)**：引入非线性
- **池化层 (Pool)**：降低空间维度
- **全连接层 (FC)**：最终分类/回归

---

## 符号约定

本模块使用的符号及读音：

| 符号 | 读音 | 含义 |
|------|------|------|
| $*$ | "卷积" | 卷积运算符 |
| $K$ 或 $W$ | "核" 或 "权重" | 卷积核/滤波器 |
| $p$ | "padding" | 填充 |
| $s$ | "stride" | 步幅 |
| $C_{in}$ | "输入通道数" | 输入特征图的通道数 |
| $C_{out}$ | "输出通道数" | 输出特征图的通道数 |
| $H, W$ | "高度, 宽度" | 特征图的空间尺寸 |
| $k_h, k_w$ | "核高, 核宽" | 卷积核尺寸 |

---

## 常见问题

### Q1: 为什么卷积比全连接好？

**参数效率**：一个 3×3 的卷积核只有 9 个参数，但可以检测整张图的特征。全连接需要为每个位置单独学习。

### Q2: 什么是感受野？

**感受野 (Receptive Field)**：输出特征图上一个点"看到"的输入区域大小。随着网络深度增加，感受野也增大。

### Q3: 为什么要用池化？

- **降低计算量**：减少后续层的参数
- **增加平移不变性**：小的位移不影响输出
- **防止过拟合**：减少参数数量

### Q4: 1x1 卷积有什么用？

- **改变通道数**：不改变空间尺寸，只改变深度
- **增加非线性**：配合激活函数
- **降维**：减少计算量

---

## 动手练习清单

每章都有练习，请务必完成：

- [ ] 01: 计算不同图像尺寸的全连接参数量
- [ ] 02: 手推输出尺寸公式
- [ ] 03: 用 NumPy 实现 2D 卷积
- [ ] 04: 实现最大池化和平均池化
- [ ] 05: 追踪特征图形状变化
- [ ] 06: 推导卷积层的梯度公式
- [ ] 07: 用 PyTorch 复现 LeNet-5
- [ ] 08: 使用预训练 ResNet 微调
- [ ] 09: 用 Grad-CAM 可视化模型关注区域

---

## 参考资源

### 经典论文
- LeNet-5 (1998): [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)
- AlexNet (2012): [ImageNet Classification with Deep CNNs](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)
- VGGNet (2014): [Very Deep Convolutional Networks](https://arxiv.org/abs/1409.1556)
- ResNet (2015): [Deep Residual Learning](https://arxiv.org/abs/1512.03385)

### 可视化工具
- [CNN Explainer](https://poloclub.github.io/cnn-explainer/) - 交互式 CNN 可视化
- [Netron](https://netron.app/) - 模型结构可视化

---

## 下一步

完成本模块后，你可以：

1. **4.2 RNN** - 学习处理序列数据
2. **阶段5.1 计算机视觉** - 深入目标检测、图像分割
3. **实战项目** - 参加 Kaggle 图像竞赛

---

**开始学习吧！** 从 `01_why_convolution.ipynb` 开始！
