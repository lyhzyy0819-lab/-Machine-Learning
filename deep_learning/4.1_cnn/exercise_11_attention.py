"""
11 æ³¨æ„åŠ›æœºåˆ¶ç»ƒä¹ é¢˜è§£ç­”

ç»ƒä¹  1ï¼šSE å‚æ•°é‡è®¡ç®—
ç»ƒä¹  2ï¼šä¸åŒ reduction ratio çš„ SE æ¨¡å—
ç»ƒä¹  3ï¼šCBAM é›†æˆåˆ° VGGï¼ˆæ¦‚å¿µæ¡†æ¶ï¼‰
ç»ƒä¹  4ï¼šè‡ªå®šä¹‰æ³¨æ„åŠ›æ¨¡å—è®¾è®¡

è¿è¡Œæ–¹æ³•ï¼š
    python exercise_11_attention.py
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F


# ============================================================
# ç»ƒä¹  1ï¼šSE å‚æ•°é‡è®¡ç®—
# ============================================================

def exercise_1_se_params():
    """
    è®¡ç®— SE æ¨¡å—å¢åŠ çš„å‚æ•°é‡

    SE æ¨¡å—å‚æ•° = FC1 å‚æ•° + FC2 å‚æ•°
               = C Ã— (C/r) + (C/r) Ã— C
               = 2 Ã— CÂ² / r

    é—®é¢˜ï¼š
    1. é€šé“æ•° 256ï¼Œreduction=16
    2. é€šé“æ•° 512ï¼Œreduction=32
    """
    print("=" * 60)
    print("ç»ƒä¹  1ï¼šSE å‚æ•°é‡è®¡ç®—")
    print("=" * 60)

    def calculate_se_params(C, r):
        """è®¡ç®— SE æ¨¡å—å‚æ•°é‡"""
        fc1_params = C * (C // r)  # é™ç»´å±‚
        fc2_params = (C // r) * C  # å‡ç»´å±‚
        total = fc1_params + fc2_params
        return total, fc1_params, fc2_params

    # æ¡ˆä¾‹ 1
    print("\næ¡ˆä¾‹ 1: C=256, r=16")
    print("-" * 50)
    total, fc1, fc2 = calculate_se_params(256, 16)
    print(f"  FC1 (256 â†’ 16): {fc1:,}")
    print(f"  FC2 (16 â†’ 256): {fc2:,}")
    print(f"  æ€»å‚æ•°: {total:,}")
    print(f"  ç†è®ºå€¼: 2 Ã— 256Â² / 16 = {2 * 256**2 // 16:,}")

    # æ¡ˆä¾‹ 2
    print("\næ¡ˆä¾‹ 2: C=512, r=32")
    print("-" * 50)
    total, fc1, fc2 = calculate_se_params(512, 32)
    print(f"  FC1 (512 â†’ 16): {fc1:,}")
    print(f"  FC2 (16 â†’ 512): {fc2:,}")
    print(f"  æ€»å‚æ•°: {total:,}")
    print(f"  ç†è®ºå€¼: 2 Ã— 512Â² / 32 = {2 * 512**2 // 32:,}")

    # ä¸ä¸»å¹²ç½‘ç»œå¯¹æ¯”
    print("\nğŸ’¡ ä¸ ResNet çš„å¯¹æ¯”ï¼š")
    print("   ResNet-50 æ€»å‚æ•°: ~25M")
    print("   SE-ResNet-50 å¢åŠ : ~2.5M (çº¦ 10%)")
    print("   ä½†å‡†ç¡®ç‡æå‡ ~1-2%ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼")


# ============================================================
# ç»ƒä¹  2ï¼šä¸åŒ reduction ratio çš„ SE æ¨¡å—
# ============================================================

class SEModule(nn.Module):
    """SE æ¨¡å—å®ç°"""

    def __init__(self, channels, reduction=16):
        super().__init__()
        self.channels = channels
        self.reduction = reduction

        self.squeeze = nn.AdaptiveAvgPool2d(1)
        self.excitation = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        N, C, H, W = x.shape
        z = self.squeeze(x).view(N, C)
        s = self.excitation(z).view(N, C, 1, 1)
        return x * s


def exercise_2_reduction_ratio():
    """ä¸åŒ reduction ratio å®éªŒ"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  2ï¼šä¸åŒ Reduction Ratio çš„ SE æ¨¡å—")
    print("=" * 60)

    channels = 256
    reductions = [4, 8, 16, 32]

    print(f"\né€šé“æ•°: {channels}")
    print(f"\n{'Reduction':>10} {'ä¸­é—´ç»´åº¦':>10} {'å‚æ•°é‡':>12} {'ç›¸å¯¹ r=16':>12}")
    print("-" * 46)

    base_params = None
    for r in reductions:
        se = SEModule(channels, reduction=r)
        params = sum(p.numel() for p in se.parameters())

        if r == 16:
            base_params = params

        mid_dim = channels // r
        ratio = params / base_params if base_params else 1.0
        print(f"{r:>10} {mid_dim:>10} {params:>12,} {ratio:>11.2f}x")

    print("\nğŸ’¡ æƒè¡¡åˆ†æï¼š")
    print("   - r=4: å‚æ•°å¤šï¼Œè¡¨è¾¾èƒ½åŠ›å¼ºï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ")
    print("   - r=8: å‚æ•°é€‚ä¸­ï¼Œå¸¸è§é€‰æ‹©")
    print("   - r=16: åŸè®ºæ–‡é»˜è®¤å€¼ï¼Œå¹³è¡¡æ€§å¥½")
    print("   - r=32: å‚æ•°å°‘ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯")

    # å®é™…æµ‹è¯•å‰å‘ä¼ æ’­
    print("\nå‰å‘ä¼ æ’­æµ‹è¯•ï¼š")
    x = torch.randn(2, channels, 16, 16)
    for r in reductions:
        se = SEModule(channels, reduction=r)
        y = se(x)
        assert y.shape == x.shape, "å½¢çŠ¶ä¸åŒ¹é…"
    print("   âœ“ æ‰€æœ‰ reduction ratio çš„ SE æ¨¡å—æµ‹è¯•é€šè¿‡")


# ============================================================
# ç»ƒä¹  3ï¼šCBAM é›†æˆåˆ° VGG
# ============================================================

class SpatialAttention(nn.Module):
    """ç©ºé—´æ³¨æ„åŠ›æ¨¡å—"""

    def __init__(self, kernel_size=7):
        super().__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        concat = torch.cat([avg_out, max_out], dim=1)
        attention = self.sigmoid(self.conv(concat))
        return x * attention


class ChannelAttention(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆCBAM ç‰ˆæœ¬ï¼‰"""

    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)

        self.mlp = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        N, C, H, W = x.shape
        avg_out = self.mlp(self.avg_pool(x).view(N, C))
        max_out = self.mlp(self.max_pool(x).view(N, C))
        attention = self.sigmoid(avg_out + max_out).view(N, C, 1, 1)
        return x * attention


class CBAM(nn.Module):
    """CBAM æ¨¡å—"""

    def __init__(self, channels, reduction=16, kernel_size=7):
        super().__init__()
        self.channel_attention = ChannelAttention(channels, reduction)
        self.spatial_attention = SpatialAttention(kernel_size)

    def forward(self, x):
        x = self.channel_attention(x)
        x = self.spatial_attention(x)
        return x


def exercise_3_cbam_vgg():
    """CBAM é›†æˆåˆ° VGG çš„æ¦‚å¿µæ¡†æ¶"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  3ï¼šCBAM é›†æˆåˆ° VGG")
    print("=" * 60)

    print("""
VGG with CBAM çš„è®¾è®¡æ€è·¯ï¼š

1. VGG åŸå§‹ç»“æ„
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   VGG-16 åŒ…å« 5 ä¸ªå·ç§¯å—ï¼š
   - Block 1: 2 Ã— Conv(64)  â†’ MaxPool
   - Block 2: 2 Ã— Conv(128) â†’ MaxPool
   - Block 3: 3 Ã— Conv(256) â†’ MaxPool
   - Block 4: 3 Ã— Conv(512) â†’ MaxPool
   - Block 5: 3 Ã— Conv(512) â†’ MaxPool

2. æ·»åŠ  CBAM çš„ä½ç½®
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   æ–¹æ¡ˆ A: æ¯ä¸ªå·ç§¯å—åæ·»åŠ  CBAM
   æ–¹æ¡ˆ B: æ¯ä¸ª Conv-ReLU åæ·»åŠ  CBAM
   æ–¹æ¡ˆ C: åªåœ¨ç‰¹å®šå—åæ·»åŠ ï¼ˆå¦‚ Block 3, 4, 5ï¼‰

3. æ¨èæ–¹æ¡ˆï¼šæ¯ä¸ªå—çš„æœ€åä¸€ä¸ªå·ç§¯åæ·»åŠ 
   è¿™æ ·å¯ä»¥åœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶è·å¾—æ³¨æ„åŠ›å¢å¼ºã€‚
""")

    # ç®€åŒ–ç‰ˆ VGG Block with CBAM
    class VGGBlockWithCBAM(nn.Module):
        """å¸¦ CBAM çš„ VGG å·ç§¯å—"""

        def __init__(self, in_channels, out_channels, num_convs):
            super().__init__()

            layers = []
            for i in range(num_convs):
                layers.append(nn.Conv2d(
                    in_channels if i == 0 else out_channels,
                    out_channels, 3, padding=1
                ))
                layers.append(nn.BatchNorm2d(out_channels))
                layers.append(nn.ReLU(inplace=True))

            self.convs = nn.Sequential(*layers)
            self.cbam = CBAM(out_channels)
            self.pool = nn.MaxPool2d(2)

        def forward(self, x):
            x = self.convs(x)
            x = self.cbam(x)  # åœ¨å·ç§¯ååº”ç”¨ CBAM
            x = self.pool(x)
            return x

    # æµ‹è¯•
    block = VGGBlockWithCBAM(64, 128, num_convs=2)
    x = torch.randn(1, 64, 32, 32)
    y = block(x)

    print(f"VGG Block with CBAM æµ‹è¯•ï¼š")
    print(f"  è¾“å…¥: {x.shape}")
    print(f"  è¾“å‡º: {y.shape}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in block.parameters()):,}")


# ============================================================
# ç»ƒä¹  4ï¼šè‡ªå®šä¹‰æ³¨æ„åŠ›æ¨¡å—è®¾è®¡
# ============================================================

class ParallelAttention(nn.Module):
    """
    å¹¶è¡Œæ³¨æ„åŠ›æ¨¡å—ï¼ˆè‡ªå®šä¹‰è®¾è®¡ï¼‰

    ä¸ CBAM çš„ä¸²è”ä¸åŒï¼Œè¿™é‡Œå¹¶è¡Œè®¡ç®—é€šé“å’Œç©ºé—´æ³¨æ„åŠ›ï¼Œç„¶åç›¸åŠ ã€‚

    ç»“æ„:
        x â†’ ChannelAttention â†’ â”€â”
                                 â”œâ†’ ç›¸åŠ  â†’ è¾“å‡º
        x â†’ SpatialAttention â†’ â”€â”˜
    """

    def __init__(self, channels, reduction=16, kernel_size=7):
        super().__init__()

        # é€šé“æ³¨æ„åŠ›åˆ†æ”¯
        self.channel_att = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )

        # ç©ºé—´æ³¨æ„åŠ›åˆ†æ”¯
        self.spatial_att = nn.Sequential(
            nn.Conv2d(channels, 1, kernel_size, padding=kernel_size//2, bias=False),
            nn.Sigmoid()
        )

        # èåˆæƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰
        self.alpha = nn.Parameter(torch.tensor(0.5))

    def forward(self, x):
        N, C, H, W = x.shape

        # é€šé“æ³¨æ„åŠ›
        ca = self.channel_att(x).view(N, C, 1, 1)
        x_ca = x * ca

        # ç©ºé—´æ³¨æ„åŠ›
        sa = self.spatial_att(x)
        x_sa = x * sa

        # åŠ æƒèåˆ
        out = self.alpha * x_ca + (1 - self.alpha) * x_sa

        return out


class MultiScaleAttention(nn.Module):
    """
    å¤šå°ºåº¦æ³¨æ„åŠ›æ¨¡å—ï¼ˆè‡ªå®šä¹‰è®¾è®¡ï¼‰

    ä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸æ•è·å¤šå°ºåº¦çš„ç©ºé—´å…³ç³»ã€‚
    """

    def __init__(self, channels):
        super().__init__()

        # å¤šå°ºåº¦å·ç§¯
        self.conv3 = nn.Conv2d(channels, channels // 4, 3, padding=1, groups=channels // 4)
        self.conv5 = nn.Conv2d(channels, channels // 4, 5, padding=2, groups=channels // 4)
        self.conv7 = nn.Conv2d(channels, channels // 4, 7, padding=3, groups=channels // 4)

        # èåˆ
        self.fuse = nn.Conv2d(channels * 3 // 4, channels, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # å¤šå°ºåº¦ç‰¹å¾
        f3 = self.conv3(x)
        f5 = self.conv5(x)
        f7 = self.conv7(x)

        # æ‹¼æ¥å¹¶èåˆ
        concat = torch.cat([f3, f5, f7], dim=1)
        attention = self.sigmoid(self.fuse(concat))

        return x * attention


def exercise_4_custom_attention():
    """è‡ªå®šä¹‰æ³¨æ„åŠ›æ¨¡å—è®¾è®¡"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  4ï¼šè‡ªå®šä¹‰æ³¨æ„åŠ›æ¨¡å—è®¾è®¡")
    print("=" * 60)

    print("\nè®¾è®¡ 1: ParallelAttentionï¼ˆå¹¶è¡Œæ³¨æ„åŠ›ï¼‰")
    print("-" * 50)

    pa = ParallelAttention(channels=64)
    x = torch.randn(2, 64, 16, 16)
    y = pa(x)

    print(f"  è¾“å…¥: {x.shape}")
    print(f"  è¾“å‡º: {y.shape}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in pa.parameters()):,}")
    print(f"  èåˆæƒé‡ alpha: {pa.alpha.item():.3f}")

    print("\nè®¾è®¡ 2: MultiScaleAttentionï¼ˆå¤šå°ºåº¦æ³¨æ„åŠ›ï¼‰")
    print("-" * 50)

    msa = MultiScaleAttention(channels=64)
    y2 = msa(x)

    print(f"  è¾“å…¥: {x.shape}")
    print(f"  è¾“å‡º: {y2.shape}")
    print(f"  å‚æ•°é‡: {sum(p.numel() for p in msa.parameters()):,}")

    print("\nğŸ’¡ è‡ªå®šä¹‰æ³¨æ„åŠ›æ¨¡å—çš„è®¾è®¡æ€è·¯ï¼š")
    print("   1. è€ƒè™‘ä¸åŒç»´åº¦ï¼ˆé€šé“ã€ç©ºé—´ã€æ—¶é—´ï¼‰")
    print("   2. è€ƒè™‘ä¸åŒå°ºåº¦ï¼ˆå¤šå°ºåº¦å·ç§¯ï¼‰")
    print("   3. è€ƒè™‘ä¸åŒèåˆæ–¹å¼ï¼ˆä¸²è”ã€å¹¶è¡Œã€åŠ æƒï¼‰")
    print("   4. ä¿æŒè½»é‡åŒ–ï¼ˆé¿å…å¼•å…¥è¿‡å¤šå‚æ•°ï¼‰")


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + "  11 æ³¨æ„åŠ›æœºåˆ¶ç»ƒä¹ é¢˜è§£ç­”  ".center(58) + "â•‘")
    print("â•š" + "â•" * 58 + "â•")

    exercise_1_se_params()
    exercise_2_reduction_ratio()
    exercise_3_cbam_vgg()
    exercise_4_custom_attention()

    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç»ƒä¹ å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
