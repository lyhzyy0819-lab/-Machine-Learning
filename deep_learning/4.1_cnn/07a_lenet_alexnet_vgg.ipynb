{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07a æ—©æœŸç»å…¸ CNN æ¶æ„ï¼šLeNetã€AlexNetã€VGGNet\n",
    "\n",
    "> ä»æ‰‹å†™è¯†åˆ«åˆ° ImageNet éœ¸ä¸»ï¼šCNN å‘å±•çš„å¥ åŸºä¹‹è·¯\n",
    "\n",
    "---\n",
    "\n",
    "**æœ¬ç« é‡ç‚¹**ï¼šç†è§£ CNN ä»è¯ç”Ÿåˆ°æˆç†Ÿçš„æ¼”è¿›å†ç¨‹ï¼ŒæŒæ¡ä¸‰ä¸ªé‡Œç¨‹ç¢‘æ¶æ„çš„æ ¸å¿ƒè®¾è®¡æ€æƒ³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "- [ ] ç†è§£ CNN å‘å±•çš„å†å²è„‰ç»œ\n",
    "- [ ] **æŒæ¡ LeNet-5 çš„å¼€åˆ›æ€§è®¾è®¡**\n",
    "- [ ] **ç†è§£ AlexNet å¸¦æ¥çš„å…³é”®åˆ›æ–°ï¼ˆReLUã€Dropoutã€GPUï¼‰**\n",
    "- [ ] **æŒæ¡ VGGNet çš„ 3Ã—3 å°å·ç§¯å †å æ€æƒ³**\n",
    "- [ ] èƒ½å¤Ÿä½¿ç”¨ PyTorch å®ç°è¿™ä¸‰ä¸ªç»å…¸æ¶æ„\n",
    "- [ ] ç†è§£æ¶æ„æ¼”è¿›èƒŒåçš„è®¾è®¡å“²å­¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” å‰ç½®çŸ¥è¯†\n",
    "\n",
    "åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»æŒæ¡ï¼š\n",
    "\n",
    "- **02_convolution_math.ipynb** - å·ç§¯çš„æ•°å­¦åŸç†\n",
    "- **03_convolution_from_scratch.ipynb** - å·ç§¯çš„ä»é›¶å®ç°\n",
    "- **04_pooling_layers.ipynb** - æ± åŒ–å±‚åŸç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®è®¾å¤‡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CNN å‘å±•æ—¶é—´çº¿\n",
    "\n",
    "```\n",
    "1998: LeNet-5      â†’ ç¬¬ä¸€ä¸ªæˆåŠŸçš„ CNNï¼Œé“¶è¡Œæ”¯ç¥¨è¯†åˆ«\n",
    "        â†“\n",
    "     ï¼ˆAI å¯’å†¬ï¼Œç¥ç»ç½‘ç»œç ”ç©¶ä½è¿·ï¼‰\n",
    "        â†“\n",
    "2012: AlexNet      â†’ ReLU + Dropout + GPUï¼ŒImageNet å† å†›ï¼Œå¼€å¯æ·±åº¦å­¦ä¹ æ—¶ä»£\n",
    "        â†“\n",
    "2014: VGGNet       â†’ 3Ã—3 å°å·ç§¯å †å ï¼Œè¯æ˜\"æ›´æ·±æ›´å¥½\"\n",
    "        â†“\n",
    "2014: GoogLeNet    â†’ Inception å¤šå°ºåº¦å¹¶è¡Œå·ç§¯\n",
    "        â†“\n",
    "2015: ResNet       â†’ æ®‹å·®è¿æ¥ï¼Œçªç ´æ·±åº¦é™åˆ¶ï¼ˆ152å±‚ï¼‰\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– CNN å‘å±•æ—¶é—´çº¿\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# æ—¶é—´çº¿æ•°æ®\n",
    "years = [1998, 2012, 2014, 2014, 2015, 2017, 2019, 2020]\n",
    "names = ['LeNet-5', 'AlexNet', 'VGGNet', 'GoogLeNet', 'ResNet', 'DenseNet', 'EfficientNet', 'ViT']\n",
    "depths = [5, 8, 19, 22, 152, 121, 'B7:66', 'L/16']\n",
    "top1 = [99.2, 84.7, 92.7, 93.3, 96.4, 96.5, 97.1, 97.3]  # ImageNet æˆ– MNIST\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db', '#9b59b6', '#f39c12', '#1abc9c', '#e67e22', '#34495e']\n",
    "highlights = [True, True, True, False, False, False, False, False]  # æœ¬ç« é‡ç‚¹\n",
    "\n",
    "# ç»˜åˆ¶æ—¶é—´çº¿\n",
    "ax.axhline(y=0, color='gray', linewidth=2, alpha=0.5)\n",
    "\n",
    "for i, (year, name, depth, acc, color, hl) in enumerate(zip(years, names, depths, top1, colors, highlights)):\n",
    "    y_offset = 0.5 if i % 2 == 0 else -0.5\n",
    "    \n",
    "    # åœ†ç‚¹å¤§å°è¡¨ç¤ºæ˜¯å¦æ˜¯æœ¬ç« é‡ç‚¹\n",
    "    size = 300 if hl else 150\n",
    "    edgecolor = 'gold' if hl else 'white'\n",
    "    linewidth = 3 if hl else 1\n",
    "    \n",
    "    ax.scatter(year, 0, s=size, c=color, zorder=5, edgecolor=edgecolor, linewidth=linewidth)\n",
    "    ax.plot([year, year], [0, y_offset * 0.8], color=color, linewidth=2)\n",
    "    \n",
    "    # æ ‡ç­¾\n",
    "    label = f\"{name}\\n({depth} layers)\" if isinstance(depth, int) else f\"{name}\\n({depth})\"\n",
    "    ax.annotate(label, (year, y_offset), ha='center', va='center' if y_offset > 0 else 'center',\n",
    "                fontsize=10, fontweight='bold' if hl else 'normal',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.3 if hl else 0.1))\n",
    "\n",
    "# æ ‡è®°æœ¬ç« é‡ç‚¹\n",
    "ax.axvspan(1996, 2015, alpha=0.1, color='yellow')\n",
    "ax.text(2006.5, 0.9, 'ğŸ“– æœ¬ç« é‡ç‚¹', fontsize=12, ha='center', fontweight='bold')\n",
    "\n",
    "ax.set_xlim(1995, 2022)\n",
    "ax.set_ylim(-1.2, 1.2)\n",
    "ax.set_xlabel('å¹´ä»½', fontsize=12)\n",
    "ax.set_title('CNN æ¶æ„å‘å±•æ—¶é—´çº¿', fontsize=14, fontweight='bold')\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ æœ¬ç« å°†æ·±å…¥å­¦ä¹ ä¸‰ä¸ªé»„è‰²è¾¹æ¡†æ ‡è®°çš„æ¶æ„ï¼šLeNet-5ã€AlexNetã€VGGNet\")\n",
    "print(\"   è¿™ä¸‰ä¸ªæ¶æ„å¥ å®šäº†ç°ä»£ CNN çš„åŸºç¡€è®¾è®¡èŒƒå¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: LeNet-5 (1998) - CNN çš„å¼€å±±ä¹‹ä½œ\n",
    "\n",
    "## 1.1 å†å²èƒŒæ™¯\n",
    "\n",
    "**Yann LeCun** äº 1998 å¹´å‘è¡¨çš„ LeNet-5 æ˜¯ç¬¬ä¸€ä¸ªåœ¨å•†ä¸šä¸ŠæˆåŠŸåº”ç”¨çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚\n",
    "\n",
    "**åº”ç”¨åœºæ™¯**ï¼šç¾å›½é“¶è¡Œæ”¯ç¥¨ä¸Šæ‰‹å†™æ•°å­—çš„è‡ªåŠ¨è¯†åˆ«\n",
    "\n",
    "**å†å²æ„ä¹‰**ï¼š\n",
    "- é¦–æ¬¡è¯æ˜ CNN å¯ä»¥åœ¨å®é™…ä»»åŠ¡ä¸­è¶…è¶Šä¼ ç»Ÿæ–¹æ³•\n",
    "- ç¡®ç«‹äº†ã€Œå·ç§¯å±‚ + æ± åŒ–å±‚ + å…¨è¿æ¥å±‚ã€çš„åŸºæœ¬æ¶æ„æ¨¡å¼\n",
    "- æå‡ºäº†å‚æ•°å…±äº«å’Œå±€éƒ¨æ„Ÿå—é‡çš„æ¦‚å¿µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 LeNet-5 æ¶æ„è¯¦è§£\n",
    "\n",
    "```\n",
    "è¾“å…¥ (1, 32, 32)  â† ç°åº¦å›¾åƒ\n",
    "        â†“\n",
    "   C1: Conv 5Ã—5, 6 filters    â†’ (6, 28, 28)\n",
    "        â†“\n",
    "   S2: AvgPool 2Ã—2            â†’ (6, 14, 14)   â† åŸè®ºæ–‡å« \"Subsampling\"\n",
    "        â†“\n",
    "   C3: Conv 5Ã—5, 16 filters   â†’ (16, 10, 10)\n",
    "        â†“\n",
    "   S4: AvgPool 2Ã—2            â†’ (16, 5, 5)\n",
    "        â†“\n",
    "   C5: Conv 5Ã—5, 120 filters  â†’ (120, 1, 1)   â† å®é™…ä¸Šç­‰ä»·äºå…¨è¿æ¥\n",
    "        â†“\n",
    "   F6: Fully Connected        â†’ 84\n",
    "        â†“\n",
    "   Output                     â†’ 10 (æ•°å­— 0-9)\n",
    "```\n",
    "\n",
    "**æ³¨æ„**ï¼š\n",
    "- åŸè®ºæ–‡ä½¿ç”¨ **Tanh** ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼ˆå½“æ—¶ ReLU è¿˜æ²¡è¢«æå‡ºï¼‰\n",
    "- ä½¿ç”¨ **Average Pooling**ï¼ˆä¸æ˜¯ Max Poolingï¼‰\n",
    "- è¾“å…¥å°ºå¯¸æ˜¯ 32Ã—32ï¼ˆMNIST æ˜¯ 28Ã—28ï¼Œéœ€è¦ paddingï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– LeNet-5 æ¶æ„\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "# å®šä¹‰æ¯å±‚çš„ä¿¡æ¯\n",
    "layers = [\n",
    "    {'name': 'Input', 'size': (32, 32), 'channels': 1, 'x': 0},\n",
    "    {'name': 'C1\\nConv 5Ã—5', 'size': (28, 28), 'channels': 6, 'x': 1.5},\n",
    "    {'name': 'S2\\nPool 2Ã—2', 'size': (14, 14), 'channels': 6, 'x': 3},\n",
    "    {'name': 'C3\\nConv 5Ã—5', 'size': (10, 10), 'channels': 16, 'x': 4.5},\n",
    "    {'name': 'S4\\nPool 2Ã—2', 'size': (5, 5), 'channels': 16, 'x': 6},\n",
    "    {'name': 'C5\\nConv 5Ã—5', 'size': (1, 1), 'channels': 120, 'x': 7.5},\n",
    "    {'name': 'F6\\nFC', 'size': (1, 1), 'channels': 84, 'x': 9},\n",
    "    {'name': 'Output\\n10 classes', 'size': (1, 1), 'channels': 10, 'x': 10.5},\n",
    "]\n",
    "\n",
    "# ç»˜åˆ¶æ¯å±‚\n",
    "for layer in layers:\n",
    "    x = layer['x']\n",
    "    h = layer['size'][0] / 32 * 2  # å½’ä¸€åŒ–é«˜åº¦\n",
    "    w = 0.4\n",
    "    c = layer['channels']\n",
    "    \n",
    "    # ç”¨çŸ©å½¢è¡¨ç¤ºç‰¹å¾å›¾\n",
    "    rect = plt.Rectangle((x - w/2, -h/2), w, h, \n",
    "                          facecolor='steelblue', edgecolor='black', alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # æ ‡ç­¾\n",
    "    ax.text(x, -h/2 - 0.3, layer['name'], ha='center', va='top', fontsize=9)\n",
    "    ax.text(x, h/2 + 0.1, f\"{layer['size'][0]}Ã—{layer['size'][1]}Ã—{c}\", \n",
    "            ha='center', va='bottom', fontsize=8, color='gray')\n",
    "\n",
    "# ç®­å¤´è¿æ¥\n",
    "for i in range(len(layers) - 1):\n",
    "    x1 = layers[i]['x'] + 0.2\n",
    "    x2 = layers[i+1]['x'] - 0.2\n",
    "    ax.annotate('', xy=(x2, 0), xytext=(x1, 0),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "ax.set_xlim(-1, 12)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title('LeNet-5 æ¶æ„å›¾', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 PyTorch å®ç° LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    LeNet-5 ç»å…¸å®ç° (Yann LeCun, 1998)\n",
    "    \n",
    "    æ¶æ„ç‰¹ç‚¹:\n",
    "        - å·ç§¯å±‚ä¸æ± åŒ–å±‚äº¤æ›¿æ’åˆ—\n",
    "        - ä½¿ç”¨ Tanh æ¿€æ´»å‡½æ•°ï¼ˆåŸè®ºæ–‡ï¼‰\n",
    "        - ä½¿ç”¨ Average Pooling\n",
    "        - å‚æ•°é‡çº¦ 60K\n",
    "    \n",
    "    è¾“å…¥:\n",
    "        x: (batch, 1, 32, 32) ç°åº¦å›¾åƒ\n",
    "        å¦‚æœè¾“å…¥æ˜¯ 28Ã—28ï¼ˆMNISTï¼‰ï¼Œä¼šè‡ªåŠ¨ padding åˆ° 32Ã—32\n",
    "    \n",
    "    è¾“å‡º:\n",
    "        logits: (batch, num_classes) åˆ†ç±» logits\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10, use_original_activation=True):\n",
    "        \"\"\"\n",
    "        å‚æ•°:\n",
    "            num_classes: åˆ†ç±»æ•°é‡ï¼Œé»˜è®¤ 10ï¼ˆæ•°å­— 0-9ï¼‰\n",
    "            use_original_activation: æ˜¯å¦ä½¿ç”¨åŸè®ºæ–‡çš„ Tanhï¼ŒFalse åˆ™ä½¿ç”¨ ReLU\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # é€‰æ‹©æ¿€æ´»å‡½æ•°\n",
    "        self.activation = nn.Tanh() if use_original_activation else nn.ReLU()\n",
    "        \n",
    "        # ========================================\n",
    "        # ç‰¹å¾æå–éƒ¨åˆ†\n",
    "        # ========================================\n",
    "        \n",
    "        # C1: ç¬¬ä¸€ä¸ªå·ç§¯å±‚\n",
    "        # è¾“å…¥: (1, 32, 32) â†’ è¾“å‡º: (6, 28, 28)\n",
    "        # å·ç§¯æ ¸: 5Ã—5, æ—  padding, stride=1\n",
    "        # è¾“å‡ºå°ºå¯¸: (32 - 5 + 1) = 28\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,      # ç°åº¦å›¾åƒ\n",
    "            out_channels=6,     # 6 ä¸ªå·ç§¯æ ¸\n",
    "            kernel_size=5,      # 5Ã—5\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        # S2: ç¬¬ä¸€ä¸ªæ± åŒ–å±‚ï¼ˆåŸè®ºæ–‡å« Subsamplingï¼‰\n",
    "        # è¾“å…¥: (6, 28, 28) â†’ è¾“å‡º: (6, 14, 14)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # C3: ç¬¬äºŒä¸ªå·ç§¯å±‚\n",
    "        # è¾“å…¥: (6, 14, 14) â†’ è¾“å‡º: (16, 10, 10)\n",
    "        # æ³¨æ„: åŸè®ºæ–‡ä¸­ C3 æœ‰å¤æ‚çš„è¿æ¥æ¨¡å¼ï¼Œè¿™é‡Œç®€åŒ–ä¸ºå…¨è¿æ¥\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=5\n",
    "        )\n",
    "        \n",
    "        # S4: ç¬¬äºŒä¸ªæ± åŒ–å±‚\n",
    "        # è¾“å…¥: (16, 10, 10) â†’ è¾“å‡º: (16, 5, 5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # C5: ç¬¬ä¸‰ä¸ªå·ç§¯å±‚ï¼ˆå®é™…ä¸Šç­‰ä»·äºå…¨è¿æ¥ï¼‰\n",
    "        # è¾“å…¥: (16, 5, 5) â†’ è¾“å‡º: (120, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=120,\n",
    "            kernel_size=5\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # åˆ†ç±»å™¨éƒ¨åˆ†\n",
    "        # ========================================\n",
    "        \n",
    "        # F6: å…¨è¿æ¥å±‚\n",
    "        # è¾“å…¥: 120 â†’ è¾“å‡º: 84\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        \n",
    "        # è¾“å‡ºå±‚\n",
    "        # è¾“å…¥: 84 â†’ è¾“å‡º: num_classes\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: (batch, 1, H, W) è¾“å…¥å›¾åƒ\n",
    "               å¦‚æœ H, W = 28ï¼ˆMNISTï¼‰ï¼Œä¼šè‡ªåŠ¨ padding\n",
    "        \n",
    "        è¿”å›:\n",
    "            logits: (batch, num_classes)\n",
    "        \"\"\"\n",
    "        # å¦‚æœè¾“å…¥æ˜¯ 28Ã—28ï¼Œpadding åˆ° 32Ã—32\n",
    "        if x.size(2) == 28:\n",
    "            x = F.pad(x, (2, 2, 2, 2))  # å·¦å³ä¸Šä¸‹å„ padding 2\n",
    "        \n",
    "        # C1 + S2\n",
    "        x = self.conv1(x)           # (batch, 6, 28, 28)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool1(x)           # (batch, 6, 14, 14)\n",
    "        \n",
    "        # C3 + S4\n",
    "        x = self.conv2(x)           # (batch, 16, 10, 10)\n",
    "        x = self.activation(x)\n",
    "        x = self.pool2(x)           # (batch, 16, 5, 5)\n",
    "        \n",
    "        # C5\n",
    "        x = self.conv3(x)           # (batch, 120, 1, 1)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)   # (batch, 120)\n",
    "        \n",
    "        # F6 + Output\n",
    "        x = self.fc1(x)             # (batch, 84)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)             # (batch, num_classes)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# æµ‹è¯• LeNet-5\n",
    "model = LeNet5(num_classes=10)\n",
    "x = torch.randn(1, 1, 28, 28)  # MNIST å°ºå¯¸\n",
    "y = model(x)\n",
    "\n",
    "print(\"LeNet-5 æµ‹è¯•ï¼š\")\n",
    "print(f\"  è¾“å…¥: {x.shape}\")\n",
    "print(f\"  è¾“å‡º: {y.shape}\")\n",
    "print(f\"  å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 åœ¨ MNIST ä¸Šè®­ç»ƒ LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ MNIST æ•°æ®é›†\n",
    "print(\"åŠ è½½ MNIST æ•°æ®é›†...\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST å‡å€¼å’Œæ ‡å‡†å·®\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬\")\n",
    "print(f\"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬\")\n",
    "\n",
    "# å¯è§†åŒ–ä¸€äº›æ ·æœ¬\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_data[i]\n",
    "    ax.imshow(img.squeeze(), cmap='gray')\n",
    "    ax.set_title(f'Label: {label}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('MNIST æ ·æœ¬', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs=5, lr=0.01, device='cpu'):\n",
    "    \"\"\"\n",
    "    è®­ç»ƒæ¨¡å‹\n",
    "    \n",
    "    è¿”å›:\n",
    "        history: åŒ…å«è®­ç»ƒå†å²çš„å­—å…¸\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # è®­ç»ƒ\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        \n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # æµ‹è¯•\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, Test Acc={test_acc:.2f}%\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# è®­ç»ƒ LeNet-5\n",
    "print(\"\\nè®­ç»ƒ LeNet-5 (åŸç‰ˆ Tanh æ¿€æ´»)...\")\n",
    "lenet_original = LeNet5(use_original_activation=True)\n",
    "history_original = train_model(lenet_original, train_loader, test_loader, epochs=5, device=device)\n",
    "\n",
    "print(f\"\\næœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {history_original['test_acc'][-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 LeNet-5 å°ç»“\n",
    "\n",
    "**æ ¸å¿ƒè´¡çŒ®**ï¼š\n",
    "1. ç¡®ç«‹äº† CNN çš„åŸºæœ¬æ¶æ„æ¨¡å¼ï¼šå·ç§¯ â†’ æ± åŒ– â†’ å·ç§¯ â†’ æ± åŒ– â†’ å…¨è¿æ¥\n",
    "2. å‚æ•°å…±äº«ï¼šåŒä¸€ä¸ªå·ç§¯æ ¸åœ¨æ•´ä¸ªå›¾åƒä¸Šæ»‘åŠ¨ï¼Œå¤§å¤§å‡å°‘å‚æ•°é‡\n",
    "3. å±€éƒ¨æ„Ÿå—é‡ï¼šæ¯ä¸ªç¥ç»å…ƒåªçœ‹å±€éƒ¨åŒºåŸŸï¼Œé€å±‚æ‰©å¤§æ„Ÿå—é‡\n",
    "\n",
    "**å±€é™æ€§**ï¼š\n",
    "- ä½¿ç”¨ Tanh æ¿€æ´»ï¼Œå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±é—®é¢˜\n",
    "- ç½‘ç»œè¾ƒæµ…ï¼ˆ5 å±‚ï¼‰ï¼Œè¡¨è¾¾èƒ½åŠ›æœ‰é™\n",
    "- è®¡ç®—èƒ½åŠ›é™åˆ¶ï¼Œæ— æ³•å¤„ç†å¤§å°ºå¯¸å›¾åƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: AlexNet (2012) - æ·±åº¦å­¦ä¹ çš„å¤å…´\n",
    "\n",
    "## 2.1 å†å²èƒŒæ™¯ï¼šImageNet ä¸æ·±åº¦å­¦ä¹ é©å‘½\n",
    "\n",
    "2012 å¹´ï¼ŒAlex Krizhevsky ç­‰äººå‡­å€Ÿ AlexNet åœ¨ ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›ï¼ˆILSVRCï¼‰ä¸­ä»¥å·¨å¤§ä¼˜åŠ¿å¤ºå† ï¼š\n",
    "\n",
    "| å¹´ä»½ | æ–¹æ³• | Top-5 é”™è¯¯ç‡ |\n",
    "|------|------|-------------|\n",
    "| 2011 | ä¼ ç»Ÿæ–¹æ³• (SIFT + FV) | 25.8% |\n",
    "| **2012** | **AlexNet** | **15.3%** â† é™ä½ 10%ï¼|\n",
    "| 2012 | ç¬¬äºŒå (ä¼ ç»Ÿæ–¹æ³•) | 26.2% |\n",
    "\n",
    "è¿™ä¸€ç»“æœéœ‡æƒŠäº†æ•´ä¸ªè®¡ç®—æœºè§†è§‰ç•Œï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ æ—¶ä»£çš„å¼€å§‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 AlexNet çš„æ ¸å¿ƒåˆ›æ–°\n",
    "\n",
    "AlexNet å¼•å…¥äº†å¤šé¡¹å…³é”®åˆ›æ–°ï¼š\n",
    "\n",
    "| åˆ›æ–° | è¯´æ˜ | å½±å“ |\n",
    "|------|------|------|\n",
    "| **ReLU æ¿€æ´»** | ç”¨ max(0, x) æ›¿ä»£ Tanh/Sigmoid | è®­ç»ƒé€Ÿåº¦å¿« 6 å€ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤± |\n",
    "| **Dropout** | è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒç¥ç»å…ƒ | å¼ºæ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |\n",
    "| **GPU è®­ç»ƒ** | é¦–æ¬¡ä½¿ç”¨åŒ GPU å¹¶è¡Œ | å¤§å¹…åŠ é€Ÿè®­ç»ƒ |\n",
    "| **LRN** | å±€éƒ¨å“åº”å½’ä¸€åŒ– | ä¾§å‘æŠ‘åˆ¶ï¼ˆåè¢« BN å–ä»£ï¼‰|\n",
    "| **æ•°æ®å¢å¼º** | éšæœºè£å‰ªã€ç¿»è½¬ã€é¢œè‰²æŠ–åŠ¨ | æ‰©å……æ•°æ®ï¼Œæå‡æ³›åŒ– |\n",
    "| **é‡å æ± åŒ–** | stride < kernel_size | ç•¥å¾®æå‡å‡†ç¡®ç‡ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– ReLU vs Sigmoid vs Tanh\n",
    "\n",
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "# å„æ¿€æ´»å‡½æ•°\n",
    "sigmoid = 1 / (1 + np.exp(-x))\n",
    "tanh = np.tanh(x)\n",
    "relu = np.maximum(0, x)\n",
    "\n",
    "# å„æ¿€æ´»å‡½æ•°çš„å¯¼æ•°\n",
    "sigmoid_grad = sigmoid * (1 - sigmoid)\n",
    "tanh_grad = 1 - tanh**2\n",
    "relu_grad = (x > 0).astype(float)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# æ¿€æ´»å‡½æ•°\n",
    "axes[0].plot(x, sigmoid, 'b-', label='Sigmoid', linewidth=2)\n",
    "axes[0].plot(x, tanh, 'g-', label='Tanh', linewidth=2)\n",
    "axes[0].plot(x, relu, 'r-', label='ReLU', linewidth=2)\n",
    "axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('f(x)')\n",
    "axes[0].set_title('æ¿€æ´»å‡½æ•°å¯¹æ¯”')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim(-2, 5)\n",
    "\n",
    "# å¯¼æ•°\n",
    "axes[1].plot(x, sigmoid_grad, 'b-', label='Sigmoid\\'', linewidth=2)\n",
    "axes[1].plot(x, tanh_grad, 'g-', label='Tanh\\'', linewidth=2)\n",
    "axes[1].plot(x, relu_grad, 'r-', label='ReLU\\'', linewidth=2)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].axhline(y=1, color='gray', linestyle=':', alpha=0.5)\n",
    "axes[1].axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel(\"f'(x)\")\n",
    "axes[1].set_title('æ¿€æ´»å‡½æ•°å¯¼æ•°ï¼ˆæ¢¯åº¦ï¼‰å¯¹æ¯”')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ä¸ºä»€ä¹ˆ ReLU æ›´å¥½ï¼Ÿ', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ ReLU çš„ä¼˜åŠ¿ï¼š\")\n",
    "print(\"   1. å¯¼æ•°æ’ä¸º 1ï¼ˆx > 0 æ—¶ï¼‰ï¼Œä¸ä¼šæ¢¯åº¦æ¶ˆå¤±\")\n",
    "print(\"   2. è®¡ç®—ç®€å•ï¼šmax(0, x)ï¼Œæ¯” exp å¿«å¾—å¤š\")\n",
    "print(\"   3. ç¨€ç–æ¿€æ´»ï¼šè´Ÿå€¼å˜ 0ï¼Œäº§ç”Ÿç¨€ç–è¡¨ç¤º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 AlexNet æ¶æ„è¯¦è§£\n",
    "\n",
    "```\n",
    "è¾“å…¥ (3, 224, 224)  â† å½©è‰²å›¾åƒï¼ˆåŸè®ºæ–‡æ˜¯ 227Ã—227ï¼‰\n",
    "        â†“\n",
    "   Conv1: 11Ã—11, 96 filters, stride=4  â†’ (96, 55, 55)\n",
    "        â†“ LRN + MaxPool 3Ã—3\n",
    "   Conv2: 5Ã—5, 256 filters, pad=2      â†’ (256, 27, 27)\n",
    "        â†“ LRN + MaxPool 3Ã—3\n",
    "   Conv3: 3Ã—3, 384 filters, pad=1      â†’ (384, 13, 13)\n",
    "        â†“\n",
    "   Conv4: 3Ã—3, 384 filters, pad=1      â†’ (384, 13, 13)\n",
    "        â†“\n",
    "   Conv5: 3Ã—3, 256 filters, pad=1      â†’ (256, 13, 13)\n",
    "        â†“ MaxPool 3Ã—3\n",
    "   FC6: 4096 + Dropout(0.5)\n",
    "        â†“\n",
    "   FC7: 4096 + Dropout(0.5)\n",
    "        â†“\n",
    "   Output: 1000 classes\n",
    "```\n",
    "\n",
    "**å‚æ•°é‡**ï¼šçº¦ 6000 ä¸‡ï¼ˆ60Mï¼‰ï¼Œå…¶ä¸­ç»å¤§éƒ¨åˆ†åœ¨å…¨è¿æ¥å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    \"\"\"\n",
    "    AlexNet å®ç° (Krizhevsky et al., 2012)\n",
    "    \n",
    "    æ ¸å¿ƒåˆ›æ–°:\n",
    "        - ReLU æ¿€æ´»å‡½æ•°\n",
    "        - Dropout æ­£åˆ™åŒ–\n",
    "        - é‡å æ± åŒ– (overlapping pooling)\n",
    "        - LRN (å¯é€‰ï¼Œç°å·²å¾ˆå°‘ä½¿ç”¨)\n",
    "    \n",
    "    è¾“å…¥:\n",
    "        x: (batch, 3, 224, 224) å½©è‰²å›¾åƒ\n",
    "    \n",
    "    è¾“å‡º:\n",
    "        logits: (batch, num_classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=1000, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ========================================\n",
    "        # ç‰¹å¾æå–éƒ¨åˆ†ï¼ˆ5 ä¸ªå·ç§¯å±‚ï¼‰\n",
    "        # ========================================\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1: å¤§å·ç§¯æ ¸å¿«é€Ÿé™ç»´\n",
    "            # è¾“å…¥: (3, 224, 224) â†’ è¾“å‡º: (96, 55, 55)\n",
    "            # è®¡ç®—: (224 - 11) / 4 + 1 = 54.25 â†’ 55 (å› ä¸º padding)\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # é‡å æ± åŒ–: kernel=3, stride=2ï¼ˆstride < kernelï¼‰\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # â†’ (96, 27, 27)\n",
    "            \n",
    "            # Conv2\n",
    "            # è¾“å…¥: (96, 27, 27) â†’ è¾“å‡º: (256, 27, 27)\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # â†’ (256, 13, 13)\n",
    "            \n",
    "            # Conv3: å¼€å§‹ä½¿ç”¨ 3Ã—3 å°å·ç§¯\n",
    "            # è¾“å…¥: (256, 13, 13) â†’ è¾“å‡º: (384, 13, 13)\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv4\n",
    "            # è¾“å…¥: (384, 13, 13) â†’ è¾“å‡º: (384, 13, 13)\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Conv5\n",
    "            # è¾“å…¥: (384, 13, 13) â†’ è¾“å‡º: (256, 13, 13)\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),  # â†’ (256, 6, 6)\n",
    "        )\n",
    "        \n",
    "        # ========================================\n",
    "        # åˆ†ç±»å™¨éƒ¨åˆ†ï¼ˆ3 ä¸ªå…¨è¿æ¥å±‚ï¼‰\n",
    "        # ========================================\n",
    "        self.classifier = nn.Sequential(\n",
    "            # Dropout: è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒ 50% ç¥ç»å…ƒ\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # FC6: 256 Ã— 6 Ã— 6 = 9216 â†’ 4096\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # FC7: 4096 â†’ 4096\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Output: 4096 â†’ num_classes\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: (batch, 3, 224, 224) è¾“å…¥å›¾åƒ\n",
    "        \n",
    "        è¿”å›:\n",
    "            logits: (batch, num_classes)\n",
    "        \"\"\"\n",
    "        x = self.features(x)            # (batch, 256, 6, 6)\n",
    "        x = x.view(x.size(0), -1)       # (batch, 9216)\n",
    "        x = self.classifier(x)          # (batch, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# æµ‹è¯• AlexNet\n",
    "alexnet = AlexNet(num_classes=1000)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "y = alexnet(x)\n",
    "\n",
    "print(\"AlexNet æµ‹è¯•ï¼š\")\n",
    "print(f\"  è¾“å…¥: {x.shape}\")\n",
    "print(f\"  è¾“å‡º: {y.shape}\")\n",
    "print(f\"  å‚æ•°é‡: {sum(p.numel() for p in alexnet.parameters()):,}\")\n",
    "\n",
    "# åˆ†æå‚æ•°åˆ†å¸ƒ\n",
    "conv_params = sum(p.numel() for name, p in alexnet.named_parameters() if 'features' in name)\n",
    "fc_params = sum(p.numel() for name, p in alexnet.named_parameters() if 'classifier' in name)\n",
    "print(f\"\\n  å·ç§¯å±‚å‚æ•°: {conv_params:,} ({conv_params / (conv_params + fc_params) * 100:.1f}%)\")\n",
    "print(f\"  å…¨è¿æ¥å±‚å‚æ•°: {fc_params:,} ({fc_params / (conv_params + fc_params) * 100:.1f}%)\")\n",
    "print(\"\\nğŸ’¡ å¤§éƒ¨åˆ†å‚æ•°é›†ä¸­åœ¨å…¨è¿æ¥å±‚ï¼Œè¿™æ˜¯åç»­æ¶æ„ä¼˜åŒ–çš„é‡ç‚¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Dropout è¯¦è§£\n",
    "\n",
    "Dropout æ˜¯ AlexNet å¼•å…¥çš„é‡è¦æ­£åˆ™åŒ–æŠ€æœ¯ï¼š\n",
    "\n",
    "**è®­ç»ƒæ—¶**ï¼šä»¥æ¦‚ç‡ $p$ éšæœºå°†ç¥ç»å…ƒè¾“å‡ºç½®ä¸º 0\n",
    "\n",
    "**æµ‹è¯•æ—¶**ï¼šä½¿ç”¨æ‰€æœ‰ç¥ç»å…ƒï¼Œä½†è¾“å‡ºä¹˜ä»¥ $(1-p)$\n",
    "\n",
    "ï¼ˆPyTorch åœ¨è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨ç¼©æ”¾ï¼Œæµ‹è¯•æ—¶ä¸éœ€è¦é¢å¤–å¤„ç†ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ– Dropout æ•ˆæœ\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„ Dropout å±‚\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "# è¾“å…¥\n",
    "x = torch.ones(1, 10)\n",
    "\n",
    "# è®­ç»ƒæ¨¡å¼\n",
    "dropout.train()\n",
    "outputs_train = [dropout(x).numpy().flatten() for _ in range(5)]\n",
    "\n",
    "# æµ‹è¯•æ¨¡å¼\n",
    "dropout.eval()\n",
    "output_eval = dropout(x).numpy().flatten()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6))\n",
    "\n",
    "# å¯è§†åŒ–è®­ç»ƒæ—¶çš„ 5 æ¬¡å‰å‘ä¼ æ’­\n",
    "for i, (ax, out) in enumerate(zip(axes[0], outputs_train[:3])):\n",
    "    colors = ['red' if v == 0 else 'green' for v in out]\n",
    "    ax.bar(range(10), out * 0.5 + 0.5, color=colors)  # ç¼©æ”¾ä¾¿äºæ˜¾ç¤º\n",
    "    ax.set_ylim(0, 1.5)\n",
    "    ax.set_title(f'è®­ç»ƒ: ç¬¬ {i+1} æ¬¡å‰å‘ä¼ æ’­')\n",
    "    ax.set_xticks(range(10))\n",
    "    dropped = sum(1 for v in out if v == 0)\n",
    "    ax.set_xlabel(f'ä¸¢å¼ƒ {dropped}/10 ä¸ªç¥ç»å…ƒ')\n",
    "\n",
    "for i, (ax, out) in enumerate(zip(axes[1][:2], outputs_train[3:5])):\n",
    "    colors = ['red' if v == 0 else 'green' for v in out]\n",
    "    ax.bar(range(10), out * 0.5 + 0.5, color=colors)\n",
    "    ax.set_ylim(0, 1.5)\n",
    "    ax.set_title(f'è®­ç»ƒ: ç¬¬ {i+4} æ¬¡å‰å‘ä¼ æ’­')\n",
    "    ax.set_xticks(range(10))\n",
    "    dropped = sum(1 for v in out if v == 0)\n",
    "    ax.set_xlabel(f'ä¸¢å¼ƒ {dropped}/10 ä¸ªç¥ç»å…ƒ')\n",
    "\n",
    "# æµ‹è¯•æ¨¡å¼\n",
    "axes[1][2].bar(range(10), output_eval, color='blue')\n",
    "axes[1][2].set_ylim(0, 1.5)\n",
    "axes[1][2].set_title('æµ‹è¯•: æ‰€æœ‰ç¥ç»å…ƒæ¿€æ´»')\n",
    "axes[1][2].set_xticks(range(10))\n",
    "axes[1][2].set_xlabel('æ— ä¸¢å¼ƒ')\n",
    "\n",
    "plt.suptitle('Dropout å·¥ä½œåŸç†', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ Dropout çš„ä½œç”¨ï¼š\")\n",
    "print(\"   1. é˜²æ­¢è¿‡æ‹Ÿåˆï¼šå¼ºåˆ¶ç½‘ç»œå­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾\")\n",
    "print(\"   2. ç›¸å½“äºè®­ç»ƒå¤šä¸ªå­ç½‘ç»œçš„é›†æˆ\")\n",
    "print(\"   3. å‡å°‘ç¥ç»å…ƒä¹‹é—´çš„ä¾èµ–å…³ç³»\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 ä½¿ç”¨ torchvision é¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒçš„ AlexNet\n",
    "print(\"åŠ è½½é¢„è®­ç»ƒ AlexNet...\")\n",
    "pretrained_alexnet = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "pretrained_alexnet.eval()\n",
    "\n",
    "# æ¨¡å‹ä¿¡æ¯\n",
    "print(f\"\\nå‚æ•°é‡: {sum(p.numel() for p in pretrained_alexnet.parameters()):,}\")\n",
    "\n",
    "# æµ‹è¯•æ¨ç†\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "with torch.no_grad():\n",
    "    output = pretrained_alexnet(x)\n",
    "print(f\"è¾“å‡ºå½¢çŠ¶: {output.shape}\")\n",
    "print(f\"é¢„æµ‹ç±»åˆ«: {output.argmax().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 AlexNet å°ç»“\n",
    "\n",
    "**æ ¸å¿ƒè´¡çŒ®**ï¼š\n",
    "1. **ReLU**ï¼šè§£å†³æ¢¯åº¦æ¶ˆå¤±ï¼ŒåŠ é€Ÿè®­ç»ƒ\n",
    "2. **Dropout**ï¼šå¼ºæ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "3. **GPU è®­ç»ƒ**ï¼šé¦–æ¬¡å¤§è§„æ¨¡ä½¿ç”¨ GPU\n",
    "4. **æ•°æ®å¢å¼º**ï¼šæå‡æ³›åŒ–èƒ½åŠ›\n",
    "\n",
    "**å±€é™æ€§**ï¼š\n",
    "- å…¨è¿æ¥å±‚å‚æ•°é‡å·¨å¤§ï¼ˆçº¦ 95%ï¼‰\n",
    "- ç¬¬ä¸€å±‚ä½¿ç”¨ 11Ã—11 å¤§å·ç§¯æ ¸ï¼Œè®¡ç®—é‡å¤§\n",
    "- æ¶æ„è®¾è®¡è¾ƒä¸ºéšæ„ï¼Œç¼ºä¹ç³»ç»Ÿæ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: VGGNet (2014) - æ·±åº¦çš„æ¢ç´¢\n",
    "\n",
    "## 3.1 è®¾è®¡å“²å­¦\n",
    "\n",
    "VGGNet ç”±ç‰›æ´¥å¤§å­¦ Visual Geometry Group æå‡ºï¼Œæ ¸å¿ƒæ€æƒ³å¾ˆç®€å•ï¼š\n",
    "\n",
    "> **ç”¨å°å·ç§¯æ ¸ï¼ˆ3Ã—3ï¼‰å †å æ›¿ä»£å¤§å·ç§¯æ ¸ï¼Œå¢åŠ ç½‘ç»œæ·±åº¦**\n",
    "\n",
    "VGGNet è¯æ˜äº†ä¸€ä¸ªé‡è¦ç»“è®ºï¼š**ç½‘ç»œæ·±åº¦å¯¹æ€§èƒ½è‡³å…³é‡è¦**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 ä¸ºä»€ä¹ˆ 3Ã—3 æ›´å¥½ï¼Ÿ\n",
    "\n",
    "### æ„Ÿå—é‡ç­‰æ•ˆ\n",
    "\n",
    "ä¸¤ä¸ª 3Ã—3 å·ç§¯å±‚çš„æ„Ÿå—é‡ = ä¸€ä¸ª 5Ã—5 å·ç§¯å±‚\n",
    "\n",
    "ä¸‰ä¸ª 3Ã—3 å·ç§¯å±‚çš„æ„Ÿå—é‡ = ä¸€ä¸ª 7Ã—7 å·ç§¯å±‚\n",
    "\n",
    "```\n",
    "             æ„Ÿå—é‡ = 5Ã—5                æ„Ÿå—é‡ = 5Ã—5\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚                 â”‚         â”‚  3Ã—3    3Ã—3     â”‚\n",
    "        â”‚      5Ã—5        â”‚   vs    â”‚   â†’  â”€â†’        â”‚\n",
    "        â”‚                 â”‚         â”‚                 â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        \n",
    "           å•ä¸ª 5Ã—5 å·ç§¯                ä¸¤ä¸ª 3Ã—3 å·ç§¯\n",
    "           25 ä¸ªå‚æ•°                   2 Ã— 9 = 18 ä¸ªå‚æ•°\n",
    "```\n",
    "\n",
    "### ä¼˜åŠ¿åˆ†æ\n",
    "\n",
    "| æ–¹æ¡ˆ | å‚æ•°é‡ | éçº¿æ€§æ¬¡æ•° |\n",
    "|------|--------|------------|\n",
    "| 1 Ã— 5Ã—5 | 25CÂ² | 1 |\n",
    "| 2 Ã— 3Ã—3 | 18CÂ² | 2 |\n",
    "| 1 Ã— 7Ã—7 | 49CÂ² | 1 |\n",
    "| 3 Ã— 3Ã—3 | 27CÂ² | 3 |\n",
    "\n",
    "ï¼ˆC ä¸ºé€šé“æ•°ï¼‰\n",
    "\n",
    "**ç»“è®º**ï¼š3Ã—3 å †å æœ‰æ›´å°‘çš„å‚æ•°å’Œæ›´å¤šçš„éçº¿æ€§ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ„Ÿå—é‡ç­‰æ•ˆ\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "def draw_receptive_field(ax, title, layers):\n",
    "    \"\"\"ç»˜åˆ¶æ„Ÿå—é‡ç¤ºæ„å›¾\"\"\"\n",
    "    ax.set_xlim(-0.5, 7.5)\n",
    "    ax.set_ylim(-0.5, 7.5)\n",
    "    \n",
    "    # ç»˜åˆ¶ç½‘æ ¼\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            rect = plt.Rectangle((i, j), 1, 1, fill=False, edgecolor='gray', linewidth=0.5)\n",
    "            ax.add_patch(rect)\n",
    "    \n",
    "    # é«˜äº®æ„Ÿå—é‡åŒºåŸŸ\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    for i, (size, color) in enumerate(zip(layers, colors)):\n",
    "        offset = (7 - size) / 2\n",
    "        rect = plt.Rectangle((offset, offset), size, size, \n",
    "                              fill=True, facecolor=color, alpha=0.3,\n",
    "                              edgecolor=color, linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # ä¸­å¿ƒç‚¹\n",
    "    ax.plot(3.5, 3.5, 'ko', markersize=10)\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "# 5Ã—5 æ„Ÿå—é‡\n",
    "draw_receptive_field(axes[0], 'å•ä¸ª 5Ã—5 å·ç§¯\\nå‚æ•°: 25CÂ²', [5])\n",
    "\n",
    "# ä¸¤ä¸ª 3Ã—3 æ„Ÿå—é‡\n",
    "draw_receptive_field(axes[1], 'ä¸¤ä¸ª 3Ã—3 å·ç§¯\\nå‚æ•°: 18CÂ²', [5, 3])\n",
    "axes[1].text(3.5, -0.8, 'ç¬¬1å±‚ â†’ ç¬¬2å±‚', ha='center', fontsize=10)\n",
    "\n",
    "# ä¸‰ä¸ª 3Ã—3 æ„Ÿå—é‡ï¼ˆç­‰ä»·äº 7Ã—7ï¼‰\n",
    "draw_receptive_field(axes[2], 'ä¸‰ä¸ª 3Ã—3 å·ç§¯\\nå‚æ•°: 27CÂ² (vs 7Ã—7: 49CÂ²)', [7, 5, 3])\n",
    "axes[2].text(3.5, -0.8, 'ç¬¬1å±‚ â†’ ç¬¬2å±‚ â†’ ç¬¬3å±‚', ha='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('3Ã—3 å·ç§¯å †å çš„æ„Ÿå—é‡ç­‰æ•ˆ', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# å‚æ•°é‡å¯¹æ¯”\n",
    "print(\"å‚æ•°é‡å¯¹æ¯”ï¼ˆå‡è®¾ C=64ï¼‰ï¼š\")\n",
    "C = 64\n",
    "print(f\"  5Ã—5 å•å±‚: {25 * C * C:,} å‚æ•°\")\n",
    "print(f\"  3Ã—3 ä¸¤å±‚: {2 * 9 * C * C:,} å‚æ•° (èŠ‚çœ {1 - 18/25:.0%})\")\n",
    "print(f\"  7Ã—7 å•å±‚: {49 * C * C:,} å‚æ•°\")\n",
    "print(f\"  3Ã—3 ä¸‰å±‚: {3 * 9 * C * C:,} å‚æ•° (èŠ‚çœ {1 - 27/49:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 VGG æ¶æ„é…ç½®\n",
    "\n",
    "VGGNet æœ‰å¤šä¸ªå˜ä½“ï¼Œé€šè¿‡ä¸åŒçš„æ·±åº¦é…ç½®ï¼š\n",
    "\n",
    "| é…ç½® | å±‚æ•° | è¯´æ˜ |\n",
    "|------|------|------|\n",
    "| VGG-11 | 11 | 8 conv + 3 fc |\n",
    "| VGG-13 | 13 | 10 conv + 3 fc |\n",
    "| **VGG-16** | 16 | 13 conv + 3 fc â† æœ€å¸¸ç”¨ |\n",
    "| VGG-19 | 19 | 16 conv + 3 fc |\n",
    "\n",
    "æ‰€æœ‰å˜ä½“çš„å…±åŒç‰¹ç‚¹ï¼š\n",
    "- åªä½¿ç”¨ 3Ã—3 å·ç§¯ï¼ˆstride=1, padding=1ï¼‰\n",
    "- åªä½¿ç”¨ 2Ã—2 æ± åŒ–ï¼ˆstride=2ï¼‰\n",
    "- é€šé“æ•°æŒ‰ 64 â†’ 128 â†’ 256 â†’ 512 é€’å¢\n",
    "- æœ€å 3 ä¸ªå…¨è¿æ¥å±‚ç»“æ„ç›¸åŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG é…ç½®å­—å…¸\n",
    "# æ•°å­—è¡¨ç¤ºå·ç§¯å±‚é€šé“æ•°ï¼Œ'M' è¡¨ç¤º MaxPool\n",
    "\n",
    "VGG_CONFIGS = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "# å¯è§†åŒ–é…ç½®å¯¹æ¯”\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "configs = ['VGG11', 'VGG13', 'VGG16', 'VGG19']\n",
    "colors = {'64': '#3498db', '128': '#2ecc71', '256': '#f39c12', '512': '#e74c3c', 'M': '#95a5a6'}\n",
    "\n",
    "for i, name in enumerate(configs):\n",
    "    cfg = VGG_CONFIGS[name]\n",
    "    x = 0\n",
    "    for item in cfg:\n",
    "        if item == 'M':\n",
    "            # æ± åŒ–å±‚\n",
    "            rect = plt.Rectangle((x, i - 0.3), 0.3, 0.6, facecolor=colors['M'], edgecolor='black')\n",
    "            ax.add_patch(rect)\n",
    "            x += 0.4\n",
    "        else:\n",
    "            # å·ç§¯å±‚\n",
    "            rect = plt.Rectangle((x, i - 0.3), 0.8, 0.6, facecolor=colors[str(item)], edgecolor='black')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x + 0.4, i, str(item), ha='center', va='center', fontsize=8, color='white')\n",
    "            x += 0.9\n",
    "\n",
    "# å›¾ä¾‹\n",
    "legend_elements = [\n",
    "    plt.Rectangle((0, 0), 1, 1, facecolor=colors['64'], label='64 channels'),\n",
    "    plt.Rectangle((0, 0), 1, 1, facecolor=colors['128'], label='128 channels'),\n",
    "    plt.Rectangle((0, 0), 1, 1, facecolor=colors['256'], label='256 channels'),\n",
    "    plt.Rectangle((0, 0), 1, 1, facecolor=colors['512'], label='512 channels'),\n",
    "    plt.Rectangle((0, 0), 1, 1, facecolor=colors['M'], label='MaxPool'),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=9)\n",
    "\n",
    "ax.set_yticks(range(len(configs)))\n",
    "ax.set_yticklabels(configs)\n",
    "ax.set_xlim(-0.5, 20)\n",
    "ax.set_ylim(-1, len(configs))\n",
    "ax.set_xlabel('å±‚é¡ºåº')\n",
    "ax.set_title('VGG æ¶æ„é…ç½®å¯¹æ¯”', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"å„é…ç½®ç»Ÿè®¡ï¼š\")\n",
    "for name, cfg in VGG_CONFIGS.items():\n",
    "    conv_layers = sum(1 for c in cfg if c != 'M')\n",
    "    pool_layers = sum(1 for c in cfg if c == 'M')\n",
    "    print(f\"  {name}: {conv_layers} conv + {pool_layers} pool + 3 fc = {conv_layers + pool_layers + 3} å±‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 PyTorch å®ç° VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \"\"\"\n",
    "    VGGNet å®ç° (Simonyan & Zisserman, 2014)\n",
    "    \n",
    "    è®¾è®¡ç‰¹ç‚¹:\n",
    "        - å…¨éƒ¨ä½¿ç”¨ 3Ã—3 å·ç§¯ï¼ˆstride=1, padding=1ï¼‰\n",
    "        - å…¨éƒ¨ä½¿ç”¨ 2Ã—2 æ± åŒ–ï¼ˆstride=2ï¼‰\n",
    "        - é€šé“æ•°é€æ­¥å¢åŠ : 64 â†’ 128 â†’ 256 â†’ 512\n",
    "        - é…ç½®é©±åŠ¨ï¼Œæ˜“äºæ‰©å±•\n",
    "    \n",
    "    è¾“å…¥:\n",
    "        x: (batch, 3, 224, 224) å½©è‰²å›¾åƒ\n",
    "    \n",
    "    è¾“å‡º:\n",
    "        logits: (batch, num_classes)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config_name='VGG16', num_classes=1000, dropout=0.5):\n",
    "        \"\"\"\n",
    "        å‚æ•°:\n",
    "            config_name: é…ç½®åç§°ï¼Œå¯é€‰ 'VGG11', 'VGG13', 'VGG16', 'VGG19'\n",
    "            num_classes: åˆ†ç±»æ•°é‡\n",
    "            dropout: Dropout æ¦‚ç‡\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # è·å–é…ç½®\n",
    "        if config_name not in VGG_CONFIGS:\n",
    "            raise ValueError(f\"Unknown config: {config_name}\")\n",
    "        config = VGG_CONFIGS[config_name]\n",
    "        \n",
    "        # ========================================\n",
    "        # ç‰¹å¾æå–éƒ¨åˆ†ï¼ˆå·ç§¯å±‚ + æ± åŒ–å±‚ï¼‰\n",
    "        # ========================================\n",
    "        self.features = self._make_layers(config)\n",
    "        \n",
    "        # ========================================\n",
    "        # åˆ†ç±»å™¨éƒ¨åˆ†ï¼ˆ3 ä¸ªå…¨è¿æ¥å±‚ï¼‰\n",
    "        # ========================================\n",
    "        self.classifier = nn.Sequential(\n",
    "            # FC1: 512 Ã— 7 Ã— 7 = 25088 â†’ 4096\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # FC2: 4096 â†’ 4096\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Output: 4096 â†’ num_classes\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        \n",
    "        # æƒé‡åˆå§‹åŒ–\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _make_layers(self, config):\n",
    "        \"\"\"\n",
    "        æ ¹æ®é…ç½®æ„å»ºå·ç§¯å±‚\n",
    "        \n",
    "        å‚æ•°:\n",
    "            config: å±‚é…ç½®åˆ—è¡¨ï¼Œå¦‚ [64, 64, 'M', 128, ...]\n",
    "        \n",
    "        è¿”å›:\n",
    "            nn.Sequential: å·ç§¯å±‚åºåˆ—\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        in_channels = 3  # RGB è¾“å…¥\n",
    "        \n",
    "        for item in config:\n",
    "            if item == 'M':\n",
    "                # MaxPool 2Ã—2, stride=2\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                # Conv 3Ã—3 + ReLU\n",
    "                out_channels = item\n",
    "                layers.extend([\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                    nn.BatchNorm2d(out_channels),  # ç°ä»£ç‰ˆæœ¬æ·»åŠ  BN\n",
    "                    nn.ReLU(inplace=True),\n",
    "                ])\n",
    "                in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"æƒé‡åˆå§‹åŒ–\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        å‰å‘ä¼ æ’­\n",
    "        \n",
    "        å‚æ•°:\n",
    "            x: (batch, 3, 224, 224) è¾“å…¥å›¾åƒ\n",
    "        \n",
    "        è¿”å›:\n",
    "            logits: (batch, num_classes)\n",
    "        \"\"\"\n",
    "        x = self.features(x)        # (batch, 512, 7, 7)\n",
    "        x = x.view(x.size(0), -1)   # (batch, 25088)\n",
    "        x = self.classifier(x)      # (batch, num_classes)\n",
    "        return x\n",
    "\n",
    "\n",
    "# æµ‹è¯• VGG-16\n",
    "vgg16 = VGG(config_name='VGG16', num_classes=1000)\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "y = vgg16(x)\n",
    "\n",
    "print(\"VGG-16 æµ‹è¯•ï¼š\")\n",
    "print(f\"  è¾“å…¥: {x.shape}\")\n",
    "print(f\"  è¾“å‡º: {y.shape}\")\n",
    "print(f\"  å‚æ•°é‡: {sum(p.numel() for p in vgg16.parameters()):,}\")\n",
    "\n",
    "# æµ‹è¯•å…¶ä»–é…ç½®\n",
    "print(\"\\nå„é…ç½®å‚æ•°é‡ï¼š\")\n",
    "for name in ['VGG11', 'VGG13', 'VGG16', 'VGG19']:\n",
    "    model = VGG(config_name=name, num_classes=1000)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"  {name}: {params:,} ({params/1e6:.1f}M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 VGGNet å°ç»“\n",
    "\n",
    "**æ ¸å¿ƒè´¡çŒ®**ï¼š\n",
    "1. è¯æ˜äº† **æ·±åº¦** å¯¹äºç½‘ç»œæ€§èƒ½çš„é‡è¦æ€§\n",
    "2. ç¡®ç«‹äº† **3Ã—3 å°å·ç§¯** çš„è®¾è®¡èŒƒå¼\n",
    "3. æä¾›äº†æ¸…æ™°ã€è§„æ•´çš„æ¶æ„è®¾è®¡æ¨¡æ¿\n",
    "\n",
    "**å±€é™æ€§**ï¼š\n",
    "- å‚æ•°é‡å·¨å¤§ï¼ˆçº¦ 138Mï¼‰ï¼Œè®­ç»ƒå’Œéƒ¨ç½²éƒ½å¾ˆå›°éš¾\n",
    "- å…¨è¿æ¥å±‚å æ®ç»å¤§éƒ¨åˆ†å‚æ•°\n",
    "- æ·±åº¦å¢åŠ åˆ°ä¸€å®šç¨‹åº¦åæ•ˆæœä¸å†æå‡ï¼ˆé€€åŒ–é—®é¢˜ï¼‰â†’ å¼•å‡º ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: ä¸‰è€…å¯¹æ¯”å®éªŒ\n",
    "\n",
    "åœ¨ CIFAR-10 ä¸Šå¯¹æ¯” LeNetã€AlexNetï¼ˆç®€åŒ–ç‰ˆï¼‰ã€VGGï¼ˆç®€åŒ–ç‰ˆï¼‰çš„æ€§èƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸º CIFAR-10 è®¾è®¡ç®€åŒ–ç‰ˆæœ¬\n",
    "\n",
    "class LeNetForCIFAR(nn.Module):\n",
    "    \"\"\"LeNet æ”¹ç¼–ç‰ˆï¼Œé€‚é… CIFAR-10 (32Ã—32 RGB)\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "class AlexNetForCIFAR(nn.Module):\n",
    "    \"\"\"AlexNet ç®€åŒ–ç‰ˆï¼Œé€‚é… CIFAR-10\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 4 * 4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "class VGGForCIFAR(nn.Module):\n",
    "    \"\"\"VGG ç®€åŒ–ç‰ˆï¼Œé€‚é… CIFAR-10\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# ç»Ÿè®¡å‚æ•°é‡\n",
    "models_dict = {\n",
    "    'LeNet': LeNetForCIFAR(),\n",
    "    'AlexNet': AlexNetForCIFAR(),\n",
    "    'VGG': VGGForCIFAR(),\n",
    "}\n",
    "\n",
    "print(\"æ¨¡å‹å‚æ•°é‡å¯¹æ¯”ï¼š\")\n",
    "for name, model in models_dict.items():\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"  {name}: {params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ CIFAR-10\n",
    "print(\"åŠ è½½ CIFAR-10 æ•°æ®é›†...\")\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "cifar_train = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "cifar_test = datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "cifar_train_loader = DataLoader(cifar_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "cifar_test_loader = DataLoader(cifar_test, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"è®­ç»ƒé›†: {len(cifar_train)} æ ·æœ¬\")\n",
    "print(f\"æµ‹è¯•é›†: {len(cifar_test)} æ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, test_loader, epochs=10, lr=0.001):\n",
    "    \"\"\"è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    history = {'train_acc': [], 'test_acc': [], 'time': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # è®­ç»ƒ\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # æµ‹è¯•\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                out = model(x)\n",
    "                correct += (out.argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        test_acc = 100 * correct / total\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['time'].append(epoch_time)\n",
    "        \n",
    "        print(f\"  Epoch {epoch+1}/{epochs}: Train={train_acc:.1f}%, Test={test_acc:.1f}%, Time={epoch_time:.1f}s\")\n",
    "        scheduler.step()\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# è®­ç»ƒå¯¹æ¯”\n",
    "EPOCHS = 10\n",
    "results = {}\n",
    "\n",
    "for name in ['LeNet', 'AlexNet', 'VGG']:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"è®­ç»ƒ {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # é‡æ–°åˆ›å»ºæ¨¡å‹\n",
    "    if name == 'LeNet':\n",
    "        model = LeNetForCIFAR()\n",
    "    elif name == 'AlexNet':\n",
    "        model = AlexNetForCIFAR()\n",
    "    else:\n",
    "        model = VGGForCIFAR()\n",
    "    \n",
    "    results[name] = train_and_evaluate(model, cifar_train_loader, cifar_test_loader, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å¯¹æ¯”ç»“æœ\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "colors = {'LeNet': '#2ecc71', 'AlexNet': '#e74c3c', 'VGG': '#3498db'}\n",
    "\n",
    "# 1. æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿\n",
    "for name, history in results.items():\n",
    "    axes[0].plot(range(1, EPOCHS+1), history['test_acc'], \n",
    "                 label=name, color=colors[name], linewidth=2, marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Test Accuracy (%)')\n",
    "axes[0].set_title('æµ‹è¯•å‡†ç¡®ç‡æ›²çº¿')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. æœ€ç»ˆå‡†ç¡®ç‡å¯¹æ¯”\n",
    "names = list(results.keys())\n",
    "final_acc = [results[n]['test_acc'][-1] for n in names]\n",
    "bars = axes[1].bar(names, final_acc, color=[colors[n] for n in names])\n",
    "axes[1].set_ylabel('Test Accuracy (%)')\n",
    "axes[1].set_title('æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡')\n",
    "axes[1].set_ylim(50, 95)\n",
    "for bar, acc in zip(bars, final_acc):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                 f'{acc:.1f}%', ha='center', fontsize=11)\n",
    "\n",
    "# 3. å‚æ•°é‡å¯¹æ¯”\n",
    "params = {\n",
    "    'LeNet': sum(p.numel() for p in LeNetForCIFAR().parameters()),\n",
    "    'AlexNet': sum(p.numel() for p in AlexNetForCIFAR().parameters()),\n",
    "    'VGG': sum(p.numel() for p in VGGForCIFAR().parameters()),\n",
    "}\n",
    "param_values = [params[n] / 1e6 for n in names]\n",
    "bars = axes[2].bar(names, param_values, color=[colors[n] for n in names])\n",
    "axes[2].set_ylabel('Parameters (M)')\n",
    "axes[2].set_title('æ¨¡å‹å‚æ•°é‡')\n",
    "for bar, p in zip(bars, param_values):\n",
    "    axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                 f'{p:.2f}M', ha='center', fontsize=11)\n",
    "\n",
    "plt.suptitle('LeNet vs AlexNet vs VGG å¯¹æ¯” (CIFAR-10)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æ€»ç»“è¡¨æ ¼\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å®éªŒæ€»ç»“\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n{'æ¨¡å‹':<10} {'å‚æ•°é‡':>12} {'æœ€ç»ˆå‡†ç¡®ç‡':>12} {'å¹³å‡Epochæ—¶é—´':>14}\")\n",
    "print(\"-\" * 50)\n",
    "for name in names:\n",
    "    p = params[name]\n",
    "    acc = results[name]['test_acc'][-1]\n",
    "    t = np.mean(results[name]['time'])\n",
    "    print(f\"{name:<10} {p/1e6:>10.2f}M {acc:>11.1f}% {t:>13.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ æœ¬ç« å°ç»“\n",
    "\n",
    "### ä¸‰ä¸ªæ¶æ„çš„æ ¸å¿ƒè´¡çŒ®\n",
    "\n",
    "| æ¶æ„ | å¹´ä»½ | æ ¸å¿ƒè´¡çŒ® | å†å²æ„ä¹‰ |\n",
    "|------|------|----------|----------|\n",
    "| **LeNet-5** | 1998 | å·ç§¯ + æ± åŒ– + å…¨è¿æ¥ | ç¡®ç«‹ CNN åŸºæœ¬èŒƒå¼ |\n",
    "| **AlexNet** | 2012 | ReLU + Dropout + GPU | å¼€å¯æ·±åº¦å­¦ä¹ æ—¶ä»£ |\n",
    "| **VGGNet** | 2014 | 3Ã—3 å°å·ç§¯å †å  | è¯æ˜æ·±åº¦çš„é‡è¦æ€§ |\n",
    "\n",
    "### å‘å±•è„‰ç»œ\n",
    "\n",
    "```\n",
    "LeNet-5 (1998)           AlexNet (2012)           VGGNet (2014)\n",
    "    â”‚                        â”‚                        â”‚\n",
    "    â”œâ”€ å·ç§¯ + æ± åŒ–           â”œâ”€ ReLU æ¿€æ´»              â”œâ”€ 3Ã—3 å°å·ç§¯\n",
    "    â”œâ”€ Tanh æ¿€æ´»             â”œâ”€ Dropout æ­£åˆ™åŒ–         â”œâ”€ æ›´æ·±çš„ç½‘ç»œ\n",
    "    â””â”€ æ‰‹å†™è¯†åˆ«              â”œâ”€ GPU è®­ç»ƒ               â””â”€ è§„æ•´çš„è®¾è®¡\n",
    "                             â””â”€ ImageNet å† å†›\n",
    "```\n",
    "\n",
    "### å…³é”®ä»£ç æ¨¡å¼\n",
    "\n",
    "```python\n",
    "# LeNet æ¨¡å¼ï¼šå·ç§¯ â†’ æ¿€æ´» â†’ æ± åŒ–\n",
    "nn.Conv2d(1, 6, 5), nn.Tanh(), nn.AvgPool2d(2)\n",
    "\n",
    "# AlexNet æ¨¡å¼ï¼šåŠ å…¥ Dropout\n",
    "nn.Conv2d(3, 96, 11, stride=4), nn.ReLU(), nn.Dropout(0.5)\n",
    "\n",
    "# VGG æ¨¡å¼ï¼š3Ã—3 å·ç§¯å †å \n",
    "nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ç»ƒä¹ é¢˜\n",
    "\n",
    "### ç»ƒä¹  1ï¼šä¿®æ”¹ LeNet é€‚é…å½©è‰²å›¾åƒ\n",
    "**éš¾åº¦**ï¼šâ­\n",
    "\n",
    "ä¿®æ”¹ LeNet5 ç±»ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç† 3 é€šé“çš„å½©è‰²å›¾åƒï¼ˆå¦‚ CIFAR-10ï¼‰ã€‚\n",
    "\n",
    "### ç»ƒä¹  2ï¼šåˆ†æ VGG ä¸­ 3Ã—3 å †å çš„æ„Ÿå—é‡\n",
    "**éš¾åº¦**ï¼šâ­â­\n",
    "\n",
    "è®¡ç®— VGG-16 ä¸­æ¯ä¸ªæ± åŒ–å±‚ä¹‹åçš„æ„Ÿå—é‡å¤§å°ã€‚æç¤ºï¼šè€ƒè™‘ stride å’Œ kernel sizeã€‚\n",
    "\n",
    "### ç»ƒä¹  3ï¼šå®ç° AlexNet çš„ LRN å±‚\n",
    "**éš¾åº¦**ï¼šâ­â­â­\n",
    "\n",
    "LRNï¼ˆLocal Response Normalizationï¼‰å…¬å¼ï¼š\n",
    "$$b_{x,y}^i = a_{x,y}^i / \\left(k + \\alpha \\sum_{j=\\max(0, i-n/2)}^{\\min(N-1, i+n/2)} (a_{x,y}^j)^2 \\right)^\\beta$$\n",
    "\n",
    "ç”¨ PyTorch å®ç°è¿™ä¸ªå½’ä¸€åŒ–å±‚ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ ä¸‹ä¸€æ­¥\n",
    "\n",
    "ç»§ç»­å­¦ä¹  **07b_inception_densenet.ipynb** - Inception ä¸ DenseNet\n",
    "\n",
    "æ¢ç´¢æ›´ç°ä»£çš„æ¶æ„åˆ›æ–°ï¼šå¤šå°ºåº¦ç‰¹å¾æå–å’Œå¯†é›†è¿æ¥ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
