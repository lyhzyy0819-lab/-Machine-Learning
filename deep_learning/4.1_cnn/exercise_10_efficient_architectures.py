"""
10 ç°ä»£è½»é‡æ¶æ„ç»ƒä¹ é¢˜è§£ç­”

ç»ƒä¹  1ï¼šå‚æ•°å‹ç¼©æ¯”è®¡ç®—
ç»ƒä¹  2ï¼šå®Œæ•´ separable_conv2d å®ç°
ç»ƒä¹  3ï¼šå®½åº¦ä¹˜æ•°å®éªŒ
ç»ƒä¹  4ï¼šæ¶æ„å¯¹æ¯”ï¼ˆæ¦‚å¿µæ¡†æ¶ï¼‰

è¿è¡Œæ–¹æ³•ï¼š
    python exercise_10_efficient_architectures.py
"""

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F


# ============================================================
# ç»ƒä¹  1ï¼šå‚æ•°å‹ç¼©æ¯”è®¡ç®—
# ============================================================

def exercise_1_compression_ratio():
    """
    è®¡ç®—æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„å‚æ•°å‹ç¼©æ¯”

    é—®é¢˜ï¼š
    1. è¾“å…¥ 128 é€šé“ï¼Œè¾“å‡º 256 é€šé“ï¼Œ5Ã—5 å·ç§¯æ ¸
    2. è¾“å…¥ 512 é€šé“ï¼Œè¾“å‡º 512 é€šé“ï¼Œ3Ã—3 å·ç§¯æ ¸

    å‹ç¼©æ¯”å…¬å¼ï¼š
        æ ‡å‡†å·ç§¯å‚æ•°: C_out Ã— C_in Ã— K Ã— K
        æ·±åº¦å¯åˆ†ç¦»å‚æ•°: C_in Ã— K Ã— K + C_out Ã— C_in
        å‹ç¼©æ¯” = æ·±åº¦å¯åˆ†ç¦» / æ ‡å‡† = 1/C_out + 1/KÂ²
    """
    print("=" * 60)
    print("ç»ƒä¹  1ï¼šå‚æ•°å‹ç¼©æ¯”è®¡ç®—")
    print("=" * 60)

    def calculate_compression(C_in, C_out, K):
        """è®¡ç®—å‹ç¼©æ¯”"""
        # æ ‡å‡†å·ç§¯å‚æ•°é‡
        std_params = C_out * C_in * K * K

        # æ·±åº¦å¯åˆ†ç¦»å·ç§¯å‚æ•°é‡
        # = Depthwise (C_in Ã— K Ã— K) + Pointwise (C_out Ã— C_in)
        dw_params = C_in * K * K
        pw_params = C_out * C_in
        sep_params = dw_params + pw_params

        # å‹ç¼©æ¯”
        ratio = sep_params / std_params
        compression = std_params / sep_params

        return std_params, sep_params, ratio, compression

    # æ¡ˆä¾‹ 1ï¼š128 â†’ 256, 5Ã—5
    print("\næ¡ˆä¾‹ 1: 128 é€šé“ â†’ 256 é€šé“, 5Ã—5 å·ç§¯æ ¸")
    print("-" * 50)
    std, sep, ratio, comp = calculate_compression(128, 256, 5)
    print(f"  æ ‡å‡†å·ç§¯å‚æ•°: {std:,}")
    print(f"  æ·±åº¦å¯åˆ†ç¦»å‚æ•°: {sep:,}")
    print(f"  å‹ç¼©æ¯”: 1/{comp:.1f} = {ratio:.4f}")
    print(f"  ç†è®ºå€¼: 1/{256} + 1/{25} = {1/256 + 1/25:.4f}")

    # æ¡ˆä¾‹ 2ï¼š512 â†’ 512, 3Ã—3
    print("\næ¡ˆä¾‹ 2: 512 é€šé“ â†’ 512 é€šé“, 3Ã—3 å·ç§¯æ ¸")
    print("-" * 50)
    std, sep, ratio, comp = calculate_compression(512, 512, 3)
    print(f"  æ ‡å‡†å·ç§¯å‚æ•°: {std:,}")
    print(f"  æ·±åº¦å¯åˆ†ç¦»å‚æ•°: {sep:,}")
    print(f"  å‹ç¼©æ¯”: 1/{comp:.1f} = {ratio:.4f}")
    print(f"  ç†è®ºå€¼: 1/{512} + 1/{9} = {1/512 + 1/9:.4f}")

    print("\nğŸ’¡ ç»“è®ºï¼š")
    print("   - 5Ã—5 å·ç§¯å‹ç¼©çº¦ 25 å€")
    print("   - 3Ã—3 å·ç§¯å‹ç¼©çº¦ 9 å€")
    print("   - é€šé“æ•°è¶Šå¤šï¼Œè¶Šæ¥è¿‘ç†è®ºæé™ 1/KÂ²")


# ============================================================
# ç»ƒä¹  2ï¼šå®Œæ•´ separable_conv2d å®ç°
# ============================================================

def depthwise_conv2d(input_tensor, kernels, stride=1, padding=0):
    """
    æ·±åº¦å·ç§¯çš„ NumPy å®ç°

    å‚æ•°:
        input_tensor: è¾“å…¥, shape (C, H, W)
        kernels: å·ç§¯æ ¸, shape (C, K, K)
        stride: æ­¥å¹…
        padding: å¡«å……

    è¿”å›:
        output: è¾“å‡º, shape (C, H_out, W_out)
    """
    C, H, W = input_tensor.shape
    _, K, _ = kernels.shape

    # æ·»åŠ  padding
    if padding > 0:
        input_padded = np.pad(
            input_tensor,
            ((0, 0), (padding, padding), (padding, padding)),
            mode='constant'
        )
    else:
        input_padded = input_tensor

    # è®¡ç®—è¾“å‡ºå°ºå¯¸
    H_out = (H + 2*padding - K) // stride + 1
    W_out = (W + 2*padding - K) // stride + 1

    # åˆå§‹åŒ–è¾“å‡º
    output = np.zeros((C, H_out, W_out))

    # å¯¹æ¯ä¸ªé€šé“ç‹¬ç«‹å·ç§¯
    for c in range(C):
        for i in range(H_out):
            for j in range(W_out):
                h_start = i * stride
                w_start = j * stride
                region = input_padded[c, h_start:h_start+K, w_start:w_start+K]
                output[c, i, j] = np.sum(region * kernels[c])

    return output


def pointwise_conv2d(input_tensor, kernels):
    """
    ç‚¹å·ç§¯ï¼ˆ1Ã—1 å·ç§¯ï¼‰çš„ NumPy å®ç°

    å‚æ•°:
        input_tensor: è¾“å…¥, shape (C_in, H, W)
        kernels: 1Ã—1 å·ç§¯æ ¸, shape (C_out, C_in)

    è¿”å›:
        output: è¾“å‡º, shape (C_out, H, W)
    """
    C_in, H, W = input_tensor.shape
    C_out, _ = kernels.shape

    # é‡å¡‘ä¸ºçŸ©é˜µä¹˜æ³•
    input_flat = input_tensor.reshape(C_in, -1)
    output_flat = kernels @ input_flat
    output = output_flat.reshape(C_out, H, W)

    return output


def separable_conv2d(input_tensor, dw_kernels, pw_kernels, stride=1, padding=0):
    """
    å®Œæ•´çš„æ·±åº¦å¯åˆ†ç¦»å·ç§¯å®ç°ï¼ˆæ”¯æŒ strideï¼‰

    å‚æ•°:
        input_tensor: è¾“å…¥, shape (C_in, H, W)
        dw_kernels: Depthwise æ ¸, shape (C_in, K, K)
        pw_kernels: Pointwise æ ¸, shape (C_out, C_in)
        stride: æ­¥å¹…ï¼ˆç”¨äº Depthwiseï¼‰
        padding: å¡«å……ï¼ˆç”¨äº Depthwiseï¼‰

    è¿”å›:
        output: è¾“å‡º, shape (C_out, H_out, W_out)
    """
    # Step 1: Depthwise å·ç§¯
    dw_output = depthwise_conv2d(input_tensor, dw_kernels, stride, padding)

    # Step 2: Pointwise å·ç§¯
    output = pointwise_conv2d(dw_output, pw_kernels)

    return output


def exercise_2_separable_conv():
    """éªŒè¯ separable_conv2d å®ç°"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  2ï¼šå®Œæ•´ separable_conv2d å®ç°")
    print("=" * 60)

    # æµ‹è¯•å‚æ•°
    np.random.seed(42)
    C_in, C_out = 32, 64
    H, W = 16, 16
    K = 3
    stride = 2
    padding = 1

    # åˆ›å»ºè¾“å…¥å’Œæƒé‡
    x = np.random.randn(C_in, H, W).astype(np.float32)
    dw_kernels = np.random.randn(C_in, K, K).astype(np.float32) * 0.1
    pw_kernels = np.random.randn(C_out, C_in).astype(np.float32) * 0.1

    # NumPy å®ç°
    output_np = separable_conv2d(x, dw_kernels, pw_kernels, stride, padding)

    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"Depthwise æ ¸: {dw_kernels.shape}")
    print(f"Pointwise æ ¸: {pw_kernels.shape}")
    print(f"stride={stride}, padding={padding}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output_np.shape}")

    # ä½¿ç”¨ PyTorch éªŒè¯
    x_torch = torch.from_numpy(x).unsqueeze(0)  # (1, C_in, H, W)

    # PyTorch Depthwise
    dw_conv = nn.Conv2d(C_in, C_in, K, stride, padding, groups=C_in, bias=False)
    dw_conv.weight.data = torch.from_numpy(dw_kernels).unsqueeze(1)

    # PyTorch Pointwise
    pw_conv = nn.Conv2d(C_in, C_out, 1, bias=False)
    pw_conv.weight.data = torch.from_numpy(pw_kernels).unsqueeze(-1).unsqueeze(-1)

    with torch.no_grad():
        dw_out = dw_conv(x_torch)
        output_torch = pw_conv(dw_out).squeeze(0).numpy()

    # æ¯”è¾ƒç»“æœ
    diff = np.abs(output_np - output_torch).max()
    print(f"\nä¸ PyTorch ç»“æœçš„æœ€å¤§å·®å¼‚: {diff:.2e}")
    print(f"éªŒè¯ç»“æœ: {'âœ“ é€šè¿‡' if diff < 1e-4 else 'âœ— å¤±è´¥'}")


# ============================================================
# ç»ƒä¹  3ï¼šå®½åº¦ä¹˜æ•°å®éªŒ
# ============================================================

class MobileNetV2_WithAlpha(nn.Module):
    """
    å¸¦å®½åº¦ä¹˜æ•°çš„ MobileNet V2

    å‚æ•°:
        alpha: å®½åº¦ä¹˜æ•°ï¼Œæ§åˆ¶æ¯å±‚é€šé“æ•°
        num_classes: åˆ†ç±»æ•°
    """

    def __init__(self, alpha=1.0, num_classes=10):
        super().__init__()

        self.alpha = alpha

        # æ ¹æ® alpha è°ƒæ•´é€šé“æ•°
        def ch(c):
            return max(8, int(c * alpha))

        # ç®€åŒ–çš„ç½‘ç»œç»“æ„
        self.features = nn.Sequential(
            # åˆå§‹å±‚
            nn.Conv2d(3, ch(32), 3, padding=1, bias=False),
            nn.BatchNorm2d(ch(32)),
            nn.ReLU6(inplace=True),

            # å‡ ä¸ªå€’æ®‹å·®å—ï¼ˆç®€åŒ–ç‰ˆï¼‰
            self._inverted_residual(ch(32), ch(16), 1, 1),
            self._inverted_residual(ch(16), ch(24), 2, 6),
            self._inverted_residual(ch(24), ch(32), 2, 6),
            self._inverted_residual(ch(32), ch(64), 2, 6),
            self._inverted_residual(ch(64), ch(96), 1, 6),
            self._inverted_residual(ch(96), ch(160), 2, 6),

            # æœ€åçš„ 1Ã—1 å·ç§¯
            nn.Conv2d(ch(160), ch(1280), 1, bias=False),
            nn.BatchNorm2d(ch(1280)),
            nn.ReLU6(inplace=True),
        )

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(ch(1280), num_classes)
        )

    def _inverted_residual(self, inp, oup, stride, expand_ratio):
        """ç®€åŒ–çš„å€’æ®‹å·®å—"""
        hidden_dim = inp * expand_ratio

        layers = []
        if expand_ratio != 1:
            layers.extend([
                nn.Conv2d(inp, hidden_dim, 1, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.ReLU6(inplace=True),
            ])

        layers.extend([
            nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU6(inplace=True),
            nn.Conv2d(hidden_dim, oup, 1, bias=False),
            nn.BatchNorm2d(oup),
        ])

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.features(x)
        return self.classifier(x)


def exercise_3_width_multiplier():
    """å®½åº¦ä¹˜æ•°å®éªŒ"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  3ï¼šå®½åº¦ä¹˜æ•°å®éªŒ")
    print("=" * 60)

    alphas = [0.5, 0.75, 1.0, 1.25]

    print(f"\n{'Alpha':<10} {'å‚æ•°é‡':>15} {'ç›¸å¯¹ Î±=1.0':>15}")
    print("-" * 42)

    base_params = None
    for alpha in alphas:
        model = MobileNetV2_WithAlpha(alpha=alpha)
        params = sum(p.numel() for p in model.parameters())

        if alpha == 1.0:
            base_params = params

        ratio = params / base_params if base_params else 1.0
        print(f"{alpha:<10} {params:>15,} {ratio:>14.2f}x")

    print("\nğŸ’¡ ç»“è®ºï¼š")
    print("   - alpha=0.5 æ—¶å‚æ•°é‡çº¦ä¸ºåŸæ¥çš„ 25%")
    print("   - alpha=0.75 æ—¶å‚æ•°é‡çº¦ä¸ºåŸæ¥çš„ 56%")
    print("   - å®½åº¦ä¹˜æ•°æ˜¯æ§åˆ¶æ¨¡å‹å¤§å°çš„æœ‰æ•ˆæ–¹å¼")


# ============================================================
# ç»ƒä¹  4ï¼šæ¶æ„å¯¹æ¯”æ¡†æ¶
# ============================================================

def exercise_4_architecture_comparison():
    """æ¶æ„å¯¹æ¯”çš„æ¦‚å¿µæ¡†æ¶"""
    print("\n" + "=" * 60)
    print("ç»ƒä¹  4ï¼šæ¶æ„å¯¹æ¯”ï¼ˆæ¦‚å¿µæ¡†æ¶ï¼‰")
    print("=" * 60)

    print("""
åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸Šå¯¹æ¯”ä¸åŒæ¶æ„çš„æ­¥éª¤ï¼š

1. æ•°æ®å‡†å¤‡
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - åŠ è½½æ•°æ®é›†ï¼ˆå¦‚ CIFAR-100ã€è‡ªå®šä¹‰æ•°æ®é›†ï¼‰
   - æ•°æ®å¢å¼ºï¼ˆRandomCrop, HorizontalFlip, ColorJitter ç­‰ï¼‰
   - åˆ’åˆ†è®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†

2. æ¨¡å‹å®šä¹‰
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - SimpleCNNï¼ˆåŸºçº¿ï¼‰
   - MobileNet V2
   - EfficientNet-B0ï¼ˆä½¿ç”¨ torchvision é¢„è®­ç»ƒæƒé‡ï¼‰
   - å¯é€‰ï¼šResNet-18 ä½œä¸ºå‚è€ƒ

3. è®­ç»ƒé…ç½®
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - ä¼˜åŒ–å™¨ï¼šAdam æˆ– SGD with momentum
   - å­¦ä¹ ç‡è°ƒåº¦ï¼šCosineAnnealingLR
   - æŸå¤±å‡½æ•°ï¼šCrossEntropyLoss
   - è®­ç»ƒè½®æ•°ï¼šæ ¹æ®æ•°æ®é›†å¤§å°è°ƒæ•´

4. è¯„ä¼°æŒ‡æ ‡
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - å‡†ç¡®ç‡ï¼ˆTop-1, Top-5ï¼‰
   - å‚æ•°é‡
   - æ¨ç†æ—¶é—´ï¼ˆFPSï¼‰
   - FLOPs

5. ç»“æœå¯è§†åŒ–
   â”€â”€â”€â”€â”€â”€â”€â”€â”€
   - å‡†ç¡®ç‡ vs Epoch æ›²çº¿
   - å‚æ•°é‡ vs å‡†ç¡®ç‡ æ•£ç‚¹å›¾
   - æ¨ç†é€Ÿåº¦å¯¹æ¯”æŸ±çŠ¶å›¾
""")

    # ç¤ºä¾‹ä»£ç æ¡†æ¶
    print("\nç¤ºä¾‹ä»£ç æ¡†æ¶ï¼š")
    print("-" * 50)
    print("""
# 1. å®šä¹‰æ¨¡å‹å­—å…¸
models = {
    'SimpleCNN': SimpleCNN(num_classes=100),
    'MobileNetV2': MobileNetV2_Small(num_classes=100),
    'EfficientNet-B0': create_efficientnet_b0(num_classes=100),
}

# 2. è®­ç»ƒå¾ªç¯
results = {}
for name, model in models.items():
    print(f"è®­ç»ƒ {name}...")
    history = train_model(model, train_loader, val_loader, epochs=50)
    results[name] = history

# 3. è¯„ä¼°å’Œå¯è§†åŒ–
plot_comparison(results)
    """)


# ============================================================
# ä¸»å‡½æ•°
# ============================================================

def main():
    print("â•”" + "â•" * 58 + "â•—")
    print("â•‘" + "  10 ç°ä»£è½»é‡æ¶æ„ç»ƒä¹ é¢˜è§£ç­”  ".center(58) + "â•‘")
    print("â•š" + "â•" * 58 + "â•")

    exercise_1_compression_ratio()
    exercise_2_separable_conv()
    exercise_3_width_multiplier()
    exercise_4_architecture_comparison()

    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç»ƒä¹ å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
