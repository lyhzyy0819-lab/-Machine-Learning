# 🌳 问题类型决策树

> 系统化地确定机器学习问题类型及解决方案
>
> ⏱️ **预计用时**：10-15分钟快速确定问题类型

---

## 📋 使用说明

本决策树帮助你：
1. ✅ **5分钟内**准确识别问题类型
2. ✅ 确定解决方案方向
3. ✅ 获得候选算法建议
4. ✅ 明确评估指标方向

---

## 🗂️ 快速跳转目录

| 问题类型 | 跳转链接 | 典型场景 |
|----------|----------|----------|
| **🔍 判断有无标签** | [第一层：监督 vs 无监督](#-第一层监督学习-vs-无监督学习) | 不确定是监督还是无监督 |
| **📊 分类 vs 回归** | [第二层：分类 vs 回归](#-第二层分类-vs-回归) | 预测类别还是数值？ |
| **🔓 无监督学习** | [第三层：无监督学习类型](#-第三层无监督学习类型) | 聚类/降维/异常检测 |
| **🎯 特殊问题类型** | [第四层：特殊问题类型](#-第四层特殊问题类型) | 时间序列、多任务学习等 |
| **📋 完整决策清单** | [完整决策检查清单](#-完整决策检查清单) | 系统化检查所有决策点 |
| **🎯 实战案例** | [实战案例决策](#-实战案例决策) | 查看真实案例的决策过程 |

**💡 使用提示**：

| 场景 | 推荐路径 | 预计时间 |
|------|----------|----------|
| **首次使用** | 按顺序阅读所有层级 | 30-40分钟 |
| **快速确定** | 使用 [完整决策树](#-完整决策树) 快速定位 | 5-10分钟 |
| **学习决策方法** | 查看 [实战案例](#-实战案例决策) | 15-20分钟 |
| **已知问题类型** | 直接跳转到对应章节验证 | 3-5分钟 |

---

## 🎯 完整决策树

```
                        【开始：定义ML问题】
                                │
                                ↓
                    ┌───────────────────────┐
                    │   是否有标注的        │
                    │   目标变量（标签）？  │
                    └───────────────────────┘
                           │           │
                          有          没有
                           │           │
                           ↓           ↓
                    ┌──────────┐  ┌──────────┐
                    │ 监督学习  │  │无监督学习│
                    └──────────┘  └──────────┘
                           │           │
        ┌──────────────────┴────┐      │
        │                       │      │
        ↓                       ↓      │
   ┌─────────┐           ┌─────────┐  │
   │预测类别？│           │预测数值？│  │
   └─────────┘           └─────────┘  │
        │                       │      │
       是                      是     │
        │                       │      │
        ↓                       ↓      │
   【分类问题】              【回归问题】 │
        │                       │      │
        │                       │      │
        │                       │      └──────────┐
        │                       │                 │
        ↓                       ↓                 ↓

┌────────────────────┐  ┌────────────────────┐  ┌────────────────────┐
│   分类问题详细      │  │   回归问题详细      │  │  无监督学习详细    │
└────────────────────┘  └────────────────────┘  └────────────────────┘
```

---

## 📊 第一层：监督学习 vs 无监督学习

### 决策点1：是否有标签？

```
有训练数据的标签（Ground Truth）？
        │
    ┌───┴───┐
    │       │
   有      没有
    │       │
    ↓       ↓
监督学习  无监督学习
```

#### ✅ 监督学习特征
- **有标签数据**：每个样本都有对应的正确答案
- **目标明确**：知道要预测什么
- **评估直观**：可以直接比较预测值和真实值

**示例数据格式：**
```python
# 分类问题
特征1  特征2  特征3  → 标签
100    50     1.2   → A类
200    60     0.8   → B类
150    55     1.0   → A类

# 回归问题
面积   房龄   地段  → 价格
100    5      市中心 → 500万
80     10     郊区   → 300万
```

#### ✅ 无监督学习特征
- **无标签数据**：只有输入特征，没有标准答案
- **探索性**：发现数据中的模式和结构
- **评估间接**：需要使用内部指标或业务验证

**示例数据格式：**
```python
# 只有特征，没有标签
特征1  特征2  特征3
100    50     1.2
200    60     0.8
150    55     1.0
# 目标：发现这些数据的群组结构
```

### 快速判断方法

```python
def check_supervised_or_not(data):
    """判断是否为监督学习问题"""

    questions = [
        "是否有明确的预测目标？",
        "是否有历史标签数据？",
        "能否量化预测的对错？"
    ]

    # 如果3个问题都是"是" → 监督学习
    # 如果都是"否" → 无监督学习
    # 如果混合 → 可能需要半监督学习
```

---

## 🎯 第二层：分类 vs 回归

### 决策点2：预测什么类型的输出？

```
预测的是离散类别还是连续数值？
            │
        ┌───┴───┐
        │       │
      类别    数值
        │       │
        ↓       ↓
     分类问题  回归问题
```

### 🏷️ 分类问题（Classification）

#### 特征识别
- **输出**：离散的类别标签
- **目标**：将样本分配到预定义的类别中
- **答案形式**：A类/B类/C类，是/否，通过/不通过

#### 典型场景

| 场景 | 输入 | 输出（类别） | 问题类型 |
|------|------|--------------|----------|
| 垃圾邮件检测 | 邮件内容 | 垃圾/正常 | 二分类 |
| 图像识别 | 图像像素 | 猫/狗/鸟... | 多分类 |
| 疾病诊断 | 症状、检查结果 | 健康/疾病A/疾病B | 多分类 |
| 情感分析 | 评论文本 | 正面/负面/中性 | 多分类 |
| 信用评级 | 财务数据 | AAA/AA/A/BBB... | 多分类 |

#### 分类问题细分

```
分类问题
    │
    ├─ 二分类（Binary Classification）
    │   • 只有2个类别
    │   • 例：是/否、正/负、0/1
    │   • 算法：逻辑回归、SVM、随机森林
    │
    ├─ 多分类（Multiclass Classification）
    │   • 3个或以上互斥类别
    │   • 每个样本只属于一个类别
    │   • 算法：Softmax回归、决策树、XGBoost
    │
    └─ 多标签（Multilabel Classification）
        • 每个样本可以有多个标签
        • 标签之间不互斥
        • 例：新闻分类（政治+经济）、电影类型
        • 算法：Binary Relevance、Classifier Chains
```

#### 判断技巧

```python
def identify_classification_type(y):
    """识别分类问题类型"""

    n_unique = len(np.unique(y))

    if n_unique == 2:
        return "二分类"
    elif n_unique <= 20:  # 经验阈值
        return "多分类"
    else:
        # 类别数过多，可能是：
        # 1. 回归问题被错误识别
        # 2. 高基数分类问题（如用户ID分类）
        return "需要重新审视问题定义"

# 示例
y_binary = [0, 1, 0, 1, 1]  # 二分类
print(identify_classification_type(y_binary))  # 输出：二分类

y_multi = ['A', 'B', 'C', 'A', 'B']  # 多分类
print(identify_classification_type(y_multi))  # 输出：多分类
```

### 📈 回归问题（Regression）

#### 特征识别
- **输出**：连续的数值
- **目标**：预测一个数量或程度
- **答案形式**：价格、温度、距离、概率

#### 典型场景

| 场景 | 输入 | 输出（数值） | 单位 |
|------|------|--------------|------|
| 房价预测 | 位置、面积、房龄 | 价格 | 万元 |
| 销量预测 | 历史销量、促销 | 未来销量 | 件数 |
| 股票预测 | 历史价格、指标 | 未来价格 | 元 |
| 温度预测 | 历史温度、气象 | 未来温度 | 摄氏度 |
| 用户评分 | 用户/物品特征 | 评分 | 1-5分 |

#### 回归问题细分

```
回归问题
    │
    ├─ 简单线性回归
    │   • 单个特征预测单个目标
    │   • y = wx + b
    │
    ├─ 多元线性回归
    │   • 多个特征预测单个目标
    │   • y = w1*x1 + w2*x2 + ... + b
    │
    ├─ 多输出回归
    │   • 同时预测多个目标
    │   • 例：预测(温度, 湿度, 气压)
    │
    └─ 时间序列回归
        • 考虑时间依赖关系
        • 例：股票价格、销量预测
```

#### 判断技巧

```python
def is_regression_problem(y):
    """判断是否为回归问题"""

    checks = {
        "是否为数值类型": np.issubdtype(y.dtype, np.number),
        "唯一值是否很多": len(np.unique(y)) > 20,
        "是否为浮点数": np.issubdtype(y.dtype, np.floating),
        "值域是否连续": (y.max() - y.min()) > 20
    }

    # 如果大部分检查通过 → 回归问题
    return sum(checks.values()) >= 3

# 示例
y_regression = [100.5, 200.3, 150.8, 180.2]
print(is_regression_problem(np.array(y_regression)))  # True

y_classification = [1, 2, 3, 1, 2]
print(is_regression_problem(np.array(y_classification)))  # False
```

### 🔄 边界情况处理

#### 情况1：有序分类（Ordinal Classification）

```python
# 评级：差(1) < 一般(2) < 好(3) < 优秀(4)
ratings = [1, 2, 3, 4, 3, 2, 1]

# 方法1：作为分类问题
# - 使用分类算法
# - 评估指标：准确率
# - 优点：直接预测类别
# - 缺点：忽略了顺序关系

# 方法2：作为回归问题
# - 使用回归算法
# - 评估指标：MAE、RMSE
# - 预测后四舍五入到最近的类别
# - 优点：考虑顺序关系
# - 缺点：预测值可能不在有效范围

# 推荐：
# 如果类别间距相等 → 回归
# 如果类别间距不等 → 有序分类专用算法
```

#### 情况2：计数问题（Count Data）

```python
# 预测每天网站访问次数：0, 1, 2, 3, ...
visits = [0, 5, 12, 3, 8, 1, 0]

# 可以看作：
# 1. 回归问题（预测数量）
#    - 使用：泊松回归
# 2. 多分类问题（如果范围小）
#    - 使用：多分类算法
#    - 注意：类别数可能很多

# 推荐：
# 如果最大值<50 → 可以考虑分类
# 如果最大值>50 → 回归更合适
```

---

## 🔓 第三层：无监督学习类型

### 决策点3：无监督学习的目标是什么？

```
数据分析的主要目的？
        │
    ┌───┴───┬───────┬────────┐
    │       │       │        │
 发现群组 降低维度 找异常  关联规则
    │       │       │        │
    ↓       ↓       ↓        ↓
  聚类    降维   异常检测  关联分析
```

### 📊 聚类（Clustering）

#### 目标
将相似的数据点分组到同一簇，不同簇之间差异明显。

#### 典型场景

| 场景 | 输入 | 输出 | 业务价值 |
|------|------|------|----------|
| 客户分群 | 消费行为 | 客户群组 | 精准营销 |
| 图像分割 | 图像像素 | 区域划分 | 目标识别 |
| 文档聚类 | 文本特征 | 主题分组 | 信息组织 |
| 基因分型 | 基因表达 | 基因类型 | 疾病研究 |

#### 算法选择

```
聚类问题
    │
    ├─ 知道簇数？
    │   │
    │   ├─ 是 → K-Means
    │   │      • 快速、可扩展
    │   │      • 适合球形簇
    │   │
    │   └─ 否 → DBSCAN
    │          • 自动确定簇数
    │          • 可识别噪声点
    │
    ├─ 需要层次结构？
    │   → 层次聚类
    │      • 提供树状图
    │      • 适合小数据集
    │
    └─ 簇形状复杂？
        → GMM（高斯混合模型）
           • 概率模型
           • 可处理椭圆形簇
```

#### 决策流程

```python
def choose_clustering_algorithm(data_info):
    """选择聚类算法"""

    n_samples = data_info['n_samples']
    know_k = data_info['know_num_clusters']
    cluster_shape = data_info['cluster_shape']  # 'spherical', 'complex'
    has_noise = data_info['has_outliers']

    if know_k and cluster_shape == 'spherical' and not has_noise:
        return "K-Means"
    elif has_noise or not know_k:
        return "DBSCAN"
    elif cluster_shape == 'complex':
        return "GMM"
    elif n_samples < 10000:
        return "Hierarchical Clustering"
    else:
        return "K-Means (默认选择)"

# 使用示例
data_info = {
    'n_samples': 50000,
    'know_num_clusters': True,
    'cluster_shape': 'spherical',
    'has_outliers': False
}
print(choose_clustering_algorithm(data_info))  # 输出：K-Means
```

### 📉 降维（Dimensionality Reduction）

#### 目标
减少特征数量，同时保留重要信息。

#### 应用场景

| 目的 | 方法 | 适用场景 |
|------|------|----------|
| 数据可视化 | t-SNE, UMAP | 高维数据→2D/3D展示 |
| 特征提取 | PCA, LDA | 提取主要成分 |
| 去噪 | PCA, Autoencoders | 过滤噪声信息 |
| 加速训练 | PCA, Feature Selection | 减少计算量 |

#### 算法选择

```
降维问题
    │
    ├─ 线性还是非线性？
    │   │
    │   ├─ 线性 → PCA
    │   │      • 最常用
    │   │      • 可逆变换
    │   │      • 解释性好
    │   │
    │   └─ 非线性 → t-SNE / UMAP
    │              • 保留局部结构
    │              • 适合可视化
    │
    ├─ 监督还是无监督？
    │   │
    │   └─ 监督 → LDA
    │          • 考虑类别信息
    │          • 最大化类间差异
    │
    └─ 需要多少维度？
        │
        ├─ 2-3维（可视化） → t-SNE
        └─ 自动选择 → PCA（解释90-95%方差）
```

### 🚨 异常检测（Anomaly Detection）

#### 目标
识别与正常模式显著不同的数据点。

#### 典型场景

| 场景 | 正常数据 | 异常数据 | 检测方法 |
|------|----------|----------|----------|
| 信用卡欺诈 | 正常交易 | 欺诈交易 | Isolation Forest |
| 设备故障 | 正常运行参数 | 故障信号 | One-Class SVM |
| 网络入侵 | 正常流量 | 攻击流量 | LOF |
| 生产质量 | 合格品 | 次品 | Autoencoder |

#### 算法选择

```
异常检测
    │
    ├─ 数据量大小？
    │   │
    │   ├─ 小(<10K) → LOF
    │   │             • 基于密度
    │   │             • 检测局部异常
    │   │
    │   └─ 大(>10K) → Isolation Forest
    │                 • 高效、可扩展
    │                 • 随机森林思想
    │
    ├─ 异常比例？
    │   │
    │   ├─ 已知(<10%) → 设置contamination参数
    │   └─ 未知 → 使用无监督方法
    │
    └─ 特征维度？
        │
        ├─ 低维(<10) → 统计方法（Z-Score、IQR）
        └─ 高维(>10) → Isolation Forest、Autoencoder
```

---

## 🎯 第四层：特殊问题类型

### 半监督学习（Semi-Supervised Learning）

#### 什么时候使用？

```
有大量无标签数据 + 少量标签数据
            │
            ↓
    半监督学习更合适
```

**适用场景：**
- 标注成本高（医学影像、专家标注）
- 数据量大但标注少（文本分类、图像识别）
- 主动学习（iterative labeling）

**方法：**
```python
from sklearn.semi_supervised import LabelPropagation

# 部分数据有标签，部分没有（用-1表示）
y = [0, 1, 0, -1, -1, 1, -1, 0]  # -1表示未标注

model = LabelPropagation()
model.fit(X, y)
predictions = model.predict(X)  # 为未标注数据预测标签
```

### 强化学习（Reinforcement Learning）

#### 什么时候使用？

```
需要通过trial-and-error学习最优策略？
            │
            ↓
    强化学习
```

**特征：**
- 没有固定的训练集
- 通过与环境交互学习
- 目标是最大化长期回报

**适用场景：**
- 游戏AI（AlphaGo、Dota2）
- 机器人控制
- 推荐系统优化
- 自动驾驶

### 迁移学习（Transfer Learning）

#### 什么时候使用？

```
目标任务数据少，但有相关任务的预训练模型？
            │
            ↓
    迁移学习
```

**适用场景：**
- 小样本学习
- 图像分类（使用ImageNet预训练）
- NLP任务（使用BERT、GPT）

---

## 📋 完整决策检查清单

### 第一步：确认数据类型

- [ ] 我有标签数据吗？
  - 有 → 监督学习
  - 没有 → 无监督学习

### 第二步：确认输出类型（监督学习）

- [ ] 输出是什么类型？
  - 类别 → 分类
    - 2个类别 → 二分类
    - 多个类别 → 多分类
  - 数值 → 回归

### 第三步：确认分析目标（无监督学习）

- [ ] 我想做什么？
  - 发现群组 → 聚类
  - 降低维度 → 降维
  - 找异常点 → 异常检测

### 第四步：特殊情况检查

- [ ] 标签少但数据多？ → 半监督学习
- [ ] 需要与环境交互？ → 强化学习
- [ ] 有相关预训练模型？ → 迁移学习

---

## 🎯 实战案例决策

### 案例1：电商用户是否会购买某商品

```
步骤1：有标签吗？
→ 是（历史购买记录）

步骤2：输出类型？
→ 类别（购买/不购买）

步骤3：多少个类别？
→ 2个（二分类）

步骤4：数据平衡吗？
→ 不平衡（购买率5%）

结论：
• 问题类型：二分类（不平衡）
• 推荐算法：XGBoost + 类权重调整
• 评估指标：AUC、F1-Score（不用准确率！）
```

### 案例2：预测明天气温

```
步骤1：有标签吗？
→ 是（历史气温数据）

步骤2：输出类型？
→ 数值（温度，连续值）

步骤3：有时间依赖吗？
→ 是（时间序列）

结论：
• 问题类型：时间序列回归
• 推荐算法：LSTM、XGBoost（滞后特征）
• 评估指标：MAE、RMSE
```

### 案例3：将新闻文章自动分组

```
步骤1：有标签吗？
→ 没有（不知道有哪些主题）

步骤2：分析目标？
→ 发现相似文章群组

步骤3：知道群组数吗？
→ 不知道

结论：
• 问题类型：聚类（无监督）
• 推荐算法：DBSCAN、层次聚类
• 评估指标：Silhouette Score
```

---

## ✅ 自我验证

完成问题定义后，回答以下问题：

1. [ ] 我能用一句话清楚描述这个问题吗？
2. [ ] 我知道输入是什么、输出是什么吗？
3. [ ] 我确定了问题类型（分类/回归/聚类等）了吗？
4. [ ] 我选择了合适的评估指标了吗？
5. [ ] 我考虑了业务约束（时间、可解释性等）了吗？

如果都是✅，恭喜你完成了正确的问题定义！

---

**下一步：** 查看 [评估指标选择指南](evaluation_metrics_guide.md)，深入理解如何评估模型！
