"""
ç‰¹å¾å·¥ç¨‹ä»£ç æ¨¡æ¿åº“
=================

å¿«é€Ÿä½¿ç”¨:
    from code_templates.feature_engineering_templates import (
        quick_feature_selection,
        create_interaction_features,
        create_time_features,
        create_aggregation_features,
        build_feature_engineering_pipeline
    )

    # 5-10è¡Œä»£ç å®Œæˆç‰¹å¾å·¥ç¨‹
    df = quick_feature_selection(df, y, method='auto')
    df = create_interaction_features(df, columns=['age', 'income'])
    df = create_time_features(df, datetime_col='signup_date')

    # æˆ–ä½¿ç”¨ä¸€é”®å¼Pipeline
    df_engineered = build_feature_engineering_pipeline(
        df, y, level='standard', interaction_cols=['age', 'income']
    )

å¯¹åº”å†³ç­–æ¨¡æ¿: 07_decision_templates/data_diagnosis_template.mdï¼ˆç‰¹å¾å·¥ç¨‹éƒ¨åˆ†ï¼‰
å‚è€ƒå®ç°: 06_comprehensive_project/src/feature_engineering.py (638è¡Œ)

é¡¹ç›®å®šä½: MLå®æˆ˜æ“ä½œæ‰‹å†Œï¼ˆéæ•™å­¦é¡¹ç›®ï¼‰
æ ¸å¿ƒä»·å€¼: 5-15åˆ†é’Ÿå¿«é€Ÿä»£ç è½åœ°
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Tuple
from sklearn.feature_selection import (
    VarianceThreshold, SelectKBest, f_classif, f_regression,
    SelectFromModel
)
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from scipy import stats
from itertools import combinations
import warnings
warnings.filterwarnings('ignore')


# ==================== 1. ç‰¹å¾é€‰æ‹© ====================

def quick_feature_selection(df: pd.DataFrame,
                           y: pd.Series,
                           method: str = 'auto',
                           n_features: int = None,
                           problem_type: str = 'classification',
                           verbose: bool = True) -> pd.DataFrame:
    """
    å¿«é€Ÿç‰¹å¾é€‰æ‹©ï¼ˆ5åˆ†é’Ÿå†³ç­–ï¼‰

    Parameters
    ----------
    df : DataFrame
        ç‰¹å¾æ•°æ®
    y : Series
        ç›®æ ‡å˜é‡
    method : {'auto', 'variance', 'correlation', 'importance'}
        'auto' - ç»„åˆä½¿ç”¨ä¸‰ç§æ–¹æ³•ï¼ˆæ¨èï¼‰
        variance    - ç§»é™¤ä½æ–¹å·®ç‰¹å¾
        correlation - ç§»é™¤é«˜ç›¸å…³ç‰¹å¾
        importance  - åŸºäºæ¨¡å‹é‡è¦æ€§
    n_features : int, optional
        ä¿ç•™ç‰¹å¾æ•°ï¼ŒNoneåˆ™è‡ªåŠ¨ç¡®å®š
    problem_type : {'classification', 'regression'}
        é—®é¢˜ç±»å‹

    Returns
    -------
    DataFrame
        é€‰æ‹©åçš„ç‰¹å¾

    Examples
    --------
    >>> # å¿«é€Ÿæ¨¡å¼ï¼šå…¨è‡ªåŠ¨
    >>> df_selected = quick_feature_selection(df, y)
    >>> # 100åˆ— â†’ 30åˆ—ï¼ˆè‡ªåŠ¨ç§»é™¤å†—ä½™ï¼‰

    >>> # å®šåˆ¶æ¨¡å¼ï¼šæŒ‡å®šä¿ç•™æ•°é‡
    >>> df_selected = quick_feature_selection(df, y, n_features=20)

    Decision Logic
    --------------
    ç‰¹å¾æ•° < 50   â†’ ä¿ç•™æ‰€æœ‰
    ç‰¹å¾æ•° 50-200 â†’ ç›¸å…³æ€§è¿‡æ»¤
    ç‰¹å¾æ•° > 200  â†’ ç»„åˆè¿‡æ»¤ï¼ˆæ–¹å·®+ç›¸å…³+é‡è¦æ€§ï¼‰

    Notes
    -----
    - å¿«é€Ÿæ¨¡å¼é€‚åˆé™ç»´å’Œæå‡æ¨¡å‹æ•ˆç‡
    - å‚è€ƒ06ç« src/feature_engineering.py:34-156
    """
    df_copy = df.copy()
    initial_n_features = df_copy.shape[1]

    if verbose:
        print(f"ğŸ” ç‰¹å¾é€‰æ‹©ï¼ˆåˆå§‹: {initial_n_features}åˆ—ï¼‰...")

    # 1. æ–¹å·®è¿‡æ»¤
    if method in ['auto', 'variance']:
        numeric_df = df_copy.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            selector = VarianceThreshold(threshold=0.01)
            selector.fit(numeric_df)
            selected_cols = numeric_df.columns[selector.get_support()].tolist()
            removed_cols = set(numeric_df.columns) - set(selected_cols)

            non_numeric_cols = df_copy.select_dtypes(exclude=[np.number]).columns.tolist()
            df_copy = df_copy[selected_cols + non_numeric_cols]

            if verbose and removed_cols:
                print(f"   âœ“ æ–¹å·®è¿‡æ»¤: ç§»é™¤{len(removed_cols)}åˆ—")

    # 2. ç›¸å…³æ€§è¿‡æ»¤
    if method in ['auto', 'correlation']:
        numeric_df = df_copy.select_dtypes(include=[np.number])
        if numeric_df.shape[1] > 1:
            corr_matrix = numeric_df.corr().abs()
            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

            to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]
            df_copy = df_copy.drop(columns=to_drop)

            if verbose and to_drop:
                print(f"   âœ“ ç›¸å…³æ€§è¿‡æ»¤: ç§»é™¤{len(to_drop)}åˆ—ï¼ˆ|r|>0.95ï¼‰")

    # 3. åŸºäºé‡è¦æ€§é€‰æ‹©
    if method in ['auto', 'importance'] and n_features:
        numeric_df = df_copy.select_dtypes(include=[np.number])

        if problem_type == 'classification':
            model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
        else:
            model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)

        selector = SelectFromModel(model, max_features=n_features, threshold=-np.inf)
        selector.fit(numeric_df, y)

        selected_cols = numeric_df.columns[selector.get_support()].tolist()
        non_numeric_cols = df_copy.select_dtypes(exclude=[np.number]).columns.tolist()
        df_copy = df_copy[selected_cols + non_numeric_cols]

        if verbose:
            print(f"   âœ“ é‡è¦æ€§é€‰æ‹©: ä¿ç•™Top {n_features}åˆ—")

    final_n_features = df_copy.shape[1]

    if verbose:
        print(f"âœ“ ç‰¹å¾é€‰æ‹©å®Œæˆ: {initial_n_features} â†’ {final_n_features}åˆ—\n")

    return df_copy


# ==================== 2. ç‰¹å¾å˜æ¢ ====================

def quick_transform_skewed(df: pd.DataFrame,
                          columns: List[str] = None,
                          method: str = 'auto',
                          threshold: float = 0.5,
                          verbose: bool = True) -> pd.DataFrame:
    """
    å¿«é€Ÿåæ€åˆ†å¸ƒå˜æ¢

    é€‚ç”¨åœºæ™¯:
    - çº¿æ€§æ¨¡å‹å¯¹åæ€æ•æ„Ÿ
    - ä»·æ ¼ã€æ”¶å…¥ç­‰å³åæ•°æ®
    - éœ€è¦æ”¹å–„æ•°æ®åˆ†å¸ƒ

    Parameters
    ----------
    columns : list, optional
        éœ€è¦å˜æ¢çš„åˆ—åï¼ŒNoneåˆ™è‡ªåŠ¨æ£€æµ‹åæ€åˆ—
    method : {'auto', 'log', 'sqrt', 'boxcox'}
        'auto' - è‡ªåŠ¨é€‰æ‹©æœ€ä½³å˜æ¢
        log     - å¯¹æ•°å˜æ¢ï¼ˆå³åæ•°æ®ï¼‰
        sqrt    - å¹³æ–¹æ ¹å˜æ¢ï¼ˆå³åæ•°æ®ï¼Œè¾ƒæ¸©å’Œï¼‰
        boxcox  - Box-Coxå˜æ¢ï¼ˆè‡ªåŠ¨å¯»æ‰¾æœ€ä½³lambdaï¼‰
    threshold : float, default=0.5
        ååº¦é˜ˆå€¼ï¼Œè¶…è¿‡åˆ™è®¤ä¸ºåæ€

    Returns
    -------
    DataFrame
        å˜æ¢åçš„æ•°æ®

    Examples
    --------
    >>> # è‡ªåŠ¨æ£€æµ‹å¹¶å˜æ¢åæ€ç‰¹å¾
    >>> df_transformed = quick_transform_skewed(df)
    >>> # âœ“ åæ€å˜æ¢å®Œæˆ: price(log), income(log)

    >>> # æ‰‹åŠ¨æŒ‡å®šå˜æ¢
    >>> df_transformed = quick_transform_skewed(
    ...     df,
    ...     columns=['price'],
    ...     method='log'
    ... )
    """
    df_copy = df.copy()

    if columns is None:
        # è‡ªåŠ¨æ£€æµ‹åæ€åˆ—
        numeric_cols = df_copy.select_dtypes(include=[np.number]).columns
        columns = []
        for col in numeric_cols:
            if df_copy[col].min() >= 0:  # ä»…æ£€æµ‹éè´Ÿåˆ—
                skewness = df_copy[col].skew()
                if abs(skewness) > threshold:
                    columns.append(col)

    if len(columns) == 0:
        if verbose:
            print("âœ“ æœªæ£€æµ‹åˆ°åæ€ç‰¹å¾ï¼Œè·³è¿‡å˜æ¢\n")
        return df_copy

    transformed_info = {}

    for col in columns:
        if col not in df_copy.columns:
            continue

        if df_copy[col].min() < 0:
            if verbose:
                print(f"   âš ï¸  {col}åŒ…å«è´Ÿå€¼ï¼Œè·³è¿‡å˜æ¢")
            continue

        # é¿å…log(0)
        if method in ['auto', 'log']:
            df_copy[col] = np.log1p(df_copy[col])
            transformed_info[col] = 'log'
        elif method == 'sqrt':
            df_copy[col] = np.sqrt(df_copy[col])
            transformed_info[col] = 'sqrt'

    if verbose:
        print("âœ“ åæ€å˜æ¢å®Œæˆ:")
        for col, method in transformed_info.items():
            print(f"   {col}: {method}")
        print()

    return df_copy


# ==================== 3. ç‰¹å¾æ„é€  ====================

def create_interaction_features(df: pd.DataFrame,
                               columns: List[str],
                               operations: List[str] = ['*', '/'],
                               max_features: int = 10,
                               verbose: bool = True) -> pd.DataFrame:
    """
    åˆ›å»ºäº¤äº’ç‰¹å¾ï¼ˆæœ€æœ‰æ•ˆçš„ç‰¹å¾å·¥ç¨‹ï¼‰

    Parameters
    ----------
    columns : list
        å‚ä¸äº¤äº’çš„åˆ—å
    operations : list, default=['*', '/']
        è¿ç®—ç±»å‹ ['*', '/', '+', '-']
    max_features : int, default=10
        æœ€å¤šç”Ÿæˆäº¤äº’ç‰¹å¾æ•°ï¼ˆé˜²æ­¢è¿‡å¤šï¼‰

    Returns
    -------
    DataFrame
        åŒ…å«åŸç‰¹å¾ + äº¤äº’ç‰¹å¾

    Examples
    --------
    >>> # åˆ›å»º2ä¸ªç‰¹å¾çš„äº¤äº’
    >>> df = create_interaction_features(
    ...     df,
    ...     columns=['age', 'income'],
    ...     operations=['*']
    ... )
    >>> # æ–°å¢åˆ—: age_multiply_income

    >>> # åˆ›å»ºå¤šä¸ªç‰¹å¾çš„äº¤äº’ç»„åˆ
    >>> df = create_interaction_features(
    ...     df,
    ...     columns=['age', 'income', 'education_years'],
    ...     operations=['*', '/'],
    ...     max_features=5
    ... )

    Best Practices
    --------------
    1. é€‰æ‹©æœ‰ä¸šåŠ¡æ„ä¹‰çš„äº¤äº’ï¼ˆå¦‚: é¢ç§¯ * å•ä»·ï¼‰
    2. å…ˆåšå°‘é‡äº¤äº’å®éªŒï¼ŒéªŒè¯æ•ˆæœåå†æ‰©å±•
    3. ä½¿ç”¨ç‰¹å¾é‡è¦æ€§ç­›é€‰æœ‰æ•ˆäº¤äº’

    Notes
    -----
    - äº¤äº’ç‰¹å¾å¸¸èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½
    - å‚è€ƒ06ç« src/feature_engineering.py:363-408
    """
    df_copy = df.copy()

    # ç¡®ä¿åˆ—å­˜åœ¨ä¸”ä¸ºæ•°å€¼å‹
    valid_columns = []
    for col in columns:
        if col in df_copy.columns and pd.api.types.is_numeric_dtype(df_copy[col]):
            valid_columns.append(col)

    if len(valid_columns) < 2:
        if verbose:
            print("âš ï¸  éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼åˆ—åˆ›å»ºäº¤äº’ç‰¹å¾\n")
        return df_copy

    created_features = []

    # ç”Ÿæˆä¸¤ä¸¤ç»„åˆ
    for col1, col2 in combinations(valid_columns, 2):
        if len(created_features) >= max_features:
            break

        for op in operations:
            if len(created_features) >= max_features:
                break

            if op == '*':
                new_col = f"{col1}_multiply_{col2}"
                df_copy[new_col] = df_copy[col1] * df_copy[col2]
                created_features.append(new_col)

            elif op == '/':
                # é¿å…é™¤é›¶
                new_col = f"{col1}_divide_{col2}"
                df_copy[new_col] = df_copy[col1] / (df_copy[col2] + 1e-8)
                created_features.append(new_col)

            elif op == '+':
                new_col = f"{col1}_plus_{col2}"
                df_copy[new_col] = df_copy[col1] + df_copy[col2]
                created_features.append(new_col)

            elif op == '-':
                new_col = f"{col1}_minus_{col2}"
                df_copy[new_col] = df_copy[col1] - df_copy[col2]
                created_features.append(new_col)

    if verbose:
        print(f"âœ“ äº¤äº’ç‰¹å¾åˆ›å»ºå®Œæˆ: æ–°å¢{len(created_features)}åˆ—")
        if created_features[:3]:
            print(f"   ç¤ºä¾‹: {created_features[:3]}")
        print()

    return df_copy


def create_time_features(df: pd.DataFrame,
                        datetime_col: str,
                        drop_original: bool = False,
                        verbose: bool = True) -> pd.DataFrame:
    """
    æ—¶é—´ç‰¹å¾æå–ï¼ˆéå¸¸æœ‰æ•ˆï¼‰

    è‡ªåŠ¨æå–:
    - å¹´ã€æœˆã€æ—¥ã€æ˜ŸæœŸå‡ 
    - æ˜¯å¦å‘¨æœ«ã€æ˜¯å¦æœˆåˆ/æœˆæœ«
    - å­£åº¦ã€å°æ—¶ï¼ˆå¦‚æœæœ‰ï¼‰
    - è·ç¦»å‚è€ƒæ—¥æœŸçš„å¤©æ•°

    Parameters
    ----------
    datetime_col : str
        æ—¶é—´åˆ—å
    drop_original : bool, default=False
        æ˜¯å¦åˆ é™¤åŸå§‹æ—¶é—´åˆ—

    Returns
    -------
    DataFrame
        åŒ…å«æ—¶é—´ç‰¹å¾çš„æ•°æ®

    Examples
    --------
    >>> df = create_time_features(df, datetime_col='signup_date')
    >>> # æ–°å¢: signup_year, signup_month, signup_dayofweek,
    >>> #       signup_is_weekend, signup_quarterç­‰

    Notes
    -----
    - æ—¶é—´ç‰¹å¾å¸¸èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½
    - å‚è€ƒ06ç« src/feature_engineering.py:525-560
    """
    df_copy = df.copy()

    if datetime_col not in df_copy.columns:
        if verbose:
            print(f"âš ï¸  åˆ—'{datetime_col}'ä¸å­˜åœ¨\n")
        return df_copy

    # è½¬æ¢ä¸ºdatetime
    df_copy[datetime_col] = pd.to_datetime(df_copy[datetime_col])

    # æå–æ—¶é—´ç‰¹å¾
    prefix = datetime_col
    df_copy[f'{prefix}_year'] = df_copy[datetime_col].dt.year
    df_copy[f'{prefix}_month'] = df_copy[datetime_col].dt.month
    df_copy[f'{prefix}_day'] = df_copy[datetime_col].dt.day
    df_copy[f'{prefix}_dayofweek'] = df_copy[datetime_col].dt.dayofweek
    df_copy[f'{prefix}_quarter'] = df_copy[datetime_col].dt.quarter
    df_copy[f'{prefix}_is_weekend'] = (df_copy[datetime_col].dt.dayofweek >= 5).astype(int)
    df_copy[f'{prefix}_is_month_start'] = df_copy[datetime_col].dt.is_month_start.astype(int)
    df_copy[f'{prefix}_is_month_end'] = df_copy[datetime_col].dt.is_month_end.astype(int)

    # è·ç¦»å‚è€ƒæ—¥æœŸçš„å¤©æ•°
    reference_date = df_copy[datetime_col].max()
    df_copy[f'{prefix}_days_from_ref'] = (reference_date - df_copy[datetime_col]).dt.days

    created_features = [col for col in df_copy.columns if col.startswith(prefix) and col != datetime_col]

    if drop_original:
        df_copy = df_copy.drop(datetime_col, axis=1)

    if verbose:
        print(f"âœ“ æ—¶é—´ç‰¹å¾æå–å®Œæˆ: æ–°å¢{len(created_features)}åˆ—")
        print(f"   {created_features[:5]}")
        print()

    return df_copy


def create_aggregation_features(df: pd.DataFrame,
                               group_col: str,
                               agg_cols: List[str],
                               agg_funcs: List[str] = ['mean', 'std', 'count'],
                               verbose: bool = True) -> pd.DataFrame:
    """
    åˆ›å»ºèšåˆç‰¹å¾ï¼ˆåˆ†ç»„ç»Ÿè®¡ï¼‰

    é€‚ç”¨åœºæ™¯:
    - ç”¨æˆ·çº§åˆ«èšåˆï¼ˆå¹³å‡è®¢å•é‡‘é¢ã€è´­ä¹°æ¬¡æ•°ï¼‰
    - ç±»åˆ«çº§åˆ«èšåˆï¼ˆåŸå¸‚å¹³å‡æˆ¿ä»·ï¼‰
    - æ—¶é—´çª—å£èšåˆï¼ˆæœ€è¿‘7å¤©äº¤æ˜“é‡ï¼‰

    Parameters
    ----------
    group_col : str
        åˆ†ç»„åˆ—å
    agg_cols : list
        éœ€è¦èšåˆçš„åˆ—å
    agg_funcs : list, default=['mean', 'std', 'count']
        èšåˆå‡½æ•° ['mean', 'sum', 'max', 'min', 'std', 'count']

    Returns
    -------
    DataFrame
        åŒ…å«èšåˆç‰¹å¾çš„æ•°æ®

    Examples
    --------
    >>> # åˆ›å»ºç”¨æˆ·çº§åˆ«çš„èšåˆç‰¹å¾
    >>> df = create_aggregation_features(
    ...     df,
    ...     group_col='user_id',
    ...     agg_cols=['order_amount', 'order_count'],
    ...     agg_funcs=['mean', 'sum', 'max']
    ... )
    >>> # æ–°å¢: user_id_order_amount_mean, user_id_order_count_sumç­‰

    Notes
    -----
    - èšåˆç‰¹å¾èƒ½æ•æ‰ç¾¤ä½“ç‰¹å¾
    - å‚è€ƒ06ç« src/feature_engineering.py:411-442
    """
    df_copy = df.copy()

    # è®¡ç®—èšåˆç‰¹å¾
    agg_dict = {col: agg_funcs for col in agg_cols}
    grouped = df_copy.groupby(group_col).agg(agg_dict)

    # é‡å‘½ååˆ—
    grouped.columns = [f'{group_col}_{col}_{func}' for col, func in grouped.columns]
    grouped = grouped.reset_index()

    # åˆå¹¶å›åŸæ•°æ®
    df_copy = df_copy.merge(grouped, on=group_col, how='left')

    created_features = [col for col in df_copy.columns if col.startswith(f'{group_col}_')]

    if verbose:
        print(f"âœ“ èšåˆç‰¹å¾åˆ›å»ºå®Œæˆ: æ–°å¢{len(created_features)}åˆ—")
        print(f"   {created_features[:3]}")
        print()

    return df_copy


# ==================== 4. å®Œæ•´ç‰¹å¾å·¥ç¨‹Pipeline ====================

def build_feature_engineering_pipeline(df: pd.DataFrame,
                                      y: pd.Series,
                                      level: str = 'basic',
                                      datetime_cols: List[str] = None,
                                      interaction_cols: List[str] = None,
                                      verbose: bool = True) -> pd.DataFrame:
    """
    ä¸€é”®å¼ç‰¹å¾å·¥ç¨‹ï¼ˆ10-15åˆ†é’Ÿï¼‰

    Parameters
    ----------
    level : {'basic', 'standard', 'advanced'}
        basic    - åŸºç¡€ç‰¹å¾å·¥ç¨‹ï¼ˆç‰¹å¾é€‰æ‹©ï¼‰
        standard - æ ‡å‡†ç‰¹å¾å·¥ç¨‹ï¼ˆ+äº¤äº’ç‰¹å¾ï¼‰
        advanced - é«˜çº§ç‰¹å¾å·¥ç¨‹ï¼ˆ+èšåˆ+æ—¶é—´ç‰¹å¾ï¼‰
    datetime_cols : list, optional
        æ—¶é—´åˆ—ååˆ—è¡¨
    interaction_cols : list, optional
        å‚ä¸äº¤äº’çš„åˆ—å

    Returns
    -------
    DataFrame
        å®Œæ•´ç‰¹å¾å·¥ç¨‹åçš„æ•°æ®

    Examples
    --------
    >>> # å¿«é€Ÿæ¨¡å¼
    >>> df_engineered = build_feature_engineering_pipeline(df, y, level='basic')

    >>> # å®Œæ•´æ¨¡å¼
    >>> df_engineered = build_feature_engineering_pipeline(
    ...     df, y,
    ...     level='advanced',
    ...     datetime_cols=['signup_date'],
    ...     interaction_cols=['age', 'income']
    ... )

    Pipeline Steps
    --------------
    basic:
    - ç‰¹å¾é€‰æ‹©ï¼ˆç§»é™¤ä½æ–¹å·®+é«˜ç›¸å…³ï¼‰

    standard:
    - ç‰¹å¾é€‰æ‹©
    - äº¤äº’ç‰¹å¾ï¼ˆ2-3ä¸ªæ ¸å¿ƒç‰¹å¾ï¼‰

    advanced:
    - ç‰¹å¾é€‰æ‹©
    - äº¤äº’ç‰¹å¾
    - æ—¶é—´ç‰¹å¾æå–
    - èšåˆç‰¹å¾ï¼ˆå¦‚æœ‰group_colï¼‰
    """
    df_copy = df.copy()

    if verbose:
        print("="*60)
        print(f"   ç‰¹å¾å·¥ç¨‹Pipeline (level: {level})")
        print("="*60 + "\n")

    # 1. ç‰¹å¾é€‰æ‹©
    df_copy = quick_feature_selection(df_copy, y, method='auto', verbose=verbose)

    # 2. äº¤äº’ç‰¹å¾ï¼ˆstandardåŠä»¥ä¸Šï¼‰
    if level in ['standard', 'advanced'] and interaction_cols:
        df_copy = create_interaction_features(
            df_copy,
            columns=interaction_cols,
            operations=['*', '/'],
            max_features=5,
            verbose=verbose
        )

    # 3. æ—¶é—´ç‰¹å¾ï¼ˆadvancedï¼‰
    if level == 'advanced' and datetime_cols:
        for col in datetime_cols:
            df_copy = create_time_features(df_copy, datetime_col=col, verbose=verbose)

    if verbose:
        print("="*60)
        print(f"   ç‰¹å¾å·¥ç¨‹å®Œæˆ: {df.shape[1]} â†’ {df_copy.shape[1]}åˆ—")
        print("="*60 + "\n")

    return df_copy
