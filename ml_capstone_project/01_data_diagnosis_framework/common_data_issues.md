# ğŸ”§ å¸¸è§æ•°æ®é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

> å®æˆ˜ä¸­æœ€å¸¸é‡åˆ°çš„æ•°æ®é—®é¢˜åŠå¤„ç†æ–¹æ³•

## ğŸš€ å¿«é€Ÿå¯¼èˆª

**æ¥è‡ªé€ŸæŸ¥è¡¨** â†’ å¦‚æœä» [data_diagnosis_quick_reference.md](data_diagnosis_quick_reference.md) è·³è½¬è¿‡æ¥ï¼Œæœ¬æ–‡æ¡£æä¾›æ¯ä¸ªé—®é¢˜çš„**æ·±å…¥ç†è§£å’Œè¯¦ç»†æ–¹æ¡ˆ**

**æŸ¥æ‰¾æ–¹æ¡ˆ** â†’ å¦‚æœéœ€è¦ç›´æ¥å¯ç”¨çš„ä»£ç ï¼ŒæŸ¥çœ‹ [data_problem_to_solution_mapping.md](data_problem_to_solution_mapping.md)

**ç³»ç»ŸåŒ–è¯Šæ–­** â†’ å¦‚æœéœ€è¦å®Œæ•´çš„è¯Šæ–­æµç¨‹ï¼ŒæŸ¥çœ‹ [data_diagnosis_decision_tree.md](data_diagnosis_decision_tree.md)

---

## ğŸ“š ç›®å½•

1. [ç¼ºå¤±å€¼é—®é¢˜](#1-ç¼ºå¤±å€¼é—®é¢˜) - æœ€å¸¸è§ï¼Œå½±å“å¤§
2. [å¼‚å¸¸å€¼é—®é¢˜](#2-å¼‚å¸¸å€¼é—®é¢˜) - éœ€åˆ¤æ–­æ€§è´¨
3. [æ•°æ®ä¸å¹³è¡¡](#3-æ•°æ®ä¸å¹³è¡¡) - åˆ†ç±»é—®é¢˜å¿…æŸ¥
4. [ç‰¹å¾ç›¸å…³æ€§é—®é¢˜](#4-ç‰¹å¾ç›¸å…³æ€§é—®é¢˜) - çº¿æ€§æ¨¡å‹æ•æ„Ÿ
5. [æ•°æ®æ³„æ¼](#5-æ•°æ®æ³„æ¼) - æœ€å±é™©
6. [æ•°æ®ç±»å‹é—®é¢˜](#6-æ•°æ®ç±»å‹é—®é¢˜) - åŸºç¡€é—®é¢˜
7. [ç‰¹æ®Šå€¼é—®é¢˜](#7-ç‰¹æ®Šå€¼é—®é¢˜) - æ˜“è¢«å¿½ç•¥
8. [æ—¶é—´ç›¸å…³é—®é¢˜](#8-æ—¶é—´ç›¸å…³é—®é¢˜) - æ—¶åºæ•°æ®ä¸“ç”¨

---

## 1. ç¼ºå¤±å€¼é—®é¢˜

### â“ é—®é¢˜æè¿°

æ•°æ®é›†ä¸­æŸäº›å€¼ä¸ºç©ºï¼ˆNaNã€NULLã€Noneç­‰ï¼‰ï¼Œå¯¼è‡´æ— æ³•ç›´æ¥å»ºæ¨¡ã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

```python
# ç¤ºä¾‹æ•°æ®
age     income    city
25      50000     åŒ—äº¬
NaN     60000     ä¸Šæµ·
30      NaN       å¹¿å·
28      55000     NaN
```

### ğŸ” è¯Šæ–­æ–¹æ³•

```python
# æ£€æŸ¥ç¼ºå¤±å€¼
print(df.isnull().sum())
print(df.isnull().sum() / len(df) * 100)  # ç¼ºå¤±ç‡

# å¯è§†åŒ–ç¼ºå¤±æ¨¡å¼
import missingno as msno
msno.matrix(df)
msno.heatmap(df)  # ç¼ºå¤±å€¼ç›¸å…³æ€§
```

### âœ… è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šåˆ é™¤æ³•

**é€‚ç”¨åœºæ™¯ï¼š** ç¼ºå¤±ç‡<5% ä¸”æ•°æ®é‡å……è¶³

```python
# åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ
df_cleaned = df.dropna()

# åˆ é™¤ç¼ºå¤±ç‡>50%çš„åˆ—
threshold = 0.5
df_cleaned = df.loc[:, df.isnull().mean() < threshold]
```

**ä¼˜ç‚¹ï¼š** ç®€å•ç›´æ¥
**ç¼ºç‚¹ï¼š** ä¸¢å¤±ä¿¡æ¯

#### æ–¹æ¡ˆ2ï¼šç®€å•å¡«å……

**é€‚ç”¨åœºæ™¯ï¼š** è½»åº¦ç¼ºå¤±ï¼Œæ•°æ®åˆ†å¸ƒç®€å•

```python
# æ•°å€¼å‹ï¼šå‡å€¼/ä¸­ä½æ•°
df['age'].fillna(df['age'].median(), inplace=True)

# ç±»åˆ«å‹ï¼šä¼—æ•°
df['city'].fillna(df['city'].mode()[0], inplace=True)

# å¸¸æ•°å¡«å……
df['income'].fillna(0, inplace=True)  # ç”¨0å¡«å……
df['city'].fillna('Unknown', inplace=True)  # ç”¨ç‰¹æ®Šæ ‡è®°å¡«å……
```

**ä¼˜ç‚¹ï¼š** å¿«é€Ÿï¼Œä¿ç•™æ•°æ®é‡
**ç¼ºç‚¹ï¼š** å¯èƒ½å¼•å…¥åå·®

#### æ–¹æ¡ˆ3ï¼šKNNå¡«å……

**é€‚ç”¨åœºæ™¯ï¼š** ä¸­åº¦ç¼ºå¤±ï¼Œç‰¹å¾é—´æœ‰ç›¸å…³æ€§

```python
from sklearn.impute import KNNImputer

imputer = KNNImputer(n_neighbors=5)
df_filled = pd.DataFrame(
    imputer.fit_transform(df),
    columns=df.columns
)
```

**ä¼˜ç‚¹ï¼š** è€ƒè™‘ç‰¹å¾å…³ç³»
**ç¼ºç‚¹ï¼š** è®¡ç®—å¼€é”€å¤§

#### æ–¹æ¡ˆ4ï¼šå»ºæ¨¡å¡«å……

**é€‚ç”¨åœºæ™¯ï¼š** é‡åº¦ç¼ºå¤±ï¼Œç‰¹å¾å…³ç³»å¤æ‚

```python
# ä½¿ç”¨å…¶ä»–ç‰¹å¾é¢„æµ‹ç¼ºå¤±ç‰¹å¾
from sklearn.ensemble import RandomForestRegressor

# åˆ†ç¦»æœ‰/æ— ç¼ºå¤±çš„æ•°æ®
df_with_age = df[df['age'].notna()]
df_without_age = df[df['age'].isna()]

# è®­ç»ƒæ¨¡å‹
X_train = df_with_age.drop('age', axis=1)
y_train = df_with_age['age']

model = RandomForestRegressor()
model.fit(X_train, y_train)

# é¢„æµ‹ç¼ºå¤±å€¼
X_pred = df_without_age.drop('age', axis=1)
df.loc[df['age'].isna(), 'age'] = model.predict(X_pred)
```

**ä¼˜ç‚¹ï¼š** æœ€å‡†ç¡®
**ç¼ºç‚¹ï¼š** å¤æ‚ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ

#### æ–¹æ¡ˆ5ï¼šä¿ç•™ç¼ºå¤±ä¿¡æ¯

**é€‚ç”¨åœºæ™¯ï¼š** ç¼ºå¤±æœ¬èº«æœ‰æ„ä¹‰

```python
# åˆ›å»ºç¼ºå¤±æŒ‡ç¤ºåˆ—
df['age_missing'] = df['age'].isna().astype(int)

# ç„¶åå¡«å……ç¼ºå¤±å€¼
df['age'].fillna(df['age'].median(), inplace=True)
```

**é€‚ç”¨æ¡ˆä¾‹ï¼š**
- åŒ»ç–—æ•°æ®ï¼šæŸäº›æ£€æŸ¥æœªåš â†’ å¯èƒ½è¡¨ç¤ºå¥åº·
- ç”¨æˆ·æ•°æ®ï¼šæŸäº›å­—æ®µæœªå¡« â†’ å¯èƒ½è¡¨ç¤ºéšç§æ„è¯†

### ğŸ“ˆ æ•ˆæœå¯¹æ¯”

| æ–¹æ³• | ä¿¡æ¯ä¿ç•™ | è®¡ç®—æˆæœ¬ | å¼•å…¥åå·®é£é™© |
|------|----------|----------|--------------|
| åˆ é™¤ | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | â˜…â˜†â˜†â˜†â˜† |
| ç®€å•å¡«å…… | â˜…â˜…â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜†â˜† |
| KNNå¡«å…… | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜†â˜†â˜† | â˜…â˜…â˜†â˜†â˜† |
| å»ºæ¨¡å¡«å…… | â˜…â˜…â˜…â˜…â˜† | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜† |
| ä¿ç•™æ ‡è®° | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† | â˜…â˜†â˜†â˜†â˜† |

---

## 2. å¼‚å¸¸å€¼é—®é¢˜

### â“ é—®é¢˜æè¿°

æ•°æ®ä¸­å­˜åœ¨æ˜æ˜¾åç¦»æ­£å¸¸èŒƒå›´çš„å€¼ï¼Œå¯èƒ½æ˜¯é”™è¯¯æˆ–çœŸå®æå€¼ã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

```python
# å¹´é¾„æ•°æ®ä¸­å‡ºç°è´Ÿæ•°æˆ–è¶…å¤§å€¼
age: [25, 28, 30, -5, 150, 27, 26]

# ä»·æ ¼æ•°æ®ä¸­çš„æç«¯å€¼
price: [100, 150, 200, 9999999, 180, 160]
```

### ğŸ” è¯Šæ–­æ–¹æ³•

```python
# ç»Ÿè®¡æ–¹æ³•
print(df.describe())

# IQRæ–¹æ³•
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['price'] < Q1 - 1.5*IQR) | (df['price'] > Q3 + 1.5*IQR)]

# Z-Scoreæ–¹æ³•
from scipy import stats
z_scores = np.abs(stats.zscore(df['price']))
outliers = df[z_scores > 3]

# å¯è§†åŒ–
df.boxplot(column='price')
```

### âœ… è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šåˆ é™¤å¼‚å¸¸å€¼

**é€‚ç”¨åœºæ™¯ï¼š** æ˜ç¡®çš„æ•°æ®é”™è¯¯

```python
# åˆ é™¤ä¸åˆç†çš„å€¼
df = df[df['age'] >= 0]  # å¹´é¾„ä¸èƒ½ä¸ºè´Ÿ
df = df[df['age'] <= 120]  # å¹´é¾„ä¸è¶…è¿‡120

# ä½¿ç”¨IQRåˆ é™¤
Q1 = df['price'].quantile(0.25)
Q3 = df['price'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['price'] >= Q1 - 1.5*IQR) & (df['price'] <= Q3 + 1.5*IQR)]
```

**å†³ç­–æ ‡å‡†ï¼š**
- ä¸šåŠ¡ä¸Šä¸å¯èƒ½ï¼ˆå¦‚è´Ÿæ•°å¹´é¾„ï¼‰â†’ åˆ é™¤
- æ˜æ˜¾çš„å½•å…¥é”™è¯¯ï¼ˆå¦‚ä»·æ ¼å¤šæ‰“ä¸€ä¸ª0ï¼‰â†’ åˆ é™¤æˆ–ä¿®æ­£

#### æ–¹æ¡ˆ2ï¼šæˆªæ–­ï¼ˆWinsorizationï¼‰

**é€‚ç”¨åœºæ™¯ï¼š** ä¿ç•™æ•°æ®é‡ï¼Œä½†é™åˆ¶æå€¼å½±å“

```python
# è®¾ç½®ä¸Šä¸‹é™
lower_bound = df['price'].quantile(0.01)
upper_bound = df['price'].quantile(0.99)

df['price'] = df['price'].clip(lower=lower_bound, upper=upper_bound)
```

**ä¼˜ç‚¹ï¼š** ä¿ç•™æ‰€æœ‰æ ·æœ¬
**ç¼ºç‚¹ï¼š** æ”¹å˜äº†æ•°æ®åˆ†å¸ƒ

#### æ–¹æ¡ˆ3ï¼šè½¬æ¢

**é€‚ç”¨åœºæ™¯ï¼š** çœŸå®æå€¼ï¼Œéœ€è¦ä¿ç•™ä½†é™ä½å½±å“

```python
# å¯¹æ•°è½¬æ¢ï¼ˆé€‚åˆå³åæ•°æ®ï¼‰
df['price_log'] = np.log1p(df['price'])

# å¹³æ–¹æ ¹è½¬æ¢
df['price_sqrt'] = np.sqrt(df['price'])

# Box-Coxè½¬æ¢ï¼ˆè‡ªåŠ¨æ‰¾æœ€ä½³Î»ï¼‰
from scipy.stats import boxcox
df['price_boxcox'], lambda_param = boxcox(df['price'] + 1)
```

#### æ–¹æ¡ˆ4ï¼šä½¿ç”¨é²æ£’æ¨¡å‹

**é€‚ç”¨åœºæ™¯ï¼š** å¼‚å¸¸å€¼æ˜¯çœŸå®æ•°æ®çš„ä¸€éƒ¨åˆ†

```python
# ä½¿ç”¨å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿçš„ç®—æ³•
from sklearn.ensemble import RandomForestRegressor  # æ ‘æ¨¡å‹å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
from sklearn.linear_model import HuberRegressor  # é²æ£’å›å½’

# æˆ–ä½¿ç”¨é²æ£’ç¼©æ”¾
from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()  # ä½¿ç”¨ä¸­ä½æ•°å’ŒIQRï¼Œä¸å—å¼‚å¸¸å€¼å½±å“
df_scaled = scaler.fit_transform(df)
```

### ğŸ¯ å†³ç­–æµç¨‹å›¾

```
å‘ç°å¼‚å¸¸å€¼
    â”‚
    â”œâ”€â†’ æ˜¯æ•°æ®é”™è¯¯ï¼Ÿ â”€â†’ æ˜¯ â”€â†’ åˆ é™¤æˆ–ä¿®æ­£
    â”‚
    â””â”€â†’ å¦ï¼ˆçœŸå®æå€¼ï¼‰
            â”‚
            â”œâ”€â†’ æ ·æœ¬é‡å……è¶³ï¼Ÿ â”€â†’ æ˜¯ â”€â†’ å¯ä»¥åˆ é™¤éƒ¨åˆ†
            â”‚
            â””â”€â†’ å¦ â”€â†’ ä¿ç•™ â”€â†’ é€‰æ‹©ï¼š
                              1. è½¬æ¢
                              2. é²æ£’æ¨¡å‹
                              3. æˆªæ–­
```

---

## 3. æ•°æ®ä¸å¹³è¡¡

### â“ é—®é¢˜æè¿°

åˆ†ç±»é—®é¢˜ä¸­ï¼ŒæŸäº›ç±»åˆ«æ ·æœ¬æ•°è¿œå°‘äºå…¶ä»–ç±»åˆ«ã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

```python
# ä¿¡ç”¨å¡æ¬ºè¯ˆæ£€æµ‹
æ­£å¸¸äº¤æ˜“: 99,500 (99.5%)
æ¬ºè¯ˆäº¤æ˜“: 500 (0.5%)

# ç–¾ç—…è¯Šæ–­
å¥åº·: 9,000 (90%)
æ‚£ç—…: 1,000 (10%)
```

### ğŸ” è¯Šæ–­æ–¹æ³•

```python
# ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
print(df['label'].value_counts())
print(df['label'].value_counts(normalize=True))

# å¯è§†åŒ–
df['label'].value_counts().plot(kind='bar')
```

### âœ… è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šé‡é‡‡æ ·

##### è¿‡é‡‡æ ·ï¼ˆå¢åŠ å°‘æ•°ç±»ï¼‰

```python
from imblearn.over_sampling import SMOTE, RandomOverSampler

# éšæœºè¿‡é‡‡æ ·
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)

# SMOTEï¼ˆåˆæˆå°‘æ•°ç±»æ ·æœ¬ï¼‰
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
```

**ä¼˜ç‚¹ï¼š** å¢åŠ å°‘æ•°ç±»æ ·æœ¬
**ç¼ºç‚¹ï¼š** å¯èƒ½è¿‡æ‹Ÿåˆ

##### æ¬ é‡‡æ ·ï¼ˆå‡å°‘å¤šæ•°ç±»ï¼‰

```python
from imblearn.under_sampling import RandomUnderSampler

rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)
```

**ä¼˜ç‚¹ï¼š** å¿«é€Ÿå¹³è¡¡
**ç¼ºç‚¹ï¼š** ä¸¢å¤±ä¿¡æ¯

##### ç»„åˆé‡‡æ ·

```python
from imblearn.combine import SMOTETomek

smt = SMOTETomek(random_state=42)
X_resampled, y_resampled = smt.fit_resample(X, y)
```

#### æ–¹æ¡ˆ2ï¼šè°ƒæ•´ç±»æƒé‡

```python
from sklearn.ensemble import RandomForestClassifier

# è‡ªåŠ¨è®¡ç®—ç±»æƒé‡
model = RandomForestClassifier(class_weight='balanced')
model.fit(X_train, y_train)

# æ‰‹åŠ¨è®¾ç½®ç±»æƒé‡
model = RandomForestClassifier(class_weight={0: 1, 1: 10})
```

#### æ–¹æ¡ˆ3ï¼šæ”¹å˜è¯„ä¼°æŒ‡æ ‡

```python
from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve

# ä¸è¦åªçœ‹å‡†ç¡®ç‡ï¼
# ä½¿ç”¨ï¼šF1-Score, AUC, Precision, Recall

# F1-Score
f1 = f1_score(y_true, y_pred)

# AUC
auc = roc_auc_score(y_true, y_pred_proba)

# PRæ›²çº¿ï¼ˆä¸å¹³è¡¡æ•°æ®æ›´é€‚åˆï¼‰
precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)
```

#### æ–¹æ¡ˆ4ï¼šä½¿ç”¨ç‰¹æ®Šç®—æ³•

```python
# XGBoost/LightGBMæœ‰å†…ç½®çš„ä¸å¹³è¡¡å¤„ç†
import xgboost as xgb

# è®¡ç®—scale_pos_weight
scale_pos_weight = (y == 0).sum() / (y == 1).sum()

model = xgb.XGBClassifier(scale_pos_weight=scale_pos_weight)
```

### ğŸ“ˆ æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æ•°æ®é‡ | è¿‡æ‹Ÿåˆé£é™© | æ•ˆæœ | éš¾åº¦ |
|------|--------|------------|------|------|
| éšæœºè¿‡é‡‡æ · | å¢åŠ  | é«˜ | â˜…â˜…â˜† | â˜…â˜†â˜† |
| SMOTE | å¢åŠ  | ä¸­ | â˜…â˜…â˜… | â˜…â˜…â˜† |
| éšæœºæ¬ é‡‡æ · | å‡å°‘ | ä½ | â˜…â˜…â˜† | â˜…â˜†â˜† |
| ç±»æƒé‡ | ä¸å˜ | ä¸­ | â˜…â˜…â˜… | â˜…â˜†â˜† |
| ç‰¹æ®Šç®—æ³• | ä¸å˜ | ä½ | â˜…â˜…â˜…â˜… | â˜…â˜…â˜† |

---

## 4. ç‰¹å¾ç›¸å…³æ€§é—®é¢˜

### â“ é—®é¢˜æè¿°

å¤šä¸ªç‰¹å¾é«˜åº¦ç›¸å…³ï¼ˆå¤šé‡å…±çº¿æ€§ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹ä¸ç¨³å®šã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

```python
# ç›¸å…³ç‰¹å¾
æ€»é¢ç§¯ = å§å®¤é¢ç§¯ + å®¢å…é¢ç§¯ + å¨æˆ¿é¢ç§¯  # å®Œå…¨çº¿æ€§ç›¸å…³
BMI = ä½“é‡ / èº«é«˜Â²  # æ•°å­¦å…³ç³»
```

### ğŸ” è¯Šæ–­æ–¹æ³•

```python
# ç›¸å…³ç³»æ•°çŸ©é˜µ
corr_matrix = df.corr()
print(corr_matrix)

# å¯è§†åŒ–
import seaborn as sns
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')

# VIFï¼ˆæ–¹å·®è†¨èƒ€å› å­ï¼‰
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_data = pd.DataFrame()
vif_data["feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]
print(vif_data)
```

### âœ… è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ1ï¼šåˆ é™¤é«˜ç›¸å…³ç‰¹å¾

```python
# æ‰¾å‡ºé«˜ç›¸å…³ç‰¹å¾å¯¹
threshold = 0.9
to_drop = set()

for i in range(len(corr_matrix.columns)):
    for j in range(i):
        if abs(corr_matrix.iloc[i, j]) > threshold:
            colname = corr_matrix.columns[i]
            to_drop.add(colname)

df_cleaned = df.drop(columns=to_drop)
```

**å†³ç­–æ ‡å‡†ï¼š**
1. ä¿ç•™ä¸ç›®æ ‡ç›¸å…³æ€§æ›´é«˜çš„
2. ä¿ç•™ä¸šåŠ¡æ„ä¹‰æ›´é‡è¦çš„
3. ä¿ç•™æ›´å®¹æ˜“è·å–çš„

#### æ–¹æ¡ˆ2ï¼šPCAé™ç»´

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=0.95)  # ä¿ç•™95%æ–¹å·®
X_pca = pca.fit_transform(X)
```

**ä¼˜ç‚¹ï¼š** è‡ªåŠ¨æ¶ˆé™¤ç›¸å…³æ€§
**ç¼ºç‚¹ï¼š** ç‰¹å¾ä¸å¯è§£é‡Š

#### æ–¹æ¡ˆ3ï¼šæ­£åˆ™åŒ–

```python
from sklearn.linear_model import Ridge, Lasso

# L2æ­£åˆ™åŒ–ï¼ˆRidgeï¼‰
model = Ridge(alpha=1.0)

# L1æ­£åˆ™åŒ–ï¼ˆLassoï¼‰- è‡ªåŠ¨ç‰¹å¾é€‰æ‹©
model = Lasso(alpha=0.1)
```

#### æ–¹æ¡ˆ4ï¼šä½¿ç”¨æ ‘æ¨¡å‹

```python
# æ ‘æ¨¡å‹å¯¹å¤šé‡å…±çº¿æ€§ä¸æ•æ„Ÿ
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
# æ— éœ€å¤„ç†å¤šé‡å…±çº¿æ€§
```

---

## 5. æ•°æ®æ³„æ¼

### â“ é—®é¢˜æè¿°

æµ‹è¯•é›†ä¿¡æ¯"æ³„æ¼"åˆ°è®­ç»ƒè¿‡ç¨‹ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœè¿‡äºä¹è§‚ã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

#### åœºæ™¯1ï¼šIDåˆ—æ³„æ¼

```python
# âŒ é”™è¯¯ï¼šç”¨æˆ·IDè¢«ç”¨ä½œç‰¹å¾
user_id  feature1  target
1001     100       1
1002     200       0

# å¦‚æœæµ‹è¯•é›†ID>2000ï¼Œæ¨¡å‹ä¼šè¿‡æ‹ŸåˆIDèŒƒå›´
```

#### åœºæ™¯2ï¼šæœªæ¥ä¿¡æ¯æ³„æ¼

```python
# âŒ é”™è¯¯ï¼šç”¨æœªæ¥æ•°æ®é¢„æµ‹è¿‡å»
# é¢„æµ‹tæ—¶åˆ»çš„é”€é‡ï¼Œå´ä½¿ç”¨äº†t+1æ—¶åˆ»çš„åº“å­˜æ•°æ®
```

#### åœºæ™¯3ï¼šç›®æ ‡å˜é‡æ³„æ¼

```python
# âŒ é”™è¯¯ï¼šç‰¹å¾æ˜¯ç›®æ ‡çš„å˜ç§
target: æ˜¯å¦è´­ä¹°
feature: è´­ä¹°é‡‘é¢  # åªæœ‰è´­ä¹°äº†æ‰æœ‰é‡‘é¢ï¼
```

#### åœºæ™¯4ï¼šæ•°æ®é¢„å¤„ç†æ³„æ¼

```python
# âŒ é”™è¯¯ï¼šåœ¨åˆ’åˆ†å‰æ ‡å‡†åŒ–
scaler.fit(X)  # åŒ…å«äº†æµ‹è¯•é›†ä¿¡æ¯ï¼
X_train, X_test = train_test_split(X)

# âœ… æ­£ç¡®ï¼šå…ˆåˆ’åˆ†ï¼Œå†æ ‡å‡†åŒ–
X_train, X_test = train_test_split(X)
scaler.fit(X_train)  # åªç”¨è®­ç»ƒé›†
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

### ğŸ” è¯Šæ–­æ–¹æ³•

```python
# 1. æ£€æŸ¥ç‰¹å¾é‡è¦æ€§
# å¦‚æœIDåˆ—é‡è¦æ€§å¾ˆé«˜ â†’ å¯èƒ½æ³„æ¼

# 2. æ£€æŸ¥è®­ç»ƒ/æµ‹è¯•é›†æ€§èƒ½å·®å¼‚
# è®­ç»ƒé›†AUC=0.99, æµ‹è¯•é›†AUC=0.6 â†’ å¯èƒ½è¿‡æ‹Ÿåˆ/æ³„æ¼

# 3. æ—¶é—´éªŒè¯
# å¯¹æ—¶é—´åºåˆ—æ•°æ®ï¼Œç”¨è¿‡å»é¢„æµ‹æœªæ¥
```

### âœ… è§£å†³æ–¹æ¡ˆ

#### é€šç”¨åŸåˆ™

1. **åˆ é™¤IDåˆ—**
```python
df = df.drop(['user_id', 'order_id'], axis=1)
```

2. **æ—¶é—´é¡ºåºéªŒè¯**
```python
# ä¸è¦éšæœºåˆ’åˆ†æ—¶é—´åºåˆ—æ•°æ®ï¼
# ç”¨2019-2020è®­ç»ƒï¼Œ2021æµ‹è¯•
train = df[df['date'] < '2021-01-01']
test = df[df['date'] >= '2021-01-01']
```

3. **ä¸¥æ ¼çš„train-teståˆ†ç¦»**
```python
# æ‰€æœ‰æ•°æ®å¤„ç†éƒ½è¦åˆ†å¼€åš
X_train, X_test, y_train, y_test = train_test_split(X, y)

# å¡«å……
imputer.fit(X_train)
X_train_filled = imputer.transform(X_train)
X_test_filled = imputer.transform(X_test)

# ç¼–ç 
encoder.fit(X_train)
X_train_encoded = encoder.transform(X_train)
X_test_encoded = encoder.transform(X_test)

# ç¼©æ”¾
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

4. **ç‰¹å¾å·¥ç¨‹pipelineåŒ–**
```python
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('imputer', SimpleImputer()),
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

# Pipelineè‡ªåŠ¨å¤„ç†train-teståˆ†ç¦»
pipeline.fit(X_train, y_train)
pipeline.score(X_test, y_test)
```

---

## 6. æ•°æ®ç±»å‹é—®é¢˜

### â“ é—®é¢˜æè¿°

æ•°æ®ç±»å‹è¯†åˆ«é”™è¯¯ï¼Œå½±å“åç»­å¤„ç†ã€‚

### ğŸ“Š å¸¸è§åœºæ™¯

```python
# æ•°å€¼å‹è¢«è¯†åˆ«ä¸ºå­—ç¬¦ä¸²
'12.5' â†’ å­—ç¬¦ä¸²ï¼Œæ— æ³•è®¡ç®—å‡å€¼

# ç±»åˆ«å‹è¢«è¯†åˆ«ä¸ºæ•°å€¼
é‚®ç¼–: 100000 â†’ è¢«å½“ä½œæ•°å€¼ï¼Œå®é™…æ˜¯ç±»åˆ«

# æ—¥æœŸè¢«è¯†åˆ«ä¸ºå­—ç¬¦ä¸²
'2024-01-01' â†’ å­—ç¬¦ä¸²ï¼Œæ— æ³•æå–å¹´æœˆæ—¥
```

### âœ… è§£å†³æ–¹æ¡ˆ

```python
# 1. æ£€æŸ¥æ•°æ®ç±»å‹
print(df.dtypes)

# 2. è½¬æ¢æ•°å€¼ç±»å‹
df['price'] = pd.to_numeric(df['price'], errors='coerce')  # æ— æ³•è½¬æ¢çš„å˜æˆNaN

# 3. è½¬æ¢ç±»åˆ«ç±»å‹
df['zipcode'] = df['zipcode'].astype('category')

# 4. è½¬æ¢æ—¥æœŸç±»å‹
df['date'] = pd.to_datetime(df['date'])

# 5. æ‰¹é‡è½¬æ¢
df = df.convert_dtypes()  # pandasè‡ªåŠ¨æ¨æ–­
```

---

## 7. ç‰¹æ®Šå€¼é—®é¢˜

### ğŸ“Š å¸¸è§ç‰¹æ®Šå€¼

```python
# -999, -99, 0, 9999 â†’ å¸¸ç”¨ä½œç¼ºå¤±å€¼æ ‡è®°
# inf, -inf â†’ é™¤ä»¥0æˆ–è®¡ç®—æº¢å‡º
# ç©ºå­—ç¬¦ä¸² '' â†’ æ–‡æœ¬ç¼ºå¤±
# 'Unknown', 'N/A', 'NULL' â†’ æ˜¾å¼ç¼ºå¤±æ ‡è®°
```

### âœ… è§£å†³æ–¹æ¡ˆ

```python
# 1. æ›¿æ¢ç‰¹æ®Šå€¼ä¸ºNaN
df.replace([-999, -99, 9999], np.nan, inplace=True)

# 2. å¤„ç†æ— ç©·å€¼
df.replace([np.inf, -np.inf], np.nan, inplace=True)

# 3. ç»Ÿä¸€ç¼ºå¤±æ ‡è®°
df.replace(['Unknown', 'N/A', 'NULL', ''], np.nan, inplace=True)

# 4. æ£€æŸ¥æ‰€æœ‰æ•°å€¼æ˜¯å¦æœ‰é™
df = df[np.isfinite(df).all(axis=1)]
```

---

## 8. æ—¶é—´ç›¸å…³é—®é¢˜

### â“ é—®é¢˜æè¿°

æ—¶é—´æ•°æ®å¤„ç†ä¸å½“ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±æˆ–æ³„æ¼ã€‚

### âœ… è§£å†³æ–¹æ¡ˆ

```python
# 1. æå–æ—¶é—´ç‰¹å¾
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['dayofweek'] = df['date'].dt.dayofweek
df['is_weekend'] = (df['date'].dt.dayofweek >= 5).astype(int)

# 2. æ—¶é—´å·®ç‰¹å¾
df['days_since'] = (pd.Timestamp.now() - df['date']).dt.days

# 3. å‘¨æœŸæ€§ç‰¹å¾ï¼ˆæ­£å¼¦/ä½™å¼¦ç¼–ç ï¼‰
df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)

# 4. æ—¶é—´çª—å£ç‰¹å¾
df['sales_7d_avg'] = df.groupby('user_id')['sales'].transform(
    lambda x: x.rolling(window=7, min_periods=1).mean()
)
```

---

## ğŸ¯ å¿«é€Ÿè¯Šæ–­æµç¨‹

```
1. åŠ è½½æ•°æ® â†’ æ£€æŸ¥dtypes
2. åŸºç¡€ç»Ÿè®¡ â†’ df.describe(), df.info()
3. ç¼ºå¤±å€¼ â†’ df.isnull().sum()
4. é‡å¤å€¼ â†’ df.duplicated().sum()
5. å¼‚å¸¸å€¼ â†’ df.boxplot()
6. åˆ†å¸ƒ â†’ df.hist()
7. ç›¸å…³æ€§ â†’ df.corr()
8. ç›®æ ‡å˜é‡ â†’ df[target].value_counts()
```

---

## ğŸ“š æ¨èå·¥å…·

```python
# è‡ªåŠ¨åŒ–æ•°æ®åˆ†ææŠ¥å‘Š
import pandas_profiling
profile = df.profile_report(title='Data Report')
profile.to_file("report.html")

# æ•°æ®æ¸…æ´—åº“
import pandas as pd
from sklearn.impute import SimpleImputer, KNNImputer
from imblearn.over_sampling import SMOTE

# å¯è§†åŒ–
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno
```

---

**ä¸‹ä¸€æ­¥ï¼š** æŸ¥çœ‹ [02_é—®é¢˜å®šä¹‰æŒ‡å—](../02_problem_definition_guide/)ï¼Œå­¦ä¹ å¦‚ä½•æ­£ç¡®å®šä¹‰æœºå™¨å­¦ä¹ é—®é¢˜ï¼
