{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Quick Baselineï¼ˆå¿«é€ŸåŸºçº¿ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ æœ¬é˜¶æ®µç›®æ ‡\n",
    "\n",
    "åœ¨Phase 1çš„æ•°æ®è¯Šæ–­åŸºç¡€ä¸Šï¼Œ**å¿«é€Ÿå»ºç«‹å¤šä¸ªåŸºçº¿æ¨¡å‹**ï¼Œä¸ºåç»­ä¼˜åŒ–æä¾›æ€§èƒ½åŸºå‡†ã€‚\n",
    "\n",
    "### æ ¸å¿ƒä»»åŠ¡\n",
    "\n",
    "1. âœ… **å¿«é€Ÿæ•°æ®é¢„å¤„ç†**ï¼šä½¿ç”¨ç®€åŒ–çš„é¢„å¤„ç†æµç¨‹\n",
    "2. âœ… **æ•°æ®é›†åˆ’åˆ†**ï¼šè®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†\n",
    "3. âœ… **è®­ç»ƒå¤šä¸ªåŸºçº¿æ¨¡å‹**ï¼šLogistic Regressionã€Random Forestã€XGBoostã€LightGBM\n",
    "4. âœ… **æ€§èƒ½å¯¹æ¯”**ï¼šäº¤å‰éªŒè¯è¯„ä¼°\n",
    "5. âœ… **é€‰æ‹©æœ€ä½³åŸºçº¿**ï¼šç¡®å®šåç»­ä¼˜åŒ–çš„èµ·ç‚¹\n",
    "\n",
    "### æ–¹æ³•è®º\n",
    "\n",
    "- **ç®€å•ä¼˜å…ˆ**ï¼šä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œä¸åšè¿‡åº¦è°ƒä¼˜\n",
    "- **å¿«é€Ÿè¿­ä»£**ï¼šå¿«é€Ÿè·å¾—æ€§èƒ½åŸºå‡†ï¼Œè¯†åˆ«é—®é¢˜\n",
    "- **å¤šæ ·æ€§**ï¼šå°è¯•ä¸åŒç±»å‹çš„ç®—æ³•ï¼ˆçº¿æ€§ã€æ ‘æ¨¡å‹ã€é›†æˆï¼‰\n",
    "- **å¯é‡å¤æ€§**ï¼šå›ºå®šéšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯å¤ç°\n",
    "\n",
    "---\n",
    "\n",
    "## é¢„æœŸæ—¶é—´\n",
    "\n",
    "â±ï¸ **10-30åˆ†é’Ÿ**ï¼ˆå–å†³äºæ•°æ®é›†å¤§å°ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# å¯¼å…¥æœ¬é¡¹ç›®çš„æ¨¡å—\n",
    "from src import data_preprocessing as dp\n",
    "from src import supervised_pipeline as sp\n",
    "from src import model_evaluation as me\n",
    "from src import visualization as viz\n",
    "\n",
    "# è®¾ç½®\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# éšæœºç§å­\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. æ•°æ®åŠ è½½\n",
    "\n",
    "åŠ è½½åŸå§‹æ•°æ®æˆ–Phase 1å¤„ç†åçš„æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹å¼1: åŠ è½½åŸå§‹æ•°æ®ï¼ˆç¤ºä¾‹ï¼šTitanicï¼‰\n",
    "# ä½ å¯ä»¥æ›¿æ¢ä¸ºè‡ªå·±çš„æ•°æ®é›†\n",
    "\n",
    "# ä½¿ç”¨Titanicæ•°æ®é›†ä½œä¸ºæ¼”ç¤º\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# å®šä¹‰ç›®æ ‡å˜é‡\n",
    "target_col = 'survived'\n",
    "\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"\\nç›®æ ‡å˜é‡: {target_col}\")\n",
    "print(f\"ç›®æ ‡å˜é‡åˆ†å¸ƒ:\\n{df[target_col].value_counts()}\")\n",
    "\n",
    "# å¿«é€ŸæŸ¥çœ‹æ•°æ®\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–¹å¼2: å¦‚æœä½ åœ¨Phase 1ä¿å­˜äº†æ¸…æ´—åçš„æ•°æ®ï¼Œå¯ä»¥è¿™æ ·åŠ è½½\n",
    "# processed_data_path = Path('data/processed/cleaned_data.csv')\n",
    "# if processed_data_path.exists():\n",
    "#     df = pd.read_csv(processed_data_path)\n",
    "#     print(f\"âœ… åŠ è½½Phase 1å¤„ç†åçš„æ•°æ®: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. å¿«é€Ÿæ•°æ®é¢„å¤„ç†\n",
    "\n",
    "ä½¿ç”¨ `quick_preprocess()` å‡½æ•°å¿«é€Ÿå®ŒæˆåŸºæœ¬é¢„å¤„ç†ï¼š\n",
    "\n",
    "### å¤„ç†æ­¥éª¤\n",
    "\n",
    "1. åˆ†ç¦»ç›®æ ‡å˜é‡\n",
    "2. åˆ é™¤IDåˆ—ï¼ˆå”¯ä¸€å€¼æ¯”ä¾‹>95%ï¼‰\n",
    "3. åˆ é™¤å¸¸é‡åˆ—\n",
    "4. åˆ é™¤é‡å¤è¡Œ\n",
    "5. åˆ é™¤ç¼ºå¤±ç‡è¿‡é«˜çš„åˆ—ï¼ˆé»˜è®¤>50%ï¼‰\n",
    "6. ç®€å•å¡«å……å‰©ä½™ç¼ºå¤±å€¼ï¼ˆæ•°å€¼å‹ç”¨ä¸­ä½æ•°ï¼Œç±»åˆ«å‹ç”¨ä¼—æ•°ï¼‰\n",
    "7. One-Hotç¼–ç ç±»åˆ«ç‰¹å¾ï¼ˆé™åˆ¶â‰¤20ç±»ï¼‰\n",
    "8. æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿé¢„å¤„ç†\n",
    "print(\"=\"*60)\n",
    "print(\"å¼€å§‹å¿«é€Ÿé¢„å¤„ç†...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X, y = dp.quick_preprocess(\n",
    "    df, \n",
    "    target_col=target_col,\n",
    "    drop_missing_threshold=0.5,  # åˆ é™¤ç¼ºå¤±ç‡>50%çš„åˆ—\n",
    "    handle_categorical=True,      # å¤„ç†ç±»åˆ«ç‰¹å¾\n",
    "    scale_features=True           # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"é¢„å¤„ç†å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}\")\n",
    "print(f\"ç›®æ ‡å˜é‡å½¢çŠ¶: {y.shape}\")\n",
    "print(f\"\\nç‰¹å¾åˆ—è¡¨ (å‰10ä¸ª):\")\n",
    "print(X.columns.tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥é¢„å¤„ç†ç»“æœ\n",
    "print(\"é¢„å¤„ç†è´¨é‡æ£€æŸ¥:\")\n",
    "print(f\"- ç¼ºå¤±å€¼æ€»æ•°: {X.isnull().sum().sum()}\")\n",
    "print(f\"- é‡å¤è¡Œæ•°: {X.duplicated().sum()}\")\n",
    "print(f\"- æ•°æ®ç±»å‹åˆ†å¸ƒ:\\n{X.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. æ•°æ®é›†åˆ’åˆ†\n",
    "\n",
    "åˆ’åˆ†ä¸ºè®­ç»ƒé›†(70%)ã€éªŒè¯é›†(15%)ã€æµ‹è¯•é›†(15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®é›†åˆ’åˆ†\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = dp.split_data(\n",
    "    X, y,\n",
    "    train_size=0.7,\n",
    "    val_size=0.15,\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=True  # ä¿æŒç›®æ ‡å˜é‡åˆ†å¸ƒä¸€è‡´\n",
    ")\n",
    "\n",
    "print(\"æ•°æ®é›†åˆ’åˆ†å®Œæˆ:\")\n",
    "print(f\"  è®­ç»ƒé›†: {X_train.shape}\")\n",
    "print(f\"  éªŒè¯é›†: {X_val.shape}\")\n",
    "print(f\"  æµ‹è¯•é›†: {X_test.shape}\")\n",
    "\n",
    "# æ£€æŸ¥ç›®æ ‡å˜é‡åˆ†å¸ƒ\n",
    "print(\"\\nç›®æ ‡å˜é‡åˆ†å¸ƒ:\")\n",
    "print(f\"  è®­ç»ƒé›†: {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  éªŒè¯é›†: {y_val.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"  æµ‹è¯•é›†: {y_test.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. å»ºç«‹åŸºçº¿æ¨¡å‹\n",
    "\n",
    "### 5.1 ç¡®å®šé—®é¢˜ç±»å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªåŠ¨æ£€æµ‹é—®é¢˜ç±»å‹\n",
    "unique_values = y.nunique()\n",
    "\n",
    "if unique_values <= 20:  # å‡è®¾ç±»åˆ«æ•°â‰¤20ä¸ºåˆ†ç±»é—®é¢˜\n",
    "    problem_type = 'classification'\n",
    "    print(f\"âœ… æ£€æµ‹åˆ°åˆ†ç±»é—®é¢˜ (ç±»åˆ«æ•°: {unique_values})\")\n",
    "else:\n",
    "    problem_type = 'regression'\n",
    "    print(f\"âœ… æ£€æµ‹åˆ°å›å½’é—®é¢˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 è®­ç»ƒå¤šä¸ªåŸºçº¿æ¨¡å‹\n",
    "\n",
    "ä½¿ç”¨ `SupervisedPipeline` å¿«é€Ÿè®­ç»ƒ4ç§ä¸åŒçš„æ¨¡å‹ï¼š\n",
    "- **Logistic Regression** (çº¿æ€§æ¨¡å‹ï¼Œå¯è§£é‡Šæ€§å¼º)\n",
    "- **Random Forest** (é›†æˆæ ‘æ¨¡å‹ï¼Œæ€§èƒ½ç¨³å®š)\n",
    "- **XGBoost** (æ¢¯åº¦æå‡æ ‘ï¼Œé€šå¸¸æ€§èƒ½ä¼˜ç§€)\n",
    "- **LightGBM** (å¿«é€Ÿæ¢¯åº¦æå‡æ ‘ï¼Œé€‚åˆå¤§æ•°æ®)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç›‘ç£å­¦ä¹ Pipeline\n",
    "pipeline = sp.SupervisedPipeline(\n",
    "    problem_type=problem_type,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼ˆ5æŠ˜äº¤å‰éªŒè¯ï¼‰\n",
    "pipeline.fit(X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 æ¨¡å‹æ€§èƒ½å¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è·å–æ¨¡å‹å¯¹æ¯”ç»“æœ\n",
    "comparison_df = pipeline.get_model_comparison()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"äº¤å‰éªŒè¯æ€§èƒ½å¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"\\næ³¨: åˆ†æ•°ä¸º5æŠ˜äº¤å‰éªŒè¯çš„å¹³å‡å€¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ¨¡å‹æ€§èƒ½å¯¹æ¯”\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# ç»˜åˆ¶æ¡å½¢å›¾\n",
    "bars = ax.barh(\n",
    "    comparison_df['æ¨¡å‹'], \n",
    "    comparison_df['å¹³å‡å¾—åˆ†'],\n",
    "    xerr=comparison_df['æ ‡å‡†å·®'],\n",
    "    capsize=5,\n",
    "    color='skyblue',\n",
    "    edgecolor='navy',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# é«˜äº®æœ€ä½³æ¨¡å‹\n",
    "best_idx = comparison_df['å¹³å‡å¾—åˆ†'].idxmax()\n",
    "bars[best_idx].set_color('orange')\n",
    "bars[best_idx].set_edgecolor('darkred')\n",
    "bars[best_idx].set_linewidth(2)\n",
    "\n",
    "ax.set_xlabel('äº¤å‰éªŒè¯å¹³å‡å¾—åˆ†', fontsize=12)\n",
    "ax.set_title('åŸºçº¿æ¨¡å‹æ€§èƒ½å¯¹æ¯” (5-Fold CV)', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for i, (score, std) in enumerate(zip(comparison_df['å¹³å‡å¾—åˆ†'], comparison_df['æ ‡å‡†å·®'])):\n",
    "    ax.text(score + 0.01, i, f'{score:.4f} Â± {std:.4f}', \n",
    "            va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… æœ€ä½³åŸºçº¿æ¨¡å‹: {pipeline.best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. éªŒè¯é›†è¯„ä¼°\n",
    "\n",
    "ä½¿ç”¨éªŒè¯é›†å¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œæ›´è¯¦ç»†çš„è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨éªŒè¯é›†ä¸Šé¢„æµ‹\n",
    "y_val_pred = pipeline.predict(X_val)\n",
    "\n",
    "if problem_type == 'classification':\n",
    "    y_val_proba = pipeline.predict_proba(X_val)\n",
    "    \n",
    "    # åˆ†ç±»è¯„ä¼°\n",
    "    print(\"=\"*60)\n",
    "    print(f\"éªŒè¯é›†è¯„ä¼° - {pipeline.best_model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
    "    val_metrics = me.evaluate_classification(\n",
    "        y_val, \n",
    "        y_val_pred,\n",
    "        y_val_proba[:, 1] if y_val_proba.shape[1] == 2 else None,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "else:  # regression\n",
    "    # å›å½’è¯„ä¼°\n",
    "    print(\"=\"*60)\n",
    "    print(f\"éªŒè¯é›†è¯„ä¼° - {pipeline.best_model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    val_metrics = me.evaluate_regression(\n",
    "        y_val,\n",
    "        y_val_pred,\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 æ··æ·†çŸ©é˜µï¼ˆåˆ†ç±»é—®é¢˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_type == 'classification':\n",
    "    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ\n",
    "    me.plot_confusion_matrix(y_val, y_val_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 ROCæ›²çº¿ï¼ˆäºŒåˆ†ç±»é—®é¢˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_type == 'classification' and y.nunique() == 2:\n",
    "    # ç»˜åˆ¶ROCæ›²çº¿\n",
    "    me.plot_roc_curve(y_val, y_val_proba[:, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 é¢„æµ‹ç»“æœå¯è§†åŒ–ï¼ˆå›å½’é—®é¢˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if problem_type == 'regression':\n",
    "    # ç»˜åˆ¶é¢„æµ‹vså®é™…\n",
    "    me.plot_regression_results(y_val, y_val_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°\n",
    "\n",
    "**æ³¨æ„**: æµ‹è¯•é›†åªåœ¨æœ€åè¯„ä¼°ä¸€æ¬¡ï¼Œé¿å…è¿‡æ‹Ÿåˆåˆ°æµ‹è¯•é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "if problem_type == 'classification':\n",
    "    y_test_proba = pipeline.predict_proba(X_test)\n",
    "    \n",
    "    # åˆ†ç±»è¯„ä¼°\n",
    "    print(\"=\"*60)\n",
    "    print(f\"æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼° - {pipeline.best_model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_metrics = me.evaluate_classification(\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "        y_test_proba[:, 1] if y_test_proba.shape[1] == 2 else None,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # æ··æ·†çŸ©é˜µ\n",
    "    me.plot_confusion_matrix(y_test, y_test_pred)\n",
    "    plt.show()\n",
    "    \n",
    "else:  # regression\n",
    "    # å›å½’è¯„ä¼°\n",
    "    print(\"=\"*60)\n",
    "    print(f\"æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼° - {pipeline.best_model_name}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_metrics = me.evaluate_regression(\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # é¢„æµ‹ç»“æœå¯è§†åŒ–\n",
    "    me.plot_regression_results(y_test, y_test_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. æ€§èƒ½æ€»ç»“\n",
    "\n",
    "å¯¹æ¯”è®­ç»ƒã€éªŒè¯ã€æµ‹è¯•ä¸‰ä¸ªé›†åˆçš„æ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æ±‡æ€»æ€§èƒ½æŒ‡æ ‡\nif problem_type == 'classification':\n    # è·å–è®­ç»ƒé›†æ€§èƒ½ï¼ˆäº¤å‰éªŒè¯ï¼‰\n    train_score = pipeline.models[pipeline.best_model_name]['mean_score']\n    \n    summary = pd.DataFrame({\n        'æ•°æ®é›†': ['è®­ç»ƒé›†(CV)', 'éªŒè¯é›†', 'æµ‹è¯•é›†'],\n        'Accuracy': [\n            train_score,\n            val_metrics.get('accuracy', None),\n            test_metrics.get('accuracy', None)\n        ],\n        'Precision': [\n            None,\n            val_metrics.get('precision', None),\n            test_metrics.get('precision', None)\n        ],\n        'Recall': [\n            None,\n            val_metrics.get('recall', None),\n            test_metrics.get('recall', None)\n        ],\n        'F1-Score': [\n            None,\n            val_metrics.get('f1', None),\n            test_metrics.get('f1', None)\n        ]\n    })\nelse:  # regression\n    train_score = pipeline.models[pipeline.best_model_name]['mean_score']\n    \n    summary = pd.DataFrame({\n        'æ•°æ®é›†': ['è®­ç»ƒé›†(CV)', 'éªŒè¯é›†', 'æµ‹è¯•é›†'],\n        'MSE': [\n            -train_score,  # æ³¨æ„ï¼šsklearnçš„neg_mean_squared_error\n            val_metrics.get('mse', None),\n            test_metrics.get('mse', None)\n        ],\n        'RMSE': [\n            np.sqrt(-train_score),\n            val_metrics.get('rmse', None),\n            test_metrics.get('rmse', None)\n        ],\n        'MAE': [\n            None,\n            val_metrics.get('mae', None),\n            test_metrics.get('mae', None)\n        ],\n        'RÂ²': [\n            None,\n            val_metrics.get('r2', None),\n            test_metrics.get('r2', None)\n        ]\n    })\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\"Phase 2 æ€§èƒ½æ€»ç»“ - {pipeline.best_model_name}\")\nprint(\"=\"*60)\nprint(summary.to_string(index=False))\nprint(\"\\næ³¨: CV = 5æŠ˜äº¤å‰éªŒè¯\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Phase 2 æ€»ç»“ä¸å»ºè®®\n",
    "\n",
    "### 9.1 å½“å‰åŸºçº¿æ€§èƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*60)\nprint(\"ğŸ“Š Phase 2 æ€»ç»“\")\nprint(\"=\"*60)\n\nprint(f\"\\nâœ… æœ€ä½³åŸºçº¿æ¨¡å‹: {pipeline.best_model_name}\")\nprint(f\"\\nğŸ“ˆ æµ‹è¯•é›†æ€§èƒ½:\")\nif problem_type == 'classification':\n    print(f\"   - Accuracy:  {test_metrics['accuracy']:.4f}\")\n    print(f\"   - Precision: {test_metrics['precision']:.4f}\")\n    print(f\"   - Recall:    {test_metrics['recall']:.4f}\")\n    print(f\"   - F1-Score:  {test_metrics['f1']:.4f}\")\nelse:\n    print(f\"   - RMSE:      {test_metrics['rmse']:.4f}\")\n    print(f\"   - MAE:       {test_metrics['mae']:.4f}\")\n    print(f\"   - RÂ² Score:  {test_metrics['r2']:.4f}\")\n\nprint(f\"\\nğŸ“‹ æ•°æ®é›†ä¿¡æ¯:\")\nprint(f\"   - è®­ç»ƒé›†: {X_train.shape[0]} æ ·æœ¬\")\nprint(f\"   - éªŒè¯é›†: {X_val.shape[0]} æ ·æœ¬\")\nprint(f\"   - æµ‹è¯•é›†: {X_test.shape[0]} æ ·æœ¬\")\nprint(f\"   - ç‰¹å¾æ•°: {X_train.shape[1]} ä¸ª\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 åç»­ä¼˜åŒ–æ–¹å‘\n",
    "\n",
    "æ ¹æ®Phase 2çš„åŸºçº¿ç»“æœï¼Œä»¥ä¸‹æ˜¯**Phase 3: Supervised Solution**çš„ä¼˜åŒ–æ–¹å‘ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ Phase 3 ä¼˜åŒ–å»ºè®®\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "optimization_suggestions = [\n",
    "    \"1. ç‰¹å¾å·¥ç¨‹\",\n",
    "    \"   - åˆ›å»ºäº¤äº’ç‰¹å¾ï¼ˆç‰¹å¾ç»„åˆï¼‰\",\n",
    "    \"   - å¤šé¡¹å¼ç‰¹å¾ï¼ˆéçº¿æ€§å…³ç³»ï¼‰\",\n",
    "    \"   - ç‰¹å¾é€‰æ‹©ï¼ˆå»é™¤å†—ä½™ç‰¹å¾ï¼‰\",\n",
    "    \"   - é¢†åŸŸçŸ¥è¯†é©±åŠ¨çš„ç‰¹å¾æ„é€ \",\n",
    "    \"\",\n",
    "    \"2. æ•°æ®é¢„å¤„ç†ä¼˜åŒ–\",\n",
    "    \"   - é«˜çº§ç¼ºå¤±å€¼å¡«å……ï¼ˆKNNã€è¿­ä»£å¡«å……ï¼‰\",\n",
    "    \"   - é«˜çº§ç¼–ç ï¼ˆTarget Encodingã€Frequency Encodingï¼‰\",\n",
    "    \"   - å¼‚å¸¸å€¼å¤„ç†ï¼ˆWinsorizationã€ç¦»ç¾¤ç‚¹ç§»é™¤ï¼‰\",\n",
    "    \"   - ä¸å¹³è¡¡æ•°æ®å¤„ç†ï¼ˆSMOTEã€ç±»åˆ«æƒé‡ï¼‰\",\n",
    "    \"\",\n",
    "    \"3. æ¨¡å‹ä¼˜åŒ–\",\n",
    "    f\"   - è¶…å‚æ•°è°ƒä¼˜ï¼ˆ{pipeline.best_model_name}ï¼‰\",\n",
    "    \"   - æ¨¡å‹é›†æˆï¼ˆVotingã€Stackingï¼‰\",\n",
    "    \"   - å°è¯•æ›´å¤šç®—æ³•ï¼ˆç¥ç»ç½‘ç»œã€SVMç­‰ï¼‰\",\n",
    "    \"\",\n",
    "    \"4. æ¨¡å‹è¯Šæ–­\",\n",
    "    \"   - å­¦ä¹ æ›²çº¿åˆ†æï¼ˆæ˜¯å¦è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆï¼‰\",\n",
    "    \"   - é”™è¯¯æ¡ˆä¾‹åˆ†æï¼ˆå“ªäº›æ ·æœ¬é¢„æµ‹é”™è¯¯ï¼‰\",\n",
    "    \"   - ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå“ªäº›ç‰¹å¾æœ€æœ‰ç”¨ï¼‰\",\n",
    "]\n",
    "\n",
    "for suggestion in optimization_suggestions:\n",
    "    print(suggestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Phase 2 æ£€æŸ¥æ¸…å•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Phase 2 å®Œæˆæ£€æŸ¥æ¸…å•\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checklist = [\n",
    "    \"âœ… æ•°æ®åŠ è½½æˆåŠŸ\",\n",
    "    \"âœ… å¿«é€Ÿé¢„å¤„ç†å®Œæˆï¼ˆæ— ç¼ºå¤±å€¼ã€æ— é‡å¤è¡Œï¼‰\",\n",
    "    \"âœ… æ•°æ®é›†æ­£ç¡®åˆ’åˆ†ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰\",\n",
    "    \"âœ… è®­ç»ƒäº†å¤šä¸ªåŸºçº¿æ¨¡å‹ï¼ˆâ‰¥3ä¸ªï¼‰\",\n",
    "    \"âœ… æ¨¡å‹æ€§èƒ½å¯¹æ¯”å®Œæˆ\",\n",
    "    \"âœ… é€‰æ‹©äº†æœ€ä½³åŸºçº¿æ¨¡å‹\",\n",
    "    \"âœ… éªŒè¯é›†è¯„ä¼°å®Œæˆ\",\n",
    "    \"âœ… æµ‹è¯•é›†æœ€ç»ˆè¯„ä¼°å®Œæˆ\",\n",
    "    \"âœ… æ€§èƒ½å¯è§†åŒ–å®Œæˆ\",\n",
    "    \"âœ… Phase 3ä¼˜åŒ–æ–¹å‘æ˜ç¡®\"\n",
    "]\n",
    "\n",
    "for item in checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ Phase 2: Quick Baseline å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nä¸‹ä¸€æ­¥: å‰å¾€ phase3_supervised_solution.ipynb è¿›è¡Œæ·±åº¦ä¼˜åŒ–\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. ä¿å­˜æ¨¡å‹å’Œç»“æœï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "# import joblib\n",
    "# model_path = Path('models/phase2_baseline_model.pkl')\n",
    "# model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# joblib.dump(pipeline.best_model, model_path)\n",
    "# print(f\"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}\")\n",
    "\n",
    "# ä¿å­˜æ€§èƒ½æ€»ç»“\n",
    "# results_path = Path('results/phase2_baseline_results.csv')\n",
    "# results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# summary.to_csv(results_path, index=False)\n",
    "# print(f\"âœ… ç»“æœå·²ä¿å­˜åˆ°: {results_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}