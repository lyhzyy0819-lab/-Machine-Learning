{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Unsupervised Insightsï¼ˆæ— ç›‘ç£å­¦ä¹ æ´å¯Ÿï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ æœ¬é˜¶æ®µç›®æ ‡\n",
    "\n",
    "é€šè¿‡æ— ç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œä»æ•°æ®ä¸­**å‘ç°éšè—æ¨¡å¼ã€è¯†åˆ«å¼‚å¸¸ç‚¹ã€æå–æ–°ç‰¹å¾**ï¼Œä¸ºç›‘ç£å­¦ä¹ æä¾›æ–°çš„è§†è§’å’Œæ´å¯Ÿã€‚\n",
    "\n",
    "### æ ¸å¿ƒä»»åŠ¡\n",
    "\n",
    "1. âœ… **èšç±»åˆ†æ**ï¼šå‘ç°æ•°æ®ä¸­çš„è‡ªç„¶åˆ†ç»„\n",
    "   - K-Meansèšç±»\n",
    "   - DBSCANï¼ˆåŸºäºå¯†åº¦çš„èšç±»ï¼‰\n",
    "   - å±‚æ¬¡èšç±»\n",
    "2. âœ… **é™ç»´å¯è§†åŒ–**ï¼šåœ¨2D/3Dç©ºé—´ä¸­ç†è§£æ•°æ®ç»“æ„\n",
    "   - PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰\n",
    "   - t-SNEï¼ˆéçº¿æ€§é™ç»´ï¼‰\n",
    "3. âœ… **å¼‚å¸¸æ£€æµ‹**ï¼šè¯†åˆ«å¼‚å¸¸æ ·æœ¬å’Œç¦»ç¾¤ç‚¹\n",
    "   - Isolation Forest\n",
    "   - Local Outlier Factor (LOF)\n",
    "4. âœ… **ç‰¹å¾æå–**ï¼šä»æ— ç›‘ç£å­¦ä¹ ä¸­æå–æ–°ç‰¹å¾\n",
    "   - èšç±»æ ‡ç­¾ä½œä¸ºç‰¹å¾\n",
    "   - å¼‚å¸¸åˆ†æ•°ä½œä¸ºç‰¹å¾\n",
    "5. âœ… **æ´å¯Ÿæ•´åˆ**ï¼šå°†æ— ç›‘ç£å­¦ä¹ çš„å‘ç°ä¸ç›‘ç£å­¦ä¹ ç»“åˆ\n",
    "\n",
    "### æ–¹æ³•è®º\n",
    "\n",
    "- **æ¢ç´¢æ€§åˆ†æ**ï¼šä¸ä¾èµ–æ ‡ç­¾ï¼Œå‘ç°æ•°æ®å†…åœ¨ç»“æ„\n",
    "- **å¤šç®—æ³•å¯¹æ¯”**ï¼šå°è¯•ä¸åŒç®—æ³•ï¼Œé€‰æ‹©æœ€ä½³æ–¹æ³•\n",
    "- **å¯è§†åŒ–é©±åŠ¨**ï¼šé€šè¿‡å¯è§†åŒ–ç†è§£èšç±»å’Œé™ç»´ç»“æœ\n",
    "- **ç›‘ç£æ•´åˆ**ï¼šå°†æ— ç›‘ç£æ´å¯Ÿåé¦ˆåˆ°ç›‘ç£å­¦ä¹ \n",
    "\n",
    "---\n",
    "\n",
    "## é¢„æœŸæ—¶é—´\n",
    "\n",
    "â±ï¸ **20-60åˆ†é’Ÿ**ï¼ˆå–å†³äºæ•°æ®é›†å¤§å°ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# å¯¼å…¥æœ¬é¡¹ç›®çš„æ¨¡å—\n",
    "from src import data_preprocessing as dp\n",
    "from src import unsupervised_pipeline as up\n",
    "from src import supervised_pipeline as sp\n",
    "from src import model_evaluation as me\n",
    "from src import visualization as viz\n",
    "\n",
    "# è®¾ç½®\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# éšæœºç§å­\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆ\")\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†\n",
    "\n",
    "ä½¿ç”¨ä¸Phase 2-3ç›¸åŒçš„æ•°æ®ï¼Œä¿æŒä¸€è‡´æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "df = sns.load_dataset('titanic')\n",
    "target_col = 'survived'\n",
    "\n",
    "print(f\"æ•°æ®å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"ç›®æ ‡å˜é‡: {target_col}\")\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿«é€Ÿé¢„å¤„ç†ï¼ˆä¸Phase 2ç›¸åŒçš„æ–¹æ³•ï¼‰\n",
    "print(\"=\"*60)\n",
    "print(\"æ•°æ®é¢„å¤„ç†\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X, y = dp.quick_preprocess(\n",
    "    df.copy(),\n",
    "    target_col=target_col,\n",
    "    drop_missing_threshold=0.5,\n",
    "    handle_categorical=True,\n",
    "    scale_features=True\n",
    ")\n",
    "\n",
    "print(f\"\\nå¤„ç†åç‰¹å¾æ•°: {X.shape[1]}\")\n",
    "print(f\"å¤„ç†åæ ·æœ¬æ•°: {X.shape[0]}\")\n",
    "\n",
    "# ä¿å­˜ç‰¹å¾åç§°\n",
    "feature_names = X.columns.tolist()\n",
    "print(f\"\\nç‰¹å¾åˆ—è¡¨ï¼ˆå‰10ä¸ªï¼‰: {feature_names[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. èšç±»åˆ†æ\n",
    "\n",
    "### 3.1 K-Means èšç±»\n",
    "\n",
    "ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™å’Œè½®å»“ç³»æ•°è‡ªåŠ¨ç¡®å®šæœ€ä½³èšç±»æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Meansèšç±»ï¼ˆè‡ªåŠ¨ç¡®å®šKå€¼ï¼‰\n",
    "print(\"=\"*60)\n",
    "print(\"K-Means èšç±»åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "kmeans_pipeline = up.ClusteringPipeline(\n",
    "    method='kmeans',\n",
    "    n_clusters=None,  # è‡ªåŠ¨ç¡®å®š\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "kmeans_labels = kmeans_pipeline.fit_predict(X)\n",
    "\n",
    "# ä¿å­˜èšç±»æ ‡ç­¾\n",
    "kmeans_k = kmeans_pipeline.n_clusters\n",
    "print(f\"\\næœ€ä½³Kå€¼: {kmeans_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æèšç±»ç»“æœä¸ç›®æ ‡å˜é‡çš„å…³ç³»\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"K-Meansèšç±» vs å®é™…æ ‡ç­¾ï¼ˆsurvivedï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cluster_analysis = pd.DataFrame({\n",
    "    'cluster': kmeans_labels,\n",
    "    'survived': y\n",
    "})\n",
    "\n",
    "# äº¤å‰è¡¨\n",
    "crosstab = pd.crosstab(\n",
    "    cluster_analysis['cluster'],\n",
    "    cluster_analysis['survived'],\n",
    "    normalize='index'\n",
    ")\n",
    "\n",
    "print(\"\\nå„èšç±»ä¸­çš„ç”Ÿå­˜ç‡:\")\n",
    "print(crosstab)\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "crosstab.plot(kind='bar', stacked=False, figsize=(10, 6), colormap='viridis')\n",
    "plt.title('K-Meansèšç±» vs ç”Ÿå­˜ç‡')\n",
    "plt.xlabel('èšç±»æ ‡ç­¾')\n",
    "plt.ylabel('æ¯”ä¾‹')\n",
    "plt.legend(['æœªç”Ÿå­˜', 'ç”Ÿå­˜'])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# å‘ç°æ´å¯Ÿ\n",
    "print(\"\\nğŸ’¡ æ´å¯Ÿ:\")\n",
    "for cluster_id in range(kmeans_k):\n",
    "    survival_rate = crosstab.loc[cluster_id, 1] if 1 in crosstab.columns else 0\n",
    "    count = (kmeans_labels == cluster_id).sum()\n",
    "    print(f\"  èšç±» {cluster_id}: {count}ä¸ªæ ·æœ¬, ç”Ÿå­˜ç‡ {survival_rate:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 DBSCAN èšç±»ï¼ˆåŸºäºå¯†åº¦ï¼‰\n",
    "\n",
    "DBSCANå¯ä»¥è‡ªåŠ¨å‘ç°ä»»æ„å½¢çŠ¶çš„ç°‡ï¼Œå¹¶è¯†åˆ«å™ªå£°ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCANèšç±»\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DBSCAN èšç±»åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dbscan_pipeline = up.ClusteringPipeline(\n",
    "    method='dbscan',\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "dbscan_labels = dbscan_pipeline.fit_predict(X)\n",
    "\n",
    "# ç»Ÿè®¡å™ªå£°ç‚¹\n",
    "n_noise = (dbscan_labels == -1).sum()\n",
    "n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "\n",
    "print(f\"\\nå‘ç° {n_clusters} ä¸ªèšç±»\")\n",
    "print(f\"å™ªå£°ç‚¹æ•°é‡: {n_noise} ({n_noise/len(dbscan_labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 å±‚æ¬¡èšç±»\n",
    "\n",
    "å±‚æ¬¡èšç±»æ„å»ºèšç±»æ ‘ï¼Œå¯ä»¥è§‚å¯Ÿä¸åŒå±‚æ¬¡çš„åˆ†ç»„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å±‚æ¬¡èšç±»\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å±‚æ¬¡èšç±»åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "hierarchical_pipeline = up.ClusteringPipeline(\n",
    "    method='hierarchical',\n",
    "    n_clusters=kmeans_k,  # ä½¿ç”¨ä¸K-Meansç›¸åŒçš„èšç±»æ•°\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "hierarchical_labels = hierarchical_pipeline.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. é™ç»´ä¸å¯è§†åŒ–\n",
    "\n",
    "### 4.1 PCAé™ç»´\n",
    "\n",
    "PCAæ˜¯çº¿æ€§é™ç»´æ–¹æ³•ï¼Œä¿ç•™æœ€å¤§æ–¹å·®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAé™ç»´åˆ°2D\n",
    "print(\"=\"*60)\n",
    "print(\"PCA é™ç»´åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pca_pipeline = up.DimensionReductionPipeline(\n",
    "    method='pca',\n",
    "    n_components=2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_pca = pca_pipeline.fit_transform(X)\n",
    "\n",
    "print(f\"\\né™ç»´åå½¢çŠ¶: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–PCAç»“æœï¼ˆæŒ‰çœŸå®æ ‡ç­¾ç€è‰²ï¼‰\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦å›¾ï¼šæŒ‰çœŸå®æ ‡ç­¾ç€è‰²\n",
    "scatter1 = axes[0].scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    c=y,\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.6,\n",
    "    edgecolors='k',\n",
    "    s=50\n",
    ")\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('PCAé™ç»´ - æŒ‰å®é™…æ ‡ç­¾ï¼ˆSurvivedï¼‰ç€è‰²')\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Survived')\n",
    "\n",
    "# å³å›¾ï¼šæŒ‰K-Meansèšç±»ç€è‰²\n",
    "scatter2 = axes[1].scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    c=kmeans_labels,\n",
    "    cmap='tab10',\n",
    "    alpha=0.6,\n",
    "    edgecolors='k',\n",
    "    s=50\n",
    ")\n",
    "axes[1].set_xlabel('PC1')\n",
    "axes[1].set_ylabel('PC2')\n",
    "axes[1].set_title('PCAé™ç»´ - æŒ‰K-Meansèšç±»ç€è‰²')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ è§‚å¯Ÿ: å¯¹æ¯”ä¸¤å›¾ï¼Œçœ‹èšç±»æ˜¯å¦ä¸çœŸå®æ ‡ç­¾å¯¹åº”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 t-SNEé™ç»´\n",
    "\n",
    "t-SNEæ˜¯éçº¿æ€§é™ç»´æ–¹æ³•ï¼Œå–„äºä¿ç•™å±€éƒ¨ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNEé™ç»´\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"t-SNE é™ç»´åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "print(\"â³ t-SNEè®¡ç®—è¾ƒæ…¢ï¼Œè¯·ç¨å€™...\")\n",
    "\n",
    "tsne_pipeline = up.DimensionReductionPipeline(\n",
    "    method='tsne',\n",
    "    n_components=2,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "X_tsne = tsne_pipeline.fit_transform(X)\n",
    "\n",
    "print(f\"\\né™ç»´åå½¢çŠ¶: {X_tsne.shape}\")\n",
    "print(\"âœ… t-SNEå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–t-SNEç»“æœ\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦å›¾ï¼šæŒ‰çœŸå®æ ‡ç­¾ç€è‰²\n",
    "scatter1 = axes[0].scatter(\n",
    "    X_tsne[:, 0],\n",
    "    X_tsne[:, 1],\n",
    "    c=y,\n",
    "    cmap='RdYlGn',\n",
    "    alpha=0.6,\n",
    "    edgecolors='k',\n",
    "    s=50\n",
    ")\n",
    "axes[0].set_xlabel('t-SNE 1')\n",
    "axes[0].set_ylabel('t-SNE 2')\n",
    "axes[0].set_title('t-SNEé™ç»´ - æŒ‰å®é™…æ ‡ç­¾ï¼ˆSurvivedï¼‰ç€è‰²')\n",
    "axes[0].grid(alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Survived')\n",
    "\n",
    "# å³å›¾ï¼šæŒ‰K-Meansèšç±»ç€è‰²\n",
    "scatter2 = axes[1].scatter(\n",
    "    X_tsne[:, 0],\n",
    "    X_tsne[:, 1],\n",
    "    c=kmeans_labels,\n",
    "    cmap='tab10',\n",
    "    alpha=0.6,\n",
    "    edgecolors='k',\n",
    "    s=50\n",
    ")\n",
    "axes[1].set_xlabel('t-SNE 1')\n",
    "axes[1].set_ylabel('t-SNE 2')\n",
    "axes[1].set_title('t-SNEé™ç»´ - æŒ‰K-Meansèšç±»ç€è‰²')\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ å¯¹æ¯”: t-SNE vs PCA\")\n",
    "print(\"  - PCA: çº¿æ€§é™ç»´ï¼Œä¿ç•™å…¨å±€ç»“æ„\")\n",
    "print(\"  - t-SNE: éçº¿æ€§é™ç»´ï¼Œä¿ç•™å±€éƒ¨ç»“æ„ï¼Œç°‡æ›´æ˜æ˜¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. å¼‚å¸¸æ£€æµ‹\n",
    "\n",
    "### 5.1 Isolation Forest å¼‚å¸¸æ£€æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forestå¼‚å¸¸æ£€æµ‹\n",
    "print(\"=\"*60)\n",
    "print(\"Isolation Forest å¼‚å¸¸æ£€æµ‹\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "iforest_pipeline = up.AnomalyDetectionPipeline(\n",
    "    method='isolation_forest',\n",
    "    contamination=0.1,  # å‡è®¾10%çš„æ•°æ®æ˜¯å¼‚å¸¸\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "iforest_predictions = iforest_pipeline.fit_predict(X)\n",
    "\n",
    "# è·å–å¼‚å¸¸åˆ†æ•°\n",
    "iforest_scores = iforest_pipeline.get_anomaly_scores(X)\n",
    "\n",
    "# æ ‡è®°å¼‚å¸¸ç‚¹\n",
    "is_anomaly_iforest = iforest_predictions == -1\n",
    "\n",
    "print(f\"\\nå¼‚å¸¸æ ·æœ¬ç´¢å¼•ï¼ˆå‰10ä¸ªï¼‰: {np.where(is_anomaly_iforest)[0][:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å¼‚å¸¸ç‚¹ï¼ˆåœ¨PCAé™ç»´ç©ºé—´ä¸­ï¼‰\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦å›¾ï¼šPCAç©ºé—´ä¸­çš„å¼‚å¸¸ç‚¹\n",
    "axes[0].scatter(\n",
    "    X_pca[~is_anomaly_iforest, 0],\n",
    "    X_pca[~is_anomaly_iforest, 1],\n",
    "    c='blue',\n",
    "    alpha=0.5,\n",
    "    label='æ­£å¸¸',\n",
    "    s=30\n",
    ")\n",
    "axes[0].scatter(\n",
    "    X_pca[is_anomaly_iforest, 0],\n",
    "    X_pca[is_anomaly_iforest, 1],\n",
    "    c='red',\n",
    "    alpha=0.8,\n",
    "    label='å¼‚å¸¸',\n",
    "    s=100,\n",
    "    marker='x',\n",
    "    linewidths=2\n",
    ")\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "axes[0].set_title('Isolation Forest - PCAç©ºé—´ä¸­çš„å¼‚å¸¸ç‚¹')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# å³å›¾ï¼šå¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ\n",
    "axes[1].hist(iforest_scores[~is_anomaly_iforest], bins=50, alpha=0.6, label='æ­£å¸¸', color='blue')\n",
    "axes[1].hist(iforest_scores[is_anomaly_iforest], bins=20, alpha=0.6, label='å¼‚å¸¸', color='red')\n",
    "axes[1].set_xlabel('å¼‚å¸¸åˆ†æ•°')\n",
    "axes[1].set_ylabel('æ ·æœ¬æ•°')\n",
    "axes[1].set_title('å¼‚å¸¸åˆ†æ•°åˆ†å¸ƒ')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Local Outlier Factor (LOF) å¼‚å¸¸æ£€æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOFå¼‚å¸¸æ£€æµ‹\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOF (Local Outlier Factor) å¼‚å¸¸æ£€æµ‹\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lof_pipeline = up.AnomalyDetectionPipeline(\n",
    "    method='lof',\n",
    "    contamination=0.1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lof_predictions = lof_pipeline.fit_predict(X)\n",
    "\n",
    "is_anomaly_lof = lof_predictions == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”ä¸¤ç§å¼‚å¸¸æ£€æµ‹æ–¹æ³•\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¼‚å¸¸æ£€æµ‹æ–¹æ³•å¯¹æ¯”\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Isolation Forest': is_anomaly_iforest.astype(int),\n",
    "    'LOF': is_anomaly_lof.astype(int)\n",
    "})\n",
    "\n",
    "# äº¤å‰è¡¨\n",
    "crosstab_anomaly = pd.crosstab(\n",
    "    comparison['Isolation Forest'],\n",
    "    comparison['LOF'],\n",
    "    rownames=['IForest'],\n",
    "    colnames=['LOF']\n",
    ")\n",
    "\n",
    "print(\"\\nä¸¤ç§æ–¹æ³•æ£€æµ‹ç»“æœå¯¹æ¯”ï¼ˆ0=æ­£å¸¸, 1=å¼‚å¸¸ï¼‰:\")\n",
    "print(crosstab_anomaly)\n",
    "\n",
    "# è®¡ç®—ä¸€è‡´æ€§\n",
    "agreement = (is_anomaly_iforest == is_anomaly_lof).sum() / len(X) * 100\n",
    "both_anomaly = (is_anomaly_iforest & is_anomaly_lof).sum()\n",
    "\n",
    "print(f\"\\nä¸¤ç§æ–¹æ³•ä¸€è‡´æ€§: {agreement:.1f}%\")\n",
    "print(f\"ä¸¤ç§æ–¹æ³•éƒ½è®¤ä¸ºæ˜¯å¼‚å¸¸çš„æ ·æœ¬æ•°: {both_anomaly}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 å¼‚å¸¸ç‚¹åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå¼‚å¸¸ç‚¹çš„ç‰¹å¾\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"å¼‚å¸¸ç‚¹ç‰¹å¾åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# é€‰æ‹©ä¸¤ç§æ–¹æ³•éƒ½è®¤ä¸ºæ˜¯å¼‚å¸¸çš„ç‚¹\n",
    "strong_anomalies = is_anomaly_iforest & is_anomaly_lof\n",
    "\n",
    "if strong_anomalies.sum() > 0:\n",
    "    print(f\"\\nå¼ºå¼‚å¸¸ç‚¹æ•°é‡: {strong_anomalies.sum()}\")\n",
    "    \n",
    "    # æŸ¥çœ‹è¿™äº›å¼‚å¸¸ç‚¹åœ¨åŸå§‹æ•°æ®ä¸­çš„æƒ…å†µ\n",
    "    anomaly_df = df.iloc[np.where(strong_anomalies)[0]]\n",
    "    \n",
    "    print(\"\\nå¼‚å¸¸ç‚¹æ ·æœ¬ï¼ˆå‰5ä¸ªï¼‰:\")\n",
    "    print(anomaly_df.head())\n",
    "    \n",
    "    # å¼‚å¸¸ç‚¹çš„ç›®æ ‡å˜é‡åˆ†å¸ƒ\n",
    "    if target_col in anomaly_df.columns:\n",
    "        print(f\"\\nå¼‚å¸¸ç‚¹ä¸­çš„ç”Ÿå­˜ç‡: {anomaly_df[target_col].mean():.2%}\")\n",
    "        print(f\"å…¨ä½“æ•°æ®çš„ç”Ÿå­˜ç‡: {df[target_col].mean():.2%}\")\n",
    "else:\n",
    "    print(\"\\næ²¡æœ‰ä¸¤ç§æ–¹æ³•éƒ½è®¤ä¸ºæ˜¯å¼‚å¸¸çš„ç‚¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. æ— ç›‘ç£å­¦ä¹ ç‰¹å¾æå–\n",
    "\n",
    "å°†æ— ç›‘ç£å­¦ä¹ çš„å‘ç°è½¬åŒ–ä¸ºæ–°ç‰¹å¾ï¼Œç”¨äºç›‘ç£å­¦ä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ— ç›‘ç£å­¦ä¹ ç‰¹å¾\n",
    "print(\"=\"*60)\n",
    "print(\"ä»æ— ç›‘ç£å­¦ä¹ ä¸­æå–æ–°ç‰¹å¾\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# åŸå§‹ç‰¹å¾\n",
    "X_enhanced = X.copy()\n",
    "\n",
    "# 1. æ·»åŠ èšç±»æ ‡ç­¾ä½œä¸ºç‰¹å¾\n",
    "X_enhanced['cluster_kmeans'] = kmeans_labels\n",
    "X_enhanced['cluster_hierarchical'] = hierarchical_labels\n",
    "\n",
    "# 2. æ·»åŠ å¼‚å¸¸åˆ†æ•°ä½œä¸ºç‰¹å¾\n",
    "X_enhanced['anomaly_score_iforest'] = iforest_scores\n",
    "\n",
    "# 3. æ·»åŠ PCAä¸»æˆåˆ†ä½œä¸ºç‰¹å¾\n",
    "X_enhanced['pca_1'] = X_pca[:, 0]\n",
    "X_enhanced['pca_2'] = X_pca[:, 1]\n",
    "\n",
    "# 4. æ·»åŠ å¼‚å¸¸æ ‡è®°\n",
    "X_enhanced['is_anomaly'] = is_anomaly_iforest.astype(int)\n",
    "\n",
    "print(f\"\\nåŸå§‹ç‰¹å¾æ•°: {X.shape[1]}\")\n",
    "print(f\"å¢å¼ºåç‰¹å¾æ•°: {X_enhanced.shape[1]}\")\n",
    "print(f\"æ–°å¢ç‰¹å¾æ•°: {X_enhanced.shape[1] - X.shape[1]}\")\n",
    "\n",
    "print(\"\\næ–°å¢ç‰¹å¾åˆ—è¡¨:\")\n",
    "new_features = [col for col in X_enhanced.columns if col not in X.columns]\n",
    "for feat in new_features:\n",
    "    print(f\"  - {feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. æ— ç›‘ç£ç‰¹å¾å¯¹ç›‘ç£å­¦ä¹ çš„å½±å“\n",
    "\n",
    "è¯„ä¼°æ·»åŠ æ— ç›‘ç£å­¦ä¹ ç‰¹å¾åï¼Œç›‘ç£å­¦ä¹ æ€§èƒ½æ˜¯å¦æå‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ’åˆ†æ•°æ®é›†\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# åŸºçº¿ï¼šä¸åŒ…å«æ— ç›‘ç£ç‰¹å¾\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# å¢å¼ºï¼šåŒ…å«æ— ç›‘ç£ç‰¹å¾\n",
    "X_train_enhanced, X_test_enhanced, _, _ = train_test_split(\n",
    "    X_enhanced, y,\n",
    "    test_size=0.3,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"æ•°æ®é›†åˆ’åˆ†:\")\n",
    "print(f\"  åŸºçº¿è®­ç»ƒé›†: {X_train_base.shape}\")\n",
    "print(f\"  å¢å¼ºè®­ç»ƒé›†: {X_train_enhanced.shape}\")\n",
    "print(f\"  æµ‹è¯•é›†: {X_test_base.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆæ— æ— ç›‘ç£ç‰¹å¾ï¼‰\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆæ— æ— ç›‘ç£ç‰¹å¾ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model_base = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "model_base.fit(X_train_base, y_train)\n",
    "\n",
    "y_pred_base = model_base.predict(X_test_base)\n",
    "acc_base = accuracy_score(y_test, y_pred_base)\n",
    "f1_base = f1_score(y_test, y_pred_base, average='binary')\n",
    "\n",
    "print(f\"\\nåŸºçº¿æ¨¡å‹æ€§èƒ½:\")\n",
    "print(f\"  Accuracy: {acc_base:.4f}\")\n",
    "print(f\"  F1-Score: {f1_base:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒå¢å¼ºæ¨¡å‹ï¼ˆåŒ…å«æ— ç›‘ç£ç‰¹å¾ï¼‰\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è®­ç»ƒå¢å¼ºæ¨¡å‹ï¼ˆåŒ…å«æ— ç›‘ç£ç‰¹å¾ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model_enhanced = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "model_enhanced.fit(X_train_enhanced, y_train)\n",
    "\n",
    "y_pred_enhanced = model_enhanced.predict(X_test_enhanced)\n",
    "acc_enhanced = accuracy_score(y_test, y_pred_enhanced)\n",
    "f1_enhanced = f1_score(y_test, y_pred_enhanced, average='binary')\n",
    "\n",
    "print(f\"\\nå¢å¼ºæ¨¡å‹æ€§èƒ½:\")\n",
    "print(f\"  Accuracy: {acc_enhanced:.4f}\")\n",
    "print(f\"  F1-Score: {f1_enhanced:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€§èƒ½å¯¹æ¯”\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"æ— ç›‘ç£ç‰¹å¾å¯¹ç›‘ç£å­¦ä¹ çš„å½±å“\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'æ¨¡å‹': ['åŸºçº¿ï¼ˆæ— æ— ç›‘ç£ç‰¹å¾ï¼‰', 'å¢å¼ºï¼ˆå«æ— ç›‘ç£ç‰¹å¾ï¼‰'],\n",
    "    'Accuracy': [acc_base, acc_enhanced],\n",
    "    'F1-Score': [f1_base, f1_enhanced],\n",
    "    'ç‰¹å¾æ•°': [X.shape[1], X_enhanced.shape[1]]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# è®¡ç®—æå‡\n",
    "acc_improvement = (acc_enhanced - acc_base) / acc_base * 100\n",
    "f1_improvement = (f1_enhanced - f1_base) / f1_base * 100\n",
    "\n",
    "print(f\"\\nğŸ“ˆ æ€§èƒ½å˜åŒ–:\")\n",
    "print(f\"  Accuracy: {acc_improvement:+.2f}%\")\n",
    "print(f\"  F1-Score: {f1_improvement:+.2f}%\")\n",
    "\n",
    "if acc_improvement > 1:\n",
    "    print(\"\\nâœ… æ— ç›‘ç£ç‰¹å¾æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼\")\n",
    "elif acc_improvement > 0:\n",
    "    print(\"\\nâœ“  æ— ç›‘ç£ç‰¹å¾ç•¥å¾®æå‡äº†æ¨¡å‹æ€§èƒ½\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  æ— ç›‘ç£ç‰¹å¾æœªèƒ½æå‡æ€§èƒ½ï¼Œå¯èƒ½åŸå› :\")\n",
    "    print(\"   - èšç±»æœªèƒ½å‘ç°æœ‰ç”¨çš„æ¨¡å¼\")\n",
    "    print(\"   - ç‰¹å¾å†—ä½™å¯¼è‡´è¿‡æ‹Ÿåˆ\")\n",
    "    print(\"   - éœ€è¦ç‰¹å¾é€‰æ‹©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ€§èƒ½å¯¹æ¯”\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_pos = np.arange(2)\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, [acc_base, f1_base], width, label='åŸºçº¿æ¨¡å‹', color='skyblue', alpha=0.8)\n",
    "ax.bar(x_pos + width/2, [acc_enhanced, f1_enhanced], width, label='å¢å¼ºæ¨¡å‹', color='orange', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('å¾—åˆ†')\n",
    "ax.set_title('æ— ç›‘ç£ç‰¹å¾å¯¹ç›‘ç£å­¦ä¹ æ€§èƒ½çš„å½±å“')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(['Accuracy', 'F1-Score'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
    "for i, (v1, v2) in enumerate(zip([acc_base, f1_base], [acc_enhanced, f1_enhanced])):\n",
    "    ax.text(i - width/2, v1 + 0.02, f'{v1:.3f}', ha='center', fontsize=10)\n",
    "    ax.text(i + width/2, v2 + 0.02, f'{v2:.3f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå¢å¼ºæ¨¡å‹ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹æ— ç›‘ç£ç‰¹å¾çš„é‡è¦æ€§\n",
    "print(\"=\"*60)\n",
    "print(\"ç‰¹å¾é‡è¦æ€§åˆ†æ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# è·å–ç‰¹å¾é‡è¦æ€§\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_enhanced.columns,\n",
    "    'importance': model_enhanced.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# æ ‡è®°æ— ç›‘ç£ç‰¹å¾\n",
    "feature_importance['type'] = feature_importance['feature'].apply(\n",
    "    lambda x: 'Unsupervised' if x in new_features else 'Original'\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 æœ€é‡è¦ç‰¹å¾:\")\n",
    "print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "# ç»Ÿè®¡æ— ç›‘ç£ç‰¹å¾åœ¨Top 20ä¸­çš„å æ¯”\n",
    "top20 = feature_importance.head(20)\n",
    "unsup_in_top20 = (top20['type'] == 'Unsupervised').sum()\n",
    "\n",
    "print(f\"\\nğŸ’¡ æ´å¯Ÿ:\")\n",
    "print(f\"  æ— ç›‘ç£ç‰¹å¾åœ¨Top 20ä¸­çš„æ•°é‡: {unsup_in_top20}/{len(new_features)}\")\n",
    "print(f\"  æ— ç›‘ç£ç‰¹å¾å¹³å‡é‡è¦æ€§: {feature_importance[feature_importance['type']=='Unsupervised']['importance'].mean():.4f}\")\n",
    "print(f\"  åŸå§‹ç‰¹å¾å¹³å‡é‡è¦æ€§: {feature_importance[feature_importance['type']=='Original']['importance'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§\n",
    "top_features = feature_importance.head(15)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = ['orange' if t == 'Unsupervised' else 'skyblue' for t in top_features['type']]\n",
    "\n",
    "ax.barh(range(len(top_features)), top_features['importance'], color=colors, alpha=0.7)\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features['feature'])\n",
    "ax.set_xlabel('é‡è¦æ€§')\n",
    "ax.set_title('Top 15 ç‰¹å¾é‡è¦æ€§ï¼ˆæ©™è‰²=æ— ç›‘ç£ç‰¹å¾ï¼‰')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Phase 4 å…³é”®æ´å¯Ÿæ€»ç»“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š Phase 4: Unsupervised Insights æ€»ç»“\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. èšç±»åˆ†æ\")\n",
    "print(f\"   âœ… K-Meansæœ€ä½³èšç±»æ•°: {kmeans_k}\")\n",
    "print(f\"   âœ… DBSCANå‘ç°èšç±»æ•°: {n_clusters}\")\n",
    "print(f\"   âœ… DBSCANå™ªå£°ç‚¹æ¯”ä¾‹: {n_noise/len(X)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n2. é™ç»´ä¸å¯è§†åŒ–\")\n",
    "print(f\"   âœ… PCAç´¯è®¡è§£é‡Šæ–¹å·®: {pca_pipeline.model.explained_variance_ratio_.sum():.1%}\")\n",
    "print(\"   âœ… t-SNEæˆåŠŸå¯è§†åŒ–æ•°æ®åˆ†å¸ƒ\")\n",
    "\n",
    "print(\"\\n3. å¼‚å¸¸æ£€æµ‹\")\n",
    "print(f\"   âœ… Isolation Forestæ£€æµ‹å¼‚å¸¸: {is_anomaly_iforest.sum()}ä¸ª\")\n",
    "print(f\"   âœ… LOFæ£€æµ‹å¼‚å¸¸: {is_anomaly_lof.sum()}ä¸ª\")\n",
    "print(f\"   âœ… ä¸¤ç§æ–¹æ³•ä¸€è‡´æ€§: {agreement:.1f}%\")\n",
    "\n",
    "print(\"\\n4. ç‰¹å¾æå–\")\n",
    "print(f\"   âœ… ä»æ— ç›‘ç£å­¦ä¹ æå– {len(new_features)} ä¸ªæ–°ç‰¹å¾\")\n",
    "print(f\"   âœ… ç‰¹å¾æ•°é‡æå‡: {X.shape[1]} â†’ {X_enhanced.shape[1]}\")\n",
    "\n",
    "print(\"\\n5. ç›‘ç£å­¦ä¹ æ€§èƒ½å½±å“\")\n",
    "print(f\"   {'âœ…' if acc_improvement > 0 else 'âš ï¸ '} Accuracyå˜åŒ–: {acc_improvement:+.2f}%\")\n",
    "print(f\"   {'âœ…' if f1_improvement > 0 else 'âš ï¸ '} F1-Scoreå˜åŒ–: {f1_improvement:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ” å…³é”®å‘ç°\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# èšç±»æ´å¯Ÿ\n",
    "if kmeans_k <= 3:\n",
    "    insights.append(f\"æ•°æ®å¯èƒ½å­˜åœ¨ {kmeans_k} ä¸ªæ˜æ˜¾çš„è‡ªç„¶åˆ†ç»„\")\n",
    "\n",
    "# å¼‚å¸¸æ£€æµ‹æ´å¯Ÿ\n",
    "if strong_anomalies.sum() > 0:\n",
    "    insights.append(f\"å‘ç° {strong_anomalies.sum()} ä¸ªé«˜ç½®ä¿¡åº¦å¼‚å¸¸æ ·æœ¬\")\n",
    "\n",
    "# æ€§èƒ½æ´å¯Ÿ\n",
    "if acc_improvement > 2:\n",
    "    insights.append(\"æ— ç›‘ç£ç‰¹å¾æ˜¾è‘—æå‡äº†ç›‘ç£å­¦ä¹ æ€§èƒ½ï¼ˆ>2%ï¼‰\")\n",
    "elif acc_improvement > 0:\n",
    "    insights.append(\"æ— ç›‘ç£ç‰¹å¾å¯¹ç›‘ç£å­¦ä¹ æœ‰è½»å¾®å¸®åŠ©\")\n",
    "else:\n",
    "    insights.append(\"æ— ç›‘ç£ç‰¹å¾æœªèƒ½æ”¹å–„æ€§èƒ½ï¼Œå»ºè®®ç‰¹å¾é€‰æ‹©\")\n",
    "\n",
    "# ç‰¹å¾é‡è¦æ€§æ´å¯Ÿ\n",
    "if unsup_in_top20 > 0:\n",
    "    insights.append(f\"{unsup_in_top20} ä¸ªæ— ç›‘ç£ç‰¹å¾è¿›å…¥Top 20é‡è¦ç‰¹å¾\")\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"  {i}. {insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Phase 4 æ£€æŸ¥æ¸…å•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Phase 4 å®Œæˆæ£€æŸ¥æ¸…å•\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checklist = [\n",
    "    \"âœ… K-Meansèšç±»åˆ†æå®Œæˆ\",\n",
    "    \"âœ… DBSCANèšç±»åˆ†æå®Œæˆ\",\n",
    "    \"âœ… å±‚æ¬¡èšç±»åˆ†æå®Œæˆ\",\n",
    "    \"âœ… PCAé™ç»´å¯è§†åŒ–å®Œæˆ\",\n",
    "    \"âœ… t-SNEé™ç»´å¯è§†åŒ–å®Œæˆ\",\n",
    "    \"âœ… Isolation Forestå¼‚å¸¸æ£€æµ‹å®Œæˆ\",\n",
    "    \"âœ… LOFå¼‚å¸¸æ£€æµ‹å®Œæˆ\",\n",
    "    \"âœ… å¼‚å¸¸ç‚¹åˆ†æå®Œæˆ\",\n",
    "    \"âœ… æ— ç›‘ç£ç‰¹å¾æå–å®Œæˆ\",\n",
    "    \"âœ… ç›‘ç£å­¦ä¹ æ€§èƒ½å¯¹æ¯”å®Œæˆ\",\n",
    "    \"âœ… ç‰¹å¾é‡è¦æ€§åˆ†æå®Œæˆ\",\n",
    "    \"âœ… å…³é”®æ´å¯Ÿæ€»ç»“å®Œæˆ\"\n",
    "]\n",
    "\n",
    "for item in checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ Phase 4: Unsupervised Insights å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nä¸‹ä¸€æ­¥é€‰é¡¹:\")\n",
    "print(\"  1. å‰å¾€ Phase 5: æ•´åˆç›‘ç£ä¸æ— ç›‘ç£æ–¹æ³•\")\n",
    "print(\"  2. å‰å¾€ Phase 6: æœ€ç»ˆè§£å†³æ–¹æ¡ˆ\")\n",
    "print(\"  3. å›é¡¾å¹¶ä¼˜åŒ– Phase 1-4 çš„å‘ç°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. ä¿å­˜ç»“æœï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜èšç±»ç»“æœ\n",
    "# results_df = X.copy()\n",
    "# results_df['cluster_kmeans'] = kmeans_labels\n",
    "# results_df['is_anomaly'] = is_anomaly_iforest\n",
    "# results_df['target'] = y\n",
    "\n",
    "# results_path = Path('results/phase4_unsupervised_results.csv')\n",
    "# results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# results_df.to_csv(results_path, index=False)\n",
    "# print(f\"âœ… ç»“æœå·²ä¿å­˜åˆ°: {results_path}\")\n",
    "\n",
    "# ä¿å­˜å¢å¼ºç‰¹å¾\n",
    "# features_path = Path('data/processed/phase4_enhanced_features.csv')\n",
    "# features_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "# X_enhanced.to_csv(features_path, index=False)\n",
    "# print(f\"âœ… å¢å¼ºç‰¹å¾å·²ä¿å­˜åˆ°: {features_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
